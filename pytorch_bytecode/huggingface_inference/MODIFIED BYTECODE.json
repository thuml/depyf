["MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              6 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             2\n             18 STORE_FAST             620 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.MaskedLMOutput'>)\n             22 EXTENDED_ARG             2\n             24 LOAD_FAST              620 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             2\n             32 LOAD_FAST              620 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 LOAD_CONST               0 (None)\n             40 LOAD_CONST               0 (None)\n             42 LOAD_CONST               7 (('loss', 'logits', 'hidden_states', 'attentions'))\n             44 CALL_FUNCTION_KW         4\n             46 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              6 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('start_positions')\n             12 BINARY_SUBSCR\n             14 LOAD_FAST                2 (inputs)\n             16 LOAD_CONST               4 ('end_positions')\n             18 BINARY_SUBSCR\n             20 CALL_FUNCTION            3\n             22 EXTENDED_ARG             2\n             24 STORE_FAST             622 (graph_out_0)\n             26 LOAD_CONST               5 (<class 'transformers.modeling_outputs.QuestionAnsweringModelOutput'>)\n             28 EXTENDED_ARG             2\n             30 LOAD_FAST              622 (graph_out_0)\n             32 LOAD_CONST               6 (0)\n             34 BINARY_SUBSCR\n             36 EXTENDED_ARG             2\n             38 LOAD_FAST              622 (graph_out_0)\n             40 LOAD_CONST               7 (1)\n             42 BINARY_SUBSCR\n             44 EXTENDED_ARG             2\n             46 LOAD_FAST              622 (graph_out_0)\n             48 LOAD_CONST               8 (2)\n             50 BINARY_SUBSCR\n             52 LOAD_CONST               0 (None)\n             54 LOAD_CONST               0 (None)\n             56 LOAD_CONST               9 (('loss', 'start_logits', 'end_logits', 'hidden_states', 'attentions'))\n             58 CALL_FUNCTION_KW         5\n             60 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              4 (__import_contextlib)\n              2 LOAD_ATTR                5 (nullcontext)\n              4 LOAD_FAST                1 (mod)\n              6 LOAD_CONST               1 (())\n              8 LOAD_CONST               2 ('input_ids')\n             10 LOAD_FAST                2 (inputs)\n             12 LOAD_CONST               2 ('input_ids')\n             14 BINARY_SUBSCR\n             16 LOAD_CONST               3 ('labels')\n             18 LOAD_FAST                2 (inputs)\n             20 LOAD_CONST               3 ('labels')\n             22 BINARY_SUBSCR\n             24 BUILD_MAP                2\n             26 LOAD_GLOBAL              4 (__import_contextlib)\n             28 LOAD_ATTR                5 (nullcontext)\n             30 CALL_FUNCTION            0\n             32 STORE_FAST              49 (___context_manager_0_0)\n             34 LOAD_FAST               49 (___context_manager_0_0)\n             36 LOAD_METHOD              6 (__enter__)\n             38 CALL_METHOD              0\n             40 POP_TOP\n             42 SETUP_FINALLY           10 (to 64)\n\n551          44 CALL_FUNCTION_EX         1\n             46 POP_BLOCK\n             48 LOAD_FAST               49 (___context_manager_0_0)\n             50 LOAD_METHOD              7 (__exit__)\n             52 LOAD_CONST               0 (None)\n             54 DUP_TOP\n             56 DUP_TOP\n             58 CALL_METHOD              3\n             60 POP_TOP\n             62 JUMP_FORWARD             9 (to 82)\n        >>   64 NOP\n             66 LOAD_FAST               49 (___context_manager_0_0)\n             68 LOAD_METHOD              7 (__exit__)\n             70 LOAD_CONST               0 (None)\n             72 DUP_TOP\n             74 DUP_TOP\n             76 CALL_METHOD              3\n             78 POP_TOP\n             80 RERAISE                  0\n        >>   82 NOP\n             84 LOAD_GLOBAL              8 (__resume_at_22_1)\n             86 ROT_THREE\n             88 CALL_FUNCTION            2\n             90 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py line 1789 \n1789           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                2 (longformer)\n               4 LOAD_FAST                1 (input_ids)\n               6 LOAD_FAST                2 (attention_mask)\n               8 LOAD_FAST                3 (global_attention_mask)\n              10 LOAD_FAST                4 (head_mask)\n              12 LOAD_FAST                5 (token_type_ids)\n              14 LOAD_FAST                6 (position_ids)\n              16 LOAD_FAST                7 (inputs_embeds)\n              18 LOAD_FAST                9 (output_attentions)\n              20 LOAD_FAST               10 (output_hidden_states)\n              22 LOAD_FAST                0 (self)\n              24 LOAD_ATTR                0 (config)\n              26 LOAD_ATTR                1 (use_return_dict)\n              28 LOAD_CONST               2 (('attention_mask', 'global_attention_mask', 'head_mask', 'token_type_ids', 'position_ids', 'inputs_embeds', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              30 LOAD_FAST                0 (self)\n              32 LOAD_ATTR                0 (config)\n              34 LOAD_ATTR                1 (use_return_dict)\n              36 STORE_FAST              11 (return_dict)\n\n1843          38 CALL_FUNCTION_KW        10\n              40 LOAD_GLOBAL             15 (__resume_at_48_2)\n              42 ROT_TWO\n              44 LOAD_FAST                0 (self)\n              46 LOAD_FAST                8 (labels)\n              48 LOAD_FAST               11 (return_dict)\n              50 CALL_FUNCTION            4\n              52 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py line 1647 \n1647           0 LOAD_GLOBAL             24 (__compiled_fn_3)\n               2 LOAD_FAST                1 (input_ids)\n               4 CALL_FUNCTION            1\n               6 STORE_FAST              60 (graph_out_0)\n               8 LOAD_FAST                0 (self)\n              10 LOAD_ATTR               16 (encoder)\n              12 LOAD_FAST               60 (graph_out_0)\n              14 LOAD_CONST               8 (0)\n              16 BINARY_SUBSCR\n              18 LOAD_FAST               60 (graph_out_0)\n              20 LOAD_CONST              11 (1)\n              22 BINARY_SUBSCR\n              24 LOAD_FAST                4 (head_mask)\n              26 LOAD_CONST               8 (0)\n              28 LOAD_FAST                0 (self)\n              30 LOAD_ATTR                0 (config)\n              32 LOAD_ATTR                1 (output_attentions)\n              34 LOAD_FAST                0 (self)\n              36 LOAD_ATTR                0 (config)\n              38 LOAD_ATTR                2 (output_hidden_states)\n              40 LOAD_FAST               10 (return_dict)\n              42 LOAD_CONST              10 (('attention_mask', 'head_mask', 'padding_len', 'output_attentions', 'output_hidden_states', 'return_dict'))\n\n1746          44 CALL_FUNCTION_KW         7\n              46 LOAD_GLOBAL             25 (__resume_at_334_4)\n              48 ROT_TWO\n              50 LOAD_FAST                0 (self)\n              52 LOAD_FAST               10 (return_dict)\n              54 CALL_FUNCTION            3\n              56 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py line 1277 \n1277           0 LOAD_GLOBAL             16 (__compiled_fn_5)\n               2 LOAD_FAST                2 (attention_mask)\n               4 CALL_FUNCTION            1\n               6 STORE_FAST              19 (graph_out_0)\n               8 LOAD_FAST               19 (graph_out_0)\n              10 LOAD_CONST               1 (0)\n              12 BINARY_SUBSCR\n              14 LOAD_ATTR                2 (item)\n              16 LOAD_FAST               19 (graph_out_0)\n              18 LOAD_CONST               9 (1)\n              20 BINARY_SUBSCR\n              22 LOAD_FAST               19 (graph_out_0)\n              24 LOAD_CONST              10 (2)\n              26 BINARY_SUBSCR\n              28 STORE_FAST               9 (is_index_global_attn)\n              30 STORE_FAST               8 (is_index_masked)\n\n1291          32 CALL_FUNCTION            0\n              34 LOAD_CLOSURE             0 (is_global_attn)\n              36 LOAD_CLOSURE             1 (output_attentions)\n              38 LOAD_CLOSURE             2 (padding_len)\n              40 BUILD_TUPLE              3\n              42 LOAD_CONST              18 (<code object <resume in forward> at 0x7fd60125cf50, file \"/workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1291>)\n              44 LOAD_CONST              19 ('__resume_at_30_6')\n              46 MAKE_FUNCTION            8 (closure)\n              48 ROT_TWO\n              50 LOAD_FAST                0 (self)\n              52 LOAD_FAST                1 (hidden_states)\n              54 LOAD_FAST                2 (attention_mask)\n              56 LOAD_FAST                3 (head_mask)\n              58 LOAD_FAST                6 (output_hidden_states)\n              60 LOAD_FAST                7 (return_dict)\n              62 LOAD_FAST                8 (is_index_masked)\n              64 LOAD_FAST                9 (is_index_global_attn)\n              66 CALL_FUNCTION            9\n              68 RETURN_VALUE\n\n", "MODIFIED BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py line 1291 \n1291           0 LOAD_GLOBAL             18 (__compiled_fn_7)\n               2 LOAD_FAST                2 (hidden_states)\n               4 LOAD_FAST                3 (attention_mask)\n               6 LOAD_FAST                7 (is_index_masked)\n               8 CALL_FUNCTION            3\n              10 EXTENDED_ARG             6\n              12 STORE_FAST            1607 (graph_out_0)\n              14 LOAD_CONST              18 (<class 'transformers.models.longformer.modeling_longformer.LongformerBaseModelOutput'>)\n              16 EXTENDED_ARG             6\n              18 LOAD_FAST             1607 (graph_out_0)\n              20 LOAD_CONST               1 (0)\n              22 BINARY_SUBSCR\n              24 LOAD_CONST               0 (None)\n              26 LOAD_CONST               0 (None)\n              28 LOAD_CONST               0 (None)\n              30 LOAD_CONST              19 (('last_hidden_state', 'hidden_states', 'attentions', 'global_attentions'))\n              32 CALL_FUNCTION_KW         4\n              34 LOAD_FAST                0 (___stack0)\n              36 STORE_DEREF              0 (is_global_attn)\n              38 RETURN_VALUE\n\n", "MODIFIED BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py line 1843 \n1843           0 LOAD_GLOBAL             14 (__compiled_fn_8)\n               2 LOAD_FAST                0 (___stack0)\n               4 LOAD_ATTR               15 (last_hidden_state)\n               6 LOAD_FAST                2 (labels)\n               8 CALL_FUNCTION            2\n              10 STORE_FAST              32 (graph_out_0)\n              12 LOAD_CONST               7 (<class 'transformers.models.longformer.modeling_longformer.LongformerMaskedLMOutput'>)\n              14 LOAD_FAST               32 (graph_out_0)\n              16 LOAD_CONST               3 (0)\n              18 BINARY_SUBSCR\n              20 LOAD_FAST               32 (graph_out_0)\n              22 LOAD_CONST               8 (1)\n              24 BINARY_SUBSCR\n              26 LOAD_FAST                0 (___stack0)\n              28 LOAD_ATTR               10 (hidden_states)\n              30 LOAD_FAST                0 (___stack0)\n              32 LOAD_ATTR               11 (attentions)\n              34 LOAD_FAST                0 (___stack0)\n              36 LOAD_ATTR               12 (global_attentions)\n              38 LOAD_CONST               9 (('loss', 'logits', 'hidden_states', 'attentions', 'global_attentions'))\n              40 CALL_FUNCTION_KW         5\n              42 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              4 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             2\n             18 STORE_FAST             686 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.CausalLMOutputWithCrossAttentions'>)\n             22 EXTENDED_ARG             2\n             24 LOAD_FAST              686 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             2\n             32 LOAD_FAST              686 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 EXTENDED_ARG             2\n             40 LOAD_FAST              686 (graph_out_0)\n             42 LOAD_CONST               7 (2)\n             44 BINARY_SUBSCR\n             46 EXTENDED_ARG             2\n             48 LOAD_FAST              686 (graph_out_0)\n             50 LOAD_CONST               8 (3)\n             52 BINARY_SUBSCR\n             54 BUILD_TUPLE              2\n             56 EXTENDED_ARG             2\n             58 LOAD_FAST              686 (graph_out_0)\n             60 LOAD_CONST               9 (4)\n             62 BINARY_SUBSCR\n             64 EXTENDED_ARG             2\n             66 LOAD_FAST              686 (graph_out_0)\n             68 LOAD_CONST              10 (5)\n             70 BINARY_SUBSCR\n             72 BUILD_TUPLE              2\n             74 EXTENDED_ARG             2\n             76 LOAD_FAST              686 (graph_out_0)\n             78 LOAD_CONST              11 (6)\n             80 BINARY_SUBSCR\n             82 EXTENDED_ARG             2\n             84 LOAD_FAST              686 (graph_out_0)\n             86 LOAD_CONST              12 (7)\n             88 BINARY_SUBSCR\n             90 BUILD_TUPLE              2\n             92 EXTENDED_ARG             2\n             94 LOAD_FAST              686 (graph_out_0)\n             96 LOAD_CONST              13 (8)\n             98 BINARY_SUBSCR\n            100 EXTENDED_ARG             2\n            102 LOAD_FAST              686 (graph_out_0)\n            104 LOAD_CONST              14 (9)\n            106 BINARY_SUBSCR\n            108 BUILD_TUPLE              2\n            110 EXTENDED_ARG             2\n            112 LOAD_FAST              686 (graph_out_0)\n            114 LOAD_CONST              15 (10)\n            116 BINARY_SUBSCR\n            118 EXTENDED_ARG             2\n            120 LOAD_FAST              686 (graph_out_0)\n            122 LOAD_CONST              16 (11)\n            124 BINARY_SUBSCR\n            126 BUILD_TUPLE              2\n            128 EXTENDED_ARG             2\n            130 LOAD_FAST              686 (graph_out_0)\n            132 LOAD_CONST              17 (12)\n            134 BINARY_SUBSCR\n            136 EXTENDED_ARG             2\n            138 LOAD_FAST              686 (graph_out_0)\n            140 LOAD_CONST              18 (13)\n            142 BINARY_SUBSCR\n            144 BUILD_TUPLE              2\n            146 EXTENDED_ARG             2\n            148 LOAD_FAST              686 (graph_out_0)\n            150 LOAD_CONST              19 (14)\n            152 BINARY_SUBSCR\n            154 EXTENDED_ARG             2\n            156 LOAD_FAST              686 (graph_out_0)\n            158 LOAD_CONST              20 (15)\n            160 BINARY_SUBSCR\n            162 BUILD_TUPLE              2\n            164 EXTENDED_ARG             2\n            166 LOAD_FAST              686 (graph_out_0)\n            168 LOAD_CONST              21 (16)\n            170 BINARY_SUBSCR\n            172 EXTENDED_ARG             2\n            174 LOAD_FAST              686 (graph_out_0)\n            176 LOAD_CONST              22 (17)\n            178 BINARY_SUBSCR\n            180 BUILD_TUPLE              2\n            182 EXTENDED_ARG             2\n            184 LOAD_FAST              686 (graph_out_0)\n            186 LOAD_CONST              23 (18)\n            188 BINARY_SUBSCR\n            190 EXTENDED_ARG             2\n            192 LOAD_FAST              686 (graph_out_0)\n            194 LOAD_CONST              24 (19)\n            196 BINARY_SUBSCR\n            198 BUILD_TUPLE              2\n            200 EXTENDED_ARG             2\n            202 LOAD_FAST              686 (graph_out_0)\n            204 LOAD_CONST              25 (20)\n            206 BINARY_SUBSCR\n            208 EXTENDED_ARG             2\n            210 LOAD_FAST              686 (graph_out_0)\n            212 LOAD_CONST              26 (21)\n            214 BINARY_SUBSCR\n            216 BUILD_TUPLE              2\n            218 EXTENDED_ARG             2\n            220 LOAD_FAST              686 (graph_out_0)\n            222 LOAD_CONST              27 (22)\n            224 BINARY_SUBSCR\n            226 EXTENDED_ARG             2\n            228 LOAD_FAST              686 (graph_out_0)\n            230 LOAD_CONST              28 (23)\n            232 BINARY_SUBSCR\n            234 BUILD_TUPLE              2\n            236 EXTENDED_ARG             2\n            238 LOAD_FAST              686 (graph_out_0)\n            240 LOAD_CONST              29 (24)\n            242 BINARY_SUBSCR\n            244 EXTENDED_ARG             2\n            246 LOAD_FAST              686 (graph_out_0)\n            248 LOAD_CONST              30 (25)\n            250 BINARY_SUBSCR\n            252 BUILD_TUPLE              2\n            254 BUILD_TUPLE             12\n            256 LOAD_CONST               0 (None)\n            258 LOAD_CONST               0 (None)\n            260 LOAD_CONST               0 (None)\n            262 LOAD_CONST              31 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n            264 CALL_FUNCTION_KW         6\n            266 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              4 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             6\n             18 STORE_FAST            1623 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.Seq2SeqLMOutput'>)\n             22 EXTENDED_ARG             6\n             24 LOAD_FAST             1623 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             6\n             32 LOAD_FAST             1623 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 LOAD_CONST               0 (None)\n             40 LOAD_CONST               0 (None)\n             42 LOAD_CONST               0 (None)\n             44 LOAD_CONST               0 (None)\n             46 EXTENDED_ARG             6\n             48 LOAD_FAST             1623 (graph_out_0)\n             50 LOAD_CONST               7 (2)\n             52 BINARY_SUBSCR\n             54 LOAD_CONST               0 (None)\n             56 LOAD_CONST               0 (None)\n             58 LOAD_CONST               8 (('loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             60 CALL_FUNCTION_KW         9\n             62 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              2 (__import_contextlib)\n              2 LOAD_ATTR                3 (nullcontext)\n              4 LOAD_FAST                1 (mod)\n              6 LOAD_CONST               1 (())\n              8 LOAD_CONST               2 ('input_ids')\n             10 LOAD_FAST                2 (inputs)\n             12 LOAD_CONST               2 ('input_ids')\n             14 BINARY_SUBSCR\n             16 LOAD_CONST               3 ('labels')\n             18 LOAD_FAST                2 (inputs)\n             20 LOAD_CONST               3 ('labels')\n             22 BINARY_SUBSCR\n             24 BUILD_MAP                2\n             26 LOAD_GLOBAL              2 (__import_contextlib)\n             28 LOAD_ATTR                3 (nullcontext)\n             30 CALL_FUNCTION            0\n             32 STORE_FAST              13 (___context_manager_0_0)\n             34 LOAD_FAST               13 (___context_manager_0_0)\n             36 LOAD_METHOD              4 (__enter__)\n             38 CALL_METHOD              0\n             40 POP_TOP\n             42 SETUP_FINALLY           10 (to 64)\n\n551          44 CALL_FUNCTION_EX         1\n             46 POP_BLOCK\n             48 LOAD_FAST               13 (___context_manager_0_0)\n             50 LOAD_METHOD              5 (__exit__)\n             52 LOAD_CONST               0 (None)\n             54 DUP_TOP\n             56 DUP_TOP\n             58 CALL_METHOD              3\n             60 POP_TOP\n             62 JUMP_FORWARD             9 (to 82)\n        >>   64 NOP\n             66 LOAD_FAST               13 (___context_manager_0_0)\n             68 LOAD_METHOD              5 (__exit__)\n             70 LOAD_CONST               0 (None)\n             72 DUP_TOP\n             74 DUP_TOP\n             76 CALL_METHOD              3\n             78 POP_TOP\n             80 RERAISE                  0\n        >>   82 NOP\n             84 LOAD_GLOBAL              6 (__resume_at_22_1)\n             86 ROT_THREE\n             88 CALL_FUNCTION            2\n             90 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py line 1326 \n1326           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                2 (bert)\n               4 LOAD_FAST                1 (input_ids)\n               6 LOAD_FAST                2 (attention_mask)\n               8 LOAD_FAST                3 (token_type_ids)\n              10 LOAD_FAST                4 (position_ids)\n              12 LOAD_FAST                5 (head_mask)\n              14 LOAD_FAST                6 (inputs_embeds)\n              16 LOAD_FAST                7 (encoder_hidden_states)\n              18 LOAD_FAST                8 (encoder_attention_mask)\n              20 LOAD_FAST               10 (output_attentions)\n              22 LOAD_FAST               11 (output_hidden_states)\n              24 LOAD_FAST                0 (self)\n              26 LOAD_ATTR                0 (config)\n              28 LOAD_ATTR                1 (use_return_dict)\n              30 LOAD_CONST               2 (('attention_mask', 'token_type_ids', 'position_ids', 'head_mask', 'inputs_embeds', 'encoder_hidden_states', 'encoder_attention_mask', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              32 LOAD_FAST                0 (self)\n              34 LOAD_ATTR                0 (config)\n              36 LOAD_ATTR                1 (use_return_dict)\n              38 STORE_FAST              12 (return_dict)\n\n1358          40 CALL_FUNCTION_KW        11\n              42 LOAD_GLOBAL             11 (__resume_at_50_2)\n              44 ROT_TWO\n              46 LOAD_FAST                0 (self)\n              48 LOAD_FAST                9 (labels)\n              50 LOAD_FAST               12 (return_dict)\n              52 CALL_FUNCTION            4\n              54 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py line 913 \n913           0 LOAD_FAST                0 (self)\n              2 LOAD_ATTR                8 (warn_if_padding_and_no_attention_mask)\n              4 LOAD_FAST                1 (input_ids)\n              6 LOAD_FAST                2 (attention_mask)\n              8 LOAD_CONST               2 (False)\n             10 LOAD_FAST                0 (self)\n             12 LOAD_ATTR                0 (config)\n             14 LOAD_ATTR                1 (output_attentions)\n             16 LOAD_FAST                0 (self)\n             18 LOAD_ATTR                0 (config)\n             20 LOAD_ATTR                2 (output_hidden_states)\n             22 LOAD_GLOBAL             30 (__import_torch)\n             24 LOAD_ATTR               31 (Size)\n             26 LOAD_CONST              15 (16)\n             28 LOAD_CONST              16 (512)\n             30 BUILD_TUPLE              2\n             32 CALL_FUNCTION            1\n             34 STORE_FAST              14 (input_shape)\n             36 STORE_FAST              12 (output_hidden_states)\n             38 STORE_FAST              11 (output_attentions)\n             40 STORE_FAST              10 (use_cache)\n\n970          42 CALL_FUNCTION            2\n             44 LOAD_GLOBAL             32 (__resume_at_144_3)\n             46 ROT_TWO\n             48 LOAD_FAST                0 (self)\n             50 LOAD_FAST                1 (input_ids)\n             52 LOAD_FAST                2 (attention_mask)\n             54 LOAD_FAST                3 (token_type_ids)\n             56 LOAD_FAST                4 (position_ids)\n             58 LOAD_FAST                5 (head_mask)\n             60 LOAD_FAST                6 (inputs_embeds)\n             62 LOAD_FAST                7 (encoder_hidden_states)\n             64 LOAD_FAST                8 (encoder_attention_mask)\n             66 LOAD_FAST                9 (past_key_values)\n             68 LOAD_FAST               10 (use_cache)\n             70 LOAD_FAST               11 (output_attentions)\n             72 LOAD_FAST               12 (output_hidden_states)\n             74 LOAD_FAST               13 (return_dict)\n             76 LOAD_FAST               14 (input_shape)\n             78 CALL_FUNCTION           16\n             80 RETURN_VALUE\n\n", "MODIFIED BYTECODE warn_if_padding_and_no_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/modeling_utils.py line 3482 \n3490           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (config)\n               4 LOAD_ATTR                1 (pad_token_id)\n               6 LOAD_FAST                1 (input_ids)\n               8 LOAD_CONST               1 (None)\n              10 LOAD_CONST               1 (None)\n              12 BUILD_SLICE              2\n              14 LOAD_CONST               2 (-1)\n              16 LOAD_CONST               3 (0)\n              18 BUILD_LIST               2\n              20 BUILD_TUPLE              2\n              22 BINARY_SUBSCR\n              24 CONTAINS_OP              0\n              26 POP_JUMP_IF_FALSE       90 (to 180)\n\n3492          28 LOAD_CONST               4 ('We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.')\n\n3491          30 STORE_FAST               3 (warn_string)\n\n3500          32 LOAD_FAST                0 (self)\n              34 LOAD_ATTR                0 (config)\n              36 LOAD_ATTR                2 (bos_token_id)\n              38 LOAD_CONST               1 (None)\n              40 IS_OP                    1\n              42 POP_JUMP_IF_FALSE       30 (to 60)\n              44 LOAD_FAST                0 (self)\n              46 LOAD_ATTR                0 (config)\n              48 LOAD_ATTR                2 (bos_token_id)\n              50 LOAD_FAST                0 (self)\n              52 LOAD_ATTR                0 (config)\n              54 LOAD_ATTR                1 (pad_token_id)\n              56 COMPARE_OP               2 (==)\n              58 POP_JUMP_IF_TRUE        58 (to 116)\n\n3501     >>   60 LOAD_FAST                0 (self)\n              62 LOAD_ATTR                0 (config)\n              64 LOAD_ATTR                3 (eos_token_id)\n              66 LOAD_CONST               1 (None)\n              68 IS_OP                    1\n              70 POP_JUMP_IF_FALSE       44 (to 88)\n              72 LOAD_FAST                0 (self)\n              74 LOAD_ATTR                0 (config)\n              76 LOAD_ATTR                3 (eos_token_id)\n              78 LOAD_FAST                0 (self)\n              80 LOAD_ATTR                0 (config)\n              82 LOAD_ATTR                1 (pad_token_id)\n              84 COMPARE_OP               2 (==)\n              86 POP_JUMP_IF_TRUE        58 (to 116)\n\n3502     >>   88 LOAD_FAST                0 (self)\n              90 LOAD_ATTR                0 (config)\n              92 LOAD_ATTR                4 (sep_token_id)\n              94 LOAD_CONST               1 (None)\n              96 IS_OP                    1\n              98 POP_JUMP_IF_FALSE       83 (to 166)\n             100 LOAD_FAST                0 (self)\n             102 LOAD_ATTR                0 (config)\n             104 LOAD_ATTR                4 (sep_token_id)\n             106 LOAD_FAST                0 (self)\n             108 LOAD_ATTR                0 (config)\n             110 LOAD_ATTR                1 (pad_token_id)\n             112 COMPARE_OP               2 (==)\n             114 POP_JUMP_IF_FALSE       83 (to 166)\n\n3504     >>  116 LOAD_FAST                3 (warn_string)\n\n3505         118 LOAD_CONST               5 ('\\nYou may ignore this warning if your `pad_token_id` (')\n             120 LOAD_FAST                0 (self)\n             122 LOAD_ATTR                0 (config)\n             124 LOAD_ATTR                1 (pad_token_id)\n             126 FORMAT_VALUE             0\n             128 LOAD_CONST               6 (') is identical to the `bos_token_id` (')\n\n3506         130 LOAD_FAST                0 (self)\n             132 LOAD_ATTR                0 (config)\n             134 LOAD_ATTR                2 (bos_token_id)\n\n3505         136 FORMAT_VALUE             0\n             138 LOAD_CONST               7 ('), `eos_token_id` (')\n\n3506         140 LOAD_FAST                0 (self)\n             142 LOAD_ATTR                0 (config)\n             144 LOAD_ATTR                3 (eos_token_id)\n\n3505         146 FORMAT_VALUE             0\n             148 LOAD_CONST               8 ('), or the `sep_token_id` (')\n\n3507         150 LOAD_FAST                0 (self)\n             152 LOAD_ATTR                0 (config)\n             154 LOAD_ATTR                4 (sep_token_id)\n\n3505         156 FORMAT_VALUE             0\n             158 LOAD_CONST               9 ('), and your input is not padded.')\n             160 BUILD_STRING             9\n\n3504         162 INPLACE_ADD\n             164 STORE_FAST               3 (warn_string)\n\n3510     >>  166 LOAD_GLOBAL              5 (logger)\n             168 LOAD_ATTR                6 (warning_once)\n             170 LOAD_FAST                3 (warn_string)\n             172 CALL_FUNCTION            1\n             174 POP_TOP\n             176 LOAD_CONST               1 (None)\n             178 RETURN_VALUE\n\n3490     >>  180 LOAD_CONST               1 (None)\n             182 RETURN_VALUE\n\n", "MODIFIED BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py line 970 \n970           0 LOAD_GLOBAL             33 (__compiled_fn_4)\n              2 LOAD_FAST                2 (input_ids)\n              4 CALL_FUNCTION            1\n              6 EXTENDED_ARG             2\n              8 STORE_FAST             745 (graph_out_0)\n             10 LOAD_CONST              15 (<class 'transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions'>)\n             12 EXTENDED_ARG             2\n             14 LOAD_FAST              745 (graph_out_0)\n             16 LOAD_CONST               6 (0)\n             18 BINARY_SUBSCR\n             20 LOAD_CONST               1 (None)\n             22 LOAD_CONST               1 (None)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               1 (None)\n             28 LOAD_CONST               1 (None)\n             30 LOAD_CONST              16 (('last_hidden_state', 'pooler_output', 'hidden_states', 'past_key_values', 'attentions', 'cross_attentions'))\n             32 CALL_FUNCTION_KW         6\n             34 RETURN_VALUE\n\n", "MODIFIED BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py line 1358 \n1358           0 LOAD_GLOBAL             11 (__compiled_fn_5)\n               2 LOAD_FAST                0 (___stack0)\n               4 LOAD_ATTR               12 (last_hidden_state)\n               6 LOAD_FAST                2 (labels)\n               8 CALL_FUNCTION            2\n              10 STORE_FAST              36 (graph_out_0)\n              12 LOAD_CONST               7 (<class 'transformers.modeling_outputs.MaskedLMOutput'>)\n              14 LOAD_FAST               36 (graph_out_0)\n              16 LOAD_CONST               3 (0)\n              18 BINARY_SUBSCR\n              20 LOAD_FAST               36 (graph_out_0)\n              22 LOAD_CONST               8 (1)\n              24 BINARY_SUBSCR\n              26 LOAD_FAST                0 (___stack0)\n              28 LOAD_ATTR                8 (hidden_states)\n              30 LOAD_FAST                0 (___stack0)\n              32 LOAD_ATTR                9 (attentions)\n              34 LOAD_CONST               9 (('loss', 'logits', 'hidden_states', 'attentions'))\n              36 CALL_FUNCTION_KW         4\n              38 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              2 (__import_contextlib)\n              2 LOAD_ATTR                3 (nullcontext)\n              4 LOAD_FAST                1 (mod)\n              6 LOAD_CONST               1 (())\n              8 LOAD_CONST               2 ('input_ids')\n             10 LOAD_FAST                2 (inputs)\n             12 LOAD_CONST               2 ('input_ids')\n             14 BINARY_SUBSCR\n             16 LOAD_CONST               3 ('start_positions')\n             18 LOAD_FAST                2 (inputs)\n             20 LOAD_CONST               3 ('start_positions')\n             22 BINARY_SUBSCR\n             24 LOAD_CONST               4 ('end_positions')\n             26 LOAD_FAST                2 (inputs)\n             28 LOAD_CONST               4 ('end_positions')\n             30 BINARY_SUBSCR\n             32 BUILD_MAP                3\n             34 LOAD_GLOBAL              2 (__import_contextlib)\n             36 LOAD_ATTR                3 (nullcontext)\n             38 CALL_FUNCTION            0\n             40 STORE_FAST              13 (___context_manager_0_0)\n             42 LOAD_FAST               13 (___context_manager_0_0)\n             44 LOAD_METHOD              4 (__enter__)\n             46 CALL_METHOD              0\n             48 POP_TOP\n             50 SETUP_FINALLY           10 (to 72)\n\n551          52 CALL_FUNCTION_EX         1\n             54 POP_BLOCK\n             56 LOAD_FAST               13 (___context_manager_0_0)\n             58 LOAD_METHOD              5 (__exit__)\n             60 LOAD_CONST               0 (None)\n             62 DUP_TOP\n             64 DUP_TOP\n             66 CALL_METHOD              3\n             68 POP_TOP\n             70 JUMP_FORWARD             9 (to 90)\n        >>   72 NOP\n             74 LOAD_FAST               13 (___context_manager_0_0)\n             76 LOAD_METHOD              5 (__exit__)\n             78 LOAD_CONST               0 (None)\n             80 DUP_TOP\n             82 DUP_TOP\n             84 CALL_METHOD              3\n             86 POP_TOP\n             88 RERAISE                  0\n        >>   90 NOP\n             92 LOAD_GLOBAL              6 (__resume_at_22_1)\n             94 ROT_THREE\n             96 CALL_FUNCTION            2\n             98 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py line 1808 \n1808           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                2 (bert)\n               4 LOAD_FAST                1 (input_ids)\n               6 LOAD_FAST                2 (attention_mask)\n               8 LOAD_FAST                3 (token_type_ids)\n              10 LOAD_FAST                4 (position_ids)\n              12 LOAD_FAST                5 (head_mask)\n              14 LOAD_FAST                6 (inputs_embeds)\n              16 LOAD_FAST                9 (output_attentions)\n              18 LOAD_FAST               10 (output_hidden_states)\n              20 LOAD_FAST                0 (self)\n              22 LOAD_ATTR                0 (config)\n              24 LOAD_ATTR                1 (use_return_dict)\n              26 LOAD_CONST               2 (('attention_mask', 'token_type_ids', 'position_ids', 'head_mask', 'inputs_embeds', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              28 LOAD_FAST                0 (self)\n              30 LOAD_ATTR                0 (config)\n              32 LOAD_ATTR                1 (use_return_dict)\n              34 STORE_FAST              11 (return_dict)\n\n1844          36 CALL_FUNCTION_KW         9\n              38 LOAD_GLOBAL             15 (__resume_at_46_2)\n              40 ROT_TWO\n              42 LOAD_FAST                0 (self)\n              44 LOAD_FAST                7 (start_positions)\n              46 LOAD_FAST                8 (end_positions)\n              48 LOAD_FAST               11 (return_dict)\n              50 CALL_FUNCTION            5\n              52 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py line 913 \n913           0 LOAD_FAST                0 (self)\n              2 LOAD_ATTR                8 (warn_if_padding_and_no_attention_mask)\n              4 LOAD_FAST                1 (input_ids)\n              6 LOAD_FAST                2 (attention_mask)\n              8 LOAD_CONST               2 (False)\n             10 LOAD_FAST                0 (self)\n             12 LOAD_ATTR                0 (config)\n             14 LOAD_ATTR                1 (output_attentions)\n             16 LOAD_FAST                0 (self)\n             18 LOAD_ATTR                0 (config)\n             20 LOAD_ATTR                2 (output_hidden_states)\n             22 LOAD_GLOBAL             30 (__import_torch)\n             24 LOAD_ATTR               31 (Size)\n             26 LOAD_CONST              15 (16)\n             28 LOAD_CONST              16 (512)\n             30 BUILD_TUPLE              2\n             32 CALL_FUNCTION            1\n             34 STORE_FAST              14 (input_shape)\n             36 STORE_FAST              12 (output_hidden_states)\n             38 STORE_FAST              11 (output_attentions)\n             40 STORE_FAST              10 (use_cache)\n\n970          42 CALL_FUNCTION            2\n             44 LOAD_GLOBAL             32 (__resume_at_144_3)\n             46 ROT_TWO\n             48 LOAD_FAST                0 (self)\n             50 LOAD_FAST                1 (input_ids)\n             52 LOAD_FAST                2 (attention_mask)\n             54 LOAD_FAST                3 (token_type_ids)\n             56 LOAD_FAST                4 (position_ids)\n             58 LOAD_FAST                5 (head_mask)\n             60 LOAD_FAST                6 (inputs_embeds)\n             62 LOAD_FAST                7 (encoder_hidden_states)\n             64 LOAD_FAST                8 (encoder_attention_mask)\n             66 LOAD_FAST                9 (past_key_values)\n             68 LOAD_FAST               10 (use_cache)\n             70 LOAD_FAST               11 (output_attentions)\n             72 LOAD_FAST               12 (output_hidden_states)\n             74 LOAD_FAST               13 (return_dict)\n             76 LOAD_FAST               14 (input_shape)\n             78 CALL_FUNCTION           16\n             80 RETURN_VALUE\n\n", "MODIFIED BYTECODE warn_if_padding_and_no_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/modeling_utils.py line 3482 \n3490           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (config)\n               4 LOAD_ATTR                1 (pad_token_id)\n               6 LOAD_FAST                1 (input_ids)\n               8 LOAD_CONST               1 (None)\n              10 LOAD_CONST               1 (None)\n              12 BUILD_SLICE              2\n              14 LOAD_CONST               2 (-1)\n              16 LOAD_CONST               3 (0)\n              18 BUILD_LIST               2\n              20 BUILD_TUPLE              2\n              22 BINARY_SUBSCR\n              24 CONTAINS_OP              0\n              26 POP_JUMP_IF_FALSE       90 (to 180)\n\n3492          28 LOAD_CONST               4 ('We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.')\n\n3491          30 STORE_FAST               3 (warn_string)\n\n3500          32 LOAD_FAST                0 (self)\n              34 LOAD_ATTR                0 (config)\n              36 LOAD_ATTR                2 (bos_token_id)\n              38 LOAD_CONST               1 (None)\n              40 IS_OP                    1\n              42 POP_JUMP_IF_FALSE       30 (to 60)\n              44 LOAD_FAST                0 (self)\n              46 LOAD_ATTR                0 (config)\n              48 LOAD_ATTR                2 (bos_token_id)\n              50 LOAD_FAST                0 (self)\n              52 LOAD_ATTR                0 (config)\n              54 LOAD_ATTR                1 (pad_token_id)\n              56 COMPARE_OP               2 (==)\n              58 POP_JUMP_IF_TRUE        58 (to 116)\n\n3501     >>   60 LOAD_FAST                0 (self)\n              62 LOAD_ATTR                0 (config)\n              64 LOAD_ATTR                3 (eos_token_id)\n              66 LOAD_CONST               1 (None)\n              68 IS_OP                    1\n              70 POP_JUMP_IF_FALSE       44 (to 88)\n              72 LOAD_FAST                0 (self)\n              74 LOAD_ATTR                0 (config)\n              76 LOAD_ATTR                3 (eos_token_id)\n              78 LOAD_FAST                0 (self)\n              80 LOAD_ATTR                0 (config)\n              82 LOAD_ATTR                1 (pad_token_id)\n              84 COMPARE_OP               2 (==)\n              86 POP_JUMP_IF_TRUE        58 (to 116)\n\n3502     >>   88 LOAD_FAST                0 (self)\n              90 LOAD_ATTR                0 (config)\n              92 LOAD_ATTR                4 (sep_token_id)\n              94 LOAD_CONST               1 (None)\n              96 IS_OP                    1\n              98 POP_JUMP_IF_FALSE       83 (to 166)\n             100 LOAD_FAST                0 (self)\n             102 LOAD_ATTR                0 (config)\n             104 LOAD_ATTR                4 (sep_token_id)\n             106 LOAD_FAST                0 (self)\n             108 LOAD_ATTR                0 (config)\n             110 LOAD_ATTR                1 (pad_token_id)\n             112 COMPARE_OP               2 (==)\n             114 POP_JUMP_IF_FALSE       83 (to 166)\n\n3504     >>  116 LOAD_FAST                3 (warn_string)\n\n3505         118 LOAD_CONST               5 ('\\nYou may ignore this warning if your `pad_token_id` (')\n             120 LOAD_FAST                0 (self)\n             122 LOAD_ATTR                0 (config)\n             124 LOAD_ATTR                1 (pad_token_id)\n             126 FORMAT_VALUE             0\n             128 LOAD_CONST               6 (') is identical to the `bos_token_id` (')\n\n3506         130 LOAD_FAST                0 (self)\n             132 LOAD_ATTR                0 (config)\n             134 LOAD_ATTR                2 (bos_token_id)\n\n3505         136 FORMAT_VALUE             0\n             138 LOAD_CONST               7 ('), `eos_token_id` (')\n\n3506         140 LOAD_FAST                0 (self)\n             142 LOAD_ATTR                0 (config)\n             144 LOAD_ATTR                3 (eos_token_id)\n\n3505         146 FORMAT_VALUE             0\n             148 LOAD_CONST               8 ('), or the `sep_token_id` (')\n\n3507         150 LOAD_FAST                0 (self)\n             152 LOAD_ATTR                0 (config)\n             154 LOAD_ATTR                4 (sep_token_id)\n\n3505         156 FORMAT_VALUE             0\n             158 LOAD_CONST               9 ('), and your input is not padded.')\n             160 BUILD_STRING             9\n\n3504         162 INPLACE_ADD\n             164 STORE_FAST               3 (warn_string)\n\n3510     >>  166 LOAD_GLOBAL              5 (logger)\n             168 LOAD_ATTR                6 (warning_once)\n             170 LOAD_FAST                3 (warn_string)\n             172 CALL_FUNCTION            1\n             174 POP_TOP\n             176 LOAD_CONST               1 (None)\n             178 RETURN_VALUE\n\n3490     >>  180 LOAD_CONST               1 (None)\n             182 RETURN_VALUE\n\n", "MODIFIED BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py line 970 \n970           0 LOAD_GLOBAL             33 (__compiled_fn_4)\n              2 LOAD_FAST                2 (input_ids)\n              4 CALL_FUNCTION            1\n              6 EXTENDED_ARG             2\n              8 STORE_FAST             745 (graph_out_0)\n             10 LOAD_CONST              15 (<class 'transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions'>)\n             12 EXTENDED_ARG             2\n             14 LOAD_FAST              745 (graph_out_0)\n             16 LOAD_CONST               6 (0)\n             18 BINARY_SUBSCR\n             20 LOAD_CONST               1 (None)\n             22 LOAD_CONST               1 (None)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               1 (None)\n             28 LOAD_CONST               1 (None)\n             30 LOAD_CONST              16 (('last_hidden_state', 'pooler_output', 'hidden_states', 'past_key_values', 'attentions', 'cross_attentions'))\n             32 CALL_FUNCTION_KW         6\n             34 RETURN_VALUE\n\n", "MODIFIED BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py line 1844 \n1844           0 LOAD_GLOBAL             14 (__compiled_fn_5)\n               2 LOAD_FAST                0 (___stack0)\n               4 LOAD_ATTR               15 (last_hidden_state)\n               6 LOAD_FAST                2 (start_positions)\n               8 LOAD_FAST                3 (end_positions)\n              10 CALL_FUNCTION            3\n              12 STORE_FAST              39 (graph_out_0)\n              14 LOAD_CONST              10 (<class 'transformers.modeling_outputs.QuestionAnsweringModelOutput'>)\n              16 LOAD_FAST               39 (graph_out_0)\n              18 LOAD_CONST               3 (0)\n              20 BINARY_SUBSCR\n              22 LOAD_FAST               39 (graph_out_0)\n              24 LOAD_CONST               4 (1)\n              26 BINARY_SUBSCR\n              28 LOAD_FAST               39 (graph_out_0)\n              30 LOAD_CONST               8 (2)\n              32 BINARY_SUBSCR\n              34 LOAD_FAST                0 (___stack0)\n              36 LOAD_ATTR               12 (hidden_states)\n              38 LOAD_FAST                0 (___stack0)\n              40 LOAD_ATTR               13 (attentions)\n              42 LOAD_CONST              11 (('loss', 'start_logits', 'end_logits', 'hidden_states', 'attentions'))\n              44 CALL_FUNCTION_KW         5\n              46 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              4 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             1\n             18 STORE_FAST             476 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.CausalLMOutputWithCrossAttentions'>)\n             22 EXTENDED_ARG             1\n             24 LOAD_FAST              476 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             1\n             32 LOAD_FAST              476 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 EXTENDED_ARG             1\n             40 LOAD_FAST              476 (graph_out_0)\n             42 LOAD_CONST               7 (2)\n             44 BINARY_SUBSCR\n             46 EXTENDED_ARG             1\n             48 LOAD_FAST              476 (graph_out_0)\n             50 LOAD_CONST               8 (3)\n             52 BINARY_SUBSCR\n             54 BUILD_TUPLE              2\n             56 EXTENDED_ARG             1\n             58 LOAD_FAST              476 (graph_out_0)\n             60 LOAD_CONST               9 (4)\n             62 BINARY_SUBSCR\n             64 EXTENDED_ARG             1\n             66 LOAD_FAST              476 (graph_out_0)\n             68 LOAD_CONST              10 (5)\n             70 BINARY_SUBSCR\n             72 BUILD_TUPLE              2\n             74 EXTENDED_ARG             1\n             76 LOAD_FAST              476 (graph_out_0)\n             78 LOAD_CONST              11 (6)\n             80 BINARY_SUBSCR\n             82 EXTENDED_ARG             1\n             84 LOAD_FAST              476 (graph_out_0)\n             86 LOAD_CONST              12 (7)\n             88 BINARY_SUBSCR\n             90 BUILD_TUPLE              2\n             92 EXTENDED_ARG             1\n             94 LOAD_FAST              476 (graph_out_0)\n             96 LOAD_CONST              13 (8)\n             98 BINARY_SUBSCR\n            100 EXTENDED_ARG             1\n            102 LOAD_FAST              476 (graph_out_0)\n            104 LOAD_CONST              14 (9)\n            106 BINARY_SUBSCR\n            108 BUILD_TUPLE              2\n            110 EXTENDED_ARG             1\n            112 LOAD_FAST              476 (graph_out_0)\n            114 LOAD_CONST              15 (10)\n            116 BINARY_SUBSCR\n            118 EXTENDED_ARG             1\n            120 LOAD_FAST              476 (graph_out_0)\n            122 LOAD_CONST              16 (11)\n            124 BINARY_SUBSCR\n            126 BUILD_TUPLE              2\n            128 EXTENDED_ARG             1\n            130 LOAD_FAST              476 (graph_out_0)\n            132 LOAD_CONST              17 (12)\n            134 BINARY_SUBSCR\n            136 EXTENDED_ARG             1\n            138 LOAD_FAST              476 (graph_out_0)\n            140 LOAD_CONST              18 (13)\n            142 BINARY_SUBSCR\n            144 BUILD_TUPLE              2\n            146 EXTENDED_ARG             1\n            148 LOAD_FAST              476 (graph_out_0)\n            150 LOAD_CONST              19 (14)\n            152 BINARY_SUBSCR\n            154 EXTENDED_ARG             1\n            156 LOAD_FAST              476 (graph_out_0)\n            158 LOAD_CONST              20 (15)\n            160 BINARY_SUBSCR\n            162 BUILD_TUPLE              2\n            164 EXTENDED_ARG             1\n            166 LOAD_FAST              476 (graph_out_0)\n            168 LOAD_CONST              21 (16)\n            170 BINARY_SUBSCR\n            172 EXTENDED_ARG             1\n            174 LOAD_FAST              476 (graph_out_0)\n            176 LOAD_CONST              22 (17)\n            178 BINARY_SUBSCR\n            180 BUILD_TUPLE              2\n            182 BUILD_TUPLE              8\n            184 LOAD_CONST               0 (None)\n            186 LOAD_CONST               0 (None)\n            188 LOAD_CONST               0 (None)\n            190 LOAD_CONST              23 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n            192 CALL_FUNCTION_KW         6\n            194 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              4 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('decoder_input_ids')\n             12 BINARY_SUBSCR\n             14 LOAD_FAST                2 (inputs)\n             16 LOAD_CONST               4 ('labels')\n             18 BINARY_SUBSCR\n             20 CALL_FUNCTION            3\n             22 EXTENDED_ARG             4\n             24 STORE_FAST            1112 (graph_out_0)\n             26 LOAD_CONST               5 (<class 'transformers.modeling_outputs.Seq2SeqLMOutput'>)\n             28 EXTENDED_ARG             4\n             30 LOAD_FAST             1112 (graph_out_0)\n             32 LOAD_CONST               6 (0)\n             34 BINARY_SUBSCR\n             36 EXTENDED_ARG             4\n             38 LOAD_FAST             1112 (graph_out_0)\n             40 LOAD_CONST               7 (1)\n             42 BINARY_SUBSCR\n             44 LOAD_CONST               0 (None)\n             46 LOAD_CONST               0 (None)\n             48 LOAD_CONST               0 (None)\n             50 LOAD_CONST               0 (None)\n             52 EXTENDED_ARG             4\n             54 LOAD_FAST             1112 (graph_out_0)\n             56 LOAD_CONST               8 (2)\n             58 BINARY_SUBSCR\n             60 LOAD_CONST               0 (None)\n             62 LOAD_CONST               0 (None)\n             64 LOAD_CONST               9 (('loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             66 CALL_FUNCTION_KW         9\n             68 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              2 (__import_contextlib)\n              2 LOAD_ATTR                3 (nullcontext)\n              4 LOAD_FAST                1 (mod)\n              6 LOAD_CONST               1 (())\n              8 LOAD_CONST               2 ('input_ids')\n             10 LOAD_FAST                2 (inputs)\n             12 LOAD_CONST               2 ('input_ids')\n             14 BINARY_SUBSCR\n             16 LOAD_CONST               3 ('labels')\n             18 LOAD_FAST                2 (inputs)\n             20 LOAD_CONST               3 ('labels')\n             22 BINARY_SUBSCR\n             24 BUILD_MAP                2\n             26 LOAD_GLOBAL              2 (__import_contextlib)\n             28 LOAD_ATTR                3 (nullcontext)\n             30 CALL_FUNCTION            0\n             32 STORE_FAST              13 (___context_manager_0_0)\n             34 LOAD_FAST               13 (___context_manager_0_0)\n             36 LOAD_METHOD              4 (__enter__)\n             38 CALL_METHOD              0\n             40 POP_TOP\n             42 SETUP_FINALLY           10 (to 64)\n\n551          44 CALL_FUNCTION_EX         1\n             46 POP_BLOCK\n             48 LOAD_FAST               13 (___context_manager_0_0)\n             50 LOAD_METHOD              5 (__exit__)\n             52 LOAD_CONST               0 (None)\n             54 DUP_TOP\n             56 DUP_TOP\n             58 CALL_METHOD              3\n             60 POP_TOP\n             62 JUMP_FORWARD             9 (to 82)\n        >>   64 NOP\n             66 LOAD_FAST               13 (___context_manager_0_0)\n             68 LOAD_METHOD              5 (__exit__)\n             70 LOAD_CONST               0 (None)\n             72 DUP_TOP\n             74 DUP_TOP\n             76 CALL_METHOD              3\n             78 POP_TOP\n             80 RERAISE                  0\n        >>   82 NOP\n             84 LOAD_GLOBAL              6 (__resume_at_22_1)\n             86 ROT_THREE\n             88 CALL_FUNCTION            2\n             90 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py line 954 \n954           0 LOAD_FAST                0 (self)\n              2 LOAD_ATTR                2 (roberta)\n              4 LOAD_FAST                1 (input_ids)\n              6 LOAD_FAST                2 (attention_mask)\n              8 LOAD_FAST                3 (token_type_ids)\n             10 LOAD_FAST                4 (position_ids)\n             12 LOAD_FAST                5 (head_mask)\n             14 LOAD_FAST                6 (inputs_embeds)\n             16 LOAD_FAST                7 (encoder_hidden_states)\n             18 LOAD_FAST                8 (encoder_attention_mask)\n             20 LOAD_FAST               10 (output_attentions)\n             22 LOAD_FAST               11 (output_hidden_states)\n             24 LOAD_FAST                0 (self)\n             26 LOAD_ATTR                0 (config)\n             28 LOAD_ATTR                1 (use_return_dict)\n             30 LOAD_CONST               2 (('attention_mask', 'token_type_ids', 'position_ids', 'head_mask', 'inputs_embeds', 'encoder_hidden_states', 'encoder_attention_mask', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                0 (config)\n             36 LOAD_ATTR                1 (use_return_dict)\n             38 STORE_FAST              12 (return_dict)\n\n988          40 CALL_FUNCTION_KW        11\n             42 LOAD_GLOBAL             13 (__resume_at_50_2)\n             44 ROT_TWO\n             46 LOAD_FAST                0 (self)\n             48 LOAD_FAST                9 (labels)\n             50 LOAD_FAST               12 (return_dict)\n             52 CALL_FUNCTION            4\n             54 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py line 787 \n787           0 LOAD_FAST                0 (self)\n              2 LOAD_ATTR                8 (warn_if_padding_and_no_attention_mask)\n              4 LOAD_FAST                1 (input_ids)\n              6 LOAD_FAST                2 (attention_mask)\n              8 LOAD_CONST               2 (False)\n             10 LOAD_FAST                0 (self)\n             12 LOAD_ATTR                0 (config)\n             14 LOAD_ATTR                1 (output_attentions)\n             16 LOAD_FAST                0 (self)\n             18 LOAD_ATTR                0 (config)\n             20 LOAD_ATTR                2 (output_hidden_states)\n             22 LOAD_GLOBAL             30 (__import_torch)\n             24 LOAD_ATTR               31 (Size)\n             26 LOAD_CONST              15 (16)\n             28 LOAD_CONST              16 (512)\n             30 BUILD_TUPLE              2\n             32 CALL_FUNCTION            1\n             34 STORE_FAST              14 (input_shape)\n             36 STORE_FAST              12 (output_hidden_states)\n             38 STORE_FAST              11 (output_attentions)\n             40 STORE_FAST              10 (use_cache)\n\n845          42 CALL_FUNCTION            2\n             44 LOAD_GLOBAL             32 (__resume_at_144_3)\n             46 ROT_TWO\n             48 LOAD_FAST                0 (self)\n             50 LOAD_FAST                1 (input_ids)\n             52 LOAD_FAST                2 (attention_mask)\n             54 LOAD_FAST                3 (token_type_ids)\n             56 LOAD_FAST                4 (position_ids)\n             58 LOAD_FAST                5 (head_mask)\n             60 LOAD_FAST                6 (inputs_embeds)\n             62 LOAD_FAST                7 (encoder_hidden_states)\n             64 LOAD_FAST                8 (encoder_attention_mask)\n             66 LOAD_FAST                9 (past_key_values)\n             68 LOAD_FAST               10 (use_cache)\n             70 LOAD_FAST               11 (output_attentions)\n             72 LOAD_FAST               12 (output_hidden_states)\n             74 LOAD_FAST               13 (return_dict)\n             76 LOAD_FAST               14 (input_shape)\n             78 CALL_FUNCTION           16\n             80 RETURN_VALUE\n\n", "MODIFIED BYTECODE warn_if_padding_and_no_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/modeling_utils.py line 3482 \n3490           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (config)\n               4 LOAD_ATTR                1 (pad_token_id)\n               6 LOAD_FAST                1 (input_ids)\n               8 LOAD_CONST               1 (None)\n              10 LOAD_CONST               1 (None)\n              12 BUILD_SLICE              2\n              14 LOAD_CONST               2 (-1)\n              16 LOAD_CONST               3 (0)\n              18 BUILD_LIST               2\n              20 BUILD_TUPLE              2\n              22 BINARY_SUBSCR\n              24 CONTAINS_OP              0\n              26 POP_JUMP_IF_FALSE       90 (to 180)\n\n3492          28 LOAD_CONST               4 ('We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.')\n\n3491          30 STORE_FAST               3 (warn_string)\n\n3500          32 LOAD_FAST                0 (self)\n              34 LOAD_ATTR                0 (config)\n              36 LOAD_ATTR                2 (bos_token_id)\n              38 LOAD_CONST               1 (None)\n              40 IS_OP                    1\n              42 POP_JUMP_IF_FALSE       30 (to 60)\n              44 LOAD_FAST                0 (self)\n              46 LOAD_ATTR                0 (config)\n              48 LOAD_ATTR                2 (bos_token_id)\n              50 LOAD_FAST                0 (self)\n              52 LOAD_ATTR                0 (config)\n              54 LOAD_ATTR                1 (pad_token_id)\n              56 COMPARE_OP               2 (==)\n              58 POP_JUMP_IF_TRUE        58 (to 116)\n\n3501     >>   60 LOAD_FAST                0 (self)\n              62 LOAD_ATTR                0 (config)\n              64 LOAD_ATTR                3 (eos_token_id)\n              66 LOAD_CONST               1 (None)\n              68 IS_OP                    1\n              70 POP_JUMP_IF_FALSE       44 (to 88)\n              72 LOAD_FAST                0 (self)\n              74 LOAD_ATTR                0 (config)\n              76 LOAD_ATTR                3 (eos_token_id)\n              78 LOAD_FAST                0 (self)\n              80 LOAD_ATTR                0 (config)\n              82 LOAD_ATTR                1 (pad_token_id)\n              84 COMPARE_OP               2 (==)\n              86 POP_JUMP_IF_TRUE        58 (to 116)\n\n3502     >>   88 LOAD_FAST                0 (self)\n              90 LOAD_ATTR                0 (config)\n              92 LOAD_ATTR                4 (sep_token_id)\n              94 LOAD_CONST               1 (None)\n              96 IS_OP                    1\n              98 POP_JUMP_IF_FALSE       83 (to 166)\n             100 LOAD_FAST                0 (self)\n             102 LOAD_ATTR                0 (config)\n             104 LOAD_ATTR                4 (sep_token_id)\n             106 LOAD_FAST                0 (self)\n             108 LOAD_ATTR                0 (config)\n             110 LOAD_ATTR                1 (pad_token_id)\n             112 COMPARE_OP               2 (==)\n             114 POP_JUMP_IF_FALSE       83 (to 166)\n\n3504     >>  116 LOAD_FAST                3 (warn_string)\n\n3505         118 LOAD_CONST               5 ('\\nYou may ignore this warning if your `pad_token_id` (')\n             120 LOAD_FAST                0 (self)\n             122 LOAD_ATTR                0 (config)\n             124 LOAD_ATTR                1 (pad_token_id)\n             126 FORMAT_VALUE             0\n             128 LOAD_CONST               6 (') is identical to the `bos_token_id` (')\n\n3506         130 LOAD_FAST                0 (self)\n             132 LOAD_ATTR                0 (config)\n             134 LOAD_ATTR                2 (bos_token_id)\n\n3505         136 FORMAT_VALUE             0\n             138 LOAD_CONST               7 ('), `eos_token_id` (')\n\n3506         140 LOAD_FAST                0 (self)\n             142 LOAD_ATTR                0 (config)\n             144 LOAD_ATTR                3 (eos_token_id)\n\n3505         146 FORMAT_VALUE             0\n             148 LOAD_CONST               8 ('), or the `sep_token_id` (')\n\n3507         150 LOAD_FAST                0 (self)\n             152 LOAD_ATTR                0 (config)\n             154 LOAD_ATTR                4 (sep_token_id)\n\n3505         156 FORMAT_VALUE             0\n             158 LOAD_CONST               9 ('), and your input is not padded.')\n             160 BUILD_STRING             9\n\n3504         162 INPLACE_ADD\n             164 STORE_FAST               3 (warn_string)\n\n3510     >>  166 LOAD_GLOBAL              5 (logger)\n             168 LOAD_ATTR                6 (warning_once)\n             170 LOAD_FAST                3 (warn_string)\n             172 CALL_FUNCTION            1\n             174 POP_TOP\n             176 LOAD_CONST               1 (None)\n             178 RETURN_VALUE\n\n3490     >>  180 LOAD_CONST               1 (None)\n             182 RETURN_VALUE\n\n", "MODIFIED BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py line 845 \n845           0 LOAD_GLOBAL             33 (__compiled_fn_4)\n              2 LOAD_FAST                2 (input_ids)\n              4 CALL_FUNCTION            1\n              6 EXTENDED_ARG             2\n              8 STORE_FAST             747 (graph_out_0)\n             10 LOAD_CONST              15 (<class 'transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions'>)\n             12 EXTENDED_ARG             2\n             14 LOAD_FAST              747 (graph_out_0)\n             16 LOAD_CONST               6 (0)\n             18 BINARY_SUBSCR\n             20 LOAD_CONST               1 (None)\n             22 LOAD_CONST               1 (None)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               1 (None)\n             28 LOAD_CONST               1 (None)\n             30 LOAD_CONST              16 (('last_hidden_state', 'pooler_output', 'hidden_states', 'past_key_values', 'attentions', 'cross_attentions'))\n             32 CALL_FUNCTION_KW         6\n             34 RETURN_VALUE\n\n", "MODIFIED BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py line 988 \n988           0 LOAD_GLOBAL             13 (__compiled_fn_5)\n              2 LOAD_FAST                0 (___stack0)\n              4 LOAD_ATTR               14 (last_hidden_state)\n              6 LOAD_FAST                2 (labels)\n              8 CALL_FUNCTION            2\n             10 STORE_FAST              33 (graph_out_0)\n             12 LOAD_CONST               7 (<class 'transformers.modeling_outputs.MaskedLMOutput'>)\n             14 LOAD_FAST               33 (graph_out_0)\n             16 LOAD_CONST               3 (0)\n             18 BINARY_SUBSCR\n             20 LOAD_FAST               33 (graph_out_0)\n             22 LOAD_CONST               8 (1)\n             24 BINARY_SUBSCR\n             26 LOAD_FAST                0 (___stack0)\n             28 LOAD_ATTR               10 (hidden_states)\n             30 LOAD_FAST                0 (___stack0)\n             32 LOAD_ATTR               11 (attentions)\n             34 LOAD_CONST               9 (('loss', 'logits', 'hidden_states', 'attentions'))\n             36 CALL_FUNCTION_KW         4\n             38 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              3 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             3\n             18 STORE_FAST             934 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.MaskedLMOutput'>)\n             22 EXTENDED_ARG             3\n             24 LOAD_FAST              934 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             3\n             32 LOAD_FAST              934 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 LOAD_CONST               0 (None)\n             40 LOAD_CONST               0 (None)\n             42 LOAD_CONST               7 (('loss', 'logits', 'hidden_states', 'attentions'))\n             44 CALL_FUNCTION_KW         4\n             46 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              3 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('start_positions')\n             12 BINARY_SUBSCR\n             14 LOAD_FAST                2 (inputs)\n             16 LOAD_CONST               4 ('end_positions')\n             18 BINARY_SUBSCR\n             20 CALL_FUNCTION            3\n             22 EXTENDED_ARG             3\n             24 STORE_FAST             933 (graph_out_0)\n             26 LOAD_CONST               5 (<class 'transformers.modeling_outputs.QuestionAnsweringModelOutput'>)\n             28 EXTENDED_ARG             3\n             30 LOAD_FAST              933 (graph_out_0)\n             32 LOAD_CONST               6 (0)\n             34 BINARY_SUBSCR\n             36 EXTENDED_ARG             3\n             38 LOAD_FAST              933 (graph_out_0)\n             40 LOAD_CONST               7 (1)\n             42 BINARY_SUBSCR\n             44 EXTENDED_ARG             3\n             46 LOAD_FAST              933 (graph_out_0)\n             48 LOAD_CONST               8 (2)\n             50 BINARY_SUBSCR\n             52 LOAD_CONST               0 (None)\n             54 LOAD_CONST               0 (None)\n             56 LOAD_CONST               9 (('loss', 'start_logits', 'end_logits', 'hidden_states', 'attentions'))\n             58 CALL_FUNCTION_KW         5\n             60 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              3 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             5\n             18 STORE_FAST            1372 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.MaskedLMOutput'>)\n             22 EXTENDED_ARG             5\n             24 LOAD_FAST             1372 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             5\n             32 LOAD_FAST             1372 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 LOAD_CONST               0 (None)\n             40 LOAD_CONST               0 (None)\n             42 LOAD_CONST               7 (('loss', 'logits', 'hidden_states', 'attentions'))\n             44 CALL_FUNCTION_KW         4\n             46 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              3 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('start_positions')\n             12 BINARY_SUBSCR\n             14 LOAD_FAST                2 (inputs)\n             16 LOAD_CONST               4 ('end_positions')\n             18 BINARY_SUBSCR\n             20 CALL_FUNCTION            3\n             22 EXTENDED_ARG             5\n             24 STORE_FAST            1371 (graph_out_0)\n             26 LOAD_CONST               5 (<class 'transformers.modeling_outputs.QuestionAnsweringModelOutput'>)\n             28 EXTENDED_ARG             5\n             30 LOAD_FAST             1371 (graph_out_0)\n             32 LOAD_CONST               6 (0)\n             34 BINARY_SUBSCR\n             36 EXTENDED_ARG             5\n             38 LOAD_FAST             1371 (graph_out_0)\n             40 LOAD_CONST               7 (1)\n             42 BINARY_SUBSCR\n             44 EXTENDED_ARG             5\n             46 LOAD_FAST             1371 (graph_out_0)\n             48 LOAD_CONST               8 (2)\n             50 BINARY_SUBSCR\n             52 LOAD_CONST               0 (None)\n             54 LOAD_CONST               0 (None)\n             56 LOAD_CONST               9 (('loss', 'start_logits', 'end_logits', 'hidden_states', 'attentions'))\n             58 CALL_FUNCTION_KW         5\n             60 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              4 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             1\n             18 STORE_FAST             267 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.MaskedLMOutput'>)\n             22 EXTENDED_ARG             1\n             24 LOAD_FAST              267 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             1\n             32 LOAD_FAST              267 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 LOAD_CONST               0 (None)\n             40 LOAD_CONST               0 (None)\n             42 LOAD_CONST               7 (('loss', 'logits', 'hidden_states', 'attentions'))\n             44 CALL_FUNCTION_KW         4\n             46 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              4 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('start_positions')\n             12 BINARY_SUBSCR\n             14 LOAD_FAST                2 (inputs)\n             16 LOAD_CONST               4 ('end_positions')\n             18 BINARY_SUBSCR\n             20 CALL_FUNCTION            3\n             22 EXTENDED_ARG             1\n             24 STORE_FAST             274 (graph_out_0)\n             26 LOAD_CONST               5 (<class 'transformers.modeling_outputs.QuestionAnsweringModelOutput'>)\n             28 EXTENDED_ARG             1\n             30 LOAD_FAST              274 (graph_out_0)\n             32 LOAD_CONST               6 (0)\n             34 BINARY_SUBSCR\n             36 EXTENDED_ARG             1\n             38 LOAD_FAST              274 (graph_out_0)\n             40 LOAD_CONST               7 (1)\n             42 BINARY_SUBSCR\n             44 EXTENDED_ARG             1\n             46 LOAD_FAST              274 (graph_out_0)\n             48 LOAD_CONST               8 (2)\n             50 BINARY_SUBSCR\n             52 LOAD_CONST               0 (None)\n             54 LOAD_CONST               0 (None)\n             56 LOAD_CONST               9 (('loss', 'start_logits', 'end_logits', 'hidden_states', 'attentions'))\n             58 CALL_FUNCTION_KW         5\n             60 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              5 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             1\n             18 STORE_FAST             488 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.CausalLMOutputWithCrossAttentions'>)\n             22 EXTENDED_ARG             1\n             24 LOAD_FAST              488 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             1\n             32 LOAD_FAST              488 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 EXTENDED_ARG             1\n             40 LOAD_FAST              488 (graph_out_0)\n             42 LOAD_CONST               7 (2)\n             44 BINARY_SUBSCR\n             46 EXTENDED_ARG             1\n             48 LOAD_FAST              488 (graph_out_0)\n             50 LOAD_CONST               8 (3)\n             52 BINARY_SUBSCR\n             54 BUILD_TUPLE              2\n             56 EXTENDED_ARG             1\n             58 LOAD_FAST              488 (graph_out_0)\n             60 LOAD_CONST               9 (4)\n             62 BINARY_SUBSCR\n             64 EXTENDED_ARG             1\n             66 LOAD_FAST              488 (graph_out_0)\n             68 LOAD_CONST              10 (5)\n             70 BINARY_SUBSCR\n             72 BUILD_TUPLE              2\n             74 EXTENDED_ARG             1\n             76 LOAD_FAST              488 (graph_out_0)\n             78 LOAD_CONST              11 (6)\n             80 BINARY_SUBSCR\n             82 EXTENDED_ARG             1\n             84 LOAD_FAST              488 (graph_out_0)\n             86 LOAD_CONST              12 (7)\n             88 BINARY_SUBSCR\n             90 BUILD_TUPLE              2\n             92 EXTENDED_ARG             1\n             94 LOAD_FAST              488 (graph_out_0)\n             96 LOAD_CONST              13 (8)\n             98 BINARY_SUBSCR\n            100 EXTENDED_ARG             1\n            102 LOAD_FAST              488 (graph_out_0)\n            104 LOAD_CONST              14 (9)\n            106 BINARY_SUBSCR\n            108 BUILD_TUPLE              2\n            110 EXTENDED_ARG             1\n            112 LOAD_FAST              488 (graph_out_0)\n            114 LOAD_CONST              15 (10)\n            116 BINARY_SUBSCR\n            118 EXTENDED_ARG             1\n            120 LOAD_FAST              488 (graph_out_0)\n            122 LOAD_CONST              16 (11)\n            124 BINARY_SUBSCR\n            126 BUILD_TUPLE              2\n            128 EXTENDED_ARG             1\n            130 LOAD_FAST              488 (graph_out_0)\n            132 LOAD_CONST              17 (12)\n            134 BINARY_SUBSCR\n            136 EXTENDED_ARG             1\n            138 LOAD_FAST              488 (graph_out_0)\n            140 LOAD_CONST              18 (13)\n            142 BINARY_SUBSCR\n            144 BUILD_TUPLE              2\n            146 BUILD_TUPLE              6\n            148 LOAD_CONST               0 (None)\n            150 LOAD_CONST               0 (None)\n            152 LOAD_CONST               0 (None)\n            154 LOAD_CONST              19 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              6 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             2\n             18 STORE_FAST             740 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.CausalLMOutputWithCrossAttentions'>)\n             22 EXTENDED_ARG             2\n             24 LOAD_FAST              740 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             2\n             32 LOAD_FAST              740 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 LOAD_CONST               0 (None)\n             40 LOAD_CONST               0 (None)\n             42 LOAD_CONST               0 (None)\n             44 LOAD_CONST               0 (None)\n             46 LOAD_CONST               7 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n             48 CALL_FUNCTION_KW         6\n             50 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              5 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('start_positions')\n             12 BINARY_SUBSCR\n             14 LOAD_FAST                2 (inputs)\n             16 LOAD_CONST               4 ('end_positions')\n             18 BINARY_SUBSCR\n             20 CALL_FUNCTION            3\n             22 EXTENDED_ARG             2\n             24 STORE_FAST             736 (graph_out_0)\n             26 LOAD_CONST               5 (<class 'transformers.modeling_outputs.QuestionAnsweringModelOutput'>)\n             28 EXTENDED_ARG             2\n             30 LOAD_FAST              736 (graph_out_0)\n             32 LOAD_CONST               6 (0)\n             34 BINARY_SUBSCR\n             36 EXTENDED_ARG             2\n             38 LOAD_FAST              736 (graph_out_0)\n             40 LOAD_CONST               7 (1)\n             42 BINARY_SUBSCR\n             44 EXTENDED_ARG             2\n             46 LOAD_FAST              736 (graph_out_0)\n             48 LOAD_CONST               8 (2)\n             50 BINARY_SUBSCR\n             52 LOAD_CONST               0 (None)\n             54 LOAD_CONST               0 (None)\n             56 LOAD_CONST               9 (('loss', 'start_logits', 'end_logits', 'hidden_states', 'attentions'))\n             58 CALL_FUNCTION_KW         5\n             60 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              5 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             3\n             18 STORE_FAST             926 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.SequenceClassifierOutputWithPast'>)\n             22 EXTENDED_ARG             3\n             24 LOAD_FAST              926 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             3\n             32 LOAD_FAST              926 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 EXTENDED_ARG             3\n             40 LOAD_FAST              926 (graph_out_0)\n             42 LOAD_CONST               7 (2)\n             44 BINARY_SUBSCR\n             46 EXTENDED_ARG             3\n             48 LOAD_FAST              926 (graph_out_0)\n             50 LOAD_CONST               8 (3)\n             52 BINARY_SUBSCR\n             54 BUILD_TUPLE              2\n             56 EXTENDED_ARG             3\n             58 LOAD_FAST              926 (graph_out_0)\n             60 LOAD_CONST               9 (4)\n             62 BINARY_SUBSCR\n             64 EXTENDED_ARG             3\n             66 LOAD_FAST              926 (graph_out_0)\n             68 LOAD_CONST              10 (5)\n             70 BINARY_SUBSCR\n             72 BUILD_TUPLE              2\n             74 EXTENDED_ARG             3\n             76 LOAD_FAST              926 (graph_out_0)\n             78 LOAD_CONST              11 (6)\n             80 BINARY_SUBSCR\n             82 EXTENDED_ARG             3\n             84 LOAD_FAST              926 (graph_out_0)\n             86 LOAD_CONST              12 (7)\n             88 BINARY_SUBSCR\n             90 BUILD_TUPLE              2\n             92 EXTENDED_ARG             3\n             94 LOAD_FAST              926 (graph_out_0)\n             96 LOAD_CONST              13 (8)\n             98 BINARY_SUBSCR\n            100 EXTENDED_ARG             3\n            102 LOAD_FAST              926 (graph_out_0)\n            104 LOAD_CONST              14 (9)\n            106 BINARY_SUBSCR\n            108 BUILD_TUPLE              2\n            110 EXTENDED_ARG             3\n            112 LOAD_FAST              926 (graph_out_0)\n            114 LOAD_CONST              15 (10)\n            116 BINARY_SUBSCR\n            118 EXTENDED_ARG             3\n            120 LOAD_FAST              926 (graph_out_0)\n            122 LOAD_CONST              16 (11)\n            124 BINARY_SUBSCR\n            126 BUILD_TUPLE              2\n            128 EXTENDED_ARG             3\n            130 LOAD_FAST              926 (graph_out_0)\n            132 LOAD_CONST              17 (12)\n            134 BINARY_SUBSCR\n            136 EXTENDED_ARG             3\n            138 LOAD_FAST              926 (graph_out_0)\n            140 LOAD_CONST              18 (13)\n            142 BINARY_SUBSCR\n            144 BUILD_TUPLE              2\n            146 EXTENDED_ARG             3\n            148 LOAD_FAST              926 (graph_out_0)\n            150 LOAD_CONST              19 (14)\n            152 BINARY_SUBSCR\n            154 EXTENDED_ARG             3\n            156 LOAD_FAST              926 (graph_out_0)\n            158 LOAD_CONST              20 (15)\n            160 BINARY_SUBSCR\n            162 BUILD_TUPLE              2\n            164 EXTENDED_ARG             3\n            166 LOAD_FAST              926 (graph_out_0)\n            168 LOAD_CONST              21 (16)\n            170 BINARY_SUBSCR\n            172 EXTENDED_ARG             3\n            174 LOAD_FAST              926 (graph_out_0)\n            176 LOAD_CONST              22 (17)\n            178 BINARY_SUBSCR\n            180 BUILD_TUPLE              2\n            182 EXTENDED_ARG             3\n            184 LOAD_FAST              926 (graph_out_0)\n            186 LOAD_CONST              23 (18)\n            188 BINARY_SUBSCR\n            190 EXTENDED_ARG             3\n            192 LOAD_FAST              926 (graph_out_0)\n            194 LOAD_CONST              24 (19)\n            196 BINARY_SUBSCR\n            198 BUILD_TUPLE              2\n            200 EXTENDED_ARG             3\n            202 LOAD_FAST              926 (graph_out_0)\n            204 LOAD_CONST              25 (20)\n            206 BINARY_SUBSCR\n            208 EXTENDED_ARG             3\n            210 LOAD_FAST              926 (graph_out_0)\n            212 LOAD_CONST              26 (21)\n            214 BINARY_SUBSCR\n            216 BUILD_TUPLE              2\n            218 EXTENDED_ARG             3\n            220 LOAD_FAST              926 (graph_out_0)\n            222 LOAD_CONST              27 (22)\n            224 BINARY_SUBSCR\n            226 EXTENDED_ARG             3\n            228 LOAD_FAST              926 (graph_out_0)\n            230 LOAD_CONST              28 (23)\n            232 BINARY_SUBSCR\n            234 BUILD_TUPLE              2\n            236 EXTENDED_ARG             3\n            238 LOAD_FAST              926 (graph_out_0)\n            240 LOAD_CONST              29 (24)\n            242 BINARY_SUBSCR\n            244 EXTENDED_ARG             3\n            246 LOAD_FAST              926 (graph_out_0)\n            248 LOAD_CONST              30 (25)\n            250 BINARY_SUBSCR\n            252 BUILD_TUPLE              2\n            254 BUILD_TUPLE             12\n            256 LOAD_CONST               0 (None)\n            258 LOAD_CONST               0 (None)\n            260 LOAD_CONST              31 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions'))\n            262 CALL_FUNCTION_KW         5\n            264 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              5 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             1\n             18 STORE_FAST             406 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.MaskedLMOutput'>)\n             22 EXTENDED_ARG             1\n             24 LOAD_FAST              406 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             1\n             32 LOAD_FAST              406 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 LOAD_CONST               0 (None)\n             40 LOAD_CONST               0 (None)\n             42 LOAD_CONST               7 (('loss', 'logits', 'hidden_states', 'attentions'))\n             44 CALL_FUNCTION_KW         4\n             46 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              5 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             2\n             18 STORE_FAST             759 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.MaskedLMOutput'>)\n             22 EXTENDED_ARG             2\n             24 LOAD_FAST              759 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             2\n             32 LOAD_FAST              759 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 LOAD_CONST               0 (None)\n             40 LOAD_CONST               0 (None)\n             42 LOAD_CONST               7 (('loss', 'logits', 'hidden_states', 'attentions'))\n             44 CALL_FUNCTION_KW         4\n             46 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              5 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             2\n             18 STORE_FAST             750 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.SequenceClassifierOutput'>)\n             22 EXTENDED_ARG             2\n             24 LOAD_FAST              750 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             2\n             32 LOAD_FAST              750 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 LOAD_CONST               0 (None)\n             40 LOAD_CONST               0 (None)\n             42 LOAD_CONST               7 (('loss', 'logits', 'hidden_states', 'attentions'))\n             44 CALL_FUNCTION_KW         4\n             46 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              4 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('decoder_input_ids')\n             12 BINARY_SUBSCR\n             14 LOAD_FAST                2 (inputs)\n             16 LOAD_CONST               4 ('labels')\n             18 BINARY_SUBSCR\n             20 CALL_FUNCTION            3\n             22 EXTENDED_ARG             6\n             24 STORE_FAST            1661 (graph_out_0)\n             26 LOAD_CONST               5 (<class 'transformers.modeling_outputs.Seq2SeqLMOutput'>)\n             28 EXTENDED_ARG             6\n             30 LOAD_FAST             1661 (graph_out_0)\n             32 LOAD_CONST               6 (0)\n             34 BINARY_SUBSCR\n             36 EXTENDED_ARG             6\n             38 LOAD_FAST             1661 (graph_out_0)\n             40 LOAD_CONST               7 (1)\n             42 BINARY_SUBSCR\n             44 EXTENDED_ARG             6\n             46 LOAD_FAST             1661 (graph_out_0)\n             48 LOAD_CONST               8 (2)\n             50 BINARY_SUBSCR\n             52 EXTENDED_ARG             6\n             54 LOAD_FAST             1661 (graph_out_0)\n             56 LOAD_CONST               9 (3)\n             58 BINARY_SUBSCR\n             60 EXTENDED_ARG             6\n             62 LOAD_FAST             1661 (graph_out_0)\n             64 LOAD_CONST              10 (4)\n             66 BINARY_SUBSCR\n             68 EXTENDED_ARG             6\n             70 LOAD_FAST             1661 (graph_out_0)\n             72 LOAD_CONST              11 (5)\n             74 BINARY_SUBSCR\n             76 BUILD_TUPLE              4\n             78 EXTENDED_ARG             6\n             80 LOAD_FAST             1661 (graph_out_0)\n             82 LOAD_CONST              12 (6)\n             84 BINARY_SUBSCR\n             86 EXTENDED_ARG             6\n             88 LOAD_FAST             1661 (graph_out_0)\n             90 LOAD_CONST              13 (7)\n             92 BINARY_SUBSCR\n             94 EXTENDED_ARG             6\n             96 LOAD_FAST             1661 (graph_out_0)\n             98 LOAD_CONST              14 (8)\n            100 BINARY_SUBSCR\n            102 EXTENDED_ARG             6\n            104 LOAD_FAST             1661 (graph_out_0)\n            106 LOAD_CONST              15 (9)\n            108 BINARY_SUBSCR\n            110 BUILD_TUPLE              4\n            112 EXTENDED_ARG             6\n            114 LOAD_FAST             1661 (graph_out_0)\n            116 LOAD_CONST              16 (10)\n            118 BINARY_SUBSCR\n            120 EXTENDED_ARG             6\n            122 LOAD_FAST             1661 (graph_out_0)\n            124 LOAD_CONST              17 (11)\n            126 BINARY_SUBSCR\n            128 EXTENDED_ARG             6\n            130 LOAD_FAST             1661 (graph_out_0)\n            132 LOAD_CONST              18 (12)\n            134 BINARY_SUBSCR\n            136 EXTENDED_ARG             6\n            138 LOAD_FAST             1661 (graph_out_0)\n            140 LOAD_CONST              19 (13)\n            142 BINARY_SUBSCR\n            144 BUILD_TUPLE              4\n            146 EXTENDED_ARG             6\n            148 LOAD_FAST             1661 (graph_out_0)\n            150 LOAD_CONST              20 (14)\n            152 BINARY_SUBSCR\n            154 EXTENDED_ARG             6\n            156 LOAD_FAST             1661 (graph_out_0)\n            158 LOAD_CONST              21 (15)\n            160 BINARY_SUBSCR\n            162 EXTENDED_ARG             6\n            164 LOAD_FAST             1661 (graph_out_0)\n            166 LOAD_CONST              22 (16)\n            168 BINARY_SUBSCR\n            170 EXTENDED_ARG             6\n            172 LOAD_FAST             1661 (graph_out_0)\n            174 LOAD_CONST              23 (17)\n            176 BINARY_SUBSCR\n            178 BUILD_TUPLE              4\n            180 EXTENDED_ARG             6\n            182 LOAD_FAST             1661 (graph_out_0)\n            184 LOAD_CONST              24 (18)\n            186 BINARY_SUBSCR\n            188 EXTENDED_ARG             6\n            190 LOAD_FAST             1661 (graph_out_0)\n            192 LOAD_CONST              25 (19)\n            194 BINARY_SUBSCR\n            196 EXTENDED_ARG             6\n            198 LOAD_FAST             1661 (graph_out_0)\n            200 LOAD_CONST              26 (20)\n            202 BINARY_SUBSCR\n            204 EXTENDED_ARG             6\n            206 LOAD_FAST             1661 (graph_out_0)\n            208 LOAD_CONST              27 (21)\n            210 BINARY_SUBSCR\n            212 BUILD_TUPLE              4\n            214 EXTENDED_ARG             6\n            216 LOAD_FAST             1661 (graph_out_0)\n            218 LOAD_CONST              28 (22)\n            220 BINARY_SUBSCR\n            222 EXTENDED_ARG             6\n            224 LOAD_FAST             1661 (graph_out_0)\n            226 LOAD_CONST              29 (23)\n            228 BINARY_SUBSCR\n            230 EXTENDED_ARG             6\n            232 LOAD_FAST             1661 (graph_out_0)\n            234 LOAD_CONST              30 (24)\n            236 BINARY_SUBSCR\n            238 EXTENDED_ARG             6\n            240 LOAD_FAST             1661 (graph_out_0)\n            242 LOAD_CONST              31 (25)\n            244 BINARY_SUBSCR\n            246 BUILD_TUPLE              4\n            248 EXTENDED_ARG             6\n            250 LOAD_FAST             1661 (graph_out_0)\n            252 LOAD_CONST              32 (26)\n            254 BINARY_SUBSCR\n            256 EXTENDED_ARG             6\n            258 LOAD_FAST             1661 (graph_out_0)\n            260 LOAD_CONST              33 (27)\n            262 BINARY_SUBSCR\n            264 EXTENDED_ARG             6\n            266 LOAD_FAST             1661 (graph_out_0)\n            268 LOAD_CONST              34 (28)\n            270 BINARY_SUBSCR\n            272 EXTENDED_ARG             6\n            274 LOAD_FAST             1661 (graph_out_0)\n            276 LOAD_CONST              35 (29)\n            278 BINARY_SUBSCR\n            280 BUILD_TUPLE              4\n            282 EXTENDED_ARG             6\n            284 LOAD_FAST             1661 (graph_out_0)\n            286 LOAD_CONST              36 (30)\n            288 BINARY_SUBSCR\n            290 EXTENDED_ARG             6\n            292 LOAD_FAST             1661 (graph_out_0)\n            294 LOAD_CONST              37 (31)\n            296 BINARY_SUBSCR\n            298 EXTENDED_ARG             6\n            300 LOAD_FAST             1661 (graph_out_0)\n            302 LOAD_CONST              38 (32)\n            304 BINARY_SUBSCR\n            306 EXTENDED_ARG             6\n            308 LOAD_FAST             1661 (graph_out_0)\n            310 LOAD_CONST              39 (33)\n            312 BINARY_SUBSCR\n            314 BUILD_TUPLE              4\n            316 EXTENDED_ARG             6\n            318 LOAD_FAST             1661 (graph_out_0)\n            320 LOAD_CONST              40 (34)\n            322 BINARY_SUBSCR\n            324 EXTENDED_ARG             6\n            326 LOAD_FAST             1661 (graph_out_0)\n            328 LOAD_CONST              41 (35)\n            330 BINARY_SUBSCR\n            332 EXTENDED_ARG             6\n            334 LOAD_FAST             1661 (graph_out_0)\n            336 LOAD_CONST              42 (36)\n            338 BINARY_SUBSCR\n            340 EXTENDED_ARG             6\n            342 LOAD_FAST             1661 (graph_out_0)\n            344 LOAD_CONST              43 (37)\n            346 BINARY_SUBSCR\n            348 BUILD_TUPLE              4\n            350 EXTENDED_ARG             6\n            352 LOAD_FAST             1661 (graph_out_0)\n            354 LOAD_CONST              44 (38)\n            356 BINARY_SUBSCR\n            358 EXTENDED_ARG             6\n            360 LOAD_FAST             1661 (graph_out_0)\n            362 LOAD_CONST              45 (39)\n            364 BINARY_SUBSCR\n            366 EXTENDED_ARG             6\n            368 LOAD_FAST             1661 (graph_out_0)\n            370 LOAD_CONST              46 (40)\n            372 BINARY_SUBSCR\n            374 EXTENDED_ARG             6\n            376 LOAD_FAST             1661 (graph_out_0)\n            378 LOAD_CONST              47 (41)\n            380 BINARY_SUBSCR\n            382 BUILD_TUPLE              4\n            384 EXTENDED_ARG             6\n            386 LOAD_FAST             1661 (graph_out_0)\n            388 LOAD_CONST              48 (42)\n            390 BINARY_SUBSCR\n            392 EXTENDED_ARG             6\n            394 LOAD_FAST             1661 (graph_out_0)\n            396 LOAD_CONST              49 (43)\n            398 BINARY_SUBSCR\n            400 EXTENDED_ARG             6\n            402 LOAD_FAST             1661 (graph_out_0)\n            404 LOAD_CONST              50 (44)\n            406 BINARY_SUBSCR\n            408 EXTENDED_ARG             6\n            410 LOAD_FAST             1661 (graph_out_0)\n            412 LOAD_CONST              51 (45)\n            414 BINARY_SUBSCR\n            416 BUILD_TUPLE              4\n            418 EXTENDED_ARG             6\n            420 LOAD_FAST             1661 (graph_out_0)\n            422 LOAD_CONST              52 (46)\n            424 BINARY_SUBSCR\n            426 EXTENDED_ARG             6\n            428 LOAD_FAST             1661 (graph_out_0)\n            430 LOAD_CONST              53 (47)\n            432 BINARY_SUBSCR\n            434 EXTENDED_ARG             6\n            436 LOAD_FAST             1661 (graph_out_0)\n            438 LOAD_CONST              54 (48)\n            440 BINARY_SUBSCR\n            442 EXTENDED_ARG             6\n            444 LOAD_FAST             1661 (graph_out_0)\n            446 LOAD_CONST              55 (49)\n            448 BINARY_SUBSCR\n            450 BUILD_TUPLE              4\n            452 BUILD_TUPLE             12\n            454 LOAD_CONST               0 (None)\n            456 LOAD_CONST               0 (None)\n            458 LOAD_CONST               0 (None)\n            460 EXTENDED_ARG             6\n            462 LOAD_FAST             1661 (graph_out_0)\n            464 LOAD_CONST              56 (50)\n            466 BINARY_SUBSCR\n            468 LOAD_CONST               0 (None)\n            470 LOAD_CONST               0 (None)\n            472 LOAD_CONST              57 (('loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n            474 CALL_FUNCTION_KW         9\n            476 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              4 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             2\n             18 STORE_FAST             686 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.CausalLMOutputWithCrossAttentions'>)\n             22 EXTENDED_ARG             2\n             24 LOAD_FAST              686 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             2\n             32 LOAD_FAST              686 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 EXTENDED_ARG             2\n             40 LOAD_FAST              686 (graph_out_0)\n             42 LOAD_CONST               7 (2)\n             44 BINARY_SUBSCR\n             46 EXTENDED_ARG             2\n             48 LOAD_FAST              686 (graph_out_0)\n             50 LOAD_CONST               8 (3)\n             52 BINARY_SUBSCR\n             54 BUILD_TUPLE              2\n             56 EXTENDED_ARG             2\n             58 LOAD_FAST              686 (graph_out_0)\n             60 LOAD_CONST               9 (4)\n             62 BINARY_SUBSCR\n             64 EXTENDED_ARG             2\n             66 LOAD_FAST              686 (graph_out_0)\n             68 LOAD_CONST              10 (5)\n             70 BINARY_SUBSCR\n             72 BUILD_TUPLE              2\n             74 EXTENDED_ARG             2\n             76 LOAD_FAST              686 (graph_out_0)\n             78 LOAD_CONST              11 (6)\n             80 BINARY_SUBSCR\n             82 EXTENDED_ARG             2\n             84 LOAD_FAST              686 (graph_out_0)\n             86 LOAD_CONST              12 (7)\n             88 BINARY_SUBSCR\n             90 BUILD_TUPLE              2\n             92 EXTENDED_ARG             2\n             94 LOAD_FAST              686 (graph_out_0)\n             96 LOAD_CONST              13 (8)\n             98 BINARY_SUBSCR\n            100 EXTENDED_ARG             2\n            102 LOAD_FAST              686 (graph_out_0)\n            104 LOAD_CONST              14 (9)\n            106 BINARY_SUBSCR\n            108 BUILD_TUPLE              2\n            110 EXTENDED_ARG             2\n            112 LOAD_FAST              686 (graph_out_0)\n            114 LOAD_CONST              15 (10)\n            116 BINARY_SUBSCR\n            118 EXTENDED_ARG             2\n            120 LOAD_FAST              686 (graph_out_0)\n            122 LOAD_CONST              16 (11)\n            124 BINARY_SUBSCR\n            126 BUILD_TUPLE              2\n            128 EXTENDED_ARG             2\n            130 LOAD_FAST              686 (graph_out_0)\n            132 LOAD_CONST              17 (12)\n            134 BINARY_SUBSCR\n            136 EXTENDED_ARG             2\n            138 LOAD_FAST              686 (graph_out_0)\n            140 LOAD_CONST              18 (13)\n            142 BINARY_SUBSCR\n            144 BUILD_TUPLE              2\n            146 EXTENDED_ARG             2\n            148 LOAD_FAST              686 (graph_out_0)\n            150 LOAD_CONST              19 (14)\n            152 BINARY_SUBSCR\n            154 EXTENDED_ARG             2\n            156 LOAD_FAST              686 (graph_out_0)\n            158 LOAD_CONST              20 (15)\n            160 BINARY_SUBSCR\n            162 BUILD_TUPLE              2\n            164 EXTENDED_ARG             2\n            166 LOAD_FAST              686 (graph_out_0)\n            168 LOAD_CONST              21 (16)\n            170 BINARY_SUBSCR\n            172 EXTENDED_ARG             2\n            174 LOAD_FAST              686 (graph_out_0)\n            176 LOAD_CONST              22 (17)\n            178 BINARY_SUBSCR\n            180 BUILD_TUPLE              2\n            182 EXTENDED_ARG             2\n            184 LOAD_FAST              686 (graph_out_0)\n            186 LOAD_CONST              23 (18)\n            188 BINARY_SUBSCR\n            190 EXTENDED_ARG             2\n            192 LOAD_FAST              686 (graph_out_0)\n            194 LOAD_CONST              24 (19)\n            196 BINARY_SUBSCR\n            198 BUILD_TUPLE              2\n            200 EXTENDED_ARG             2\n            202 LOAD_FAST              686 (graph_out_0)\n            204 LOAD_CONST              25 (20)\n            206 BINARY_SUBSCR\n            208 EXTENDED_ARG             2\n            210 LOAD_FAST              686 (graph_out_0)\n            212 LOAD_CONST              26 (21)\n            214 BINARY_SUBSCR\n            216 BUILD_TUPLE              2\n            218 EXTENDED_ARG             2\n            220 LOAD_FAST              686 (graph_out_0)\n            222 LOAD_CONST              27 (22)\n            224 BINARY_SUBSCR\n            226 EXTENDED_ARG             2\n            228 LOAD_FAST              686 (graph_out_0)\n            230 LOAD_CONST              28 (23)\n            232 BINARY_SUBSCR\n            234 BUILD_TUPLE              2\n            236 EXTENDED_ARG             2\n            238 LOAD_FAST              686 (graph_out_0)\n            240 LOAD_CONST              29 (24)\n            242 BINARY_SUBSCR\n            244 EXTENDED_ARG             2\n            246 LOAD_FAST              686 (graph_out_0)\n            248 LOAD_CONST              30 (25)\n            250 BINARY_SUBSCR\n            252 BUILD_TUPLE              2\n            254 BUILD_TUPLE             12\n            256 LOAD_CONST               0 (None)\n            258 LOAD_CONST               0 (None)\n            260 LOAD_CONST               0 (None)\n            262 LOAD_CONST              31 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n            264 CALL_FUNCTION_KW         6\n            266 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              4 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             6\n             18 STORE_FAST            1624 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.Seq2SeqLMOutput'>)\n             22 EXTENDED_ARG             6\n             24 LOAD_FAST             1624 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             6\n             32 LOAD_FAST             1624 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 LOAD_CONST               0 (None)\n             40 LOAD_CONST               0 (None)\n             42 LOAD_CONST               0 (None)\n             44 LOAD_CONST               0 (None)\n             46 EXTENDED_ARG             6\n             48 LOAD_FAST             1624 (graph_out_0)\n             50 LOAD_CONST               7 (2)\n             52 BINARY_SUBSCR\n             54 LOAD_CONST               0 (None)\n             56 LOAD_CONST               0 (None)\n             58 LOAD_CONST               8 (('loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             60 CALL_FUNCTION_KW         9\n             62 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL             14 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('decoder_input_ids')\n             12 BINARY_SUBSCR\n             14 LOAD_FAST                2 (inputs)\n             16 LOAD_CONST               4 ('labels')\n             18 BINARY_SUBSCR\n             20 CALL_FUNCTION            3\n             22 EXTENDED_ARG             5\n             24 STORE_FAST            1451 (graph_out_0)\n             26 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n             28 LOAD_ATTR                6 (make_cell)\n             30 CALL_FUNCTION            0\n             32 EXTENDED_ARG             5\n             34 STORE_FAST            1500 (tmp_48)\n             36 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n             38 LOAD_ATTR                6 (make_cell)\n             40 CALL_FUNCTION            0\n             42 EXTENDED_ARG             5\n             44 STORE_FAST            1501 (tmp_49)\n             46 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n             48 LOAD_ATTR                6 (make_cell)\n             50 CALL_FUNCTION            0\n             52 EXTENDED_ARG             5\n             54 STORE_FAST            1502 (tmp_50)\n             56 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n             58 LOAD_ATTR                6 (make_cell)\n             60 CALL_FUNCTION            0\n             62 EXTENDED_ARG             5\n             64 STORE_FAST            1503 (tmp_51)\n             66 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n             68 LOAD_ATTR                6 (make_cell)\n             70 CALL_FUNCTION            0\n             72 EXTENDED_ARG             5\n             74 STORE_FAST            1504 (tmp_52)\n             76 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n             78 LOAD_ATTR                6 (make_cell)\n             80 CALL_FUNCTION            0\n             82 EXTENDED_ARG             5\n             84 STORE_FAST            1505 (tmp_53)\n             86 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n             88 LOAD_ATTR                6 (make_cell)\n             90 CALL_FUNCTION            0\n             92 EXTENDED_ARG             5\n             94 STORE_FAST            1506 (tmp_54)\n             96 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n             98 LOAD_ATTR                6 (make_cell)\n            100 CALL_FUNCTION            0\n            102 EXTENDED_ARG             5\n            104 STORE_FAST            1507 (tmp_55)\n            106 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            108 LOAD_ATTR                6 (make_cell)\n            110 CALL_FUNCTION            0\n            112 EXTENDED_ARG             5\n            114 STORE_FAST            1508 (tmp_56)\n            116 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            118 LOAD_ATTR                6 (make_cell)\n            120 CALL_FUNCTION            0\n            122 EXTENDED_ARG             5\n            124 STORE_FAST            1509 (tmp_57)\n            126 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            128 LOAD_ATTR                6 (make_cell)\n            130 CALL_FUNCTION            0\n            132 EXTENDED_ARG             5\n            134 STORE_FAST            1510 (tmp_58)\n            136 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            138 LOAD_ATTR                6 (make_cell)\n            140 CALL_FUNCTION            0\n            142 EXTENDED_ARG             5\n            144 STORE_FAST            1511 (tmp_59)\n            146 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            148 LOAD_ATTR                6 (make_cell)\n            150 CALL_FUNCTION            0\n            152 EXTENDED_ARG             5\n            154 STORE_FAST            1512 (tmp_60)\n            156 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            158 LOAD_ATTR                6 (make_cell)\n            160 CALL_FUNCTION            0\n            162 EXTENDED_ARG             5\n            164 STORE_FAST            1513 (tmp_61)\n            166 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            168 LOAD_ATTR                6 (make_cell)\n            170 CALL_FUNCTION            0\n            172 EXTENDED_ARG             5\n            174 STORE_FAST            1514 (tmp_62)\n            176 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            178 LOAD_ATTR                6 (make_cell)\n            180 CALL_FUNCTION            0\n            182 EXTENDED_ARG             5\n            184 STORE_FAST            1515 (tmp_63)\n            186 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            188 LOAD_ATTR                6 (make_cell)\n            190 CALL_FUNCTION            0\n            192 EXTENDED_ARG             5\n            194 STORE_FAST            1516 (tmp_64)\n            196 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            198 LOAD_ATTR                6 (make_cell)\n            200 CALL_FUNCTION            0\n            202 EXTENDED_ARG             5\n            204 STORE_FAST            1517 (tmp_65)\n            206 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            208 LOAD_ATTR                6 (make_cell)\n            210 CALL_FUNCTION            0\n            212 EXTENDED_ARG             5\n            214 STORE_FAST            1518 (tmp_66)\n            216 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            218 LOAD_ATTR                6 (make_cell)\n            220 CALL_FUNCTION            0\n            222 EXTENDED_ARG             5\n            224 STORE_FAST            1519 (tmp_67)\n            226 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            228 LOAD_ATTR                6 (make_cell)\n            230 CALL_FUNCTION            0\n            232 EXTENDED_ARG             5\n            234 STORE_FAST            1520 (tmp_68)\n            236 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            238 LOAD_ATTR                6 (make_cell)\n            240 CALL_FUNCTION            0\n            242 EXTENDED_ARG             5\n            244 STORE_FAST            1521 (tmp_69)\n            246 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            248 LOAD_ATTR                6 (make_cell)\n            250 CALL_FUNCTION            0\n            252 EXTENDED_ARG             5\n            254 STORE_FAST            1522 (tmp_70)\n            256 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            258 LOAD_ATTR                6 (make_cell)\n            260 CALL_FUNCTION            0\n            262 EXTENDED_ARG             5\n            264 STORE_FAST            1523 (tmp_71)\n            266 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            268 LOAD_ATTR                6 (make_cell)\n            270 CALL_FUNCTION            0\n            272 EXTENDED_ARG             5\n            274 STORE_FAST            1524 (tmp_72)\n            276 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            278 LOAD_ATTR                6 (make_cell)\n            280 CALL_FUNCTION            0\n            282 EXTENDED_ARG             5\n            284 STORE_FAST            1525 (tmp_73)\n            286 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            288 LOAD_ATTR                6 (make_cell)\n            290 CALL_FUNCTION            0\n            292 EXTENDED_ARG             5\n            294 STORE_FAST            1526 (tmp_74)\n            296 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            298 LOAD_ATTR                6 (make_cell)\n            300 CALL_FUNCTION            0\n            302 EXTENDED_ARG             5\n            304 STORE_FAST            1527 (tmp_75)\n            306 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            308 LOAD_ATTR                6 (make_cell)\n            310 CALL_FUNCTION            0\n            312 EXTENDED_ARG             5\n            314 STORE_FAST            1528 (tmp_76)\n            316 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            318 LOAD_ATTR                6 (make_cell)\n            320 CALL_FUNCTION            0\n            322 EXTENDED_ARG             5\n            324 STORE_FAST            1529 (tmp_77)\n            326 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            328 LOAD_ATTR                6 (make_cell)\n            330 CALL_FUNCTION            0\n            332 EXTENDED_ARG             5\n            334 STORE_FAST            1530 (tmp_78)\n            336 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            338 LOAD_ATTR                6 (make_cell)\n            340 CALL_FUNCTION            0\n            342 EXTENDED_ARG             5\n            344 STORE_FAST            1531 (tmp_79)\n            346 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            348 LOAD_ATTR                6 (make_cell)\n            350 CALL_FUNCTION            0\n            352 EXTENDED_ARG             5\n            354 STORE_FAST            1532 (tmp_80)\n            356 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            358 LOAD_ATTR                6 (make_cell)\n            360 CALL_FUNCTION            0\n            362 EXTENDED_ARG             5\n            364 STORE_FAST            1533 (tmp_81)\n            366 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            368 LOAD_ATTR                6 (make_cell)\n            370 CALL_FUNCTION            0\n            372 EXTENDED_ARG             5\n            374 STORE_FAST            1534 (tmp_82)\n            376 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            378 LOAD_ATTR                6 (make_cell)\n            380 CALL_FUNCTION            0\n            382 EXTENDED_ARG             5\n            384 STORE_FAST            1535 (tmp_83)\n            386 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            388 LOAD_ATTR                6 (make_cell)\n            390 CALL_FUNCTION            0\n            392 EXTENDED_ARG             6\n            394 STORE_FAST            1536 (tmp_84)\n            396 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            398 LOAD_ATTR                6 (make_cell)\n            400 CALL_FUNCTION            0\n            402 EXTENDED_ARG             6\n            404 STORE_FAST            1537 (tmp_85)\n            406 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            408 LOAD_ATTR                6 (make_cell)\n            410 CALL_FUNCTION            0\n            412 EXTENDED_ARG             6\n            414 STORE_FAST            1538 (tmp_86)\n            416 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            418 LOAD_ATTR                6 (make_cell)\n            420 CALL_FUNCTION            0\n            422 EXTENDED_ARG             6\n            424 STORE_FAST            1539 (tmp_87)\n            426 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            428 LOAD_ATTR                6 (make_cell)\n            430 CALL_FUNCTION            0\n            432 EXTENDED_ARG             6\n            434 STORE_FAST            1540 (tmp_88)\n            436 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            438 LOAD_ATTR                6 (make_cell)\n            440 CALL_FUNCTION            0\n            442 EXTENDED_ARG             6\n            444 STORE_FAST            1541 (tmp_89)\n            446 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            448 LOAD_ATTR                6 (make_cell)\n            450 CALL_FUNCTION            0\n            452 EXTENDED_ARG             6\n            454 STORE_FAST            1542 (tmp_90)\n            456 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            458 LOAD_ATTR                6 (make_cell)\n            460 CALL_FUNCTION            0\n            462 EXTENDED_ARG             6\n            464 STORE_FAST            1543 (tmp_91)\n            466 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            468 LOAD_ATTR                6 (make_cell)\n            470 CALL_FUNCTION            0\n            472 EXTENDED_ARG             6\n            474 STORE_FAST            1544 (tmp_92)\n            476 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            478 LOAD_ATTR                6 (make_cell)\n            480 CALL_FUNCTION            0\n            482 EXTENDED_ARG             6\n            484 STORE_FAST            1545 (tmp_93)\n            486 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            488 LOAD_ATTR                6 (make_cell)\n            490 CALL_FUNCTION            0\n            492 EXTENDED_ARG             6\n            494 STORE_FAST            1546 (tmp_94)\n            496 LOAD_GLOBAL              5 (__import_torch_dot__dynamo_dot_utils)\n            498 LOAD_ATTR                6 (make_cell)\n            500 CALL_FUNCTION            0\n            502 EXTENDED_ARG             6\n            504 STORE_FAST            1547 (tmp_95)\n            506 LOAD_CONST               5 (<class 'transformers.modeling_outputs.Seq2SeqLMOutput'>)\n            508 EXTENDED_ARG             5\n            510 LOAD_FAST             1451 (graph_out_0)\n            512 LOAD_CONST               6 (0)\n            514 BINARY_SUBSCR\n            516 EXTENDED_ARG             5\n            518 LOAD_FAST             1451 (graph_out_0)\n            520 LOAD_CONST               7 (1)\n            522 BINARY_SUBSCR\n            524 EXTENDED_ARG             5\n            526 LOAD_FAST             1451 (graph_out_0)\n            528 LOAD_CONST               8 (2)\n            530 BINARY_SUBSCR\n            532 EXTENDED_ARG             5\n            534 LOAD_FAST             1451 (graph_out_0)\n            536 LOAD_CONST               9 (3)\n            538 BINARY_SUBSCR\n            540 EXTENDED_ARG             5\n            542 LOAD_FAST             1451 (graph_out_0)\n            544 LOAD_CONST              10 (4)\n            546 BINARY_SUBSCR\n            548 EXTENDED_ARG             5\n            550 LOAD_FAST             1451 (graph_out_0)\n            552 LOAD_CONST              11 (5)\n            554 BINARY_SUBSCR\n            556 BUILD_TUPLE              4\n            558 EXTENDED_ARG             5\n            560 LOAD_FAST             1451 (graph_out_0)\n            562 LOAD_CONST              12 (6)\n            564 BINARY_SUBSCR\n            566 EXTENDED_ARG             5\n            568 LOAD_FAST             1451 (graph_out_0)\n            570 LOAD_CONST              13 (7)\n            572 BINARY_SUBSCR\n            574 EXTENDED_ARG             5\n            576 LOAD_FAST             1451 (graph_out_0)\n            578 LOAD_CONST              14 (8)\n            580 BINARY_SUBSCR\n            582 EXTENDED_ARG             5\n            584 LOAD_FAST             1451 (graph_out_0)\n            586 LOAD_CONST              15 (9)\n            588 BINARY_SUBSCR\n            590 BUILD_TUPLE              4\n            592 EXTENDED_ARG             5\n            594 LOAD_FAST             1451 (graph_out_0)\n            596 LOAD_CONST              16 (10)\n            598 BINARY_SUBSCR\n            600 EXTENDED_ARG             5\n            602 LOAD_FAST             1451 (graph_out_0)\n            604 LOAD_CONST              17 (11)\n            606 BINARY_SUBSCR\n            608 EXTENDED_ARG             5\n            610 LOAD_FAST             1451 (graph_out_0)\n            612 LOAD_CONST              18 (12)\n            614 BINARY_SUBSCR\n            616 EXTENDED_ARG             5\n            618 LOAD_FAST             1451 (graph_out_0)\n            620 LOAD_CONST              19 (13)\n            622 BINARY_SUBSCR\n            624 BUILD_TUPLE              4\n            626 EXTENDED_ARG             5\n            628 LOAD_FAST             1451 (graph_out_0)\n            630 LOAD_CONST              20 (14)\n            632 BINARY_SUBSCR\n            634 EXTENDED_ARG             5\n            636 LOAD_FAST             1451 (graph_out_0)\n            638 LOAD_CONST              21 (15)\n            640 BINARY_SUBSCR\n            642 EXTENDED_ARG             5\n            644 LOAD_FAST             1451 (graph_out_0)\n            646 LOAD_CONST              22 (16)\n            648 BINARY_SUBSCR\n            650 EXTENDED_ARG             5\n            652 LOAD_FAST             1451 (graph_out_0)\n            654 LOAD_CONST              23 (17)\n            656 BINARY_SUBSCR\n            658 BUILD_TUPLE              4\n            660 EXTENDED_ARG             5\n            662 LOAD_FAST             1451 (graph_out_0)\n            664 LOAD_CONST              24 (18)\n            666 BINARY_SUBSCR\n            668 EXTENDED_ARG             5\n            670 LOAD_FAST             1451 (graph_out_0)\n            672 LOAD_CONST              25 (19)\n            674 BINARY_SUBSCR\n            676 EXTENDED_ARG             5\n            678 LOAD_FAST             1451 (graph_out_0)\n            680 LOAD_CONST              26 (20)\n            682 BINARY_SUBSCR\n            684 EXTENDED_ARG             5\n            686 LOAD_FAST             1451 (graph_out_0)\n            688 LOAD_CONST              27 (21)\n            690 BINARY_SUBSCR\n            692 BUILD_TUPLE              4\n            694 EXTENDED_ARG             5\n            696 LOAD_FAST             1451 (graph_out_0)\n            698 LOAD_CONST              28 (22)\n            700 BINARY_SUBSCR\n            702 EXTENDED_ARG             5\n            704 LOAD_FAST             1451 (graph_out_0)\n            706 LOAD_CONST              29 (23)\n            708 BINARY_SUBSCR\n            710 EXTENDED_ARG             5\n            712 LOAD_FAST             1451 (graph_out_0)\n            714 LOAD_CONST              30 (24)\n            716 BINARY_SUBSCR\n            718 EXTENDED_ARG             5\n            720 LOAD_FAST             1451 (graph_out_0)\n            722 LOAD_CONST              31 (25)\n            724 BINARY_SUBSCR\n            726 BUILD_TUPLE              4\n            728 EXTENDED_ARG             5\n            730 LOAD_FAST             1451 (graph_out_0)\n            732 LOAD_CONST              32 (26)\n            734 BINARY_SUBSCR\n            736 EXTENDED_ARG             5\n            738 LOAD_FAST             1451 (graph_out_0)\n            740 LOAD_CONST              33 (27)\n            742 BINARY_SUBSCR\n            744 EXTENDED_ARG             5\n            746 LOAD_FAST             1451 (graph_out_0)\n            748 LOAD_CONST              34 (28)\n            750 BINARY_SUBSCR\n            752 EXTENDED_ARG             5\n            754 LOAD_FAST             1451 (graph_out_0)\n            756 LOAD_CONST              35 (29)\n            758 BINARY_SUBSCR\n            760 BUILD_TUPLE              4\n            762 EXTENDED_ARG             5\n            764 LOAD_FAST             1451 (graph_out_0)\n            766 LOAD_CONST              36 (30)\n            768 BINARY_SUBSCR\n            770 EXTENDED_ARG             5\n            772 LOAD_FAST             1451 (graph_out_0)\n            774 LOAD_CONST              37 (31)\n            776 BINARY_SUBSCR\n            778 EXTENDED_ARG             5\n            780 LOAD_FAST             1451 (graph_out_0)\n            782 LOAD_CONST              38 (32)\n            784 BINARY_SUBSCR\n            786 EXTENDED_ARG             5\n            788 LOAD_FAST             1451 (graph_out_0)\n            790 LOAD_CONST              39 (33)\n            792 BINARY_SUBSCR\n            794 BUILD_TUPLE              4\n            796 BUILD_TUPLE              8\n            798 LOAD_CONST               0 (None)\n            800 LOAD_CONST               0 (None)\n            802 LOAD_CONST               0 (None)\n            804 EXTENDED_ARG             5\n            806 LOAD_FAST             1451 (graph_out_0)\n            808 LOAD_CONST              40 (34)\n            810 BINARY_SUBSCR\n            812 LOAD_CONST               0 (None)\n            814 LOAD_CONST               0 (None)\n            816 LOAD_CONST              41 (('loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n            818 CALL_FUNCTION_KW         9\n            820 LOAD_CONST              22 (16)\n            822 EXTENDED_ARG             5\n            824 LOAD_FAST             1500 (tmp_48)\n            826 LOAD_FAST                1 (mod)\n            828 LOAD_ATTR                8 (encoder)\n            830 LOAD_ATTR                9 (block)\n            832 LOAD_CONST               6 (0)\n            834 BINARY_SUBSCR\n            836 LOAD_ATTR               10 (layer)\n            838 LOAD_CONST               6 (0)\n            840 BINARY_SUBSCR\n            842 LOAD_ATTR               11 (SelfAttention)\n            844 EXTENDED_ARG             5\n            846 LOAD_FAST             1501 (tmp_49)\n            848 LOAD_CONST              22 (16)\n            850 EXTENDED_ARG             5\n            852 LOAD_FAST             1502 (tmp_50)\n            854 LOAD_FAST                1 (mod)\n            856 LOAD_ATTR                8 (encoder)\n            858 LOAD_ATTR                9 (block)\n            860 LOAD_CONST               7 (1)\n            862 BINARY_SUBSCR\n            864 LOAD_ATTR               10 (layer)\n            866 LOAD_CONST               6 (0)\n            868 BINARY_SUBSCR\n            870 LOAD_ATTR               11 (SelfAttention)\n            872 EXTENDED_ARG             5\n            874 LOAD_FAST             1503 (tmp_51)\n            876 LOAD_CONST              22 (16)\n            878 EXTENDED_ARG             5\n            880 LOAD_FAST             1504 (tmp_52)\n            882 LOAD_FAST                1 (mod)\n            884 LOAD_ATTR                8 (encoder)\n            886 LOAD_ATTR                9 (block)\n            888 LOAD_CONST               8 (2)\n            890 BINARY_SUBSCR\n            892 LOAD_ATTR               10 (layer)\n            894 LOAD_CONST               6 (0)\n            896 BINARY_SUBSCR\n            898 LOAD_ATTR               11 (SelfAttention)\n            900 EXTENDED_ARG             5\n            902 LOAD_FAST             1505 (tmp_53)\n            904 LOAD_CONST              22 (16)\n            906 EXTENDED_ARG             5\n            908 LOAD_FAST             1506 (tmp_54)\n            910 LOAD_FAST                1 (mod)\n            912 LOAD_ATTR                8 (encoder)\n            914 LOAD_ATTR                9 (block)\n            916 LOAD_CONST               9 (3)\n            918 BINARY_SUBSCR\n            920 LOAD_ATTR               10 (layer)\n            922 LOAD_CONST               6 (0)\n            924 BINARY_SUBSCR\n            926 LOAD_ATTR               11 (SelfAttention)\n            928 EXTENDED_ARG             5\n            930 LOAD_FAST             1507 (tmp_55)\n            932 LOAD_CONST              22 (16)\n            934 EXTENDED_ARG             5\n            936 LOAD_FAST             1508 (tmp_56)\n            938 LOAD_FAST                1 (mod)\n            940 LOAD_ATTR                8 (encoder)\n            942 LOAD_ATTR                9 (block)\n            944 LOAD_CONST              10 (4)\n            946 BINARY_SUBSCR\n            948 LOAD_ATTR               10 (layer)\n            950 LOAD_CONST               6 (0)\n            952 BINARY_SUBSCR\n            954 LOAD_ATTR               11 (SelfAttention)\n            956 EXTENDED_ARG             5\n            958 LOAD_FAST             1509 (tmp_57)\n            960 LOAD_CONST              22 (16)\n            962 EXTENDED_ARG             5\n            964 LOAD_FAST             1510 (tmp_58)\n            966 LOAD_FAST                1 (mod)\n            968 LOAD_ATTR                8 (encoder)\n            970 LOAD_ATTR                9 (block)\n            972 LOAD_CONST              11 (5)\n            974 BINARY_SUBSCR\n            976 LOAD_ATTR               10 (layer)\n            978 LOAD_CONST               6 (0)\n            980 BINARY_SUBSCR\n            982 LOAD_ATTR               11 (SelfAttention)\n            984 EXTENDED_ARG             5\n            986 LOAD_FAST             1511 (tmp_59)\n            988 LOAD_CONST              22 (16)\n            990 EXTENDED_ARG             5\n            992 LOAD_FAST             1512 (tmp_60)\n            994 LOAD_FAST                1 (mod)\n            996 LOAD_ATTR                8 (encoder)\n            998 LOAD_ATTR                9 (block)\n           1000 LOAD_CONST              12 (6)\n           1002 BINARY_SUBSCR\n           1004 LOAD_ATTR               10 (layer)\n           1006 LOAD_CONST               6 (0)\n           1008 BINARY_SUBSCR\n           1010 LOAD_ATTR               11 (SelfAttention)\n           1012 EXTENDED_ARG             5\n           1014 LOAD_FAST             1513 (tmp_61)\n           1016 LOAD_CONST              22 (16)\n           1018 EXTENDED_ARG             5\n           1020 LOAD_FAST             1514 (tmp_62)\n           1022 LOAD_FAST                1 (mod)\n           1024 LOAD_ATTR                8 (encoder)\n           1026 LOAD_ATTR                9 (block)\n           1028 LOAD_CONST              13 (7)\n           1030 BINARY_SUBSCR\n           1032 LOAD_ATTR               10 (layer)\n           1034 LOAD_CONST               6 (0)\n           1036 BINARY_SUBSCR\n           1038 LOAD_ATTR               11 (SelfAttention)\n           1040 EXTENDED_ARG             5\n           1042 LOAD_FAST             1515 (tmp_63)\n           1044 LOAD_CONST              22 (16)\n           1046 EXTENDED_ARG             5\n           1048 LOAD_FAST             1516 (tmp_64)\n           1050 LOAD_FAST                1 (mod)\n           1052 LOAD_ATTR               12 (decoder)\n           1054 LOAD_ATTR                9 (block)\n           1056 LOAD_CONST               6 (0)\n           1058 BINARY_SUBSCR\n           1060 LOAD_ATTR               10 (layer)\n           1062 LOAD_CONST               6 (0)\n           1064 BINARY_SUBSCR\n           1066 LOAD_ATTR               11 (SelfAttention)\n           1068 EXTENDED_ARG             5\n           1070 LOAD_FAST             1517 (tmp_65)\n           1072 LOAD_CONST              22 (16)\n           1074 EXTENDED_ARG             5\n           1076 LOAD_FAST             1518 (tmp_66)\n           1078 LOAD_FAST                1 (mod)\n           1080 LOAD_ATTR               12 (decoder)\n           1082 LOAD_ATTR                9 (block)\n           1084 LOAD_CONST               6 (0)\n           1086 BINARY_SUBSCR\n           1088 LOAD_ATTR               10 (layer)\n           1090 LOAD_CONST               7 (1)\n           1092 BINARY_SUBSCR\n           1094 LOAD_ATTR               13 (EncDecAttention)\n           1096 EXTENDED_ARG             5\n           1098 LOAD_FAST             1519 (tmp_67)\n           1100 LOAD_CONST              22 (16)\n           1102 EXTENDED_ARG             5\n           1104 LOAD_FAST             1520 (tmp_68)\n           1106 LOAD_FAST                1 (mod)\n           1108 LOAD_ATTR               12 (decoder)\n           1110 LOAD_ATTR                9 (block)\n           1112 LOAD_CONST               7 (1)\n           1114 BINARY_SUBSCR\n           1116 LOAD_ATTR               10 (layer)\n           1118 LOAD_CONST               6 (0)\n           1120 BINARY_SUBSCR\n           1122 LOAD_ATTR               11 (SelfAttention)\n           1124 EXTENDED_ARG             5\n           1126 LOAD_FAST             1521 (tmp_69)\n           1128 LOAD_CONST              22 (16)\n           1130 EXTENDED_ARG             5\n           1132 LOAD_FAST             1522 (tmp_70)\n           1134 LOAD_FAST                1 (mod)\n           1136 LOAD_ATTR               12 (decoder)\n           1138 LOAD_ATTR                9 (block)\n           1140 LOAD_CONST               7 (1)\n           1142 BINARY_SUBSCR\n           1144 LOAD_ATTR               10 (layer)\n           1146 LOAD_CONST               7 (1)\n           1148 BINARY_SUBSCR\n           1150 LOAD_ATTR               13 (EncDecAttention)\n           1152 EXTENDED_ARG             5\n           1154 LOAD_FAST             1523 (tmp_71)\n           1156 LOAD_CONST              22 (16)\n           1158 EXTENDED_ARG             5\n           1160 LOAD_FAST             1524 (tmp_72)\n           1162 LOAD_FAST                1 (mod)\n           1164 LOAD_ATTR               12 (decoder)\n           1166 LOAD_ATTR                9 (block)\n           1168 LOAD_CONST               8 (2)\n           1170 BINARY_SUBSCR\n           1172 LOAD_ATTR               10 (layer)\n           1174 LOAD_CONST               6 (0)\n           1176 BINARY_SUBSCR\n           1178 LOAD_ATTR               11 (SelfAttention)\n           1180 EXTENDED_ARG             5\n           1182 LOAD_FAST             1525 (tmp_73)\n           1184 LOAD_CONST              22 (16)\n           1186 EXTENDED_ARG             5\n           1188 LOAD_FAST             1526 (tmp_74)\n           1190 LOAD_FAST                1 (mod)\n           1192 LOAD_ATTR               12 (decoder)\n           1194 LOAD_ATTR                9 (block)\n           1196 LOAD_CONST               8 (2)\n           1198 BINARY_SUBSCR\n           1200 LOAD_ATTR               10 (layer)\n           1202 LOAD_CONST               7 (1)\n           1204 BINARY_SUBSCR\n           1206 LOAD_ATTR               13 (EncDecAttention)\n           1208 EXTENDED_ARG             5\n           1210 LOAD_FAST             1527 (tmp_75)\n           1212 LOAD_CONST              22 (16)\n           1214 EXTENDED_ARG             5\n           1216 LOAD_FAST             1528 (tmp_76)\n           1218 LOAD_FAST                1 (mod)\n           1220 LOAD_ATTR               12 (decoder)\n           1222 LOAD_ATTR                9 (block)\n           1224 LOAD_CONST               9 (3)\n           1226 BINARY_SUBSCR\n           1228 LOAD_ATTR               10 (layer)\n           1230 LOAD_CONST               6 (0)\n           1232 BINARY_SUBSCR\n           1234 LOAD_ATTR               11 (SelfAttention)\n           1236 EXTENDED_ARG             5\n           1238 LOAD_FAST             1529 (tmp_77)\n           1240 LOAD_CONST              22 (16)\n           1242 EXTENDED_ARG             5\n           1244 LOAD_FAST             1530 (tmp_78)\n           1246 LOAD_FAST                1 (mod)\n           1248 LOAD_ATTR               12 (decoder)\n           1250 LOAD_ATTR                9 (block)\n           1252 LOAD_CONST               9 (3)\n           1254 BINARY_SUBSCR\n           1256 LOAD_ATTR               10 (layer)\n           1258 LOAD_CONST               7 (1)\n           1260 BINARY_SUBSCR\n           1262 LOAD_ATTR               13 (EncDecAttention)\n           1264 EXTENDED_ARG             5\n           1266 LOAD_FAST             1531 (tmp_79)\n           1268 LOAD_CONST              22 (16)\n           1270 EXTENDED_ARG             5\n           1272 LOAD_FAST             1532 (tmp_80)\n           1274 LOAD_FAST                1 (mod)\n           1276 LOAD_ATTR               12 (decoder)\n           1278 LOAD_ATTR                9 (block)\n           1280 LOAD_CONST              10 (4)\n           1282 BINARY_SUBSCR\n           1284 LOAD_ATTR               10 (layer)\n           1286 LOAD_CONST               6 (0)\n           1288 BINARY_SUBSCR\n           1290 LOAD_ATTR               11 (SelfAttention)\n           1292 EXTENDED_ARG             5\n           1294 LOAD_FAST             1533 (tmp_81)\n           1296 LOAD_CONST              22 (16)\n           1298 EXTENDED_ARG             5\n           1300 LOAD_FAST             1534 (tmp_82)\n           1302 LOAD_FAST                1 (mod)\n           1304 LOAD_ATTR               12 (decoder)\n           1306 LOAD_ATTR                9 (block)\n           1308 LOAD_CONST              10 (4)\n           1310 BINARY_SUBSCR\n           1312 LOAD_ATTR               10 (layer)\n           1314 LOAD_CONST               7 (1)\n           1316 BINARY_SUBSCR\n           1318 LOAD_ATTR               13 (EncDecAttention)\n           1320 EXTENDED_ARG             5\n           1322 LOAD_FAST             1535 (tmp_83)\n           1324 LOAD_CONST              22 (16)\n           1326 EXTENDED_ARG             6\n           1328 LOAD_FAST             1536 (tmp_84)\n           1330 LOAD_FAST                1 (mod)\n           1332 LOAD_ATTR               12 (decoder)\n           1334 LOAD_ATTR                9 (block)\n           1336 LOAD_CONST              11 (5)\n           1338 BINARY_SUBSCR\n           1340 LOAD_ATTR               10 (layer)\n           1342 LOAD_CONST               6 (0)\n           1344 BINARY_SUBSCR\n           1346 LOAD_ATTR               11 (SelfAttention)\n           1348 EXTENDED_ARG             6\n           1350 LOAD_FAST             1537 (tmp_85)\n           1352 LOAD_CONST              22 (16)\n           1354 EXTENDED_ARG             6\n           1356 LOAD_FAST             1538 (tmp_86)\n           1358 LOAD_FAST                1 (mod)\n           1360 LOAD_ATTR               12 (decoder)\n           1362 LOAD_ATTR                9 (block)\n           1364 LOAD_CONST              11 (5)\n           1366 BINARY_SUBSCR\n           1368 LOAD_ATTR               10 (layer)\n           1370 LOAD_CONST               7 (1)\n           1372 BINARY_SUBSCR\n           1374 LOAD_ATTR               13 (EncDecAttention)\n           1376 EXTENDED_ARG             6\n           1378 LOAD_FAST             1539 (tmp_87)\n           1380 LOAD_CONST              22 (16)\n           1382 EXTENDED_ARG             6\n           1384 LOAD_FAST             1540 (tmp_88)\n           1386 LOAD_FAST                1 (mod)\n           1388 LOAD_ATTR               12 (decoder)\n           1390 LOAD_ATTR                9 (block)\n           1392 LOAD_CONST              12 (6)\n           1394 BINARY_SUBSCR\n           1396 LOAD_ATTR               10 (layer)\n           1398 LOAD_CONST               6 (0)\n           1400 BINARY_SUBSCR\n           1402 LOAD_ATTR               11 (SelfAttention)\n           1404 EXTENDED_ARG             6\n           1406 LOAD_FAST             1541 (tmp_89)\n           1408 LOAD_CONST              22 (16)\n           1410 EXTENDED_ARG             6\n           1412 LOAD_FAST             1542 (tmp_90)\n           1414 LOAD_FAST                1 (mod)\n           1416 LOAD_ATTR               12 (decoder)\n           1418 LOAD_ATTR                9 (block)\n           1420 LOAD_CONST              12 (6)\n           1422 BINARY_SUBSCR\n           1424 LOAD_ATTR               10 (layer)\n           1426 LOAD_CONST               7 (1)\n           1428 BINARY_SUBSCR\n           1430 LOAD_ATTR               13 (EncDecAttention)\n           1432 EXTENDED_ARG             6\n           1434 LOAD_FAST             1543 (tmp_91)\n           1436 LOAD_CONST              22 (16)\n           1438 EXTENDED_ARG             6\n           1440 LOAD_FAST             1544 (tmp_92)\n           1442 LOAD_FAST                1 (mod)\n           1444 LOAD_ATTR               12 (decoder)\n           1446 LOAD_ATTR                9 (block)\n           1448 LOAD_CONST              13 (7)\n           1450 BINARY_SUBSCR\n           1452 LOAD_ATTR               10 (layer)\n           1454 LOAD_CONST               6 (0)\n           1456 BINARY_SUBSCR\n           1458 LOAD_ATTR               11 (SelfAttention)\n           1460 EXTENDED_ARG             6\n           1462 LOAD_FAST             1545 (tmp_93)\n           1464 LOAD_CONST              22 (16)\n           1466 EXTENDED_ARG             6\n           1468 LOAD_FAST             1546 (tmp_94)\n           1470 LOAD_FAST                1 (mod)\n           1472 LOAD_ATTR               12 (decoder)\n           1474 LOAD_ATTR                9 (block)\n           1476 LOAD_CONST              13 (7)\n           1478 BINARY_SUBSCR\n           1480 LOAD_ATTR               10 (layer)\n           1482 LOAD_CONST               7 (1)\n           1484 BINARY_SUBSCR\n           1486 LOAD_ATTR               13 (EncDecAttention)\n           1488 EXTENDED_ARG             6\n           1490 LOAD_FAST             1547 (tmp_95)\n           1492 STORE_ATTR               7 (cell_contents)\n           1494 STORE_ATTR               7 (cell_contents)\n           1496 STORE_ATTR               7 (cell_contents)\n           1498 STORE_ATTR               7 (cell_contents)\n           1500 STORE_ATTR               7 (cell_contents)\n           1502 STORE_ATTR               7 (cell_contents)\n           1504 STORE_ATTR               7 (cell_contents)\n           1506 STORE_ATTR               7 (cell_contents)\n           1508 STORE_ATTR               7 (cell_contents)\n           1510 STORE_ATTR               7 (cell_contents)\n           1512 STORE_ATTR               7 (cell_contents)\n           1514 STORE_ATTR               7 (cell_contents)\n           1516 STORE_ATTR               7 (cell_contents)\n           1518 STORE_ATTR               7 (cell_contents)\n           1520 STORE_ATTR               7 (cell_contents)\n           1522 STORE_ATTR               7 (cell_contents)\n           1524 STORE_ATTR               7 (cell_contents)\n           1526 STORE_ATTR               7 (cell_contents)\n           1528 STORE_ATTR               7 (cell_contents)\n           1530 STORE_ATTR               7 (cell_contents)\n           1532 STORE_ATTR               7 (cell_contents)\n           1534 STORE_ATTR               7 (cell_contents)\n           1536 STORE_ATTR               7 (cell_contents)\n           1538 STORE_ATTR               7 (cell_contents)\n           1540 STORE_ATTR               7 (cell_contents)\n           1542 STORE_ATTR               7 (cell_contents)\n           1544 STORE_ATTR               7 (cell_contents)\n           1546 STORE_ATTR               7 (cell_contents)\n           1548 STORE_ATTR               7 (cell_contents)\n           1550 STORE_ATTR               7 (cell_contents)\n           1552 STORE_ATTR               7 (cell_contents)\n           1554 STORE_ATTR               7 (cell_contents)\n           1556 STORE_ATTR               7 (cell_contents)\n           1558 STORE_ATTR               7 (cell_contents)\n           1560 STORE_ATTR               7 (cell_contents)\n           1562 STORE_ATTR               7 (cell_contents)\n           1564 STORE_ATTR               7 (cell_contents)\n           1566 STORE_ATTR               7 (cell_contents)\n           1568 STORE_ATTR               7 (cell_contents)\n           1570 STORE_ATTR               7 (cell_contents)\n           1572 STORE_ATTR               7 (cell_contents)\n           1574 STORE_ATTR               7 (cell_contents)\n           1576 STORE_ATTR               7 (cell_contents)\n           1578 STORE_ATTR               7 (cell_contents)\n           1580 STORE_ATTR               7 (cell_contents)\n           1582 STORE_ATTR               7 (cell_contents)\n           1584 STORE_ATTR               7 (cell_contents)\n           1586 STORE_ATTR               7 (cell_contents)\n           1588 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              5 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             5\n             18 STORE_FAST            1418 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.CausalLMOutputWithCrossAttentions'>)\n             22 EXTENDED_ARG             5\n             24 LOAD_FAST             1418 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             5\n             32 LOAD_FAST             1418 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 LOAD_CONST               0 (None)\n             40 LOAD_CONST               0 (None)\n             42 LOAD_CONST               0 (None)\n             44 LOAD_CONST               0 (None)\n             46 LOAD_CONST               7 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n             48 CALL_FUNCTION_KW         6\n             50 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              5 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('start_positions')\n             12 BINARY_SUBSCR\n             14 LOAD_FAST                2 (inputs)\n             16 LOAD_CONST               4 ('end_positions')\n             18 BINARY_SUBSCR\n             20 CALL_FUNCTION            3\n             22 EXTENDED_ARG             5\n             24 STORE_FAST            1412 (graph_out_0)\n             26 LOAD_CONST               5 (<class 'transformers.modeling_outputs.QuestionAnsweringModelOutput'>)\n             28 EXTENDED_ARG             5\n             30 LOAD_FAST             1412 (graph_out_0)\n             32 LOAD_CONST               6 (0)\n             34 BINARY_SUBSCR\n             36 EXTENDED_ARG             5\n             38 LOAD_FAST             1412 (graph_out_0)\n             40 LOAD_CONST               7 (1)\n             42 BINARY_SUBSCR\n             44 EXTENDED_ARG             5\n             46 LOAD_FAST             1412 (graph_out_0)\n             48 LOAD_CONST               8 (2)\n             50 BINARY_SUBSCR\n             52 LOAD_CONST               0 (None)\n             54 LOAD_CONST               0 (None)\n             56 LOAD_CONST               9 (('loss', 'start_logits', 'end_logits', 'hidden_states', 'attentions'))\n             58 CALL_FUNCTION_KW         5\n             60 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              4 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG            10\n             18 STORE_FAST            2790 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.MaskedLMOutput'>)\n             22 EXTENDED_ARG            10\n             24 LOAD_FAST             2790 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG            10\n             32 LOAD_FAST             2790 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 LOAD_CONST               0 (None)\n             40 LOAD_CONST               0 (None)\n             42 LOAD_CONST               7 (('loss', 'logits', 'hidden_states', 'attentions'))\n             44 CALL_FUNCTION_KW         4\n             46 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              4 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('start_positions')\n             12 BINARY_SUBSCR\n             14 LOAD_FAST                2 (inputs)\n             16 LOAD_CONST               4 ('end_positions')\n             18 BINARY_SUBSCR\n             20 CALL_FUNCTION            3\n             22 EXTENDED_ARG            10\n             24 STORE_FAST            2789 (graph_out_0)\n             26 LOAD_CONST               5 (<class 'transformers.modeling_outputs.QuestionAnsweringModelOutput'>)\n             28 EXTENDED_ARG            10\n             30 LOAD_FAST             2789 (graph_out_0)\n             32 LOAD_CONST               6 (0)\n             34 BINARY_SUBSCR\n             36 EXTENDED_ARG            10\n             38 LOAD_FAST             2789 (graph_out_0)\n             40 LOAD_CONST               7 (1)\n             42 BINARY_SUBSCR\n             44 EXTENDED_ARG            10\n             46 LOAD_FAST             2789 (graph_out_0)\n             48 LOAD_CONST               8 (2)\n             50 BINARY_SUBSCR\n             52 LOAD_CONST               0 (None)\n             54 LOAD_CONST               0 (None)\n             56 LOAD_CONST               9 (('loss', 'start_logits', 'end_logits', 'hidden_states', 'attentions'))\n             58 CALL_FUNCTION_KW         5\n             60 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              4 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             2\n             18 STORE_FAST             679 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.CausalLMOutputWithPast'>)\n             22 EXTENDED_ARG             2\n             24 LOAD_FAST              679 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             2\n             32 LOAD_FAST              679 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 EXTENDED_ARG             2\n             40 LOAD_FAST              679 (graph_out_0)\n             42 LOAD_CONST               7 (2)\n             44 BINARY_SUBSCR\n             46 EXTENDED_ARG             2\n             48 LOAD_FAST              679 (graph_out_0)\n             50 LOAD_CONST               8 (3)\n             52 BINARY_SUBSCR\n             54 BUILD_TUPLE              2\n             56 EXTENDED_ARG             2\n             58 LOAD_FAST              679 (graph_out_0)\n             60 LOAD_CONST               9 (4)\n             62 BINARY_SUBSCR\n             64 EXTENDED_ARG             2\n             66 LOAD_FAST              679 (graph_out_0)\n             68 LOAD_CONST              10 (5)\n             70 BINARY_SUBSCR\n             72 BUILD_TUPLE              2\n             74 EXTENDED_ARG             2\n             76 LOAD_FAST              679 (graph_out_0)\n             78 LOAD_CONST              11 (6)\n             80 BINARY_SUBSCR\n             82 EXTENDED_ARG             2\n             84 LOAD_FAST              679 (graph_out_0)\n             86 LOAD_CONST              12 (7)\n             88 BINARY_SUBSCR\n             90 BUILD_TUPLE              2\n             92 EXTENDED_ARG             2\n             94 LOAD_FAST              679 (graph_out_0)\n             96 LOAD_CONST              13 (8)\n             98 BINARY_SUBSCR\n            100 EXTENDED_ARG             2\n            102 LOAD_FAST              679 (graph_out_0)\n            104 LOAD_CONST              14 (9)\n            106 BINARY_SUBSCR\n            108 BUILD_TUPLE              2\n            110 EXTENDED_ARG             2\n            112 LOAD_FAST              679 (graph_out_0)\n            114 LOAD_CONST              15 (10)\n            116 BINARY_SUBSCR\n            118 EXTENDED_ARG             2\n            120 LOAD_FAST              679 (graph_out_0)\n            122 LOAD_CONST              16 (11)\n            124 BINARY_SUBSCR\n            126 BUILD_TUPLE              2\n            128 EXTENDED_ARG             2\n            130 LOAD_FAST              679 (graph_out_0)\n            132 LOAD_CONST              17 (12)\n            134 BINARY_SUBSCR\n            136 EXTENDED_ARG             2\n            138 LOAD_FAST              679 (graph_out_0)\n            140 LOAD_CONST              18 (13)\n            142 BINARY_SUBSCR\n            144 BUILD_TUPLE              2\n            146 EXTENDED_ARG             2\n            148 LOAD_FAST              679 (graph_out_0)\n            150 LOAD_CONST              19 (14)\n            152 BINARY_SUBSCR\n            154 EXTENDED_ARG             2\n            156 LOAD_FAST              679 (graph_out_0)\n            158 LOAD_CONST              20 (15)\n            160 BINARY_SUBSCR\n            162 BUILD_TUPLE              2\n            164 EXTENDED_ARG             2\n            166 LOAD_FAST              679 (graph_out_0)\n            168 LOAD_CONST              21 (16)\n            170 BINARY_SUBSCR\n            172 EXTENDED_ARG             2\n            174 LOAD_FAST              679 (graph_out_0)\n            176 LOAD_CONST              22 (17)\n            178 BINARY_SUBSCR\n            180 BUILD_TUPLE              2\n            182 EXTENDED_ARG             2\n            184 LOAD_FAST              679 (graph_out_0)\n            186 LOAD_CONST              23 (18)\n            188 BINARY_SUBSCR\n            190 EXTENDED_ARG             2\n            192 LOAD_FAST              679 (graph_out_0)\n            194 LOAD_CONST              24 (19)\n            196 BINARY_SUBSCR\n            198 BUILD_TUPLE              2\n            200 EXTENDED_ARG             2\n            202 LOAD_FAST              679 (graph_out_0)\n            204 LOAD_CONST              25 (20)\n            206 BINARY_SUBSCR\n            208 EXTENDED_ARG             2\n            210 LOAD_FAST              679 (graph_out_0)\n            212 LOAD_CONST              26 (21)\n            214 BINARY_SUBSCR\n            216 BUILD_TUPLE              2\n            218 EXTENDED_ARG             2\n            220 LOAD_FAST              679 (graph_out_0)\n            222 LOAD_CONST              27 (22)\n            224 BINARY_SUBSCR\n            226 EXTENDED_ARG             2\n            228 LOAD_FAST              679 (graph_out_0)\n            230 LOAD_CONST              28 (23)\n            232 BINARY_SUBSCR\n            234 BUILD_TUPLE              2\n            236 EXTENDED_ARG             2\n            238 LOAD_FAST              679 (graph_out_0)\n            240 LOAD_CONST              29 (24)\n            242 BINARY_SUBSCR\n            244 EXTENDED_ARG             2\n            246 LOAD_FAST              679 (graph_out_0)\n            248 LOAD_CONST              30 (25)\n            250 BINARY_SUBSCR\n            252 BUILD_TUPLE              2\n            254 BUILD_TUPLE             12\n            256 LOAD_CONST               0 (None)\n            258 LOAD_CONST               0 (None)\n            260 LOAD_CONST              31 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions'))\n            262 CALL_FUNCTION_KW         5\n            264 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              4 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             1\n             18 STORE_FAST             374 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.CausalLMOutputWithCrossAttentions'>)\n             22 EXTENDED_ARG             1\n             24 LOAD_FAST              374 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             1\n             32 LOAD_FAST              374 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 EXTENDED_ARG             1\n             40 LOAD_FAST              374 (graph_out_0)\n             42 LOAD_CONST               7 (2)\n             44 BINARY_SUBSCR\n             46 EXTENDED_ARG             1\n             48 LOAD_FAST              374 (graph_out_0)\n             50 LOAD_CONST               8 (3)\n             52 BINARY_SUBSCR\n             54 BUILD_TUPLE              2\n             56 EXTENDED_ARG             1\n             58 LOAD_FAST              374 (graph_out_0)\n             60 LOAD_CONST               9 (4)\n             62 BINARY_SUBSCR\n             64 EXTENDED_ARG             1\n             66 LOAD_FAST              374 (graph_out_0)\n             68 LOAD_CONST              10 (5)\n             70 BINARY_SUBSCR\n             72 BUILD_TUPLE              2\n             74 EXTENDED_ARG             1\n             76 LOAD_FAST              374 (graph_out_0)\n             78 LOAD_CONST              11 (6)\n             80 BINARY_SUBSCR\n             82 EXTENDED_ARG             1\n             84 LOAD_FAST              374 (graph_out_0)\n             86 LOAD_CONST              12 (7)\n             88 BINARY_SUBSCR\n             90 BUILD_TUPLE              2\n             92 EXTENDED_ARG             1\n             94 LOAD_FAST              374 (graph_out_0)\n             96 LOAD_CONST              13 (8)\n             98 BINARY_SUBSCR\n            100 EXTENDED_ARG             1\n            102 LOAD_FAST              374 (graph_out_0)\n            104 LOAD_CONST              14 (9)\n            106 BINARY_SUBSCR\n            108 BUILD_TUPLE              2\n            110 EXTENDED_ARG             1\n            112 LOAD_FAST              374 (graph_out_0)\n            114 LOAD_CONST              15 (10)\n            116 BINARY_SUBSCR\n            118 EXTENDED_ARG             1\n            120 LOAD_FAST              374 (graph_out_0)\n            122 LOAD_CONST              16 (11)\n            124 BINARY_SUBSCR\n            126 BUILD_TUPLE              2\n            128 EXTENDED_ARG             1\n            130 LOAD_FAST              374 (graph_out_0)\n            132 LOAD_CONST              17 (12)\n            134 BINARY_SUBSCR\n            136 EXTENDED_ARG             1\n            138 LOAD_FAST              374 (graph_out_0)\n            140 LOAD_CONST              18 (13)\n            142 BINARY_SUBSCR\n            144 BUILD_TUPLE              2\n            146 BUILD_TUPLE              6\n            148 LOAD_CONST               0 (None)\n            150 LOAD_CONST               0 (None)\n            152 LOAD_CONST               0 (None)\n            154 LOAD_CONST              19 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              4 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             3\n             18 STORE_FAST             879 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.Seq2SeqLMOutput'>)\n             22 EXTENDED_ARG             3\n             24 LOAD_FAST              879 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             3\n             32 LOAD_FAST              879 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 EXTENDED_ARG             3\n             40 LOAD_FAST              879 (graph_out_0)\n             42 LOAD_CONST               7 (2)\n             44 BINARY_SUBSCR\n             46 EXTENDED_ARG             3\n             48 LOAD_FAST              879 (graph_out_0)\n             50 LOAD_CONST               8 (3)\n             52 BINARY_SUBSCR\n             54 EXTENDED_ARG             3\n             56 LOAD_FAST              879 (graph_out_0)\n             58 LOAD_CONST               9 (4)\n             60 BINARY_SUBSCR\n             62 EXTENDED_ARG             3\n             64 LOAD_FAST              879 (graph_out_0)\n             66 LOAD_CONST              10 (5)\n             68 BINARY_SUBSCR\n             70 BUILD_TUPLE              4\n             72 EXTENDED_ARG             3\n             74 LOAD_FAST              879 (graph_out_0)\n             76 LOAD_CONST              11 (6)\n             78 BINARY_SUBSCR\n             80 EXTENDED_ARG             3\n             82 LOAD_FAST              879 (graph_out_0)\n             84 LOAD_CONST              12 (7)\n             86 BINARY_SUBSCR\n             88 EXTENDED_ARG             3\n             90 LOAD_FAST              879 (graph_out_0)\n             92 LOAD_CONST              13 (8)\n             94 BINARY_SUBSCR\n             96 EXTENDED_ARG             3\n             98 LOAD_FAST              879 (graph_out_0)\n            100 LOAD_CONST              14 (9)\n            102 BINARY_SUBSCR\n            104 BUILD_TUPLE              4\n            106 EXTENDED_ARG             3\n            108 LOAD_FAST              879 (graph_out_0)\n            110 LOAD_CONST              15 (10)\n            112 BINARY_SUBSCR\n            114 EXTENDED_ARG             3\n            116 LOAD_FAST              879 (graph_out_0)\n            118 LOAD_CONST              16 (11)\n            120 BINARY_SUBSCR\n            122 EXTENDED_ARG             3\n            124 LOAD_FAST              879 (graph_out_0)\n            126 LOAD_CONST              17 (12)\n            128 BINARY_SUBSCR\n            130 EXTENDED_ARG             3\n            132 LOAD_FAST              879 (graph_out_0)\n            134 LOAD_CONST              18 (13)\n            136 BINARY_SUBSCR\n            138 BUILD_TUPLE              4\n            140 EXTENDED_ARG             3\n            142 LOAD_FAST              879 (graph_out_0)\n            144 LOAD_CONST              19 (14)\n            146 BINARY_SUBSCR\n            148 EXTENDED_ARG             3\n            150 LOAD_FAST              879 (graph_out_0)\n            152 LOAD_CONST              20 (15)\n            154 BINARY_SUBSCR\n            156 EXTENDED_ARG             3\n            158 LOAD_FAST              879 (graph_out_0)\n            160 LOAD_CONST              21 (16)\n            162 BINARY_SUBSCR\n            164 EXTENDED_ARG             3\n            166 LOAD_FAST              879 (graph_out_0)\n            168 LOAD_CONST              22 (17)\n            170 BINARY_SUBSCR\n            172 BUILD_TUPLE              4\n            174 EXTENDED_ARG             3\n            176 LOAD_FAST              879 (graph_out_0)\n            178 LOAD_CONST              23 (18)\n            180 BINARY_SUBSCR\n            182 EXTENDED_ARG             3\n            184 LOAD_FAST              879 (graph_out_0)\n            186 LOAD_CONST              24 (19)\n            188 BINARY_SUBSCR\n            190 EXTENDED_ARG             3\n            192 LOAD_FAST              879 (graph_out_0)\n            194 LOAD_CONST              25 (20)\n            196 BINARY_SUBSCR\n            198 EXTENDED_ARG             3\n            200 LOAD_FAST              879 (graph_out_0)\n            202 LOAD_CONST              26 (21)\n            204 BINARY_SUBSCR\n            206 BUILD_TUPLE              4\n            208 EXTENDED_ARG             3\n            210 LOAD_FAST              879 (graph_out_0)\n            212 LOAD_CONST              27 (22)\n            214 BINARY_SUBSCR\n            216 EXTENDED_ARG             3\n            218 LOAD_FAST              879 (graph_out_0)\n            220 LOAD_CONST              28 (23)\n            222 BINARY_SUBSCR\n            224 EXTENDED_ARG             3\n            226 LOAD_FAST              879 (graph_out_0)\n            228 LOAD_CONST              29 (24)\n            230 BINARY_SUBSCR\n            232 EXTENDED_ARG             3\n            234 LOAD_FAST              879 (graph_out_0)\n            236 LOAD_CONST              30 (25)\n            238 BINARY_SUBSCR\n            240 BUILD_TUPLE              4\n            242 BUILD_TUPLE              6\n            244 LOAD_CONST               0 (None)\n            246 LOAD_CONST               0 (None)\n            248 LOAD_CONST               0 (None)\n            250 EXTENDED_ARG             3\n            252 LOAD_FAST              879 (graph_out_0)\n            254 LOAD_CONST              31 (26)\n            256 BINARY_SUBSCR\n            258 LOAD_CONST               0 (None)\n            260 LOAD_CONST               0 (None)\n            262 LOAD_CONST              32 (('loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n            264 CALL_FUNCTION_KW         9\n            266 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              4 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             2\n             18 STORE_FAST             684 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.CausalLMOutputWithCrossAttentions'>)\n             22 EXTENDED_ARG             2\n             24 LOAD_FAST              684 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             2\n             32 LOAD_FAST              684 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 EXTENDED_ARG             2\n             40 LOAD_FAST              684 (graph_out_0)\n             42 LOAD_CONST               7 (2)\n             44 BINARY_SUBSCR\n             46 EXTENDED_ARG             2\n             48 LOAD_FAST              684 (graph_out_0)\n             50 LOAD_CONST               8 (3)\n             52 BINARY_SUBSCR\n             54 BUILD_TUPLE              2\n             56 EXTENDED_ARG             2\n             58 LOAD_FAST              684 (graph_out_0)\n             60 LOAD_CONST               9 (4)\n             62 BINARY_SUBSCR\n             64 EXTENDED_ARG             2\n             66 LOAD_FAST              684 (graph_out_0)\n             68 LOAD_CONST              10 (5)\n             70 BINARY_SUBSCR\n             72 BUILD_TUPLE              2\n             74 EXTENDED_ARG             2\n             76 LOAD_FAST              684 (graph_out_0)\n             78 LOAD_CONST              11 (6)\n             80 BINARY_SUBSCR\n             82 EXTENDED_ARG             2\n             84 LOAD_FAST              684 (graph_out_0)\n             86 LOAD_CONST              12 (7)\n             88 BINARY_SUBSCR\n             90 BUILD_TUPLE              2\n             92 EXTENDED_ARG             2\n             94 LOAD_FAST              684 (graph_out_0)\n             96 LOAD_CONST              13 (8)\n             98 BINARY_SUBSCR\n            100 EXTENDED_ARG             2\n            102 LOAD_FAST              684 (graph_out_0)\n            104 LOAD_CONST              14 (9)\n            106 BINARY_SUBSCR\n            108 BUILD_TUPLE              2\n            110 EXTENDED_ARG             2\n            112 LOAD_FAST              684 (graph_out_0)\n            114 LOAD_CONST              15 (10)\n            116 BINARY_SUBSCR\n            118 EXTENDED_ARG             2\n            120 LOAD_FAST              684 (graph_out_0)\n            122 LOAD_CONST              16 (11)\n            124 BINARY_SUBSCR\n            126 BUILD_TUPLE              2\n            128 EXTENDED_ARG             2\n            130 LOAD_FAST              684 (graph_out_0)\n            132 LOAD_CONST              17 (12)\n            134 BINARY_SUBSCR\n            136 EXTENDED_ARG             2\n            138 LOAD_FAST              684 (graph_out_0)\n            140 LOAD_CONST              18 (13)\n            142 BINARY_SUBSCR\n            144 BUILD_TUPLE              2\n            146 EXTENDED_ARG             2\n            148 LOAD_FAST              684 (graph_out_0)\n            150 LOAD_CONST              19 (14)\n            152 BINARY_SUBSCR\n            154 EXTENDED_ARG             2\n            156 LOAD_FAST              684 (graph_out_0)\n            158 LOAD_CONST              20 (15)\n            160 BINARY_SUBSCR\n            162 BUILD_TUPLE              2\n            164 EXTENDED_ARG             2\n            166 LOAD_FAST              684 (graph_out_0)\n            168 LOAD_CONST              21 (16)\n            170 BINARY_SUBSCR\n            172 EXTENDED_ARG             2\n            174 LOAD_FAST              684 (graph_out_0)\n            176 LOAD_CONST              22 (17)\n            178 BINARY_SUBSCR\n            180 BUILD_TUPLE              2\n            182 EXTENDED_ARG             2\n            184 LOAD_FAST              684 (graph_out_0)\n            186 LOAD_CONST              23 (18)\n            188 BINARY_SUBSCR\n            190 EXTENDED_ARG             2\n            192 LOAD_FAST              684 (graph_out_0)\n            194 LOAD_CONST              24 (19)\n            196 BINARY_SUBSCR\n            198 BUILD_TUPLE              2\n            200 EXTENDED_ARG             2\n            202 LOAD_FAST              684 (graph_out_0)\n            204 LOAD_CONST              25 (20)\n            206 BINARY_SUBSCR\n            208 EXTENDED_ARG             2\n            210 LOAD_FAST              684 (graph_out_0)\n            212 LOAD_CONST              26 (21)\n            214 BINARY_SUBSCR\n            216 BUILD_TUPLE              2\n            218 EXTENDED_ARG             2\n            220 LOAD_FAST              684 (graph_out_0)\n            222 LOAD_CONST              27 (22)\n            224 BINARY_SUBSCR\n            226 EXTENDED_ARG             2\n            228 LOAD_FAST              684 (graph_out_0)\n            230 LOAD_CONST              28 (23)\n            232 BINARY_SUBSCR\n            234 BUILD_TUPLE              2\n            236 EXTENDED_ARG             2\n            238 LOAD_FAST              684 (graph_out_0)\n            240 LOAD_CONST              29 (24)\n            242 BINARY_SUBSCR\n            244 EXTENDED_ARG             2\n            246 LOAD_FAST              684 (graph_out_0)\n            248 LOAD_CONST              30 (25)\n            250 BINARY_SUBSCR\n            252 BUILD_TUPLE              2\n            254 BUILD_TUPLE             12\n            256 LOAD_CONST               0 (None)\n            258 LOAD_CONST               0 (None)\n            260 LOAD_CONST               0 (None)\n            262 LOAD_CONST              31 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n            264 CALL_FUNCTION_KW         6\n            266 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              4 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('decoder_input_ids')\n             12 BINARY_SUBSCR\n             14 LOAD_FAST                2 (inputs)\n             16 LOAD_CONST               4 ('labels')\n             18 BINARY_SUBSCR\n             20 CALL_FUNCTION            3\n             22 EXTENDED_ARG             6\n             24 STORE_FAST            1616 (graph_out_0)\n             26 LOAD_CONST               5 (<class 'transformers.modeling_outputs.Seq2SeqLMOutput'>)\n             28 EXTENDED_ARG             6\n             30 LOAD_FAST             1616 (graph_out_0)\n             32 LOAD_CONST               6 (0)\n             34 BINARY_SUBSCR\n             36 EXTENDED_ARG             6\n             38 LOAD_FAST             1616 (graph_out_0)\n             40 LOAD_CONST               7 (1)\n             42 BINARY_SUBSCR\n             44 LOAD_CONST               0 (None)\n             46 LOAD_CONST               0 (None)\n             48 LOAD_CONST               0 (None)\n             50 LOAD_CONST               0 (None)\n             52 EXTENDED_ARG             6\n             54 LOAD_FAST             1616 (graph_out_0)\n             56 LOAD_CONST               8 (2)\n             58 BINARY_SUBSCR\n             60 LOAD_CONST               0 (None)\n             62 LOAD_CONST               0 (None)\n             64 LOAD_CONST               9 (('loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             66 CALL_FUNCTION_KW         9\n             68 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              2 (__import_contextlib)\n              2 LOAD_ATTR                3 (nullcontext)\n              4 LOAD_FAST                1 (mod)\n              6 LOAD_CONST               1 (())\n              8 LOAD_CONST               2 ('input_ids')\n             10 LOAD_FAST                2 (inputs)\n             12 LOAD_CONST               2 ('input_ids')\n             14 BINARY_SUBSCR\n             16 LOAD_CONST               3 ('labels')\n             18 LOAD_FAST                2 (inputs)\n             20 LOAD_CONST               3 ('labels')\n             22 BINARY_SUBSCR\n             24 BUILD_MAP                2\n             26 LOAD_GLOBAL              2 (__import_contextlib)\n             28 LOAD_ATTR                3 (nullcontext)\n             30 CALL_FUNCTION            0\n             32 STORE_FAST              14 (___context_manager_0_0)\n             34 LOAD_FAST               14 (___context_manager_0_0)\n             36 LOAD_METHOD              4 (__enter__)\n             38 CALL_METHOD              0\n             40 POP_TOP\n             42 SETUP_FINALLY           10 (to 64)\n\n551          44 CALL_FUNCTION_EX         1\n             46 POP_BLOCK\n             48 LOAD_FAST               14 (___context_manager_0_0)\n             50 LOAD_METHOD              5 (__exit__)\n             52 LOAD_CONST               0 (None)\n             54 DUP_TOP\n             56 DUP_TOP\n             58 CALL_METHOD              3\n             60 POP_TOP\n             62 JUMP_FORWARD             9 (to 82)\n        >>   64 NOP\n             66 LOAD_FAST               14 (___context_manager_0_0)\n             68 LOAD_METHOD              5 (__exit__)\n             70 LOAD_CONST               0 (None)\n             72 DUP_TOP\n             74 DUP_TOP\n             76 CALL_METHOD              3\n             78 POP_TOP\n             80 RERAISE                  0\n        >>   82 NOP\n             84 LOAD_GLOBAL              6 (__resume_at_22_1)\n             86 ROT_THREE\n             88 CALL_FUNCTION            2\n             90 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py line 896 \n896           0 LOAD_FAST                0 (self)\n              2 LOAD_ATTR                2 (roberta)\n              4 LOAD_FAST                1 (input_ids)\n              6 LOAD_FAST                2 (attention_mask)\n              8 LOAD_FAST                3 (token_type_ids)\n             10 LOAD_FAST                4 (position_ids)\n             12 LOAD_FAST                5 (head_mask)\n             14 LOAD_FAST                6 (inputs_embeds)\n             16 LOAD_FAST                7 (encoder_hidden_states)\n             18 LOAD_FAST                8 (encoder_attention_mask)\n             20 LOAD_FAST               10 (past_key_values)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_FAST               12 (output_attentions)\n             26 LOAD_FAST               13 (output_hidden_states)\n             28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (config)\n             32 LOAD_ATTR                1 (use_return_dict)\n             34 LOAD_CONST               3 (('attention_mask', 'token_type_ids', 'position_ids', 'head_mask', 'inputs_embeds', 'encoder_hidden_states', 'encoder_attention_mask', 'past_key_values', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                0 (config)\n             40 LOAD_ATTR                1 (use_return_dict)\n             42 STORE_FAST              14 (return_dict)\n\n962          44 CALL_FUNCTION_KW        13\n             46 LOAD_GLOBAL             16 (__resume_at_66_2)\n             48 ROT_TWO\n             50 LOAD_FAST                0 (self)\n             52 LOAD_FAST                9 (labels)\n             54 LOAD_FAST               14 (return_dict)\n             56 CALL_FUNCTION            4\n             58 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py line 734 \n734           0 LOAD_FAST                0 (self)\n              2 LOAD_ATTR                8 (warn_if_padding_and_no_attention_mask)\n              4 LOAD_FAST                1 (input_ids)\n              6 LOAD_FAST                2 (attention_mask)\n              8 LOAD_CONST               2 (False)\n             10 LOAD_FAST                0 (self)\n             12 LOAD_ATTR                0 (config)\n             14 LOAD_ATTR                1 (output_attentions)\n             16 LOAD_FAST                0 (self)\n             18 LOAD_ATTR                0 (config)\n             20 LOAD_ATTR                2 (output_hidden_states)\n             22 LOAD_GLOBAL             30 (__import_torch)\n             24 LOAD_ATTR               31 (Size)\n             26 LOAD_CONST              15 (16)\n             28 LOAD_CONST              16 (512)\n             30 BUILD_TUPLE              2\n             32 CALL_FUNCTION            1\n             34 STORE_FAST              14 (input_shape)\n             36 STORE_FAST              12 (output_hidden_states)\n             38 STORE_FAST              11 (output_attentions)\n             40 STORE_FAST              10 (use_cache)\n\n792          42 CALL_FUNCTION            2\n             44 LOAD_GLOBAL             32 (__resume_at_144_3)\n             46 ROT_TWO\n             48 LOAD_FAST                0 (self)\n             50 LOAD_FAST                1 (input_ids)\n             52 LOAD_FAST                2 (attention_mask)\n             54 LOAD_FAST                3 (token_type_ids)\n             56 LOAD_FAST                4 (position_ids)\n             58 LOAD_FAST                5 (head_mask)\n             60 LOAD_FAST                6 (inputs_embeds)\n             62 LOAD_FAST                7 (encoder_hidden_states)\n             64 LOAD_FAST                8 (encoder_attention_mask)\n             66 LOAD_FAST                9 (past_key_values)\n             68 LOAD_FAST               10 (use_cache)\n             70 LOAD_FAST               11 (output_attentions)\n             72 LOAD_FAST               12 (output_hidden_states)\n             74 LOAD_FAST               13 (return_dict)\n             76 LOAD_FAST               14 (input_shape)\n             78 CALL_FUNCTION           16\n             80 RETURN_VALUE\n\n", "MODIFIED BYTECODE warn_if_padding_and_no_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/modeling_utils.py line 3482 \n3490           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (config)\n               4 LOAD_ATTR                1 (pad_token_id)\n               6 LOAD_FAST                1 (input_ids)\n               8 LOAD_CONST               1 (None)\n              10 LOAD_CONST               1 (None)\n              12 BUILD_SLICE              2\n              14 LOAD_CONST               2 (-1)\n              16 LOAD_CONST               3 (0)\n              18 BUILD_LIST               2\n              20 BUILD_TUPLE              2\n              22 BINARY_SUBSCR\n              24 CONTAINS_OP              0\n              26 POP_JUMP_IF_FALSE       90 (to 180)\n\n3492          28 LOAD_CONST               4 ('We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.')\n\n3491          30 STORE_FAST               3 (warn_string)\n\n3500          32 LOAD_FAST                0 (self)\n              34 LOAD_ATTR                0 (config)\n              36 LOAD_ATTR                2 (bos_token_id)\n              38 LOAD_CONST               1 (None)\n              40 IS_OP                    1\n              42 POP_JUMP_IF_FALSE       30 (to 60)\n              44 LOAD_FAST                0 (self)\n              46 LOAD_ATTR                0 (config)\n              48 LOAD_ATTR                2 (bos_token_id)\n              50 LOAD_FAST                0 (self)\n              52 LOAD_ATTR                0 (config)\n              54 LOAD_ATTR                1 (pad_token_id)\n              56 COMPARE_OP               2 (==)\n              58 POP_JUMP_IF_TRUE        58 (to 116)\n\n3501     >>   60 LOAD_FAST                0 (self)\n              62 LOAD_ATTR                0 (config)\n              64 LOAD_ATTR                3 (eos_token_id)\n              66 LOAD_CONST               1 (None)\n              68 IS_OP                    1\n              70 POP_JUMP_IF_FALSE       44 (to 88)\n              72 LOAD_FAST                0 (self)\n              74 LOAD_ATTR                0 (config)\n              76 LOAD_ATTR                3 (eos_token_id)\n              78 LOAD_FAST                0 (self)\n              80 LOAD_ATTR                0 (config)\n              82 LOAD_ATTR                1 (pad_token_id)\n              84 COMPARE_OP               2 (==)\n              86 POP_JUMP_IF_TRUE        58 (to 116)\n\n3502     >>   88 LOAD_FAST                0 (self)\n              90 LOAD_ATTR                0 (config)\n              92 LOAD_ATTR                4 (sep_token_id)\n              94 LOAD_CONST               1 (None)\n              96 IS_OP                    1\n              98 POP_JUMP_IF_FALSE       83 (to 166)\n             100 LOAD_FAST                0 (self)\n             102 LOAD_ATTR                0 (config)\n             104 LOAD_ATTR                4 (sep_token_id)\n             106 LOAD_FAST                0 (self)\n             108 LOAD_ATTR                0 (config)\n             110 LOAD_ATTR                1 (pad_token_id)\n             112 COMPARE_OP               2 (==)\n             114 POP_JUMP_IF_FALSE       83 (to 166)\n\n3504     >>  116 LOAD_FAST                3 (warn_string)\n\n3505         118 LOAD_CONST               5 ('\\nYou may ignore this warning if your `pad_token_id` (')\n             120 LOAD_FAST                0 (self)\n             122 LOAD_ATTR                0 (config)\n             124 LOAD_ATTR                1 (pad_token_id)\n             126 FORMAT_VALUE             0\n             128 LOAD_CONST               6 (') is identical to the `bos_token_id` (')\n\n3506         130 LOAD_FAST                0 (self)\n             132 LOAD_ATTR                0 (config)\n             134 LOAD_ATTR                2 (bos_token_id)\n\n3505         136 FORMAT_VALUE             0\n             138 LOAD_CONST               7 ('), `eos_token_id` (')\n\n3506         140 LOAD_FAST                0 (self)\n             142 LOAD_ATTR                0 (config)\n             144 LOAD_ATTR                3 (eos_token_id)\n\n3505         146 FORMAT_VALUE             0\n             148 LOAD_CONST               8 ('), or the `sep_token_id` (')\n\n3507         150 LOAD_FAST                0 (self)\n             152 LOAD_ATTR                0 (config)\n             154 LOAD_ATTR                4 (sep_token_id)\n\n3505         156 FORMAT_VALUE             0\n             158 LOAD_CONST               9 ('), and your input is not padded.')\n             160 BUILD_STRING             9\n\n3504         162 INPLACE_ADD\n             164 STORE_FAST               3 (warn_string)\n\n3510     >>  166 LOAD_GLOBAL              5 (logger)\n             168 LOAD_ATTR                6 (warning_once)\n             170 LOAD_FAST                3 (warn_string)\n             172 CALL_FUNCTION            1\n             174 POP_TOP\n             176 LOAD_CONST               1 (None)\n             178 RETURN_VALUE\n\n3490     >>  180 LOAD_CONST               1 (None)\n             182 RETURN_VALUE\n\n", "MODIFIED BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py line 792 \n792           0 LOAD_GLOBAL             33 (__compiled_fn_4)\n              2 LOAD_FAST                2 (input_ids)\n              4 CALL_FUNCTION            1\n              6 EXTENDED_ARG             2\n              8 STORE_FAST             747 (graph_out_0)\n             10 LOAD_CONST              15 (<class 'transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions'>)\n             12 EXTENDED_ARG             2\n             14 LOAD_FAST              747 (graph_out_0)\n             16 LOAD_CONST               6 (0)\n             18 BINARY_SUBSCR\n             20 LOAD_CONST               1 (None)\n             22 LOAD_CONST               1 (None)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               1 (None)\n             28 LOAD_CONST               1 (None)\n             30 LOAD_CONST              16 (('last_hidden_state', 'pooler_output', 'hidden_states', 'past_key_values', 'attentions', 'cross_attentions'))\n             32 CALL_FUNCTION_KW         6\n             34 RETURN_VALUE\n\n", "MODIFIED BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py line 962 \n962           0 LOAD_GLOBAL             16 (__compiled_fn_5)\n              2 LOAD_FAST                0 (___stack0)\n              4 LOAD_ATTR               17 (last_hidden_state)\n              6 LOAD_FAST                2 (labels)\n              8 CALL_FUNCTION            2\n             10 STORE_FAST              38 (graph_out_0)\n             12 LOAD_CONST               9 (<class 'transformers.modeling_outputs.CausalLMOutputWithCrossAttentions'>)\n             14 LOAD_FAST               38 (graph_out_0)\n             16 LOAD_CONST               4 (0)\n             18 BINARY_SUBSCR\n             20 LOAD_FAST               38 (graph_out_0)\n             22 LOAD_CONST               6 (1)\n             24 BINARY_SUBSCR\n             26 LOAD_FAST                0 (___stack0)\n             28 LOAD_ATTR               11 (past_key_values)\n             30 LOAD_FAST                0 (___stack0)\n             32 LOAD_ATTR               12 (hidden_states)\n             34 LOAD_FAST                0 (___stack0)\n             36 LOAD_ATTR               13 (attentions)\n             38 LOAD_FAST                0 (___stack0)\n             40 LOAD_ATTR               14 (cross_attentions)\n             42 LOAD_CONST              10 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n             44 CALL_FUNCTION_KW         6\n             46 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              2 (__import_contextlib)\n              2 LOAD_ATTR                3 (nullcontext)\n              4 LOAD_FAST                1 (mod)\n              6 LOAD_CONST               1 (())\n              8 LOAD_CONST               2 ('input_ids')\n             10 LOAD_FAST                2 (inputs)\n             12 LOAD_CONST               2 ('input_ids')\n             14 BINARY_SUBSCR\n             16 LOAD_CONST               3 ('start_positions')\n             18 LOAD_FAST                2 (inputs)\n             20 LOAD_CONST               3 ('start_positions')\n             22 BINARY_SUBSCR\n             24 LOAD_CONST               4 ('end_positions')\n             26 LOAD_FAST                2 (inputs)\n             28 LOAD_CONST               4 ('end_positions')\n             30 BINARY_SUBSCR\n             32 BUILD_MAP                3\n             34 LOAD_GLOBAL              2 (__import_contextlib)\n             36 LOAD_ATTR                3 (nullcontext)\n             38 CALL_FUNCTION            0\n             40 STORE_FAST              13 (___context_manager_0_0)\n             42 LOAD_FAST               13 (___context_manager_0_0)\n             44 LOAD_METHOD              4 (__enter__)\n             46 CALL_METHOD              0\n             48 POP_TOP\n             50 SETUP_FINALLY           10 (to 72)\n\n551          52 CALL_FUNCTION_EX         1\n             54 POP_BLOCK\n             56 LOAD_FAST               13 (___context_manager_0_0)\n             58 LOAD_METHOD              5 (__exit__)\n             60 LOAD_CONST               0 (None)\n             62 DUP_TOP\n             64 DUP_TOP\n             66 CALL_METHOD              3\n             68 POP_TOP\n             70 JUMP_FORWARD             9 (to 90)\n        >>   72 NOP\n             74 LOAD_FAST               13 (___context_manager_0_0)\n             76 LOAD_METHOD              5 (__exit__)\n             78 LOAD_CONST               0 (None)\n             80 DUP_TOP\n             82 DUP_TOP\n             84 CALL_METHOD              3\n             86 POP_TOP\n             88 RERAISE                  0\n        >>   90 NOP\n             92 LOAD_GLOBAL              6 (__resume_at_22_1)\n             94 ROT_THREE\n             96 CALL_FUNCTION            2\n             98 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py line 1464 \n1464           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                2 (roberta)\n               4 LOAD_FAST                1 (input_ids)\n               6 LOAD_FAST                2 (attention_mask)\n               8 LOAD_FAST                3 (token_type_ids)\n              10 LOAD_FAST                4 (position_ids)\n              12 LOAD_FAST                5 (head_mask)\n              14 LOAD_FAST                6 (inputs_embeds)\n              16 LOAD_FAST                9 (output_attentions)\n              18 LOAD_FAST               10 (output_hidden_states)\n              20 LOAD_FAST                0 (self)\n              22 LOAD_ATTR                0 (config)\n              24 LOAD_ATTR                1 (use_return_dict)\n              26 LOAD_CONST               2 (('attention_mask', 'token_type_ids', 'position_ids', 'head_mask', 'inputs_embeds', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              28 LOAD_FAST                0 (self)\n              30 LOAD_ATTR                0 (config)\n              32 LOAD_ATTR                1 (use_return_dict)\n              34 STORE_FAST              11 (return_dict)\n\n1498          36 CALL_FUNCTION_KW         9\n              38 LOAD_GLOBAL             15 (__resume_at_46_2)\n              40 ROT_TWO\n              42 LOAD_FAST                0 (self)\n              44 LOAD_FAST                7 (start_positions)\n              46 LOAD_FAST                8 (end_positions)\n              48 LOAD_FAST               11 (return_dict)\n              50 CALL_FUNCTION            5\n              52 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py line 734 \n734           0 LOAD_FAST                0 (self)\n              2 LOAD_ATTR                8 (warn_if_padding_and_no_attention_mask)\n              4 LOAD_FAST                1 (input_ids)\n              6 LOAD_FAST                2 (attention_mask)\n              8 LOAD_CONST               2 (False)\n             10 LOAD_FAST                0 (self)\n             12 LOAD_ATTR                0 (config)\n             14 LOAD_ATTR                1 (output_attentions)\n             16 LOAD_FAST                0 (self)\n             18 LOAD_ATTR                0 (config)\n             20 LOAD_ATTR                2 (output_hidden_states)\n             22 LOAD_GLOBAL             30 (__import_torch)\n             24 LOAD_ATTR               31 (Size)\n             26 LOAD_CONST              15 (16)\n             28 LOAD_CONST              16 (512)\n             30 BUILD_TUPLE              2\n             32 CALL_FUNCTION            1\n             34 STORE_FAST              14 (input_shape)\n             36 STORE_FAST              12 (output_hidden_states)\n             38 STORE_FAST              11 (output_attentions)\n             40 STORE_FAST              10 (use_cache)\n\n792          42 CALL_FUNCTION            2\n             44 LOAD_GLOBAL             32 (__resume_at_144_3)\n             46 ROT_TWO\n             48 LOAD_FAST                0 (self)\n             50 LOAD_FAST                1 (input_ids)\n             52 LOAD_FAST                2 (attention_mask)\n             54 LOAD_FAST                3 (token_type_ids)\n             56 LOAD_FAST                4 (position_ids)\n             58 LOAD_FAST                5 (head_mask)\n             60 LOAD_FAST                6 (inputs_embeds)\n             62 LOAD_FAST                7 (encoder_hidden_states)\n             64 LOAD_FAST                8 (encoder_attention_mask)\n             66 LOAD_FAST                9 (past_key_values)\n             68 LOAD_FAST               10 (use_cache)\n             70 LOAD_FAST               11 (output_attentions)\n             72 LOAD_FAST               12 (output_hidden_states)\n             74 LOAD_FAST               13 (return_dict)\n             76 LOAD_FAST               14 (input_shape)\n             78 CALL_FUNCTION           16\n             80 RETURN_VALUE\n\n", "MODIFIED BYTECODE warn_if_padding_and_no_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/modeling_utils.py line 3482 \n3490           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (config)\n               4 LOAD_ATTR                1 (pad_token_id)\n               6 LOAD_FAST                1 (input_ids)\n               8 LOAD_CONST               1 (None)\n              10 LOAD_CONST               1 (None)\n              12 BUILD_SLICE              2\n              14 LOAD_CONST               2 (-1)\n              16 LOAD_CONST               3 (0)\n              18 BUILD_LIST               2\n              20 BUILD_TUPLE              2\n              22 BINARY_SUBSCR\n              24 CONTAINS_OP              0\n              26 POP_JUMP_IF_FALSE       90 (to 180)\n\n3492          28 LOAD_CONST               4 ('We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.')\n\n3491          30 STORE_FAST               3 (warn_string)\n\n3500          32 LOAD_FAST                0 (self)\n              34 LOAD_ATTR                0 (config)\n              36 LOAD_ATTR                2 (bos_token_id)\n              38 LOAD_CONST               1 (None)\n              40 IS_OP                    1\n              42 POP_JUMP_IF_FALSE       30 (to 60)\n              44 LOAD_FAST                0 (self)\n              46 LOAD_ATTR                0 (config)\n              48 LOAD_ATTR                2 (bos_token_id)\n              50 LOAD_FAST                0 (self)\n              52 LOAD_ATTR                0 (config)\n              54 LOAD_ATTR                1 (pad_token_id)\n              56 COMPARE_OP               2 (==)\n              58 POP_JUMP_IF_TRUE        58 (to 116)\n\n3501     >>   60 LOAD_FAST                0 (self)\n              62 LOAD_ATTR                0 (config)\n              64 LOAD_ATTR                3 (eos_token_id)\n              66 LOAD_CONST               1 (None)\n              68 IS_OP                    1\n              70 POP_JUMP_IF_FALSE       44 (to 88)\n              72 LOAD_FAST                0 (self)\n              74 LOAD_ATTR                0 (config)\n              76 LOAD_ATTR                3 (eos_token_id)\n              78 LOAD_FAST                0 (self)\n              80 LOAD_ATTR                0 (config)\n              82 LOAD_ATTR                1 (pad_token_id)\n              84 COMPARE_OP               2 (==)\n              86 POP_JUMP_IF_TRUE        58 (to 116)\n\n3502     >>   88 LOAD_FAST                0 (self)\n              90 LOAD_ATTR                0 (config)\n              92 LOAD_ATTR                4 (sep_token_id)\n              94 LOAD_CONST               1 (None)\n              96 IS_OP                    1\n              98 POP_JUMP_IF_FALSE       83 (to 166)\n             100 LOAD_FAST                0 (self)\n             102 LOAD_ATTR                0 (config)\n             104 LOAD_ATTR                4 (sep_token_id)\n             106 LOAD_FAST                0 (self)\n             108 LOAD_ATTR                0 (config)\n             110 LOAD_ATTR                1 (pad_token_id)\n             112 COMPARE_OP               2 (==)\n             114 POP_JUMP_IF_FALSE       83 (to 166)\n\n3504     >>  116 LOAD_FAST                3 (warn_string)\n\n3505         118 LOAD_CONST               5 ('\\nYou may ignore this warning if your `pad_token_id` (')\n             120 LOAD_FAST                0 (self)\n             122 LOAD_ATTR                0 (config)\n             124 LOAD_ATTR                1 (pad_token_id)\n             126 FORMAT_VALUE             0\n             128 LOAD_CONST               6 (') is identical to the `bos_token_id` (')\n\n3506         130 LOAD_FAST                0 (self)\n             132 LOAD_ATTR                0 (config)\n             134 LOAD_ATTR                2 (bos_token_id)\n\n3505         136 FORMAT_VALUE             0\n             138 LOAD_CONST               7 ('), `eos_token_id` (')\n\n3506         140 LOAD_FAST                0 (self)\n             142 LOAD_ATTR                0 (config)\n             144 LOAD_ATTR                3 (eos_token_id)\n\n3505         146 FORMAT_VALUE             0\n             148 LOAD_CONST               8 ('), or the `sep_token_id` (')\n\n3507         150 LOAD_FAST                0 (self)\n             152 LOAD_ATTR                0 (config)\n             154 LOAD_ATTR                4 (sep_token_id)\n\n3505         156 FORMAT_VALUE             0\n             158 LOAD_CONST               9 ('), and your input is not padded.')\n             160 BUILD_STRING             9\n\n3504         162 INPLACE_ADD\n             164 STORE_FAST               3 (warn_string)\n\n3510     >>  166 LOAD_GLOBAL              5 (logger)\n             168 LOAD_ATTR                6 (warning_once)\n             170 LOAD_FAST                3 (warn_string)\n             172 CALL_FUNCTION            1\n             174 POP_TOP\n             176 LOAD_CONST               1 (None)\n             178 RETURN_VALUE\n\n3490     >>  180 LOAD_CONST               1 (None)\n             182 RETURN_VALUE\n\n", "MODIFIED BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py line 792 \n792           0 LOAD_GLOBAL             33 (__compiled_fn_4)\n              2 LOAD_FAST                2 (input_ids)\n              4 CALL_FUNCTION            1\n              6 EXTENDED_ARG             2\n              8 STORE_FAST             747 (graph_out_0)\n             10 LOAD_CONST              15 (<class 'transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions'>)\n             12 EXTENDED_ARG             2\n             14 LOAD_FAST              747 (graph_out_0)\n             16 LOAD_CONST               6 (0)\n             18 BINARY_SUBSCR\n             20 LOAD_CONST               1 (None)\n             22 LOAD_CONST               1 (None)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               1 (None)\n             28 LOAD_CONST               1 (None)\n             30 LOAD_CONST              16 (('last_hidden_state', 'pooler_output', 'hidden_states', 'past_key_values', 'attentions', 'cross_attentions'))\n             32 CALL_FUNCTION_KW         6\n             34 RETURN_VALUE\n\n", "MODIFIED BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py line 1498 \n1498           0 LOAD_GLOBAL             14 (__compiled_fn_5)\n               2 LOAD_FAST                0 (___stack0)\n               4 LOAD_ATTR               15 (last_hidden_state)\n               6 LOAD_FAST                2 (start_positions)\n               8 LOAD_FAST                3 (end_positions)\n              10 CALL_FUNCTION            3\n              12 STORE_FAST              39 (graph_out_0)\n              14 LOAD_CONST              10 (<class 'transformers.modeling_outputs.QuestionAnsweringModelOutput'>)\n              16 LOAD_FAST               39 (graph_out_0)\n              18 LOAD_CONST               3 (0)\n              20 BINARY_SUBSCR\n              22 LOAD_FAST               39 (graph_out_0)\n              24 LOAD_CONST               4 (1)\n              26 BINARY_SUBSCR\n              28 LOAD_FAST               39 (graph_out_0)\n              30 LOAD_CONST               8 (2)\n              32 BINARY_SUBSCR\n              34 LOAD_FAST                0 (___stack0)\n              36 LOAD_ATTR               12 (hidden_states)\n              38 LOAD_FAST                0 (___stack0)\n              40 LOAD_ATTR               13 (attentions)\n              42 LOAD_CONST              11 (('loss', 'start_logits', 'end_logits', 'hidden_states', 'attentions'))\n              44 CALL_FUNCTION_KW         5\n              46 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              3 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             1\n             18 STORE_FAST             367 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.CausalLMOutputWithCrossAttentions'>)\n             22 EXTENDED_ARG             1\n             24 LOAD_FAST              367 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             1\n             32 LOAD_FAST              367 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 EXTENDED_ARG             1\n             40 LOAD_FAST              367 (graph_out_0)\n             42 LOAD_CONST               7 (2)\n             44 BINARY_SUBSCR\n             46 EXTENDED_ARG             1\n             48 LOAD_FAST              367 (graph_out_0)\n             50 LOAD_CONST               8 (3)\n             52 BINARY_SUBSCR\n             54 BUILD_TUPLE              2\n             56 EXTENDED_ARG             1\n             58 LOAD_FAST              367 (graph_out_0)\n             60 LOAD_CONST               9 (4)\n             62 BINARY_SUBSCR\n             64 EXTENDED_ARG             1\n             66 LOAD_FAST              367 (graph_out_0)\n             68 LOAD_CONST              10 (5)\n             70 BINARY_SUBSCR\n             72 BUILD_TUPLE              2\n             74 EXTENDED_ARG             1\n             76 LOAD_FAST              367 (graph_out_0)\n             78 LOAD_CONST              11 (6)\n             80 BINARY_SUBSCR\n             82 EXTENDED_ARG             1\n             84 LOAD_FAST              367 (graph_out_0)\n             86 LOAD_CONST              12 (7)\n             88 BINARY_SUBSCR\n             90 BUILD_TUPLE              2\n             92 EXTENDED_ARG             1\n             94 LOAD_FAST              367 (graph_out_0)\n             96 LOAD_CONST              13 (8)\n             98 BINARY_SUBSCR\n            100 EXTENDED_ARG             1\n            102 LOAD_FAST              367 (graph_out_0)\n            104 LOAD_CONST              14 (9)\n            106 BINARY_SUBSCR\n            108 BUILD_TUPLE              2\n            110 EXTENDED_ARG             1\n            112 LOAD_FAST              367 (graph_out_0)\n            114 LOAD_CONST              15 (10)\n            116 BINARY_SUBSCR\n            118 EXTENDED_ARG             1\n            120 LOAD_FAST              367 (graph_out_0)\n            122 LOAD_CONST              16 (11)\n            124 BINARY_SUBSCR\n            126 BUILD_TUPLE              2\n            128 EXTENDED_ARG             1\n            130 LOAD_FAST              367 (graph_out_0)\n            132 LOAD_CONST              17 (12)\n            134 BINARY_SUBSCR\n            136 EXTENDED_ARG             1\n            138 LOAD_FAST              367 (graph_out_0)\n            140 LOAD_CONST              18 (13)\n            142 BINARY_SUBSCR\n            144 BUILD_TUPLE              2\n            146 BUILD_TUPLE              6\n            148 LOAD_CONST               0 (None)\n            150 LOAD_CONST               0 (None)\n            152 LOAD_CONST               0 (None)\n            154 LOAD_CONST              19 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL             13 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('decoder_input_ids')\n             12 BINARY_SUBSCR\n             14 LOAD_FAST                2 (inputs)\n             16 LOAD_CONST               4 ('labels')\n             18 BINARY_SUBSCR\n             20 CALL_FUNCTION            3\n             22 EXTENDED_ARG             4\n             24 STORE_FAST            1108 (graph_out_0)\n             26 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n             28 LOAD_ATTR                5 (make_cell)\n             30 CALL_FUNCTION            0\n             32 EXTENDED_ARG             4\n             34 STORE_FAST            1145 (tmp_36)\n             36 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n             38 LOAD_ATTR                5 (make_cell)\n             40 CALL_FUNCTION            0\n             42 EXTENDED_ARG             4\n             44 STORE_FAST            1146 (tmp_37)\n             46 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n             48 LOAD_ATTR                5 (make_cell)\n             50 CALL_FUNCTION            0\n             52 EXTENDED_ARG             4\n             54 STORE_FAST            1147 (tmp_38)\n             56 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n             58 LOAD_ATTR                5 (make_cell)\n             60 CALL_FUNCTION            0\n             62 EXTENDED_ARG             4\n             64 STORE_FAST            1148 (tmp_39)\n             66 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n             68 LOAD_ATTR                5 (make_cell)\n             70 CALL_FUNCTION            0\n             72 EXTENDED_ARG             4\n             74 STORE_FAST            1149 (tmp_40)\n             76 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n             78 LOAD_ATTR                5 (make_cell)\n             80 CALL_FUNCTION            0\n             82 EXTENDED_ARG             4\n             84 STORE_FAST            1150 (tmp_41)\n             86 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n             88 LOAD_ATTR                5 (make_cell)\n             90 CALL_FUNCTION            0\n             92 EXTENDED_ARG             4\n             94 STORE_FAST            1151 (tmp_42)\n             96 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n             98 LOAD_ATTR                5 (make_cell)\n            100 CALL_FUNCTION            0\n            102 EXTENDED_ARG             4\n            104 STORE_FAST            1152 (tmp_43)\n            106 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            108 LOAD_ATTR                5 (make_cell)\n            110 CALL_FUNCTION            0\n            112 EXTENDED_ARG             4\n            114 STORE_FAST            1153 (tmp_44)\n            116 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            118 LOAD_ATTR                5 (make_cell)\n            120 CALL_FUNCTION            0\n            122 EXTENDED_ARG             4\n            124 STORE_FAST            1154 (tmp_45)\n            126 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            128 LOAD_ATTR                5 (make_cell)\n            130 CALL_FUNCTION            0\n            132 EXTENDED_ARG             4\n            134 STORE_FAST            1155 (tmp_46)\n            136 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            138 LOAD_ATTR                5 (make_cell)\n            140 CALL_FUNCTION            0\n            142 EXTENDED_ARG             4\n            144 STORE_FAST            1156 (tmp_47)\n            146 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            148 LOAD_ATTR                5 (make_cell)\n            150 CALL_FUNCTION            0\n            152 EXTENDED_ARG             4\n            154 STORE_FAST            1157 (tmp_48)\n            156 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            158 LOAD_ATTR                5 (make_cell)\n            160 CALL_FUNCTION            0\n            162 EXTENDED_ARG             4\n            164 STORE_FAST            1158 (tmp_49)\n            166 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            168 LOAD_ATTR                5 (make_cell)\n            170 CALL_FUNCTION            0\n            172 EXTENDED_ARG             4\n            174 STORE_FAST            1159 (tmp_50)\n            176 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            178 LOAD_ATTR                5 (make_cell)\n            180 CALL_FUNCTION            0\n            182 EXTENDED_ARG             4\n            184 STORE_FAST            1160 (tmp_51)\n            186 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            188 LOAD_ATTR                5 (make_cell)\n            190 CALL_FUNCTION            0\n            192 EXTENDED_ARG             4\n            194 STORE_FAST            1161 (tmp_52)\n            196 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            198 LOAD_ATTR                5 (make_cell)\n            200 CALL_FUNCTION            0\n            202 EXTENDED_ARG             4\n            204 STORE_FAST            1162 (tmp_53)\n            206 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            208 LOAD_ATTR                5 (make_cell)\n            210 CALL_FUNCTION            0\n            212 EXTENDED_ARG             4\n            214 STORE_FAST            1163 (tmp_54)\n            216 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            218 LOAD_ATTR                5 (make_cell)\n            220 CALL_FUNCTION            0\n            222 EXTENDED_ARG             4\n            224 STORE_FAST            1164 (tmp_55)\n            226 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            228 LOAD_ATTR                5 (make_cell)\n            230 CALL_FUNCTION            0\n            232 EXTENDED_ARG             4\n            234 STORE_FAST            1165 (tmp_56)\n            236 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            238 LOAD_ATTR                5 (make_cell)\n            240 CALL_FUNCTION            0\n            242 EXTENDED_ARG             4\n            244 STORE_FAST            1166 (tmp_57)\n            246 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            248 LOAD_ATTR                5 (make_cell)\n            250 CALL_FUNCTION            0\n            252 EXTENDED_ARG             4\n            254 STORE_FAST            1167 (tmp_58)\n            256 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            258 LOAD_ATTR                5 (make_cell)\n            260 CALL_FUNCTION            0\n            262 EXTENDED_ARG             4\n            264 STORE_FAST            1168 (tmp_59)\n            266 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            268 LOAD_ATTR                5 (make_cell)\n            270 CALL_FUNCTION            0\n            272 EXTENDED_ARG             4\n            274 STORE_FAST            1169 (tmp_60)\n            276 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            278 LOAD_ATTR                5 (make_cell)\n            280 CALL_FUNCTION            0\n            282 EXTENDED_ARG             4\n            284 STORE_FAST            1170 (tmp_61)\n            286 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            288 LOAD_ATTR                5 (make_cell)\n            290 CALL_FUNCTION            0\n            292 EXTENDED_ARG             4\n            294 STORE_FAST            1171 (tmp_62)\n            296 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            298 LOAD_ATTR                5 (make_cell)\n            300 CALL_FUNCTION            0\n            302 EXTENDED_ARG             4\n            304 STORE_FAST            1172 (tmp_63)\n            306 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            308 LOAD_ATTR                5 (make_cell)\n            310 CALL_FUNCTION            0\n            312 EXTENDED_ARG             4\n            314 STORE_FAST            1173 (tmp_64)\n            316 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            318 LOAD_ATTR                5 (make_cell)\n            320 CALL_FUNCTION            0\n            322 EXTENDED_ARG             4\n            324 STORE_FAST            1174 (tmp_65)\n            326 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            328 LOAD_ATTR                5 (make_cell)\n            330 CALL_FUNCTION            0\n            332 EXTENDED_ARG             4\n            334 STORE_FAST            1175 (tmp_66)\n            336 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            338 LOAD_ATTR                5 (make_cell)\n            340 CALL_FUNCTION            0\n            342 EXTENDED_ARG             4\n            344 STORE_FAST            1176 (tmp_67)\n            346 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            348 LOAD_ATTR                5 (make_cell)\n            350 CALL_FUNCTION            0\n            352 EXTENDED_ARG             4\n            354 STORE_FAST            1177 (tmp_68)\n            356 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            358 LOAD_ATTR                5 (make_cell)\n            360 CALL_FUNCTION            0\n            362 EXTENDED_ARG             4\n            364 STORE_FAST            1178 (tmp_69)\n            366 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            368 LOAD_ATTR                5 (make_cell)\n            370 CALL_FUNCTION            0\n            372 EXTENDED_ARG             4\n            374 STORE_FAST            1179 (tmp_70)\n            376 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            378 LOAD_ATTR                5 (make_cell)\n            380 CALL_FUNCTION            0\n            382 EXTENDED_ARG             4\n            384 STORE_FAST            1180 (tmp_71)\n            386 LOAD_CONST               5 (<class 'transformers.modeling_outputs.Seq2SeqLMOutput'>)\n            388 EXTENDED_ARG             4\n            390 LOAD_FAST             1108 (graph_out_0)\n            392 LOAD_CONST               6 (0)\n            394 BINARY_SUBSCR\n            396 EXTENDED_ARG             4\n            398 LOAD_FAST             1108 (graph_out_0)\n            400 LOAD_CONST               7 (1)\n            402 BINARY_SUBSCR\n            404 EXTENDED_ARG             4\n            406 LOAD_FAST             1108 (graph_out_0)\n            408 LOAD_CONST               8 (2)\n            410 BINARY_SUBSCR\n            412 EXTENDED_ARG             4\n            414 LOAD_FAST             1108 (graph_out_0)\n            416 LOAD_CONST               9 (3)\n            418 BINARY_SUBSCR\n            420 EXTENDED_ARG             4\n            422 LOAD_FAST             1108 (graph_out_0)\n            424 LOAD_CONST              10 (4)\n            426 BINARY_SUBSCR\n            428 EXTENDED_ARG             4\n            430 LOAD_FAST             1108 (graph_out_0)\n            432 LOAD_CONST              11 (5)\n            434 BINARY_SUBSCR\n            436 BUILD_TUPLE              4\n            438 EXTENDED_ARG             4\n            440 LOAD_FAST             1108 (graph_out_0)\n            442 LOAD_CONST              12 (6)\n            444 BINARY_SUBSCR\n            446 EXTENDED_ARG             4\n            448 LOAD_FAST             1108 (graph_out_0)\n            450 LOAD_CONST              13 (7)\n            452 BINARY_SUBSCR\n            454 EXTENDED_ARG             4\n            456 LOAD_FAST             1108 (graph_out_0)\n            458 LOAD_CONST              14 (8)\n            460 BINARY_SUBSCR\n            462 EXTENDED_ARG             4\n            464 LOAD_FAST             1108 (graph_out_0)\n            466 LOAD_CONST              15 (9)\n            468 BINARY_SUBSCR\n            470 BUILD_TUPLE              4\n            472 EXTENDED_ARG             4\n            474 LOAD_FAST             1108 (graph_out_0)\n            476 LOAD_CONST              16 (10)\n            478 BINARY_SUBSCR\n            480 EXTENDED_ARG             4\n            482 LOAD_FAST             1108 (graph_out_0)\n            484 LOAD_CONST              17 (11)\n            486 BINARY_SUBSCR\n            488 EXTENDED_ARG             4\n            490 LOAD_FAST             1108 (graph_out_0)\n            492 LOAD_CONST              18 (12)\n            494 BINARY_SUBSCR\n            496 EXTENDED_ARG             4\n            498 LOAD_FAST             1108 (graph_out_0)\n            500 LOAD_CONST              19 (13)\n            502 BINARY_SUBSCR\n            504 BUILD_TUPLE              4\n            506 EXTENDED_ARG             4\n            508 LOAD_FAST             1108 (graph_out_0)\n            510 LOAD_CONST              20 (14)\n            512 BINARY_SUBSCR\n            514 EXTENDED_ARG             4\n            516 LOAD_FAST             1108 (graph_out_0)\n            518 LOAD_CONST              21 (15)\n            520 BINARY_SUBSCR\n            522 EXTENDED_ARG             4\n            524 LOAD_FAST             1108 (graph_out_0)\n            526 LOAD_CONST              22 (16)\n            528 BINARY_SUBSCR\n            530 EXTENDED_ARG             4\n            532 LOAD_FAST             1108 (graph_out_0)\n            534 LOAD_CONST              23 (17)\n            536 BINARY_SUBSCR\n            538 BUILD_TUPLE              4\n            540 EXTENDED_ARG             4\n            542 LOAD_FAST             1108 (graph_out_0)\n            544 LOAD_CONST              24 (18)\n            546 BINARY_SUBSCR\n            548 EXTENDED_ARG             4\n            550 LOAD_FAST             1108 (graph_out_0)\n            552 LOAD_CONST              25 (19)\n            554 BINARY_SUBSCR\n            556 EXTENDED_ARG             4\n            558 LOAD_FAST             1108 (graph_out_0)\n            560 LOAD_CONST              26 (20)\n            562 BINARY_SUBSCR\n            564 EXTENDED_ARG             4\n            566 LOAD_FAST             1108 (graph_out_0)\n            568 LOAD_CONST              27 (21)\n            570 BINARY_SUBSCR\n            572 BUILD_TUPLE              4\n            574 EXTENDED_ARG             4\n            576 LOAD_FAST             1108 (graph_out_0)\n            578 LOAD_CONST              28 (22)\n            580 BINARY_SUBSCR\n            582 EXTENDED_ARG             4\n            584 LOAD_FAST             1108 (graph_out_0)\n            586 LOAD_CONST              29 (23)\n            588 BINARY_SUBSCR\n            590 EXTENDED_ARG             4\n            592 LOAD_FAST             1108 (graph_out_0)\n            594 LOAD_CONST              30 (24)\n            596 BINARY_SUBSCR\n            598 EXTENDED_ARG             4\n            600 LOAD_FAST             1108 (graph_out_0)\n            602 LOAD_CONST              31 (25)\n            604 BINARY_SUBSCR\n            606 BUILD_TUPLE              4\n            608 BUILD_TUPLE              6\n            610 LOAD_CONST               0 (None)\n            612 LOAD_CONST               0 (None)\n            614 LOAD_CONST               0 (None)\n            616 EXTENDED_ARG             4\n            618 LOAD_FAST             1108 (graph_out_0)\n            620 LOAD_CONST              32 (26)\n            622 BINARY_SUBSCR\n            624 LOAD_CONST               0 (None)\n            626 LOAD_CONST               0 (None)\n            628 LOAD_CONST              33 (('loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n            630 CALL_FUNCTION_KW         9\n            632 LOAD_CONST              10 (4)\n            634 EXTENDED_ARG             4\n            636 LOAD_FAST             1145 (tmp_36)\n            638 LOAD_FAST                1 (mod)\n            640 LOAD_ATTR                7 (encoder)\n            642 LOAD_ATTR                8 (block)\n            644 LOAD_CONST               6 (0)\n            646 BINARY_SUBSCR\n            648 LOAD_ATTR                9 (layer)\n            650 LOAD_CONST               6 (0)\n            652 BINARY_SUBSCR\n            654 LOAD_ATTR               10 (SelfAttention)\n            656 EXTENDED_ARG             4\n            658 LOAD_FAST             1146 (tmp_37)\n            660 LOAD_CONST              10 (4)\n            662 EXTENDED_ARG             4\n            664 LOAD_FAST             1147 (tmp_38)\n            666 LOAD_FAST                1 (mod)\n            668 LOAD_ATTR                7 (encoder)\n            670 LOAD_ATTR                8 (block)\n            672 LOAD_CONST               7 (1)\n            674 BINARY_SUBSCR\n            676 LOAD_ATTR                9 (layer)\n            678 LOAD_CONST               6 (0)\n            680 BINARY_SUBSCR\n            682 LOAD_ATTR               10 (SelfAttention)\n            684 EXTENDED_ARG             4\n            686 LOAD_FAST             1148 (tmp_39)\n            688 LOAD_CONST              10 (4)\n            690 EXTENDED_ARG             4\n            692 LOAD_FAST             1149 (tmp_40)\n            694 LOAD_FAST                1 (mod)\n            696 LOAD_ATTR                7 (encoder)\n            698 LOAD_ATTR                8 (block)\n            700 LOAD_CONST               8 (2)\n            702 BINARY_SUBSCR\n            704 LOAD_ATTR                9 (layer)\n            706 LOAD_CONST               6 (0)\n            708 BINARY_SUBSCR\n            710 LOAD_ATTR               10 (SelfAttention)\n            712 EXTENDED_ARG             4\n            714 LOAD_FAST             1150 (tmp_41)\n            716 LOAD_CONST              10 (4)\n            718 EXTENDED_ARG             4\n            720 LOAD_FAST             1151 (tmp_42)\n            722 LOAD_FAST                1 (mod)\n            724 LOAD_ATTR                7 (encoder)\n            726 LOAD_ATTR                8 (block)\n            728 LOAD_CONST               9 (3)\n            730 BINARY_SUBSCR\n            732 LOAD_ATTR                9 (layer)\n            734 LOAD_CONST               6 (0)\n            736 BINARY_SUBSCR\n            738 LOAD_ATTR               10 (SelfAttention)\n            740 EXTENDED_ARG             4\n            742 LOAD_FAST             1152 (tmp_43)\n            744 LOAD_CONST              10 (4)\n            746 EXTENDED_ARG             4\n            748 LOAD_FAST             1153 (tmp_44)\n            750 LOAD_FAST                1 (mod)\n            752 LOAD_ATTR                7 (encoder)\n            754 LOAD_ATTR                8 (block)\n            756 LOAD_CONST              10 (4)\n            758 BINARY_SUBSCR\n            760 LOAD_ATTR                9 (layer)\n            762 LOAD_CONST               6 (0)\n            764 BINARY_SUBSCR\n            766 LOAD_ATTR               10 (SelfAttention)\n            768 EXTENDED_ARG             4\n            770 LOAD_FAST             1154 (tmp_45)\n            772 LOAD_CONST              10 (4)\n            774 EXTENDED_ARG             4\n            776 LOAD_FAST             1155 (tmp_46)\n            778 LOAD_FAST                1 (mod)\n            780 LOAD_ATTR                7 (encoder)\n            782 LOAD_ATTR                8 (block)\n            784 LOAD_CONST              11 (5)\n            786 BINARY_SUBSCR\n            788 LOAD_ATTR                9 (layer)\n            790 LOAD_CONST               6 (0)\n            792 BINARY_SUBSCR\n            794 LOAD_ATTR               10 (SelfAttention)\n            796 EXTENDED_ARG             4\n            798 LOAD_FAST             1156 (tmp_47)\n            800 LOAD_CONST              10 (4)\n            802 EXTENDED_ARG             4\n            804 LOAD_FAST             1157 (tmp_48)\n            806 LOAD_FAST                1 (mod)\n            808 LOAD_ATTR               11 (decoder)\n            810 LOAD_ATTR                8 (block)\n            812 LOAD_CONST               6 (0)\n            814 BINARY_SUBSCR\n            816 LOAD_ATTR                9 (layer)\n            818 LOAD_CONST               6 (0)\n            820 BINARY_SUBSCR\n            822 LOAD_ATTR               10 (SelfAttention)\n            824 EXTENDED_ARG             4\n            826 LOAD_FAST             1158 (tmp_49)\n            828 LOAD_CONST              10 (4)\n            830 EXTENDED_ARG             4\n            832 LOAD_FAST             1159 (tmp_50)\n            834 LOAD_FAST                1 (mod)\n            836 LOAD_ATTR               11 (decoder)\n            838 LOAD_ATTR                8 (block)\n            840 LOAD_CONST               6 (0)\n            842 BINARY_SUBSCR\n            844 LOAD_ATTR                9 (layer)\n            846 LOAD_CONST               7 (1)\n            848 BINARY_SUBSCR\n            850 LOAD_ATTR               12 (EncDecAttention)\n            852 EXTENDED_ARG             4\n            854 LOAD_FAST             1160 (tmp_51)\n            856 LOAD_CONST              10 (4)\n            858 EXTENDED_ARG             4\n            860 LOAD_FAST             1161 (tmp_52)\n            862 LOAD_FAST                1 (mod)\n            864 LOAD_ATTR               11 (decoder)\n            866 LOAD_ATTR                8 (block)\n            868 LOAD_CONST               7 (1)\n            870 BINARY_SUBSCR\n            872 LOAD_ATTR                9 (layer)\n            874 LOAD_CONST               6 (0)\n            876 BINARY_SUBSCR\n            878 LOAD_ATTR               10 (SelfAttention)\n            880 EXTENDED_ARG             4\n            882 LOAD_FAST             1162 (tmp_53)\n            884 LOAD_CONST              10 (4)\n            886 EXTENDED_ARG             4\n            888 LOAD_FAST             1163 (tmp_54)\n            890 LOAD_FAST                1 (mod)\n            892 LOAD_ATTR               11 (decoder)\n            894 LOAD_ATTR                8 (block)\n            896 LOAD_CONST               7 (1)\n            898 BINARY_SUBSCR\n            900 LOAD_ATTR                9 (layer)\n            902 LOAD_CONST               7 (1)\n            904 BINARY_SUBSCR\n            906 LOAD_ATTR               12 (EncDecAttention)\n            908 EXTENDED_ARG             4\n            910 LOAD_FAST             1164 (tmp_55)\n            912 LOAD_CONST              10 (4)\n            914 EXTENDED_ARG             4\n            916 LOAD_FAST             1165 (tmp_56)\n            918 LOAD_FAST                1 (mod)\n            920 LOAD_ATTR               11 (decoder)\n            922 LOAD_ATTR                8 (block)\n            924 LOAD_CONST               8 (2)\n            926 BINARY_SUBSCR\n            928 LOAD_ATTR                9 (layer)\n            930 LOAD_CONST               6 (0)\n            932 BINARY_SUBSCR\n            934 LOAD_ATTR               10 (SelfAttention)\n            936 EXTENDED_ARG             4\n            938 LOAD_FAST             1166 (tmp_57)\n            940 LOAD_CONST              10 (4)\n            942 EXTENDED_ARG             4\n            944 LOAD_FAST             1167 (tmp_58)\n            946 LOAD_FAST                1 (mod)\n            948 LOAD_ATTR               11 (decoder)\n            950 LOAD_ATTR                8 (block)\n            952 LOAD_CONST               8 (2)\n            954 BINARY_SUBSCR\n            956 LOAD_ATTR                9 (layer)\n            958 LOAD_CONST               7 (1)\n            960 BINARY_SUBSCR\n            962 LOAD_ATTR               12 (EncDecAttention)\n            964 EXTENDED_ARG             4\n            966 LOAD_FAST             1168 (tmp_59)\n            968 LOAD_CONST              10 (4)\n            970 EXTENDED_ARG             4\n            972 LOAD_FAST             1169 (tmp_60)\n            974 LOAD_FAST                1 (mod)\n            976 LOAD_ATTR               11 (decoder)\n            978 LOAD_ATTR                8 (block)\n            980 LOAD_CONST               9 (3)\n            982 BINARY_SUBSCR\n            984 LOAD_ATTR                9 (layer)\n            986 LOAD_CONST               6 (0)\n            988 BINARY_SUBSCR\n            990 LOAD_ATTR               10 (SelfAttention)\n            992 EXTENDED_ARG             4\n            994 LOAD_FAST             1170 (tmp_61)\n            996 LOAD_CONST              10 (4)\n            998 EXTENDED_ARG             4\n           1000 LOAD_FAST             1171 (tmp_62)\n           1002 LOAD_FAST                1 (mod)\n           1004 LOAD_ATTR               11 (decoder)\n           1006 LOAD_ATTR                8 (block)\n           1008 LOAD_CONST               9 (3)\n           1010 BINARY_SUBSCR\n           1012 LOAD_ATTR                9 (layer)\n           1014 LOAD_CONST               7 (1)\n           1016 BINARY_SUBSCR\n           1018 LOAD_ATTR               12 (EncDecAttention)\n           1020 EXTENDED_ARG             4\n           1022 LOAD_FAST             1172 (tmp_63)\n           1024 LOAD_CONST              10 (4)\n           1026 EXTENDED_ARG             4\n           1028 LOAD_FAST             1173 (tmp_64)\n           1030 LOAD_FAST                1 (mod)\n           1032 LOAD_ATTR               11 (decoder)\n           1034 LOAD_ATTR                8 (block)\n           1036 LOAD_CONST              10 (4)\n           1038 BINARY_SUBSCR\n           1040 LOAD_ATTR                9 (layer)\n           1042 LOAD_CONST               6 (0)\n           1044 BINARY_SUBSCR\n           1046 LOAD_ATTR               10 (SelfAttention)\n           1048 EXTENDED_ARG             4\n           1050 LOAD_FAST             1174 (tmp_65)\n           1052 LOAD_CONST              10 (4)\n           1054 EXTENDED_ARG             4\n           1056 LOAD_FAST             1175 (tmp_66)\n           1058 LOAD_FAST                1 (mod)\n           1060 LOAD_ATTR               11 (decoder)\n           1062 LOAD_ATTR                8 (block)\n           1064 LOAD_CONST              10 (4)\n           1066 BINARY_SUBSCR\n           1068 LOAD_ATTR                9 (layer)\n           1070 LOAD_CONST               7 (1)\n           1072 BINARY_SUBSCR\n           1074 LOAD_ATTR               12 (EncDecAttention)\n           1076 EXTENDED_ARG             4\n           1078 LOAD_FAST             1176 (tmp_67)\n           1080 LOAD_CONST              10 (4)\n           1082 EXTENDED_ARG             4\n           1084 LOAD_FAST             1177 (tmp_68)\n           1086 LOAD_FAST                1 (mod)\n           1088 LOAD_ATTR               11 (decoder)\n           1090 LOAD_ATTR                8 (block)\n           1092 LOAD_CONST              11 (5)\n           1094 BINARY_SUBSCR\n           1096 LOAD_ATTR                9 (layer)\n           1098 LOAD_CONST               6 (0)\n           1100 BINARY_SUBSCR\n           1102 LOAD_ATTR               10 (SelfAttention)\n           1104 EXTENDED_ARG             4\n           1106 LOAD_FAST             1178 (tmp_69)\n           1108 LOAD_CONST              10 (4)\n           1110 EXTENDED_ARG             4\n           1112 LOAD_FAST             1179 (tmp_70)\n           1114 LOAD_FAST                1 (mod)\n           1116 LOAD_ATTR               11 (decoder)\n           1118 LOAD_ATTR                8 (block)\n           1120 LOAD_CONST              11 (5)\n           1122 BINARY_SUBSCR\n           1124 LOAD_ATTR                9 (layer)\n           1126 LOAD_CONST               7 (1)\n           1128 BINARY_SUBSCR\n           1130 LOAD_ATTR               12 (EncDecAttention)\n           1132 EXTENDED_ARG             4\n           1134 LOAD_FAST             1180 (tmp_71)\n           1136 STORE_ATTR               6 (cell_contents)\n           1138 STORE_ATTR               6 (cell_contents)\n           1140 STORE_ATTR               6 (cell_contents)\n           1142 STORE_ATTR               6 (cell_contents)\n           1144 STORE_ATTR               6 (cell_contents)\n           1146 STORE_ATTR               6 (cell_contents)\n           1148 STORE_ATTR               6 (cell_contents)\n           1150 STORE_ATTR               6 (cell_contents)\n           1152 STORE_ATTR               6 (cell_contents)\n           1154 STORE_ATTR               6 (cell_contents)\n           1156 STORE_ATTR               6 (cell_contents)\n           1158 STORE_ATTR               6 (cell_contents)\n           1160 STORE_ATTR               6 (cell_contents)\n           1162 STORE_ATTR               6 (cell_contents)\n           1164 STORE_ATTR               6 (cell_contents)\n           1166 STORE_ATTR               6 (cell_contents)\n           1168 STORE_ATTR               6 (cell_contents)\n           1170 STORE_ATTR               6 (cell_contents)\n           1172 STORE_ATTR               6 (cell_contents)\n           1174 STORE_ATTR               6 (cell_contents)\n           1176 STORE_ATTR               6 (cell_contents)\n           1178 STORE_ATTR               6 (cell_contents)\n           1180 STORE_ATTR               6 (cell_contents)\n           1182 STORE_ATTR               6 (cell_contents)\n           1184 STORE_ATTR               6 (cell_contents)\n           1186 STORE_ATTR               6 (cell_contents)\n           1188 STORE_ATTR               6 (cell_contents)\n           1190 STORE_ATTR               6 (cell_contents)\n           1192 STORE_ATTR               6 (cell_contents)\n           1194 STORE_ATTR               6 (cell_contents)\n           1196 STORE_ATTR               6 (cell_contents)\n           1198 STORE_ATTR               6 (cell_contents)\n           1200 STORE_ATTR               6 (cell_contents)\n           1202 STORE_ATTR               6 (cell_contents)\n           1204 STORE_ATTR               6 (cell_contents)\n           1206 STORE_ATTR               6 (cell_contents)\n           1208 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL             13 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('decoder_input_ids')\n             12 BINARY_SUBSCR\n             14 LOAD_FAST                2 (inputs)\n             16 LOAD_CONST               4 ('labels')\n             18 BINARY_SUBSCR\n             20 CALL_FUNCTION            3\n             22 EXTENDED_ARG             4\n             24 STORE_FAST            1108 (graph_out_0)\n             26 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n             28 LOAD_ATTR                5 (make_cell)\n             30 CALL_FUNCTION            0\n             32 EXTENDED_ARG             4\n             34 STORE_FAST            1145 (tmp_36)\n             36 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n             38 LOAD_ATTR                5 (make_cell)\n             40 CALL_FUNCTION            0\n             42 EXTENDED_ARG             4\n             44 STORE_FAST            1146 (tmp_37)\n             46 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n             48 LOAD_ATTR                5 (make_cell)\n             50 CALL_FUNCTION            0\n             52 EXTENDED_ARG             4\n             54 STORE_FAST            1147 (tmp_38)\n             56 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n             58 LOAD_ATTR                5 (make_cell)\n             60 CALL_FUNCTION            0\n             62 EXTENDED_ARG             4\n             64 STORE_FAST            1148 (tmp_39)\n             66 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n             68 LOAD_ATTR                5 (make_cell)\n             70 CALL_FUNCTION            0\n             72 EXTENDED_ARG             4\n             74 STORE_FAST            1149 (tmp_40)\n             76 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n             78 LOAD_ATTR                5 (make_cell)\n             80 CALL_FUNCTION            0\n             82 EXTENDED_ARG             4\n             84 STORE_FAST            1150 (tmp_41)\n             86 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n             88 LOAD_ATTR                5 (make_cell)\n             90 CALL_FUNCTION            0\n             92 EXTENDED_ARG             4\n             94 STORE_FAST            1151 (tmp_42)\n             96 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n             98 LOAD_ATTR                5 (make_cell)\n            100 CALL_FUNCTION            0\n            102 EXTENDED_ARG             4\n            104 STORE_FAST            1152 (tmp_43)\n            106 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            108 LOAD_ATTR                5 (make_cell)\n            110 CALL_FUNCTION            0\n            112 EXTENDED_ARG             4\n            114 STORE_FAST            1153 (tmp_44)\n            116 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            118 LOAD_ATTR                5 (make_cell)\n            120 CALL_FUNCTION            0\n            122 EXTENDED_ARG             4\n            124 STORE_FAST            1154 (tmp_45)\n            126 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            128 LOAD_ATTR                5 (make_cell)\n            130 CALL_FUNCTION            0\n            132 EXTENDED_ARG             4\n            134 STORE_FAST            1155 (tmp_46)\n            136 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            138 LOAD_ATTR                5 (make_cell)\n            140 CALL_FUNCTION            0\n            142 EXTENDED_ARG             4\n            144 STORE_FAST            1156 (tmp_47)\n            146 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            148 LOAD_ATTR                5 (make_cell)\n            150 CALL_FUNCTION            0\n            152 EXTENDED_ARG             4\n            154 STORE_FAST            1157 (tmp_48)\n            156 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            158 LOAD_ATTR                5 (make_cell)\n            160 CALL_FUNCTION            0\n            162 EXTENDED_ARG             4\n            164 STORE_FAST            1158 (tmp_49)\n            166 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            168 LOAD_ATTR                5 (make_cell)\n            170 CALL_FUNCTION            0\n            172 EXTENDED_ARG             4\n            174 STORE_FAST            1159 (tmp_50)\n            176 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            178 LOAD_ATTR                5 (make_cell)\n            180 CALL_FUNCTION            0\n            182 EXTENDED_ARG             4\n            184 STORE_FAST            1160 (tmp_51)\n            186 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            188 LOAD_ATTR                5 (make_cell)\n            190 CALL_FUNCTION            0\n            192 EXTENDED_ARG             4\n            194 STORE_FAST            1161 (tmp_52)\n            196 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            198 LOAD_ATTR                5 (make_cell)\n            200 CALL_FUNCTION            0\n            202 EXTENDED_ARG             4\n            204 STORE_FAST            1162 (tmp_53)\n            206 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            208 LOAD_ATTR                5 (make_cell)\n            210 CALL_FUNCTION            0\n            212 EXTENDED_ARG             4\n            214 STORE_FAST            1163 (tmp_54)\n            216 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            218 LOAD_ATTR                5 (make_cell)\n            220 CALL_FUNCTION            0\n            222 EXTENDED_ARG             4\n            224 STORE_FAST            1164 (tmp_55)\n            226 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            228 LOAD_ATTR                5 (make_cell)\n            230 CALL_FUNCTION            0\n            232 EXTENDED_ARG             4\n            234 STORE_FAST            1165 (tmp_56)\n            236 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            238 LOAD_ATTR                5 (make_cell)\n            240 CALL_FUNCTION            0\n            242 EXTENDED_ARG             4\n            244 STORE_FAST            1166 (tmp_57)\n            246 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            248 LOAD_ATTR                5 (make_cell)\n            250 CALL_FUNCTION            0\n            252 EXTENDED_ARG             4\n            254 STORE_FAST            1167 (tmp_58)\n            256 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            258 LOAD_ATTR                5 (make_cell)\n            260 CALL_FUNCTION            0\n            262 EXTENDED_ARG             4\n            264 STORE_FAST            1168 (tmp_59)\n            266 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            268 LOAD_ATTR                5 (make_cell)\n            270 CALL_FUNCTION            0\n            272 EXTENDED_ARG             4\n            274 STORE_FAST            1169 (tmp_60)\n            276 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            278 LOAD_ATTR                5 (make_cell)\n            280 CALL_FUNCTION            0\n            282 EXTENDED_ARG             4\n            284 STORE_FAST            1170 (tmp_61)\n            286 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            288 LOAD_ATTR                5 (make_cell)\n            290 CALL_FUNCTION            0\n            292 EXTENDED_ARG             4\n            294 STORE_FAST            1171 (tmp_62)\n            296 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            298 LOAD_ATTR                5 (make_cell)\n            300 CALL_FUNCTION            0\n            302 EXTENDED_ARG             4\n            304 STORE_FAST            1172 (tmp_63)\n            306 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            308 LOAD_ATTR                5 (make_cell)\n            310 CALL_FUNCTION            0\n            312 EXTENDED_ARG             4\n            314 STORE_FAST            1173 (tmp_64)\n            316 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            318 LOAD_ATTR                5 (make_cell)\n            320 CALL_FUNCTION            0\n            322 EXTENDED_ARG             4\n            324 STORE_FAST            1174 (tmp_65)\n            326 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            328 LOAD_ATTR                5 (make_cell)\n            330 CALL_FUNCTION            0\n            332 EXTENDED_ARG             4\n            334 STORE_FAST            1175 (tmp_66)\n            336 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            338 LOAD_ATTR                5 (make_cell)\n            340 CALL_FUNCTION            0\n            342 EXTENDED_ARG             4\n            344 STORE_FAST            1176 (tmp_67)\n            346 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            348 LOAD_ATTR                5 (make_cell)\n            350 CALL_FUNCTION            0\n            352 EXTENDED_ARG             4\n            354 STORE_FAST            1177 (tmp_68)\n            356 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            358 LOAD_ATTR                5 (make_cell)\n            360 CALL_FUNCTION            0\n            362 EXTENDED_ARG             4\n            364 STORE_FAST            1178 (tmp_69)\n            366 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            368 LOAD_ATTR                5 (make_cell)\n            370 CALL_FUNCTION            0\n            372 EXTENDED_ARG             4\n            374 STORE_FAST            1179 (tmp_70)\n            376 LOAD_GLOBAL              4 (__import_torch_dot__dynamo_dot_utils)\n            378 LOAD_ATTR                5 (make_cell)\n            380 CALL_FUNCTION            0\n            382 EXTENDED_ARG             4\n            384 STORE_FAST            1180 (tmp_71)\n            386 LOAD_CONST               5 (<class 'transformers.modeling_outputs.Seq2SeqLMOutput'>)\n            388 EXTENDED_ARG             4\n            390 LOAD_FAST             1108 (graph_out_0)\n            392 LOAD_CONST               6 (0)\n            394 BINARY_SUBSCR\n            396 EXTENDED_ARG             4\n            398 LOAD_FAST             1108 (graph_out_0)\n            400 LOAD_CONST               7 (1)\n            402 BINARY_SUBSCR\n            404 EXTENDED_ARG             4\n            406 LOAD_FAST             1108 (graph_out_0)\n            408 LOAD_CONST               8 (2)\n            410 BINARY_SUBSCR\n            412 EXTENDED_ARG             4\n            414 LOAD_FAST             1108 (graph_out_0)\n            416 LOAD_CONST               9 (3)\n            418 BINARY_SUBSCR\n            420 EXTENDED_ARG             4\n            422 LOAD_FAST             1108 (graph_out_0)\n            424 LOAD_CONST              10 (4)\n            426 BINARY_SUBSCR\n            428 EXTENDED_ARG             4\n            430 LOAD_FAST             1108 (graph_out_0)\n            432 LOAD_CONST              11 (5)\n            434 BINARY_SUBSCR\n            436 BUILD_TUPLE              4\n            438 EXTENDED_ARG             4\n            440 LOAD_FAST             1108 (graph_out_0)\n            442 LOAD_CONST              12 (6)\n            444 BINARY_SUBSCR\n            446 EXTENDED_ARG             4\n            448 LOAD_FAST             1108 (graph_out_0)\n            450 LOAD_CONST              13 (7)\n            452 BINARY_SUBSCR\n            454 EXTENDED_ARG             4\n            456 LOAD_FAST             1108 (graph_out_0)\n            458 LOAD_CONST              14 (8)\n            460 BINARY_SUBSCR\n            462 EXTENDED_ARG             4\n            464 LOAD_FAST             1108 (graph_out_0)\n            466 LOAD_CONST              15 (9)\n            468 BINARY_SUBSCR\n            470 BUILD_TUPLE              4\n            472 EXTENDED_ARG             4\n            474 LOAD_FAST             1108 (graph_out_0)\n            476 LOAD_CONST              16 (10)\n            478 BINARY_SUBSCR\n            480 EXTENDED_ARG             4\n            482 LOAD_FAST             1108 (graph_out_0)\n            484 LOAD_CONST              17 (11)\n            486 BINARY_SUBSCR\n            488 EXTENDED_ARG             4\n            490 LOAD_FAST             1108 (graph_out_0)\n            492 LOAD_CONST              18 (12)\n            494 BINARY_SUBSCR\n            496 EXTENDED_ARG             4\n            498 LOAD_FAST             1108 (graph_out_0)\n            500 LOAD_CONST              19 (13)\n            502 BINARY_SUBSCR\n            504 BUILD_TUPLE              4\n            506 EXTENDED_ARG             4\n            508 LOAD_FAST             1108 (graph_out_0)\n            510 LOAD_CONST              20 (14)\n            512 BINARY_SUBSCR\n            514 EXTENDED_ARG             4\n            516 LOAD_FAST             1108 (graph_out_0)\n            518 LOAD_CONST              21 (15)\n            520 BINARY_SUBSCR\n            522 EXTENDED_ARG             4\n            524 LOAD_FAST             1108 (graph_out_0)\n            526 LOAD_CONST              22 (16)\n            528 BINARY_SUBSCR\n            530 EXTENDED_ARG             4\n            532 LOAD_FAST             1108 (graph_out_0)\n            534 LOAD_CONST              23 (17)\n            536 BINARY_SUBSCR\n            538 BUILD_TUPLE              4\n            540 EXTENDED_ARG             4\n            542 LOAD_FAST             1108 (graph_out_0)\n            544 LOAD_CONST              24 (18)\n            546 BINARY_SUBSCR\n            548 EXTENDED_ARG             4\n            550 LOAD_FAST             1108 (graph_out_0)\n            552 LOAD_CONST              25 (19)\n            554 BINARY_SUBSCR\n            556 EXTENDED_ARG             4\n            558 LOAD_FAST             1108 (graph_out_0)\n            560 LOAD_CONST              26 (20)\n            562 BINARY_SUBSCR\n            564 EXTENDED_ARG             4\n            566 LOAD_FAST             1108 (graph_out_0)\n            568 LOAD_CONST              27 (21)\n            570 BINARY_SUBSCR\n            572 BUILD_TUPLE              4\n            574 EXTENDED_ARG             4\n            576 LOAD_FAST             1108 (graph_out_0)\n            578 LOAD_CONST              28 (22)\n            580 BINARY_SUBSCR\n            582 EXTENDED_ARG             4\n            584 LOAD_FAST             1108 (graph_out_0)\n            586 LOAD_CONST              29 (23)\n            588 BINARY_SUBSCR\n            590 EXTENDED_ARG             4\n            592 LOAD_FAST             1108 (graph_out_0)\n            594 LOAD_CONST              30 (24)\n            596 BINARY_SUBSCR\n            598 EXTENDED_ARG             4\n            600 LOAD_FAST             1108 (graph_out_0)\n            602 LOAD_CONST              31 (25)\n            604 BINARY_SUBSCR\n            606 BUILD_TUPLE              4\n            608 BUILD_TUPLE              6\n            610 LOAD_CONST               0 (None)\n            612 LOAD_CONST               0 (None)\n            614 LOAD_CONST               0 (None)\n            616 EXTENDED_ARG             4\n            618 LOAD_FAST             1108 (graph_out_0)\n            620 LOAD_CONST              32 (26)\n            622 BINARY_SUBSCR\n            624 LOAD_CONST               0 (None)\n            626 LOAD_CONST               0 (None)\n            628 LOAD_CONST              33 (('loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n            630 CALL_FUNCTION_KW         9\n            632 LOAD_CONST              10 (4)\n            634 EXTENDED_ARG             4\n            636 LOAD_FAST             1145 (tmp_36)\n            638 LOAD_FAST                1 (mod)\n            640 LOAD_ATTR                7 (encoder)\n            642 LOAD_ATTR                8 (block)\n            644 LOAD_CONST               6 (0)\n            646 BINARY_SUBSCR\n            648 LOAD_ATTR                9 (layer)\n            650 LOAD_CONST               6 (0)\n            652 BINARY_SUBSCR\n            654 LOAD_ATTR               10 (SelfAttention)\n            656 EXTENDED_ARG             4\n            658 LOAD_FAST             1146 (tmp_37)\n            660 LOAD_CONST              10 (4)\n            662 EXTENDED_ARG             4\n            664 LOAD_FAST             1147 (tmp_38)\n            666 LOAD_FAST                1 (mod)\n            668 LOAD_ATTR                7 (encoder)\n            670 LOAD_ATTR                8 (block)\n            672 LOAD_CONST               7 (1)\n            674 BINARY_SUBSCR\n            676 LOAD_ATTR                9 (layer)\n            678 LOAD_CONST               6 (0)\n            680 BINARY_SUBSCR\n            682 LOAD_ATTR               10 (SelfAttention)\n            684 EXTENDED_ARG             4\n            686 LOAD_FAST             1148 (tmp_39)\n            688 LOAD_CONST              10 (4)\n            690 EXTENDED_ARG             4\n            692 LOAD_FAST             1149 (tmp_40)\n            694 LOAD_FAST                1 (mod)\n            696 LOAD_ATTR                7 (encoder)\n            698 LOAD_ATTR                8 (block)\n            700 LOAD_CONST               8 (2)\n            702 BINARY_SUBSCR\n            704 LOAD_ATTR                9 (layer)\n            706 LOAD_CONST               6 (0)\n            708 BINARY_SUBSCR\n            710 LOAD_ATTR               10 (SelfAttention)\n            712 EXTENDED_ARG             4\n            714 LOAD_FAST             1150 (tmp_41)\n            716 LOAD_CONST              10 (4)\n            718 EXTENDED_ARG             4\n            720 LOAD_FAST             1151 (tmp_42)\n            722 LOAD_FAST                1 (mod)\n            724 LOAD_ATTR                7 (encoder)\n            726 LOAD_ATTR                8 (block)\n            728 LOAD_CONST               9 (3)\n            730 BINARY_SUBSCR\n            732 LOAD_ATTR                9 (layer)\n            734 LOAD_CONST               6 (0)\n            736 BINARY_SUBSCR\n            738 LOAD_ATTR               10 (SelfAttention)\n            740 EXTENDED_ARG             4\n            742 LOAD_FAST             1152 (tmp_43)\n            744 LOAD_CONST              10 (4)\n            746 EXTENDED_ARG             4\n            748 LOAD_FAST             1153 (tmp_44)\n            750 LOAD_FAST                1 (mod)\n            752 LOAD_ATTR                7 (encoder)\n            754 LOAD_ATTR                8 (block)\n            756 LOAD_CONST              10 (4)\n            758 BINARY_SUBSCR\n            760 LOAD_ATTR                9 (layer)\n            762 LOAD_CONST               6 (0)\n            764 BINARY_SUBSCR\n            766 LOAD_ATTR               10 (SelfAttention)\n            768 EXTENDED_ARG             4\n            770 LOAD_FAST             1154 (tmp_45)\n            772 LOAD_CONST              10 (4)\n            774 EXTENDED_ARG             4\n            776 LOAD_FAST             1155 (tmp_46)\n            778 LOAD_FAST                1 (mod)\n            780 LOAD_ATTR                7 (encoder)\n            782 LOAD_ATTR                8 (block)\n            784 LOAD_CONST              11 (5)\n            786 BINARY_SUBSCR\n            788 LOAD_ATTR                9 (layer)\n            790 LOAD_CONST               6 (0)\n            792 BINARY_SUBSCR\n            794 LOAD_ATTR               10 (SelfAttention)\n            796 EXTENDED_ARG             4\n            798 LOAD_FAST             1156 (tmp_47)\n            800 LOAD_CONST              10 (4)\n            802 EXTENDED_ARG             4\n            804 LOAD_FAST             1157 (tmp_48)\n            806 LOAD_FAST                1 (mod)\n            808 LOAD_ATTR               11 (decoder)\n            810 LOAD_ATTR                8 (block)\n            812 LOAD_CONST               6 (0)\n            814 BINARY_SUBSCR\n            816 LOAD_ATTR                9 (layer)\n            818 LOAD_CONST               6 (0)\n            820 BINARY_SUBSCR\n            822 LOAD_ATTR               10 (SelfAttention)\n            824 EXTENDED_ARG             4\n            826 LOAD_FAST             1158 (tmp_49)\n            828 LOAD_CONST              10 (4)\n            830 EXTENDED_ARG             4\n            832 LOAD_FAST             1159 (tmp_50)\n            834 LOAD_FAST                1 (mod)\n            836 LOAD_ATTR               11 (decoder)\n            838 LOAD_ATTR                8 (block)\n            840 LOAD_CONST               6 (0)\n            842 BINARY_SUBSCR\n            844 LOAD_ATTR                9 (layer)\n            846 LOAD_CONST               7 (1)\n            848 BINARY_SUBSCR\n            850 LOAD_ATTR               12 (EncDecAttention)\n            852 EXTENDED_ARG             4\n            854 LOAD_FAST             1160 (tmp_51)\n            856 LOAD_CONST              10 (4)\n            858 EXTENDED_ARG             4\n            860 LOAD_FAST             1161 (tmp_52)\n            862 LOAD_FAST                1 (mod)\n            864 LOAD_ATTR               11 (decoder)\n            866 LOAD_ATTR                8 (block)\n            868 LOAD_CONST               7 (1)\n            870 BINARY_SUBSCR\n            872 LOAD_ATTR                9 (layer)\n            874 LOAD_CONST               6 (0)\n            876 BINARY_SUBSCR\n            878 LOAD_ATTR               10 (SelfAttention)\n            880 EXTENDED_ARG             4\n            882 LOAD_FAST             1162 (tmp_53)\n            884 LOAD_CONST              10 (4)\n            886 EXTENDED_ARG             4\n            888 LOAD_FAST             1163 (tmp_54)\n            890 LOAD_FAST                1 (mod)\n            892 LOAD_ATTR               11 (decoder)\n            894 LOAD_ATTR                8 (block)\n            896 LOAD_CONST               7 (1)\n            898 BINARY_SUBSCR\n            900 LOAD_ATTR                9 (layer)\n            902 LOAD_CONST               7 (1)\n            904 BINARY_SUBSCR\n            906 LOAD_ATTR               12 (EncDecAttention)\n            908 EXTENDED_ARG             4\n            910 LOAD_FAST             1164 (tmp_55)\n            912 LOAD_CONST              10 (4)\n            914 EXTENDED_ARG             4\n            916 LOAD_FAST             1165 (tmp_56)\n            918 LOAD_FAST                1 (mod)\n            920 LOAD_ATTR               11 (decoder)\n            922 LOAD_ATTR                8 (block)\n            924 LOAD_CONST               8 (2)\n            926 BINARY_SUBSCR\n            928 LOAD_ATTR                9 (layer)\n            930 LOAD_CONST               6 (0)\n            932 BINARY_SUBSCR\n            934 LOAD_ATTR               10 (SelfAttention)\n            936 EXTENDED_ARG             4\n            938 LOAD_FAST             1166 (tmp_57)\n            940 LOAD_CONST              10 (4)\n            942 EXTENDED_ARG             4\n            944 LOAD_FAST             1167 (tmp_58)\n            946 LOAD_FAST                1 (mod)\n            948 LOAD_ATTR               11 (decoder)\n            950 LOAD_ATTR                8 (block)\n            952 LOAD_CONST               8 (2)\n            954 BINARY_SUBSCR\n            956 LOAD_ATTR                9 (layer)\n            958 LOAD_CONST               7 (1)\n            960 BINARY_SUBSCR\n            962 LOAD_ATTR               12 (EncDecAttention)\n            964 EXTENDED_ARG             4\n            966 LOAD_FAST             1168 (tmp_59)\n            968 LOAD_CONST              10 (4)\n            970 EXTENDED_ARG             4\n            972 LOAD_FAST             1169 (tmp_60)\n            974 LOAD_FAST                1 (mod)\n            976 LOAD_ATTR               11 (decoder)\n            978 LOAD_ATTR                8 (block)\n            980 LOAD_CONST               9 (3)\n            982 BINARY_SUBSCR\n            984 LOAD_ATTR                9 (layer)\n            986 LOAD_CONST               6 (0)\n            988 BINARY_SUBSCR\n            990 LOAD_ATTR               10 (SelfAttention)\n            992 EXTENDED_ARG             4\n            994 LOAD_FAST             1170 (tmp_61)\n            996 LOAD_CONST              10 (4)\n            998 EXTENDED_ARG             4\n           1000 LOAD_FAST             1171 (tmp_62)\n           1002 LOAD_FAST                1 (mod)\n           1004 LOAD_ATTR               11 (decoder)\n           1006 LOAD_ATTR                8 (block)\n           1008 LOAD_CONST               9 (3)\n           1010 BINARY_SUBSCR\n           1012 LOAD_ATTR                9 (layer)\n           1014 LOAD_CONST               7 (1)\n           1016 BINARY_SUBSCR\n           1018 LOAD_ATTR               12 (EncDecAttention)\n           1020 EXTENDED_ARG             4\n           1022 LOAD_FAST             1172 (tmp_63)\n           1024 LOAD_CONST              10 (4)\n           1026 EXTENDED_ARG             4\n           1028 LOAD_FAST             1173 (tmp_64)\n           1030 LOAD_FAST                1 (mod)\n           1032 LOAD_ATTR               11 (decoder)\n           1034 LOAD_ATTR                8 (block)\n           1036 LOAD_CONST              10 (4)\n           1038 BINARY_SUBSCR\n           1040 LOAD_ATTR                9 (layer)\n           1042 LOAD_CONST               6 (0)\n           1044 BINARY_SUBSCR\n           1046 LOAD_ATTR               10 (SelfAttention)\n           1048 EXTENDED_ARG             4\n           1050 LOAD_FAST             1174 (tmp_65)\n           1052 LOAD_CONST              10 (4)\n           1054 EXTENDED_ARG             4\n           1056 LOAD_FAST             1175 (tmp_66)\n           1058 LOAD_FAST                1 (mod)\n           1060 LOAD_ATTR               11 (decoder)\n           1062 LOAD_ATTR                8 (block)\n           1064 LOAD_CONST              10 (4)\n           1066 BINARY_SUBSCR\n           1068 LOAD_ATTR                9 (layer)\n           1070 LOAD_CONST               7 (1)\n           1072 BINARY_SUBSCR\n           1074 LOAD_ATTR               12 (EncDecAttention)\n           1076 EXTENDED_ARG             4\n           1078 LOAD_FAST             1176 (tmp_67)\n           1080 LOAD_CONST              10 (4)\n           1082 EXTENDED_ARG             4\n           1084 LOAD_FAST             1177 (tmp_68)\n           1086 LOAD_FAST                1 (mod)\n           1088 LOAD_ATTR               11 (decoder)\n           1090 LOAD_ATTR                8 (block)\n           1092 LOAD_CONST              11 (5)\n           1094 BINARY_SUBSCR\n           1096 LOAD_ATTR                9 (layer)\n           1098 LOAD_CONST               6 (0)\n           1100 BINARY_SUBSCR\n           1102 LOAD_ATTR               10 (SelfAttention)\n           1104 EXTENDED_ARG             4\n           1106 LOAD_FAST             1178 (tmp_69)\n           1108 LOAD_CONST              10 (4)\n           1110 EXTENDED_ARG             4\n           1112 LOAD_FAST             1179 (tmp_70)\n           1114 LOAD_FAST                1 (mod)\n           1116 LOAD_ATTR               11 (decoder)\n           1118 LOAD_ATTR                8 (block)\n           1120 LOAD_CONST              11 (5)\n           1122 BINARY_SUBSCR\n           1124 LOAD_ATTR                9 (layer)\n           1126 LOAD_CONST               7 (1)\n           1128 BINARY_SUBSCR\n           1130 LOAD_ATTR               12 (EncDecAttention)\n           1132 EXTENDED_ARG             4\n           1134 LOAD_FAST             1180 (tmp_71)\n           1136 STORE_ATTR               6 (cell_contents)\n           1138 STORE_ATTR               6 (cell_contents)\n           1140 STORE_ATTR               6 (cell_contents)\n           1142 STORE_ATTR               6 (cell_contents)\n           1144 STORE_ATTR               6 (cell_contents)\n           1146 STORE_ATTR               6 (cell_contents)\n           1148 STORE_ATTR               6 (cell_contents)\n           1150 STORE_ATTR               6 (cell_contents)\n           1152 STORE_ATTR               6 (cell_contents)\n           1154 STORE_ATTR               6 (cell_contents)\n           1156 STORE_ATTR               6 (cell_contents)\n           1158 STORE_ATTR               6 (cell_contents)\n           1160 STORE_ATTR               6 (cell_contents)\n           1162 STORE_ATTR               6 (cell_contents)\n           1164 STORE_ATTR               6 (cell_contents)\n           1166 STORE_ATTR               6 (cell_contents)\n           1168 STORE_ATTR               6 (cell_contents)\n           1170 STORE_ATTR               6 (cell_contents)\n           1172 STORE_ATTR               6 (cell_contents)\n           1174 STORE_ATTR               6 (cell_contents)\n           1176 STORE_ATTR               6 (cell_contents)\n           1178 STORE_ATTR               6 (cell_contents)\n           1180 STORE_ATTR               6 (cell_contents)\n           1182 STORE_ATTR               6 (cell_contents)\n           1184 STORE_ATTR               6 (cell_contents)\n           1186 STORE_ATTR               6 (cell_contents)\n           1188 STORE_ATTR               6 (cell_contents)\n           1190 STORE_ATTR               6 (cell_contents)\n           1192 STORE_ATTR               6 (cell_contents)\n           1194 STORE_ATTR               6 (cell_contents)\n           1196 STORE_ATTR               6 (cell_contents)\n           1198 STORE_ATTR               6 (cell_contents)\n           1200 STORE_ATTR               6 (cell_contents)\n           1202 STORE_ATTR               6 (cell_contents)\n           1204 STORE_ATTR               6 (cell_contents)\n           1206 STORE_ATTR               6 (cell_contents)\n           1208 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              4 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             2\n             18 STORE_FAST             684 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.CausalLMOutputWithCrossAttentions'>)\n             22 EXTENDED_ARG             2\n             24 LOAD_FAST              684 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             2\n             32 LOAD_FAST              684 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 EXTENDED_ARG             2\n             40 LOAD_FAST              684 (graph_out_0)\n             42 LOAD_CONST               7 (2)\n             44 BINARY_SUBSCR\n             46 EXTENDED_ARG             2\n             48 LOAD_FAST              684 (graph_out_0)\n             50 LOAD_CONST               8 (3)\n             52 BINARY_SUBSCR\n             54 BUILD_TUPLE              2\n             56 EXTENDED_ARG             2\n             58 LOAD_FAST              684 (graph_out_0)\n             60 LOAD_CONST               9 (4)\n             62 BINARY_SUBSCR\n             64 EXTENDED_ARG             2\n             66 LOAD_FAST              684 (graph_out_0)\n             68 LOAD_CONST              10 (5)\n             70 BINARY_SUBSCR\n             72 BUILD_TUPLE              2\n             74 EXTENDED_ARG             2\n             76 LOAD_FAST              684 (graph_out_0)\n             78 LOAD_CONST              11 (6)\n             80 BINARY_SUBSCR\n             82 EXTENDED_ARG             2\n             84 LOAD_FAST              684 (graph_out_0)\n             86 LOAD_CONST              12 (7)\n             88 BINARY_SUBSCR\n             90 BUILD_TUPLE              2\n             92 EXTENDED_ARG             2\n             94 LOAD_FAST              684 (graph_out_0)\n             96 LOAD_CONST              13 (8)\n             98 BINARY_SUBSCR\n            100 EXTENDED_ARG             2\n            102 LOAD_FAST              684 (graph_out_0)\n            104 LOAD_CONST              14 (9)\n            106 BINARY_SUBSCR\n            108 BUILD_TUPLE              2\n            110 EXTENDED_ARG             2\n            112 LOAD_FAST              684 (graph_out_0)\n            114 LOAD_CONST              15 (10)\n            116 BINARY_SUBSCR\n            118 EXTENDED_ARG             2\n            120 LOAD_FAST              684 (graph_out_0)\n            122 LOAD_CONST              16 (11)\n            124 BINARY_SUBSCR\n            126 BUILD_TUPLE              2\n            128 EXTENDED_ARG             2\n            130 LOAD_FAST              684 (graph_out_0)\n            132 LOAD_CONST              17 (12)\n            134 BINARY_SUBSCR\n            136 EXTENDED_ARG             2\n            138 LOAD_FAST              684 (graph_out_0)\n            140 LOAD_CONST              18 (13)\n            142 BINARY_SUBSCR\n            144 BUILD_TUPLE              2\n            146 EXTENDED_ARG             2\n            148 LOAD_FAST              684 (graph_out_0)\n            150 LOAD_CONST              19 (14)\n            152 BINARY_SUBSCR\n            154 EXTENDED_ARG             2\n            156 LOAD_FAST              684 (graph_out_0)\n            158 LOAD_CONST              20 (15)\n            160 BINARY_SUBSCR\n            162 BUILD_TUPLE              2\n            164 EXTENDED_ARG             2\n            166 LOAD_FAST              684 (graph_out_0)\n            168 LOAD_CONST              21 (16)\n            170 BINARY_SUBSCR\n            172 EXTENDED_ARG             2\n            174 LOAD_FAST              684 (graph_out_0)\n            176 LOAD_CONST              22 (17)\n            178 BINARY_SUBSCR\n            180 BUILD_TUPLE              2\n            182 EXTENDED_ARG             2\n            184 LOAD_FAST              684 (graph_out_0)\n            186 LOAD_CONST              23 (18)\n            188 BINARY_SUBSCR\n            190 EXTENDED_ARG             2\n            192 LOAD_FAST              684 (graph_out_0)\n            194 LOAD_CONST              24 (19)\n            196 BINARY_SUBSCR\n            198 BUILD_TUPLE              2\n            200 EXTENDED_ARG             2\n            202 LOAD_FAST              684 (graph_out_0)\n            204 LOAD_CONST              25 (20)\n            206 BINARY_SUBSCR\n            208 EXTENDED_ARG             2\n            210 LOAD_FAST              684 (graph_out_0)\n            212 LOAD_CONST              26 (21)\n            214 BINARY_SUBSCR\n            216 BUILD_TUPLE              2\n            218 EXTENDED_ARG             2\n            220 LOAD_FAST              684 (graph_out_0)\n            222 LOAD_CONST              27 (22)\n            224 BINARY_SUBSCR\n            226 EXTENDED_ARG             2\n            228 LOAD_FAST              684 (graph_out_0)\n            230 LOAD_CONST              28 (23)\n            232 BINARY_SUBSCR\n            234 BUILD_TUPLE              2\n            236 EXTENDED_ARG             2\n            238 LOAD_FAST              684 (graph_out_0)\n            240 LOAD_CONST              29 (24)\n            242 BINARY_SUBSCR\n            244 EXTENDED_ARG             2\n            246 LOAD_FAST              684 (graph_out_0)\n            248 LOAD_CONST              30 (25)\n            250 BINARY_SUBSCR\n            252 BUILD_TUPLE              2\n            254 BUILD_TUPLE             12\n            256 LOAD_CONST               0 (None)\n            258 LOAD_CONST               0 (None)\n            260 LOAD_CONST               0 (None)\n            262 LOAD_CONST              31 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n            264 CALL_FUNCTION_KW         6\n            266 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              3 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             5\n             18 STORE_FAST            1334 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.CausalLMOutputWithCrossAttentions'>)\n             22 EXTENDED_ARG             5\n             24 LOAD_FAST             1334 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             5\n             32 LOAD_FAST             1334 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 EXTENDED_ARG             5\n             40 LOAD_FAST             1334 (graph_out_0)\n             42 LOAD_CONST               7 (2)\n             44 BINARY_SUBSCR\n             46 EXTENDED_ARG             5\n             48 LOAD_FAST             1334 (graph_out_0)\n             50 LOAD_CONST               8 (3)\n             52 BINARY_SUBSCR\n             54 BUILD_TUPLE              2\n             56 EXTENDED_ARG             5\n             58 LOAD_FAST             1334 (graph_out_0)\n             60 LOAD_CONST               9 (4)\n             62 BINARY_SUBSCR\n             64 EXTENDED_ARG             5\n             66 LOAD_FAST             1334 (graph_out_0)\n             68 LOAD_CONST              10 (5)\n             70 BINARY_SUBSCR\n             72 BUILD_TUPLE              2\n             74 EXTENDED_ARG             5\n             76 LOAD_FAST             1334 (graph_out_0)\n             78 LOAD_CONST              11 (6)\n             80 BINARY_SUBSCR\n             82 EXTENDED_ARG             5\n             84 LOAD_FAST             1334 (graph_out_0)\n             86 LOAD_CONST              12 (7)\n             88 BINARY_SUBSCR\n             90 BUILD_TUPLE              2\n             92 EXTENDED_ARG             5\n             94 LOAD_FAST             1334 (graph_out_0)\n             96 LOAD_CONST              13 (8)\n             98 BINARY_SUBSCR\n            100 EXTENDED_ARG             5\n            102 LOAD_FAST             1334 (graph_out_0)\n            104 LOAD_CONST              14 (9)\n            106 BINARY_SUBSCR\n            108 BUILD_TUPLE              2\n            110 EXTENDED_ARG             5\n            112 LOAD_FAST             1334 (graph_out_0)\n            114 LOAD_CONST              15 (10)\n            116 BINARY_SUBSCR\n            118 EXTENDED_ARG             5\n            120 LOAD_FAST             1334 (graph_out_0)\n            122 LOAD_CONST              16 (11)\n            124 BINARY_SUBSCR\n            126 BUILD_TUPLE              2\n            128 EXTENDED_ARG             5\n            130 LOAD_FAST             1334 (graph_out_0)\n            132 LOAD_CONST              17 (12)\n            134 BINARY_SUBSCR\n            136 EXTENDED_ARG             5\n            138 LOAD_FAST             1334 (graph_out_0)\n            140 LOAD_CONST              18 (13)\n            142 BINARY_SUBSCR\n            144 BUILD_TUPLE              2\n            146 EXTENDED_ARG             5\n            148 LOAD_FAST             1334 (graph_out_0)\n            150 LOAD_CONST              19 (14)\n            152 BINARY_SUBSCR\n            154 EXTENDED_ARG             5\n            156 LOAD_FAST             1334 (graph_out_0)\n            158 LOAD_CONST              20 (15)\n            160 BINARY_SUBSCR\n            162 BUILD_TUPLE              2\n            164 EXTENDED_ARG             5\n            166 LOAD_FAST             1334 (graph_out_0)\n            168 LOAD_CONST              21 (16)\n            170 BINARY_SUBSCR\n            172 EXTENDED_ARG             5\n            174 LOAD_FAST             1334 (graph_out_0)\n            176 LOAD_CONST              22 (17)\n            178 BINARY_SUBSCR\n            180 BUILD_TUPLE              2\n            182 EXTENDED_ARG             5\n            184 LOAD_FAST             1334 (graph_out_0)\n            186 LOAD_CONST              23 (18)\n            188 BINARY_SUBSCR\n            190 EXTENDED_ARG             5\n            192 LOAD_FAST             1334 (graph_out_0)\n            194 LOAD_CONST              24 (19)\n            196 BINARY_SUBSCR\n            198 BUILD_TUPLE              2\n            200 EXTENDED_ARG             5\n            202 LOAD_FAST             1334 (graph_out_0)\n            204 LOAD_CONST              25 (20)\n            206 BINARY_SUBSCR\n            208 EXTENDED_ARG             5\n            210 LOAD_FAST             1334 (graph_out_0)\n            212 LOAD_CONST              26 (21)\n            214 BINARY_SUBSCR\n            216 BUILD_TUPLE              2\n            218 EXTENDED_ARG             5\n            220 LOAD_FAST             1334 (graph_out_0)\n            222 LOAD_CONST              27 (22)\n            224 BINARY_SUBSCR\n            226 EXTENDED_ARG             5\n            228 LOAD_FAST             1334 (graph_out_0)\n            230 LOAD_CONST              28 (23)\n            232 BINARY_SUBSCR\n            234 BUILD_TUPLE              2\n            236 EXTENDED_ARG             5\n            238 LOAD_FAST             1334 (graph_out_0)\n            240 LOAD_CONST              29 (24)\n            242 BINARY_SUBSCR\n            244 EXTENDED_ARG             5\n            246 LOAD_FAST             1334 (graph_out_0)\n            248 LOAD_CONST              30 (25)\n            250 BINARY_SUBSCR\n            252 BUILD_TUPLE              2\n            254 EXTENDED_ARG             5\n            256 LOAD_FAST             1334 (graph_out_0)\n            258 LOAD_CONST              31 (26)\n            260 BINARY_SUBSCR\n            262 EXTENDED_ARG             5\n            264 LOAD_FAST             1334 (graph_out_0)\n            266 LOAD_CONST              32 (27)\n            268 BINARY_SUBSCR\n            270 BUILD_TUPLE              2\n            272 EXTENDED_ARG             5\n            274 LOAD_FAST             1334 (graph_out_0)\n            276 LOAD_CONST              33 (28)\n            278 BINARY_SUBSCR\n            280 EXTENDED_ARG             5\n            282 LOAD_FAST             1334 (graph_out_0)\n            284 LOAD_CONST              34 (29)\n            286 BINARY_SUBSCR\n            288 BUILD_TUPLE              2\n            290 EXTENDED_ARG             5\n            292 LOAD_FAST             1334 (graph_out_0)\n            294 LOAD_CONST              35 (30)\n            296 BINARY_SUBSCR\n            298 EXTENDED_ARG             5\n            300 LOAD_FAST             1334 (graph_out_0)\n            302 LOAD_CONST              36 (31)\n            304 BINARY_SUBSCR\n            306 BUILD_TUPLE              2\n            308 EXTENDED_ARG             5\n            310 LOAD_FAST             1334 (graph_out_0)\n            312 LOAD_CONST              37 (32)\n            314 BINARY_SUBSCR\n            316 EXTENDED_ARG             5\n            318 LOAD_FAST             1334 (graph_out_0)\n            320 LOAD_CONST              38 (33)\n            322 BINARY_SUBSCR\n            324 BUILD_TUPLE              2\n            326 EXTENDED_ARG             5\n            328 LOAD_FAST             1334 (graph_out_0)\n            330 LOAD_CONST              39 (34)\n            332 BINARY_SUBSCR\n            334 EXTENDED_ARG             5\n            336 LOAD_FAST             1334 (graph_out_0)\n            338 LOAD_CONST              40 (35)\n            340 BINARY_SUBSCR\n            342 BUILD_TUPLE              2\n            344 EXTENDED_ARG             5\n            346 LOAD_FAST             1334 (graph_out_0)\n            348 LOAD_CONST              41 (36)\n            350 BINARY_SUBSCR\n            352 EXTENDED_ARG             5\n            354 LOAD_FAST             1334 (graph_out_0)\n            356 LOAD_CONST              42 (37)\n            358 BINARY_SUBSCR\n            360 BUILD_TUPLE              2\n            362 EXTENDED_ARG             5\n            364 LOAD_FAST             1334 (graph_out_0)\n            366 LOAD_CONST              43 (38)\n            368 BINARY_SUBSCR\n            370 EXTENDED_ARG             5\n            372 LOAD_FAST             1334 (graph_out_0)\n            374 LOAD_CONST              44 (39)\n            376 BINARY_SUBSCR\n            378 BUILD_TUPLE              2\n            380 EXTENDED_ARG             5\n            382 LOAD_FAST             1334 (graph_out_0)\n            384 LOAD_CONST              45 (40)\n            386 BINARY_SUBSCR\n            388 EXTENDED_ARG             5\n            390 LOAD_FAST             1334 (graph_out_0)\n            392 LOAD_CONST              46 (41)\n            394 BINARY_SUBSCR\n            396 BUILD_TUPLE              2\n            398 EXTENDED_ARG             5\n            400 LOAD_FAST             1334 (graph_out_0)\n            402 LOAD_CONST              47 (42)\n            404 BINARY_SUBSCR\n            406 EXTENDED_ARG             5\n            408 LOAD_FAST             1334 (graph_out_0)\n            410 LOAD_CONST              48 (43)\n            412 BINARY_SUBSCR\n            414 BUILD_TUPLE              2\n            416 EXTENDED_ARG             5\n            418 LOAD_FAST             1334 (graph_out_0)\n            420 LOAD_CONST              49 (44)\n            422 BINARY_SUBSCR\n            424 EXTENDED_ARG             5\n            426 LOAD_FAST             1334 (graph_out_0)\n            428 LOAD_CONST              50 (45)\n            430 BINARY_SUBSCR\n            432 BUILD_TUPLE              2\n            434 EXTENDED_ARG             5\n            436 LOAD_FAST             1334 (graph_out_0)\n            438 LOAD_CONST              51 (46)\n            440 BINARY_SUBSCR\n            442 EXTENDED_ARG             5\n            444 LOAD_FAST             1334 (graph_out_0)\n            446 LOAD_CONST              52 (47)\n            448 BINARY_SUBSCR\n            450 BUILD_TUPLE              2\n            452 EXTENDED_ARG             5\n            454 LOAD_FAST             1334 (graph_out_0)\n            456 LOAD_CONST              53 (48)\n            458 BINARY_SUBSCR\n            460 EXTENDED_ARG             5\n            462 LOAD_FAST             1334 (graph_out_0)\n            464 LOAD_CONST              54 (49)\n            466 BINARY_SUBSCR\n            468 BUILD_TUPLE              2\n            470 BUILD_TUPLE             24\n            472 LOAD_CONST               0 (None)\n            474 LOAD_CONST               0 (None)\n            476 LOAD_CONST               0 (None)\n            478 LOAD_CONST              55 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n            480 CALL_FUNCTION_KW         6\n            482 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              5 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             5\n             18 STORE_FAST            1306 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.models.xlnet.modeling_xlnet.XLNetLMHeadModelOutput'>)\n             22 EXTENDED_ARG             5\n             24 LOAD_FAST             1306 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             5\n             32 LOAD_FAST             1306 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 EXTENDED_ARG             5\n             40 LOAD_FAST             1306 (graph_out_0)\n             42 LOAD_CONST               7 (2)\n             44 BINARY_SUBSCR\n             46 EXTENDED_ARG             5\n             48 LOAD_FAST             1306 (graph_out_0)\n             50 LOAD_CONST               8 (3)\n             52 BINARY_SUBSCR\n             54 EXTENDED_ARG             5\n             56 LOAD_FAST             1306 (graph_out_0)\n             58 LOAD_CONST               9 (4)\n             60 BINARY_SUBSCR\n             62 EXTENDED_ARG             5\n             64 LOAD_FAST             1306 (graph_out_0)\n             66 LOAD_CONST              10 (5)\n             68 BINARY_SUBSCR\n             70 EXTENDED_ARG             5\n             72 LOAD_FAST             1306 (graph_out_0)\n             74 LOAD_CONST              11 (6)\n             76 BINARY_SUBSCR\n             78 EXTENDED_ARG             5\n             80 LOAD_FAST             1306 (graph_out_0)\n             82 LOAD_CONST              12 (7)\n             84 BINARY_SUBSCR\n             86 EXTENDED_ARG             5\n             88 LOAD_FAST             1306 (graph_out_0)\n             90 LOAD_CONST              13 (8)\n             92 BINARY_SUBSCR\n             94 EXTENDED_ARG             5\n             96 LOAD_FAST             1306 (graph_out_0)\n             98 LOAD_CONST              14 (9)\n            100 BINARY_SUBSCR\n            102 EXTENDED_ARG             5\n            104 LOAD_FAST             1306 (graph_out_0)\n            106 LOAD_CONST              15 (10)\n            108 BINARY_SUBSCR\n            110 EXTENDED_ARG             5\n            112 LOAD_FAST             1306 (graph_out_0)\n            114 LOAD_CONST              16 (11)\n            116 BINARY_SUBSCR\n            118 EXTENDED_ARG             5\n            120 LOAD_FAST             1306 (graph_out_0)\n            122 LOAD_CONST              17 (12)\n            124 BINARY_SUBSCR\n            126 EXTENDED_ARG             5\n            128 LOAD_FAST             1306 (graph_out_0)\n            130 LOAD_CONST              18 (13)\n            132 BINARY_SUBSCR\n            134 EXTENDED_ARG             5\n            136 LOAD_FAST             1306 (graph_out_0)\n            138 LOAD_CONST              19 (14)\n            140 BINARY_SUBSCR\n            142 EXTENDED_ARG             5\n            144 LOAD_FAST             1306 (graph_out_0)\n            146 LOAD_CONST              20 (15)\n            148 BINARY_SUBSCR\n            150 EXTENDED_ARG             5\n            152 LOAD_FAST             1306 (graph_out_0)\n            154 LOAD_CONST              21 (16)\n            156 BINARY_SUBSCR\n            158 EXTENDED_ARG             5\n            160 LOAD_FAST             1306 (graph_out_0)\n            162 LOAD_CONST              22 (17)\n            164 BINARY_SUBSCR\n            166 EXTENDED_ARG             5\n            168 LOAD_FAST             1306 (graph_out_0)\n            170 LOAD_CONST              23 (18)\n            172 BINARY_SUBSCR\n            174 EXTENDED_ARG             5\n            176 LOAD_FAST             1306 (graph_out_0)\n            178 LOAD_CONST              24 (19)\n            180 BINARY_SUBSCR\n            182 EXTENDED_ARG             5\n            184 LOAD_FAST             1306 (graph_out_0)\n            186 LOAD_CONST              25 (20)\n            188 BINARY_SUBSCR\n            190 EXTENDED_ARG             5\n            192 LOAD_FAST             1306 (graph_out_0)\n            194 LOAD_CONST              26 (21)\n            196 BINARY_SUBSCR\n            198 EXTENDED_ARG             5\n            200 LOAD_FAST             1306 (graph_out_0)\n            202 LOAD_CONST              27 (22)\n            204 BINARY_SUBSCR\n            206 EXTENDED_ARG             5\n            208 LOAD_FAST             1306 (graph_out_0)\n            210 LOAD_CONST              28 (23)\n            212 BINARY_SUBSCR\n            214 EXTENDED_ARG             5\n            216 LOAD_FAST             1306 (graph_out_0)\n            218 LOAD_CONST              29 (24)\n            220 BINARY_SUBSCR\n            222 EXTENDED_ARG             5\n            224 LOAD_FAST             1306 (graph_out_0)\n            226 LOAD_CONST              30 (25)\n            228 BINARY_SUBSCR\n            230 BUILD_TUPLE             24\n            232 LOAD_CONST               0 (None)\n            234 LOAD_CONST               0 (None)\n            236 LOAD_CONST              31 (('loss', 'logits', 'mems', 'hidden_states', 'attentions'))\n            238 CALL_FUNCTION_KW         5\n            240 RETURN_VALUE\n\n", "MODIFIED BYTECODE forward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 549 \n549           0 LOAD_GLOBAL              6 (__compiled_fn_0)\n              2 LOAD_FAST                2 (inputs)\n              4 LOAD_CONST               2 ('input_ids')\n              6 BINARY_SUBSCR\n              8 LOAD_FAST                2 (inputs)\n             10 LOAD_CONST               3 ('labels')\n             12 BINARY_SUBSCR\n             14 CALL_FUNCTION            2\n             16 EXTENDED_ARG             3\n             18 STORE_FAST             957 (graph_out_0)\n             20 LOAD_CONST               4 (<class 'transformers.modeling_outputs.MaskedLMOutput'>)\n             22 EXTENDED_ARG             3\n             24 LOAD_FAST              957 (graph_out_0)\n             26 LOAD_CONST               5 (0)\n             28 BINARY_SUBSCR\n             30 EXTENDED_ARG             3\n             32 LOAD_FAST              957 (graph_out_0)\n             34 LOAD_CONST               6 (1)\n             36 BINARY_SUBSCR\n             38 LOAD_CONST               0 (None)\n             40 LOAD_CONST               0 (None)\n             42 LOAD_CONST               7 (('loss', 'logits', 'hidden_states', 'attentions'))\n             44 CALL_FUNCTION_KW         4\n             46 RETURN_VALUE\n\n"]