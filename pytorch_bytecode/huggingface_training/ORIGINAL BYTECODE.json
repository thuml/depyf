["ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py line 1789 \n1841           0 LOAD_FAST               11 (return_dict)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               11 (return_dict)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (use_return_dict)\n         >>   18 STORE_FAST              11 (return_dict)\n\n1843          20 LOAD_FAST                0 (self)\n              22 LOAD_ATTR                2 (longformer)\n\n1844          24 LOAD_FAST                1 (input_ids)\n\n1845          26 LOAD_FAST                2 (attention_mask)\n\n1846          28 LOAD_FAST                3 (global_attention_mask)\n\n1847          30 LOAD_FAST                4 (head_mask)\n\n1848          32 LOAD_FAST                5 (token_type_ids)\n\n1849          34 LOAD_FAST                6 (position_ids)\n\n1850          36 LOAD_FAST                7 (inputs_embeds)\n\n1851          38 LOAD_FAST                9 (output_attentions)\n\n1852          40 LOAD_FAST               10 (output_hidden_states)\n\n1853          42 LOAD_FAST               11 (return_dict)\n\n1843          44 LOAD_CONST               2 (('attention_mask', 'global_attention_mask', 'head_mask', 'token_type_ids', 'position_ids', 'inputs_embeds', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              46 CALL_FUNCTION_KW        10\n              48 STORE_FAST              12 (outputs)\n\n1855          50 LOAD_FAST               12 (outputs)\n              52 LOAD_CONST               3 (0)\n              54 BINARY_SUBSCR\n              56 STORE_FAST              13 (sequence_output)\n\n1856          58 LOAD_FAST                0 (self)\n              60 LOAD_METHOD              3 (lm_head)\n              62 LOAD_FAST               13 (sequence_output)\n              64 CALL_METHOD              1\n              66 STORE_FAST              14 (prediction_scores)\n\n1858          68 LOAD_CONST               1 (None)\n              70 STORE_FAST              15 (masked_lm_loss)\n\n1859          72 LOAD_FAST                8 (labels)\n              74 LOAD_CONST               1 (None)\n              76 IS_OP                    1\n              78 POP_JUMP_IF_FALSE       63 (to 126)\n\n1860          80 LOAD_GLOBAL              4 (CrossEntropyLoss)\n              82 CALL_FUNCTION            0\n              84 STORE_FAST              16 (loss_fct)\n\n1862          86 LOAD_FAST                8 (labels)\n              88 LOAD_METHOD              5 (to)\n              90 LOAD_FAST               14 (prediction_scores)\n              92 LOAD_ATTR                6 (device)\n              94 CALL_METHOD              1\n              96 STORE_FAST               8 (labels)\n\n1863          98 LOAD_FAST               16 (loss_fct)\n             100 LOAD_FAST               14 (prediction_scores)\n             102 LOAD_METHOD              7 (view)\n             104 LOAD_CONST               4 (-1)\n             106 LOAD_FAST                0 (self)\n             108 LOAD_ATTR                0 (config)\n             110 LOAD_ATTR                8 (vocab_size)\n             112 CALL_METHOD              2\n             114 LOAD_FAST                8 (labels)\n             116 LOAD_METHOD              7 (view)\n             118 LOAD_CONST               4 (-1)\n             120 CALL_METHOD              1\n             122 CALL_FUNCTION            2\n             124 STORE_FAST              15 (masked_lm_loss)\n\n1865     >>  126 LOAD_FAST               11 (return_dict)\n             128 POP_JUMP_IF_TRUE        85 (to 170)\n\n1866         130 LOAD_FAST               14 (prediction_scores)\n             132 BUILD_TUPLE              1\n             134 LOAD_FAST               12 (outputs)\n             136 LOAD_CONST               5 (2)\n             138 LOAD_CONST               1 (None)\n             140 BUILD_SLICE              2\n             142 BINARY_SUBSCR\n             144 BINARY_ADD\n             146 STORE_FAST              17 (output)\n\n1867         148 LOAD_FAST               15 (masked_lm_loss)\n             150 LOAD_CONST               1 (None)\n             152 IS_OP                    1\n             154 POP_JUMP_IF_FALSE       83 (to 166)\n             156 LOAD_FAST               15 (masked_lm_loss)\n             158 BUILD_TUPLE              1\n             160 LOAD_FAST               17 (output)\n             162 BINARY_ADD\n             164 RETURN_VALUE\n         >>  166 LOAD_FAST               17 (output)\n             168 RETURN_VALUE\n\n1869     >>  170 LOAD_GLOBAL              9 (LongformerMaskedLMOutput)\n\n1870         172 LOAD_FAST               15 (masked_lm_loss)\n\n1871         174 LOAD_FAST               14 (prediction_scores)\n\n1872         176 LOAD_FAST               12 (outputs)\n             178 LOAD_ATTR               10 (hidden_states)\n\n1873         180 LOAD_FAST               12 (outputs)\n             182 LOAD_ATTR               11 (attentions)\n\n1874         184 LOAD_FAST               12 (outputs)\n             186 LOAD_ATTR               12 (global_attentions)\n\n1869         188 LOAD_CONST               6 (('loss', 'logits', 'hidden_states', 'attentions', 'global_attentions'))\n             190 CALL_FUNCTION_KW         5\n             192 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py line 1647 \n1701           0 LOAD_FAST                8 (output_attentions)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST                8 (output_attentions)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (output_attentions)\n         >>   18 STORE_FAST               8 (output_attentions)\n\n1703          20 LOAD_FAST                9 (output_hidden_states)\n              22 LOAD_CONST               1 (None)\n              24 IS_OP                    1\n              26 POP_JUMP_IF_FALSE       16 (to 32)\n              28 LOAD_FAST                9 (output_hidden_states)\n              30 JUMP_FORWARD             3 (to 38)\n         >>   32 LOAD_FAST                0 (self)\n              34 LOAD_ATTR                0 (config)\n              36 LOAD_ATTR                2 (output_hidden_states)\n\n1702     >>   38 STORE_FAST               9 (output_hidden_states)\n\n1705          40 LOAD_FAST               10 (return_dict)\n              42 LOAD_CONST               1 (None)\n              44 IS_OP                    1\n              46 POP_JUMP_IF_FALSE       26 (to 52)\n              48 LOAD_FAST               10 (return_dict)\n              50 JUMP_FORWARD             3 (to 58)\n         >>   52 LOAD_FAST                0 (self)\n              54 LOAD_ATTR                0 (config)\n              56 LOAD_ATTR                3 (use_return_dict)\n         >>   58 STORE_FAST              10 (return_dict)\n\n1707          60 LOAD_FAST                1 (input_ids)\n              62 LOAD_CONST               1 (None)\n              64 IS_OP                    1\n              66 POP_JUMP_IF_FALSE       42 (to 84)\n              68 LOAD_FAST                7 (inputs_embeds)\n              70 LOAD_CONST               1 (None)\n              72 IS_OP                    1\n              74 POP_JUMP_IF_FALSE       42 (to 84)\n\n1708          76 LOAD_GLOBAL              4 (ValueError)\n              78 LOAD_CONST               2 ('You cannot specify both input_ids and inputs_embeds at the same time')\n              80 CALL_FUNCTION            1\n              82 RAISE_VARARGS            1\n\n1709     >>   84 LOAD_FAST                1 (input_ids)\n              86 LOAD_CONST               1 (None)\n              88 IS_OP                    1\n              90 POP_JUMP_IF_FALSE       51 (to 102)\n\n1710          92 LOAD_FAST                1 (input_ids)\n              94 LOAD_METHOD              5 (size)\n              96 CALL_METHOD              0\n              98 STORE_FAST              11 (input_shape)\n             100 JUMP_FORWARD            17 (to 136)\n\n1711     >>  102 LOAD_FAST                7 (inputs_embeds)\n             104 LOAD_CONST               1 (None)\n             106 IS_OP                    1\n             108 POP_JUMP_IF_FALSE       64 (to 128)\n\n1712         110 LOAD_FAST                7 (inputs_embeds)\n             112 LOAD_METHOD              5 (size)\n             114 CALL_METHOD              0\n             116 LOAD_CONST               1 (None)\n             118 LOAD_CONST               3 (-1)\n             120 BUILD_SLICE              2\n             122 BINARY_SUBSCR\n             124 STORE_FAST              11 (input_shape)\n             126 JUMP_FORWARD             4 (to 136)\n\n1714     >>  128 LOAD_GLOBAL              4 (ValueError)\n             130 LOAD_CONST               4 ('You have to specify either input_ids or inputs_embeds')\n             132 CALL_FUNCTION            1\n             134 RAISE_VARARGS            1\n\n1716     >>  136 LOAD_FAST                1 (input_ids)\n             138 LOAD_CONST               1 (None)\n             140 IS_OP                    1\n             142 POP_JUMP_IF_FALSE       75 (to 150)\n             144 LOAD_FAST                1 (input_ids)\n             146 LOAD_ATTR                6 (device)\n             148 JUMP_FORWARD             2 (to 154)\n         >>  150 LOAD_FAST                7 (inputs_embeds)\n             152 LOAD_ATTR                6 (device)\n         >>  154 STORE_FAST              12 (device)\n\n1718         156 LOAD_FAST                2 (attention_mask)\n             158 LOAD_CONST               1 (None)\n             160 IS_OP                    0\n             162 POP_JUMP_IF_FALSE       89 (to 178)\n\n1719         164 LOAD_GLOBAL              7 (torch)\n             166 LOAD_ATTR                8 (ones)\n             168 LOAD_FAST               11 (input_shape)\n             170 LOAD_FAST               12 (device)\n             172 LOAD_CONST               5 (('device',))\n             174 CALL_FUNCTION_KW         2\n             176 STORE_FAST               2 (attention_mask)\n\n1720     >>  178 LOAD_FAST                5 (token_type_ids)\n             180 LOAD_CONST               1 (None)\n             182 IS_OP                    0\n             184 POP_JUMP_IF_FALSE      102 (to 204)\n\n1721         186 LOAD_GLOBAL              7 (torch)\n             188 LOAD_ATTR                9 (zeros)\n             190 LOAD_FAST               11 (input_shape)\n             192 LOAD_GLOBAL              7 (torch)\n             194 LOAD_ATTR               10 (long)\n             196 LOAD_FAST               12 (device)\n             198 LOAD_CONST               6 (('dtype', 'device'))\n             200 CALL_FUNCTION_KW         3\n             202 STORE_FAST               5 (token_type_ids)\n\n1724     >>  204 LOAD_FAST                3 (global_attention_mask)\n             206 LOAD_CONST               1 (None)\n             208 IS_OP                    1\n             210 POP_JUMP_IF_FALSE      112 (to 224)\n\n1725         212 LOAD_FAST                0 (self)\n             214 LOAD_METHOD             11 (_merge_to_attention_mask)\n             216 LOAD_FAST                2 (attention_mask)\n             218 LOAD_FAST                3 (global_attention_mask)\n             220 CALL_METHOD              2\n             222 STORE_FAST               2 (attention_mask)\n\n1727     >>  224 LOAD_FAST                0 (self)\n             226 LOAD_ATTR               12 (_pad_to_window_size)\n\n1728         228 LOAD_FAST                1 (input_ids)\n\n1729         230 LOAD_FAST                2 (attention_mask)\n\n1730         232 LOAD_FAST                5 (token_type_ids)\n\n1731         234 LOAD_FAST                6 (position_ids)\n\n1732         236 LOAD_FAST                7 (inputs_embeds)\n\n1733         238 LOAD_FAST                0 (self)\n             240 LOAD_ATTR                0 (config)\n             242 LOAD_ATTR               13 (pad_token_id)\n\n1727         244 LOAD_CONST               7 (('input_ids', 'attention_mask', 'token_type_ids', 'position_ids', 'inputs_embeds', 'pad_token_id'))\n             246 CALL_FUNCTION_KW         6\n             248 UNPACK_SEQUENCE          6\n             250 STORE_FAST              13 (padding_len)\n             252 STORE_FAST               1 (input_ids)\n             254 STORE_FAST               2 (attention_mask)\n             256 STORE_FAST               5 (token_type_ids)\n             258 STORE_FAST               6 (position_ids)\n             260 STORE_FAST               7 (inputs_embeds)\n\n1738         262 LOAD_FAST                0 (self)\n             264 LOAD_METHOD             14 (get_extended_attention_mask)\n             266 LOAD_FAST                2 (attention_mask)\n             268 LOAD_FAST               11 (input_shape)\n             270 CALL_METHOD              2\n\n1739         272 LOAD_CONST               1 (None)\n             274 LOAD_CONST               1 (None)\n             276 BUILD_SLICE              2\n             278 LOAD_CONST               8 (0)\n             280 LOAD_CONST               8 (0)\n             282 LOAD_CONST               1 (None)\n             284 LOAD_CONST               1 (None)\n             286 BUILD_SLICE              2\n             288 BUILD_TUPLE              4\n\n1738         290 BINARY_SUBSCR\n             292 STORE_FAST              14 (extended_attention_mask)\n\n1742         294 LOAD_FAST                0 (self)\n             296 LOAD_ATTR               15 (embeddings)\n\n1743         298 LOAD_FAST                1 (input_ids)\n             300 LOAD_FAST                6 (position_ids)\n             302 LOAD_FAST                5 (token_type_ids)\n             304 LOAD_FAST                7 (inputs_embeds)\n\n1742         306 LOAD_CONST               9 (('input_ids', 'position_ids', 'token_type_ids', 'inputs_embeds'))\n             308 CALL_FUNCTION_KW         4\n             310 STORE_FAST              15 (embedding_output)\n\n1746         312 LOAD_FAST                0 (self)\n             314 LOAD_ATTR               16 (encoder)\n\n1747         316 LOAD_FAST               15 (embedding_output)\n\n1748         318 LOAD_FAST               14 (extended_attention_mask)\n\n1749         320 LOAD_FAST                4 (head_mask)\n\n1750         322 LOAD_FAST               13 (padding_len)\n\n1751         324 LOAD_FAST                8 (output_attentions)\n\n1752         326 LOAD_FAST                9 (output_hidden_states)\n\n1753         328 LOAD_FAST               10 (return_dict)\n\n1746         330 LOAD_CONST              10 (('attention_mask', 'head_mask', 'padding_len', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             332 CALL_FUNCTION_KW         7\n             334 STORE_FAST              16 (encoder_outputs)\n\n1755         336 LOAD_FAST               16 (encoder_outputs)\n             338 LOAD_CONST               8 (0)\n             340 BINARY_SUBSCR\n             342 STORE_FAST              17 (sequence_output)\n\n1756         344 LOAD_FAST                0 (self)\n             346 LOAD_ATTR               17 (pooler)\n             348 LOAD_CONST               1 (None)\n             350 IS_OP                    1\n             352 POP_JUMP_IF_FALSE      182 (to 364)\n             354 LOAD_FAST                0 (self)\n             356 LOAD_METHOD             17 (pooler)\n             358 LOAD_FAST               17 (sequence_output)\n             360 CALL_METHOD              1\n             362 JUMP_FORWARD             1 (to 366)\n         >>  364 LOAD_CONST               1 (None)\n         >>  366 STORE_FAST              18 (pooled_output)\n\n1758         368 LOAD_FAST               10 (return_dict)\n             370 POP_JUMP_IF_TRUE       196 (to 392)\n\n1759         372 LOAD_FAST               17 (sequence_output)\n             374 LOAD_FAST               18 (pooled_output)\n             376 BUILD_TUPLE              2\n             378 LOAD_FAST               16 (encoder_outputs)\n             380 LOAD_CONST              11 (1)\n             382 LOAD_CONST               1 (None)\n             384 BUILD_SLICE              2\n             386 BINARY_SUBSCR\n             388 BINARY_ADD\n             390 RETURN_VALUE\n\n1761     >>  392 LOAD_GLOBAL             18 (LongformerBaseModelOutputWithPooling)\n\n1762         394 LOAD_FAST               17 (sequence_output)\n\n1763         396 LOAD_FAST               18 (pooled_output)\n\n1764         398 LOAD_FAST               16 (encoder_outputs)\n             400 LOAD_ATTR               19 (hidden_states)\n\n1765         402 LOAD_FAST               16 (encoder_outputs)\n             404 LOAD_ATTR               20 (attentions)\n\n1766         406 LOAD_FAST               16 (encoder_outputs)\n             408 LOAD_ATTR               21 (global_attentions)\n\n1761         410 LOAD_CONST              12 (('last_hidden_state', 'pooler_output', 'hidden_states', 'attentions', 'global_attentions'))\n             412 CALL_FUNCTION_KW         5\n             414 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py line 1277 \n1287           0 LOAD_FAST                2 (attention_mask)\n               2 LOAD_CONST               1 (0)\n               4 COMPARE_OP               0 (<)\n               6 STORE_FAST               8 (is_index_masked)\n\n1288           8 LOAD_FAST                2 (attention_mask)\n              10 LOAD_CONST               1 (0)\n              12 COMPARE_OP               4 (>)\n              14 STORE_FAST               9 (is_index_global_attn)\n\n1291          16 LOAD_FAST                9 (is_index_global_attn)\n              18 LOAD_METHOD              0 (flatten)\n              20 CALL_METHOD              0\n              22 LOAD_METHOD              1 (any)\n              24 CALL_METHOD              0\n              26 LOAD_METHOD              2 (item)\n              28 CALL_METHOD              0\n              30 STORE_DEREF              0 (is_global_attn)\n\n1293          32 LOAD_FAST                6 (output_hidden_states)\n              34 POP_JUMP_IF_FALSE       20 (to 40)\n              36 LOAD_CONST               2 (())\n              38 JUMP_FORWARD             1 (to 42)\n         >>   40 LOAD_CONST               0 (None)\n         >>   42 STORE_FAST              10 (all_hidden_states)\n\n1294          44 LOAD_DEREF               1 (output_attentions)\n              46 POP_JUMP_IF_FALSE       26 (to 52)\n              48 LOAD_CONST               2 (())\n              50 JUMP_FORWARD             1 (to 54)\n         >>   52 LOAD_CONST               0 (None)\n         >>   54 STORE_FAST              11 (all_attentions)\n\n1295          56 LOAD_DEREF               1 (output_attentions)\n              58 POP_JUMP_IF_FALSE       34 (to 68)\n              60 LOAD_DEREF               0 (is_global_attn)\n              62 POP_JUMP_IF_FALSE       34 (to 68)\n              64 LOAD_CONST               2 (())\n              66 JUMP_FORWARD             1 (to 70)\n         >>   68 LOAD_CONST               0 (None)\n         >>   70 STORE_FAST              12 (all_global_attentions)\n\n1298          72 LOAD_FAST                3 (head_mask)\n              74 LOAD_CONST               0 (None)\n              76 IS_OP                    1\n              78 POP_JUMP_IF_FALSE       69 (to 138)\n\n1299          80 LOAD_FAST                3 (head_mask)\n              82 LOAD_METHOD              3 (size)\n              84 CALL_METHOD              0\n              86 LOAD_CONST               1 (0)\n              88 BINARY_SUBSCR\n\n1300          90 LOAD_GLOBAL              4 (len)\n              92 LOAD_FAST                0 (self)\n              94 LOAD_ATTR                5 (layer)\n              96 CALL_FUNCTION            1\n\n1299          98 COMPARE_OP               2 (==)\n             100 POP_JUMP_IF_TRUE        69 (to 138)\n             102 LOAD_ASSERTION_ERROR\n\n1301         104 LOAD_CONST               3 ('The head_mask should be specified for ')\n             106 LOAD_GLOBAL              4 (len)\n             108 LOAD_FAST                0 (self)\n             110 LOAD_ATTR                5 (layer)\n             112 CALL_FUNCTION            1\n             114 FORMAT_VALUE             0\n             116 LOAD_CONST               4 (' layers, but it is for ')\n             118 LOAD_FAST                3 (head_mask)\n             120 LOAD_METHOD              3 (size)\n             122 CALL_METHOD              0\n             124 LOAD_CONST               1 (0)\n             126 BINARY_SUBSCR\n             128 FORMAT_VALUE             0\n             130 LOAD_CONST               5 ('.')\n             132 BUILD_STRING             5\n\n1299         134 CALL_FUNCTION            1\n             136 RAISE_VARARGS            1\n\n1302     >>  138 LOAD_GLOBAL              6 (enumerate)\n             140 LOAD_FAST                0 (self)\n             142 LOAD_ATTR                5 (layer)\n             144 CALL_FUNCTION            1\n             146 GET_ITER\n         >>  148 FOR_ITER                96 (to 342)\n             150 UNPACK_SEQUENCE          2\n             152 STORE_FAST              13 (idx)\n             154 STORE_FAST              14 (layer_module)\n\n1303         156 LOAD_FAST                6 (output_hidden_states)\n             158 POP_JUMP_IF_FALSE       85 (to 170)\n\n1304         160 LOAD_FAST               10 (all_hidden_states)\n             162 LOAD_FAST                1 (hidden_states)\n             164 BUILD_TUPLE              1\n             166 BINARY_ADD\n             168 STORE_FAST              10 (all_hidden_states)\n\n1306     >>  170 LOAD_FAST                0 (self)\n             172 LOAD_ATTR                7 (gradient_checkpointing)\n             174 POP_JUMP_IF_FALSE      121 (to 242)\n             176 LOAD_FAST                0 (self)\n             178 LOAD_ATTR                8 (training)\n             180 POP_JUMP_IF_FALSE      121 (to 242)\n\n1308         182 LOAD_CLOSURE             0 (is_global_attn)\n             184 LOAD_CLOSURE             1 (output_attentions)\n             186 BUILD_TUPLE              2\n             188 LOAD_CONST               6 (<code object create_custom_forward at 0x7f1887f45e70, file \"/workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1308>)\n             190 LOAD_CONST               7 ('LongformerEncoder.forward.<locals>.create_custom_forward')\n             192 MAKE_FUNCTION            8 (closure)\n             194 STORE_FAST              15 (create_custom_forward)\n\n1314         196 LOAD_GLOBAL              9 (torch)\n             198 LOAD_ATTR               10 (utils)\n             200 LOAD_ATTR               11 (checkpoint)\n             202 LOAD_METHOD             11 (checkpoint)\n\n1315         204 LOAD_FAST               15 (create_custom_forward)\n             206 LOAD_FAST               14 (layer_module)\n             208 CALL_FUNCTION            1\n\n1316         210 LOAD_FAST                1 (hidden_states)\n\n1317         212 LOAD_FAST                2 (attention_mask)\n\n1318         214 LOAD_FAST                3 (head_mask)\n             216 LOAD_CONST               0 (None)\n             218 IS_OP                    1\n             220 POP_JUMP_IF_FALSE      115 (to 230)\n             222 LOAD_FAST                3 (head_mask)\n             224 LOAD_FAST               13 (idx)\n             226 BINARY_SUBSCR\n             228 JUMP_FORWARD             1 (to 232)\n         >>  230 LOAD_CONST               0 (None)\n\n1319     >>  232 LOAD_FAST                8 (is_index_masked)\n\n1320         234 LOAD_FAST                9 (is_index_global_attn)\n\n1314         236 CALL_METHOD              6\n             238 STORE_FAST              16 (layer_outputs)\n             240 JUMP_FORWARD            19 (to 280)\n\n1323     >>  242 LOAD_FAST               14 (layer_module)\n\n1324         244 LOAD_FAST                1 (hidden_states)\n\n1325         246 LOAD_FAST                2 (attention_mask)\n\n1326         248 LOAD_FAST                3 (head_mask)\n             250 LOAD_CONST               0 (None)\n             252 IS_OP                    1\n             254 POP_JUMP_IF_FALSE      132 (to 264)\n             256 LOAD_FAST                3 (head_mask)\n             258 LOAD_FAST               13 (idx)\n             260 BINARY_SUBSCR\n             262 JUMP_FORWARD             1 (to 266)\n         >>  264 LOAD_CONST               0 (None)\n\n1327     >>  266 LOAD_FAST                8 (is_index_masked)\n\n1328         268 LOAD_FAST                9 (is_index_global_attn)\n\n1329         270 LOAD_DEREF               0 (is_global_attn)\n\n1330         272 LOAD_DEREF               1 (output_attentions)\n\n1323         274 LOAD_CONST               8 (('attention_mask', 'layer_head_mask', 'is_index_masked', 'is_index_global_attn', 'is_global_attn', 'output_attentions'))\n             276 CALL_FUNCTION_KW         7\n             278 STORE_FAST              16 (layer_outputs)\n\n1332     >>  280 LOAD_FAST               16 (layer_outputs)\n             282 LOAD_CONST               1 (0)\n             284 BINARY_SUBSCR\n             286 STORE_FAST               1 (hidden_states)\n\n1334         288 LOAD_DEREF               1 (output_attentions)\n             290 POP_JUMP_IF_FALSE      170 (to 340)\n\n1336         292 LOAD_FAST               11 (all_attentions)\n             294 LOAD_FAST               16 (layer_outputs)\n             296 LOAD_CONST               9 (1)\n             298 BINARY_SUBSCR\n             300 LOAD_METHOD             12 (transpose)\n             302 LOAD_CONST               9 (1)\n             304 LOAD_CONST              10 (2)\n             306 CALL_METHOD              2\n             308 BUILD_TUPLE              1\n             310 BINARY_ADD\n             312 STORE_FAST              11 (all_attentions)\n\n1338         314 LOAD_DEREF               0 (is_global_attn)\n             316 POP_JUMP_IF_FALSE      170 (to 340)\n\n1340         318 LOAD_FAST               12 (all_global_attentions)\n             320 LOAD_FAST               16 (layer_outputs)\n             322 LOAD_CONST              10 (2)\n             324 BINARY_SUBSCR\n             326 LOAD_METHOD             12 (transpose)\n             328 LOAD_CONST              10 (2)\n             330 LOAD_CONST              11 (3)\n             332 CALL_METHOD              2\n             334 BUILD_TUPLE              1\n             336 BINARY_ADD\n             338 STORE_FAST              12 (all_global_attentions)\n         >>  340 JUMP_ABSOLUTE           74 (to 148)\n\n1343     >>  342 LOAD_FAST                6 (output_hidden_states)\n             344 POP_JUMP_IF_FALSE      178 (to 356)\n\n1344         346 LOAD_FAST               10 (all_hidden_states)\n             348 LOAD_FAST                1 (hidden_states)\n             350 BUILD_TUPLE              1\n             352 BINARY_ADD\n             354 STORE_FAST              10 (all_hidden_states)\n\n1348     >>  356 LOAD_FAST                1 (hidden_states)\n             358 LOAD_CONST               0 (None)\n             360 LOAD_CONST               0 (None)\n             362 BUILD_SLICE              2\n             364 LOAD_CONST               0 (None)\n             366 LOAD_FAST                1 (hidden_states)\n             368 LOAD_ATTR               13 (shape)\n             370 LOAD_CONST               9 (1)\n             372 BINARY_SUBSCR\n             374 LOAD_DEREF               2 (padding_len)\n             376 BINARY_SUBTRACT\n             378 BUILD_SLICE              2\n             380 BUILD_TUPLE              2\n             382 BINARY_SUBSCR\n             384 STORE_FAST               1 (hidden_states)\n\n1349         386 LOAD_FAST                6 (output_hidden_states)\n             388 POP_JUMP_IF_FALSE      206 (to 412)\n\n1350         390 LOAD_GLOBAL             14 (tuple)\n             392 LOAD_CLOSURE             2 (padding_len)\n             394 BUILD_TUPLE              1\n             396 LOAD_CONST              12 (<code object <listcomp> at 0x7f1887f45f20, file \"/workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1350>)\n             398 LOAD_CONST              13 ('LongformerEncoder.forward.<locals>.<listcomp>')\n             400 MAKE_FUNCTION            8 (closure)\n             402 LOAD_FAST               10 (all_hidden_states)\n             404 GET_ITER\n             406 CALL_FUNCTION            1\n             408 CALL_FUNCTION            1\n             410 STORE_FAST              10 (all_hidden_states)\n\n1352     >>  412 LOAD_DEREF               1 (output_attentions)\n             414 POP_JUMP_IF_FALSE      219 (to 438)\n\n1353         416 LOAD_GLOBAL             14 (tuple)\n             418 LOAD_CLOSURE             2 (padding_len)\n             420 BUILD_TUPLE              1\n             422 LOAD_CONST              14 (<code object <listcomp> at 0x7f1887f45fd0, file \"/workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1353>)\n             424 LOAD_CONST              13 ('LongformerEncoder.forward.<locals>.<listcomp>')\n             426 MAKE_FUNCTION            8 (closure)\n             428 LOAD_FAST               11 (all_attentions)\n             430 GET_ITER\n             432 CALL_FUNCTION            1\n             434 CALL_FUNCTION            1\n             436 STORE_FAST              11 (all_attentions)\n\n1355     >>  438 LOAD_FAST                7 (return_dict)\n             440 POP_JUMP_IF_TRUE       234 (to 468)\n\n1356         442 LOAD_GLOBAL             14 (tuple)\n             444 LOAD_CONST              15 (<code object <genexpr> at 0x7f1887f46080, file \"/workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1356>)\n             446 LOAD_CONST              16 ('LongformerEncoder.forward.<locals>.<genexpr>')\n             448 MAKE_FUNCTION            0\n\n1357         450 LOAD_FAST                1 (hidden_states)\n             452 LOAD_FAST               10 (all_hidden_states)\n             454 LOAD_FAST               11 (all_attentions)\n             456 LOAD_FAST               12 (all_global_attentions)\n             458 BUILD_TUPLE              4\n\n1356         460 GET_ITER\n             462 CALL_FUNCTION            1\n             464 CALL_FUNCTION            1\n             466 RETURN_VALUE\n\n1359     >>  468 LOAD_GLOBAL             15 (LongformerBaseModelOutput)\n\n1360         470 LOAD_FAST                1 (hidden_states)\n\n1361         472 LOAD_FAST               10 (all_hidden_states)\n\n1362         474 LOAD_FAST               11 (all_attentions)\n\n1363         476 LOAD_FAST               12 (all_global_attentions)\n\n1359         478 LOAD_CONST              17 (('last_hidden_state', 'hidden_states', 'attentions', 'global_attentions'))\n             480 CALL_FUNCTION_KW         4\n             482 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py line 1291 \n1291           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           17 (to 34)\n               4 LOAD_FAST                3 (attention_mask)\n               6 LOAD_CONST               1 (0)\n               8 COMPARE_OP               0 (<)\n              10 STORE_FAST               7 (is_index_masked)\n              12 LOAD_FAST                3 (attention_mask)\n              14 LOAD_CONST               1 (0)\n              16 COMPARE_OP               4 (>)\n              18 STORE_FAST               8 (is_index_global_attn)\n              20 LOAD_FAST                8 (is_index_global_attn)\n              22 LOAD_ATTR                0 (flatten)\n              24 CALL_FUNCTION            0\n              26 LOAD_ATTR                1 (any)\n              28 CALL_FUNCTION            0\n              30 LOAD_ATTR                2 (item)\n              32 CALL_FUNCTION            0\n         >>   34 STORE_DEREF              0 (is_global_attn)\n\n1293          36 LOAD_FAST                5 (output_hidden_states)\n              38 POP_JUMP_IF_FALSE       22 (to 44)\n              40 LOAD_CONST               2 (())\n              42 JUMP_FORWARD             1 (to 46)\n         >>   44 LOAD_CONST               0 (None)\n         >>   46 STORE_FAST              11 (all_hidden_states)\n\n1294          48 LOAD_DEREF               1 (output_attentions)\n              50 POP_JUMP_IF_FALSE       28 (to 56)\n              52 LOAD_CONST               2 (())\n              54 JUMP_FORWARD             1 (to 58)\n         >>   56 LOAD_CONST               0 (None)\n         >>   58 STORE_FAST              12 (all_attentions)\n\n1295          60 LOAD_DEREF               1 (output_attentions)\n              62 POP_JUMP_IF_FALSE       36 (to 72)\n              64 LOAD_DEREF               0 (is_global_attn)\n              66 POP_JUMP_IF_FALSE       36 (to 72)\n              68 LOAD_CONST               2 (())\n              70 JUMP_FORWARD             1 (to 74)\n         >>   72 LOAD_CONST               0 (None)\n         >>   74 STORE_FAST              13 (all_global_attentions)\n\n1298          76 LOAD_FAST                4 (head_mask)\n              78 LOAD_CONST               0 (None)\n              80 IS_OP                    1\n              82 POP_JUMP_IF_FALSE       71 (to 142)\n\n1299          84 LOAD_FAST                4 (head_mask)\n              86 LOAD_ATTR                3 (size)\n              88 CALL_FUNCTION            0\n              90 LOAD_CONST               1 (0)\n              92 BINARY_SUBSCR\n\n1300          94 LOAD_GLOBAL              4 (len)\n              96 LOAD_FAST                1 (self)\n              98 LOAD_ATTR                5 (layer)\n             100 CALL_FUNCTION            1\n\n1299         102 COMPARE_OP               2 (==)\n             104 POP_JUMP_IF_TRUE        71 (to 142)\n             106 LOAD_ASSERTION_ERROR\n\n1301         108 LOAD_CONST               3 ('The head_mask should be specified for ')\n             110 LOAD_GLOBAL              4 (len)\n             112 LOAD_FAST                1 (self)\n             114 LOAD_ATTR                5 (layer)\n             116 CALL_FUNCTION            1\n             118 FORMAT_VALUE             0\n             120 LOAD_CONST               4 (' layers, but it is for ')\n             122 LOAD_FAST                4 (head_mask)\n             124 LOAD_ATTR                3 (size)\n             126 CALL_FUNCTION            0\n             128 LOAD_CONST               1 (0)\n             130 BINARY_SUBSCR\n             132 FORMAT_VALUE             0\n             134 LOAD_CONST               5 ('.')\n             136 BUILD_STRING             5\n\n1299         138 CALL_FUNCTION            1\n             140 RAISE_VARARGS            1\n\n1302     >>  142 LOAD_GLOBAL              6 (enumerate)\n             144 LOAD_FAST                1 (self)\n             146 LOAD_ATTR                5 (layer)\n             148 CALL_FUNCTION            1\n             150 GET_ITER\n         >>  152 FOR_ITER                96 (to 346)\n             154 UNPACK_SEQUENCE          2\n             156 STORE_FAST              14 (idx)\n             158 STORE_FAST              15 (layer_module)\n\n1303         160 LOAD_FAST                5 (output_hidden_states)\n             162 POP_JUMP_IF_FALSE       87 (to 174)\n\n1304         164 LOAD_FAST               11 (all_hidden_states)\n             166 LOAD_FAST                2 (hidden_states)\n             168 BUILD_TUPLE              1\n             170 BINARY_ADD\n             172 STORE_FAST              11 (all_hidden_states)\n\n1306     >>  174 LOAD_FAST                1 (self)\n             176 LOAD_ATTR                7 (gradient_checkpointing)\n             178 POP_JUMP_IF_FALSE      123 (to 246)\n             180 LOAD_FAST                1 (self)\n             182 LOAD_ATTR                8 (training)\n             184 POP_JUMP_IF_FALSE      123 (to 246)\n\n1308         186 LOAD_CLOSURE             0 (is_global_attn)\n             188 LOAD_CLOSURE             1 (output_attentions)\n             190 BUILD_TUPLE              2\n             192 LOAD_CONST               6 (<code object create_custom_forward at 0x7f1887f45e70, file \"/workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1308>)\n             194 LOAD_CONST               7 ('LongformerEncoder.forward.<locals>.create_custom_forward')\n             196 MAKE_FUNCTION            8 (closure)\n             198 STORE_FAST              16 (create_custom_forward)\n\n1314         200 LOAD_GLOBAL              9 (torch)\n             202 LOAD_ATTR               10 (utils)\n             204 LOAD_ATTR               11 (checkpoint)\n             206 LOAD_ATTR               11 (checkpoint)\n\n1315         208 LOAD_FAST               16 (create_custom_forward)\n             210 LOAD_FAST               15 (layer_module)\n             212 CALL_FUNCTION            1\n\n1316         214 LOAD_FAST                2 (hidden_states)\n\n1317         216 LOAD_FAST                3 (attention_mask)\n\n1318         218 LOAD_FAST                4 (head_mask)\n             220 LOAD_CONST               0 (None)\n             222 IS_OP                    1\n             224 POP_JUMP_IF_FALSE      117 (to 234)\n             226 LOAD_FAST                4 (head_mask)\n             228 LOAD_FAST               14 (idx)\n             230 BINARY_SUBSCR\n             232 JUMP_FORWARD             1 (to 236)\n         >>  234 LOAD_CONST               0 (None)\n\n1319     >>  236 LOAD_FAST                7 (is_index_masked)\n\n1320         238 LOAD_FAST                8 (is_index_global_attn)\n\n1314         240 CALL_FUNCTION            6\n             242 STORE_FAST              17 (layer_outputs)\n             244 JUMP_FORWARD            19 (to 284)\n\n1323     >>  246 LOAD_FAST               15 (layer_module)\n\n1324         248 LOAD_FAST                2 (hidden_states)\n\n1325         250 LOAD_FAST                3 (attention_mask)\n\n1326         252 LOAD_FAST                4 (head_mask)\n             254 LOAD_CONST               0 (None)\n             256 IS_OP                    1\n             258 POP_JUMP_IF_FALSE      134 (to 268)\n             260 LOAD_FAST                4 (head_mask)\n             262 LOAD_FAST               14 (idx)\n             264 BINARY_SUBSCR\n             266 JUMP_FORWARD             1 (to 270)\n         >>  268 LOAD_CONST               0 (None)\n\n1327     >>  270 LOAD_FAST                7 (is_index_masked)\n\n1328         272 LOAD_FAST                8 (is_index_global_attn)\n\n1329         274 LOAD_DEREF               0 (is_global_attn)\n\n1330         276 LOAD_DEREF               1 (output_attentions)\n\n1323         278 LOAD_CONST               8 (('attention_mask', 'layer_head_mask', 'is_index_masked', 'is_index_global_attn', 'is_global_attn', 'output_attentions'))\n             280 CALL_FUNCTION_KW         7\n             282 STORE_FAST              17 (layer_outputs)\n\n1332     >>  284 LOAD_FAST               17 (layer_outputs)\n             286 LOAD_CONST               1 (0)\n             288 BINARY_SUBSCR\n             290 STORE_FAST               2 (hidden_states)\n\n1334         292 LOAD_DEREF               1 (output_attentions)\n             294 POP_JUMP_IF_FALSE      172 (to 344)\n\n1336         296 LOAD_FAST               12 (all_attentions)\n             298 LOAD_FAST               17 (layer_outputs)\n             300 LOAD_CONST               9 (1)\n             302 BINARY_SUBSCR\n             304 LOAD_ATTR               12 (transpose)\n             306 LOAD_CONST               9 (1)\n             308 LOAD_CONST              10 (2)\n             310 CALL_FUNCTION            2\n             312 BUILD_TUPLE              1\n             314 BINARY_ADD\n             316 STORE_FAST              12 (all_attentions)\n\n1338         318 LOAD_DEREF               0 (is_global_attn)\n             320 POP_JUMP_IF_FALSE      172 (to 344)\n\n1340         322 LOAD_FAST               13 (all_global_attentions)\n             324 LOAD_FAST               17 (layer_outputs)\n             326 LOAD_CONST              10 (2)\n             328 BINARY_SUBSCR\n             330 LOAD_ATTR               12 (transpose)\n             332 LOAD_CONST              10 (2)\n             334 LOAD_CONST              11 (3)\n             336 CALL_FUNCTION            2\n             338 BUILD_TUPLE              1\n             340 BINARY_ADD\n             342 STORE_FAST              13 (all_global_attentions)\n         >>  344 JUMP_ABSOLUTE           76 (to 152)\n\n1343     >>  346 LOAD_FAST                5 (output_hidden_states)\n             348 POP_JUMP_IF_FALSE      180 (to 360)\n\n1344         350 LOAD_FAST               11 (all_hidden_states)\n             352 LOAD_FAST                2 (hidden_states)\n             354 BUILD_TUPLE              1\n             356 BINARY_ADD\n             358 STORE_FAST              11 (all_hidden_states)\n\n1348     >>  360 LOAD_FAST                2 (hidden_states)\n             362 LOAD_CONST               0 (None)\n             364 LOAD_CONST               0 (None)\n             366 BUILD_SLICE              2\n             368 LOAD_CONST               0 (None)\n             370 LOAD_FAST                2 (hidden_states)\n             372 LOAD_ATTR               13 (shape)\n             374 LOAD_CONST               9 (1)\n             376 BINARY_SUBSCR\n             378 LOAD_DEREF               2 (padding_len)\n             380 BINARY_SUBTRACT\n             382 BUILD_SLICE              2\n             384 BUILD_TUPLE              2\n             386 BINARY_SUBSCR\n             388 STORE_FAST               2 (hidden_states)\n\n1349         390 LOAD_FAST                5 (output_hidden_states)\n             392 POP_JUMP_IF_FALSE      208 (to 416)\n\n1350         394 LOAD_GLOBAL             14 (tuple)\n             396 LOAD_CLOSURE             2 (padding_len)\n             398 BUILD_TUPLE              1\n             400 LOAD_CONST              12 (<code object <listcomp> at 0x7f1887f45f20, file \"/workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1350>)\n             402 LOAD_CONST              13 ('LongformerEncoder.forward.<locals>.<listcomp>')\n             404 MAKE_FUNCTION            8 (closure)\n             406 LOAD_FAST               11 (all_hidden_states)\n             408 GET_ITER\n             410 CALL_FUNCTION            1\n             412 CALL_FUNCTION            1\n             414 STORE_FAST              11 (all_hidden_states)\n\n1352     >>  416 LOAD_DEREF               1 (output_attentions)\n             418 POP_JUMP_IF_FALSE      221 (to 442)\n\n1353         420 LOAD_GLOBAL             14 (tuple)\n             422 LOAD_CLOSURE             2 (padding_len)\n             424 BUILD_TUPLE              1\n             426 LOAD_CONST              14 (<code object <listcomp> at 0x7f1887f45fd0, file \"/workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1353>)\n             428 LOAD_CONST              13 ('LongformerEncoder.forward.<locals>.<listcomp>')\n             430 MAKE_FUNCTION            8 (closure)\n             432 LOAD_FAST               12 (all_attentions)\n             434 GET_ITER\n             436 CALL_FUNCTION            1\n             438 CALL_FUNCTION            1\n             440 STORE_FAST              12 (all_attentions)\n\n1355     >>  442 LOAD_FAST                6 (return_dict)\n             444 POP_JUMP_IF_TRUE       236 (to 472)\n\n1356         446 LOAD_GLOBAL             14 (tuple)\n             448 LOAD_CONST              15 (<code object <genexpr> at 0x7f1887f46080, file \"/workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py\", line 1356>)\n             450 LOAD_CONST              16 ('LongformerEncoder.forward.<locals>.<genexpr>')\n             452 MAKE_FUNCTION            0\n\n1357         454 LOAD_FAST                2 (hidden_states)\n             456 LOAD_FAST               11 (all_hidden_states)\n             458 LOAD_FAST               12 (all_attentions)\n             460 LOAD_FAST               13 (all_global_attentions)\n             462 BUILD_TUPLE              4\n\n1356         464 GET_ITER\n             466 CALL_FUNCTION            1\n             468 CALL_FUNCTION            1\n             470 RETURN_VALUE\n\n1359     >>  472 LOAD_GLOBAL             15 (LongformerBaseModelOutput)\n\n1360         474 LOAD_FAST                2 (hidden_states)\n\n1361         476 LOAD_FAST               11 (all_hidden_states)\n\n1362         478 LOAD_FAST               12 (all_attentions)\n\n1363         480 LOAD_FAST               13 (all_global_attentions)\n\n1359         482 LOAD_CONST              17 (('last_hidden_state', 'hidden_states', 'attentions', 'global_attentions'))\n             484 CALL_FUNCTION_KW         4\n             486 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py line 1843 \n1843           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           26 (to 52)\n               4 LOAD_FAST                3 (return_dict)\n               6 LOAD_CONST               1 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST                3 (return_dict)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (use_return_dict)\n         >>   22 STORE_FAST               3 (return_dict)\n              24 LOAD_FAST                1 (self)\n              26 LOAD_ATTR                2 (longformer)\n              28 LOAD_FAST                4 (input_ids)\n              30 LOAD_FAST                5 (attention_mask)\n              32 LOAD_FAST                6 (global_attention_mask)\n              34 LOAD_FAST                7 (head_mask)\n              36 LOAD_FAST                8 (token_type_ids)\n              38 LOAD_FAST                9 (position_ids)\n              40 LOAD_FAST               10 (inputs_embeds)\n              42 LOAD_FAST               11 (output_attentions)\n              44 LOAD_FAST               12 (output_hidden_states)\n              46 LOAD_FAST                3 (return_dict)\n              48 LOAD_CONST               2 (('attention_mask', 'global_attention_mask', 'head_mask', 'token_type_ids', 'position_ids', 'inputs_embeds', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              50 CALL_FUNCTION_KW        10\n         >>   52 STORE_FAST              13 (outputs)\n\n1855          54 LOAD_FAST               13 (outputs)\n              56 LOAD_CONST               3 (0)\n              58 BINARY_SUBSCR\n              60 STORE_FAST              14 (sequence_output)\n\n1856          62 LOAD_FAST                1 (self)\n              64 LOAD_ATTR                3 (lm_head)\n              66 LOAD_FAST               14 (sequence_output)\n              68 CALL_FUNCTION            1\n              70 STORE_FAST              15 (prediction_scores)\n\n1858          72 LOAD_CONST               1 (None)\n              74 STORE_FAST              16 (masked_lm_loss)\n\n1859          76 LOAD_FAST                2 (labels)\n              78 LOAD_CONST               1 (None)\n              80 IS_OP                    1\n              82 POP_JUMP_IF_FALSE       65 (to 130)\n\n1860          84 LOAD_GLOBAL              4 (CrossEntropyLoss)\n              86 CALL_FUNCTION            0\n              88 STORE_FAST              17 (loss_fct)\n\n1862          90 LOAD_FAST                2 (labels)\n              92 LOAD_ATTR                5 (to)\n              94 LOAD_FAST               15 (prediction_scores)\n              96 LOAD_ATTR                6 (device)\n              98 CALL_FUNCTION            1\n             100 STORE_FAST               2 (labels)\n\n1863         102 LOAD_FAST               17 (loss_fct)\n             104 LOAD_FAST               15 (prediction_scores)\n             106 LOAD_ATTR                7 (view)\n             108 LOAD_CONST               4 (-1)\n             110 LOAD_FAST                1 (self)\n             112 LOAD_ATTR                0 (config)\n             114 LOAD_ATTR                8 (vocab_size)\n             116 CALL_FUNCTION            2\n             118 LOAD_FAST                2 (labels)\n             120 LOAD_ATTR                7 (view)\n             122 LOAD_CONST               4 (-1)\n             124 CALL_FUNCTION            1\n             126 CALL_FUNCTION            2\n             128 STORE_FAST              16 (masked_lm_loss)\n\n1865     >>  130 LOAD_FAST                3 (return_dict)\n             132 POP_JUMP_IF_TRUE        87 (to 174)\n\n1866         134 LOAD_FAST               15 (prediction_scores)\n             136 BUILD_TUPLE              1\n             138 LOAD_FAST               13 (outputs)\n             140 LOAD_CONST               5 (2)\n             142 LOAD_CONST               1 (None)\n             144 BUILD_SLICE              2\n             146 BINARY_SUBSCR\n             148 BINARY_ADD\n             150 STORE_FAST              18 (output)\n\n1867         152 LOAD_FAST               16 (masked_lm_loss)\n             154 LOAD_CONST               1 (None)\n             156 IS_OP                    1\n             158 POP_JUMP_IF_FALSE       85 (to 170)\n             160 LOAD_FAST               16 (masked_lm_loss)\n             162 BUILD_TUPLE              1\n             164 LOAD_FAST               18 (output)\n             166 BINARY_ADD\n             168 RETURN_VALUE\n         >>  170 LOAD_FAST               18 (output)\n             172 RETURN_VALUE\n\n1869     >>  174 LOAD_GLOBAL              9 (LongformerMaskedLMOutput)\n\n1870         176 LOAD_FAST               16 (masked_lm_loss)\n\n1871         178 LOAD_FAST               15 (prediction_scores)\n\n1872         180 LOAD_FAST               13 (outputs)\n             182 LOAD_ATTR               10 (hidden_states)\n\n1873         184 LOAD_FAST               13 (outputs)\n             186 LOAD_ATTR               11 (attentions)\n\n1874         188 LOAD_FAST               13 (outputs)\n             190 LOAD_ATTR               12 (global_attentions)\n\n1869         192 LOAD_CONST               6 (('loss', 'logits', 'hidden_states', 'attentions', 'global_attentions'))\n             194 CALL_FUNCTION_KW         5\n             196 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 557 \n557           0 LOAD_FAST                0 (___stack0)\n              2 CALL_FUNCTION            0\n              4 SETUP_WITH              10 (to 26)\n              6 POP_TOP\n              8 LOAD_FAST                1 (___stack1)\n             10 JUMP_ABSOLUTE           44 (to 88)\n             12 POP_BLOCK\n             14 LOAD_CONST               0 (None)\n             16 DUP_TOP\n             18 DUP_TOP\n             20 CALL_FUNCTION            3\n             22 POP_TOP\n             24 JUMP_FORWARD             8 (to 42)\n        >>   26 WITH_EXCEPT_START\n             28 POP_JUMP_IF_TRUE        16 (to 32)\n             30 RERAISE                  0\n        >>   32 POP_TOP\n             34 POP_TOP\n             36 POP_TOP\n             38 POP_EXCEPT\n             40 POP_TOP\n        >>   42 NOP\n             44 LOAD_CONST               0 (None)\n             46 RAISE_VARARGS            1\n             48 LOAD_GLOBAL              0 (clone_inputs)\n             50 LOAD_FAST                6 (inputs)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (cloned_inputs)\n             56 LOAD_FAST                2 (self)\n             58 LOAD_ATTR                1 (optimizer_zero_grad)\n             60 LOAD_FAST                3 (mod)\n             62 CALL_FUNCTION            1\n             64 POP_TOP\n             66 LOAD_FAST                2 (self)\n             68 LOAD_ATTR                2 (autocast)\n             70 CALL_FUNCTION            0\n             72 SETUP_WITH              20 (to 114)\n             74 POP_TOP\n             76 LOAD_FAST                3 (mod)\n             78 LOAD_CONST               1 (())\n             80 BUILD_MAP                0\n             82 LOAD_FAST                5 (cloned_inputs)\n             84 DICT_MERGE               1\n             86 CALL_FUNCTION_EX         1\n        >>   88 STORE_FAST               7 (pred)\n\n558          90 LOAD_FAST                2 (self)\n             92 LOAD_ATTR                3 (compute_loss)\n             94 LOAD_FAST                7 (pred)\n             96 CALL_FUNCTION            1\n             98 STORE_FAST               8 (loss)\n            100 POP_BLOCK\n\n556         102 LOAD_CONST               0 (None)\n            104 DUP_TOP\n            106 DUP_TOP\n            108 CALL_FUNCTION            3\n            110 POP_TOP\n            112 JUMP_FORWARD             8 (to 130)\n        >>  114 WITH_EXCEPT_START\n            116 POP_JUMP_IF_TRUE        60 (to 120)\n            118 RERAISE                  1\n        >>  120 POP_TOP\n            122 POP_TOP\n            124 POP_TOP\n            126 POP_EXCEPT\n            128 POP_TOP\n\n559     >>  130 LOAD_FAST                2 (self)\n            132 LOAD_ATTR                4 (grad_scaler)\n            134 LOAD_ATTR                5 (scale)\n            136 LOAD_FAST                8 (loss)\n            138 CALL_FUNCTION            1\n            140 LOAD_ATTR                6 (backward)\n            142 CALL_FUNCTION            0\n            144 POP_TOP\n\n560         146 LOAD_FAST                2 (self)\n            148 LOAD_ATTR                7 (optimizer_step)\n            150 CALL_FUNCTION            0\n            152 POP_TOP\n\n561         154 LOAD_FAST                4 (collect_outputs)\n            156 POP_JUMP_IF_FALSE       86 (to 172)\n\n562         158 LOAD_GLOBAL              8 (collect_results)\n            160 LOAD_FAST                3 (mod)\n            162 LOAD_FAST                7 (pred)\n            164 LOAD_FAST                8 (loss)\n            166 LOAD_FAST                5 (cloned_inputs)\n            168 CALL_FUNCTION            4\n            170 RETURN_VALUE\n\n563     >>  172 LOAD_CONST               0 (None)\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 1775 \n1877           0 LOAD_FAST               11 (output_attentions)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               11 (output_attentions)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (output_attentions)\n         >>   18 STORE_FAST              11 (output_attentions)\n\n1879          20 LOAD_FAST               12 (output_hidden_states)\n              22 LOAD_CONST               1 (None)\n              24 IS_OP                    1\n              26 POP_JUMP_IF_FALSE       16 (to 32)\n              28 LOAD_FAST               12 (output_hidden_states)\n              30 JUMP_FORWARD             3 (to 38)\n         >>   32 LOAD_FAST                0 (self)\n              34 LOAD_ATTR                0 (config)\n              36 LOAD_ATTR                2 (output_hidden_states)\n\n1878     >>   38 STORE_FAST              12 (output_hidden_states)\n\n1881          40 LOAD_FAST               13 (return_dict)\n              42 LOAD_CONST               1 (None)\n              44 IS_OP                    1\n              46 POP_JUMP_IF_FALSE       26 (to 52)\n              48 LOAD_FAST               13 (return_dict)\n              50 JUMP_FORWARD             3 (to 58)\n         >>   52 LOAD_FAST                0 (self)\n              54 LOAD_ATTR                0 (config)\n              56 LOAD_ATTR                3 (use_return_dict)\n         >>   58 STORE_FAST              13 (return_dict)\n\n1884          60 LOAD_FAST                0 (self)\n              62 LOAD_ATTR                4 (model)\n              64 LOAD_ATTR                5 (decoder)\n\n1885          66 LOAD_FAST                1 (input_ids)\n\n1886          68 LOAD_FAST                2 (attention_mask)\n\n1887          70 LOAD_FAST                3 (encoder_hidden_states)\n\n1888          72 LOAD_FAST                4 (encoder_attention_mask)\n\n1889          74 LOAD_FAST                5 (head_mask)\n\n1890          76 LOAD_FAST                6 (cross_attn_head_mask)\n\n1891          78 LOAD_FAST                7 (past_key_values)\n\n1892          80 LOAD_FAST                8 (inputs_embeds)\n\n1893          82 LOAD_FAST               10 (use_cache)\n\n1894          84 LOAD_FAST               11 (output_attentions)\n\n1895          86 LOAD_FAST               12 (output_hidden_states)\n\n1896          88 LOAD_FAST               13 (return_dict)\n\n1884          90 LOAD_CONST               2 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              92 CALL_FUNCTION_KW        12\n              94 STORE_FAST              14 (outputs)\n\n1899          96 LOAD_FAST                0 (self)\n              98 LOAD_METHOD              6 (lm_head)\n             100 LOAD_FAST               14 (outputs)\n             102 LOAD_CONST               3 (0)\n             104 BINARY_SUBSCR\n             106 CALL_METHOD              1\n             108 STORE_FAST              15 (logits)\n\n1901         110 LOAD_CONST               1 (None)\n             112 STORE_FAST              16 (loss)\n\n1902         114 LOAD_FAST                9 (labels)\n             116 LOAD_CONST               1 (None)\n             118 IS_OP                    1\n             120 POP_JUMP_IF_FALSE       84 (to 168)\n\n1903         122 LOAD_FAST                9 (labels)\n             124 LOAD_METHOD              7 (to)\n             126 LOAD_FAST               15 (logits)\n             128 LOAD_ATTR                8 (device)\n             130 CALL_METHOD              1\n             132 STORE_FAST               9 (labels)\n\n1904         134 LOAD_GLOBAL              9 (CrossEntropyLoss)\n             136 CALL_FUNCTION            0\n             138 STORE_FAST              17 (loss_fct)\n\n1905         140 LOAD_FAST               17 (loss_fct)\n             142 LOAD_FAST               15 (logits)\n             144 LOAD_METHOD             10 (view)\n             146 LOAD_CONST               4 (-1)\n             148 LOAD_FAST                0 (self)\n             150 LOAD_ATTR                0 (config)\n             152 LOAD_ATTR               11 (vocab_size)\n             154 CALL_METHOD              2\n             156 LOAD_FAST                9 (labels)\n             158 LOAD_METHOD             10 (view)\n             160 LOAD_CONST               4 (-1)\n             162 CALL_METHOD              1\n             164 CALL_FUNCTION            2\n             166 STORE_FAST              16 (loss)\n\n1907     >>  168 LOAD_FAST               13 (return_dict)\n             170 POP_JUMP_IF_TRUE       106 (to 212)\n\n1908         172 LOAD_FAST               15 (logits)\n             174 BUILD_TUPLE              1\n             176 LOAD_FAST               14 (outputs)\n             178 LOAD_CONST               5 (1)\n             180 LOAD_CONST               1 (None)\n             182 BUILD_SLICE              2\n             184 BINARY_SUBSCR\n             186 BINARY_ADD\n             188 STORE_FAST              18 (output)\n\n1909         190 LOAD_FAST               16 (loss)\n             192 LOAD_CONST               1 (None)\n             194 IS_OP                    1\n             196 POP_JUMP_IF_FALSE      104 (to 208)\n             198 LOAD_FAST               16 (loss)\n             200 BUILD_TUPLE              1\n             202 LOAD_FAST               18 (output)\n             204 BINARY_ADD\n             206 RETURN_VALUE\n         >>  208 LOAD_FAST               18 (output)\n             210 RETURN_VALUE\n\n1911     >>  212 LOAD_GLOBAL             12 (CausalLMOutputWithCrossAttentions)\n\n1912         214 LOAD_FAST               16 (loss)\n\n1913         216 LOAD_FAST               15 (logits)\n\n1914         218 LOAD_FAST               14 (outputs)\n             220 LOAD_ATTR               13 (past_key_values)\n\n1915         222 LOAD_FAST               14 (outputs)\n             224 LOAD_ATTR               14 (hidden_states)\n\n1916         226 LOAD_FAST               14 (outputs)\n             228 LOAD_ATTR               15 (attentions)\n\n1917         230 LOAD_FAST               14 (outputs)\n             232 LOAD_ATTR               16 (cross_attentions)\n\n1911         234 LOAD_CONST               6 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n             236 CALL_FUNCTION_KW         6\n             238 RETURN_VALUE\n\n", "ORIGINAL BYTECODE _prepare_decoder_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 924 \n927           0 LOAD_CONST               0 (None)\n              2 STORE_FAST               5 (combined_attention_mask)\n\n928           4 LOAD_FAST                2 (input_shape)\n              6 LOAD_CONST               1 (-1)\n              8 BINARY_SUBSCR\n             10 LOAD_CONST               2 (1)\n             12 COMPARE_OP               4 (>)\n             14 POP_JUMP_IF_FALSE       18 (to 36)\n\n929          16 LOAD_GLOBAL              0 (_make_causal_mask)\n\n930          18 LOAD_FAST                2 (input_shape)\n\n931          20 LOAD_FAST                3 (inputs_embeds)\n             22 LOAD_ATTR                1 (dtype)\n\n932          24 LOAD_FAST                3 (inputs_embeds)\n             26 LOAD_ATTR                2 (device)\n\n933          28 LOAD_FAST                4 (past_key_values_length)\n\n929          30 LOAD_CONST               3 (('device', 'past_key_values_length'))\n             32 CALL_FUNCTION_KW         4\n             34 STORE_FAST               5 (combined_attention_mask)\n\n936     >>   36 LOAD_FAST                1 (attention_mask)\n             38 LOAD_CONST               0 (None)\n             40 IS_OP                    1\n             42 POP_JUMP_IF_FALSE       46 (to 92)\n\n938          44 LOAD_GLOBAL              3 (_expand_mask)\n             46 LOAD_FAST                1 (attention_mask)\n             48 LOAD_FAST                3 (inputs_embeds)\n             50 LOAD_ATTR                1 (dtype)\n             52 LOAD_FAST                2 (input_shape)\n             54 LOAD_CONST               1 (-1)\n             56 BINARY_SUBSCR\n             58 LOAD_CONST               4 (('tgt_len',))\n             60 CALL_FUNCTION_KW         3\n             62 LOAD_METHOD              4 (to)\n\n939          64 LOAD_FAST                3 (inputs_embeds)\n             66 LOAD_ATTR                2 (device)\n\n938          68 CALL_METHOD              1\n             70 STORE_FAST               6 (expanded_attn_mask)\n\n942          72 LOAD_FAST                5 (combined_attention_mask)\n             74 LOAD_CONST               0 (None)\n             76 IS_OP                    0\n             78 POP_JUMP_IF_FALSE       42 (to 84)\n             80 LOAD_FAST                6 (expanded_attn_mask)\n             82 JUMP_FORWARD             3 (to 90)\n        >>   84 LOAD_FAST                6 (expanded_attn_mask)\n             86 LOAD_FAST                5 (combined_attention_mask)\n             88 BINARY_ADD\n\n941     >>   90 STORE_FAST               5 (combined_attention_mask)\n\n945     >>   92 LOAD_FAST                5 (combined_attention_mask)\n             94 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 131 \n134           0 LOAD_FAST                1 (input_ids)\n              2 LOAD_ATTR                0 (shape)\n              4 LOAD_CONST               1 (None)\n              6 LOAD_CONST               2 (2)\n              8 BUILD_SLICE              2\n             10 BINARY_SUBSCR\n             12 UNPACK_SEQUENCE          2\n             14 STORE_FAST               3 (bsz)\n             16 STORE_FAST               4 (seq_len)\n\n135          18 LOAD_GLOBAL              1 (torch)\n             20 LOAD_ATTR                2 (arange)\n\n136          22 LOAD_FAST                2 (past_key_values_length)\n             24 LOAD_FAST                2 (past_key_values_length)\n             26 LOAD_FAST                4 (seq_len)\n             28 BINARY_ADD\n             30 LOAD_GLOBAL              1 (torch)\n             32 LOAD_ATTR                3 (long)\n             34 LOAD_FAST                0 (self)\n             36 LOAD_ATTR                4 (weight)\n             38 LOAD_ATTR                5 (device)\n\n135          40 LOAD_CONST               3 (('dtype', 'device'))\n             42 CALL_FUNCTION_KW         4\n\n137          44 LOAD_METHOD              6 (expand)\n             46 LOAD_FAST                3 (bsz)\n             48 LOAD_CONST               4 (-1)\n             50 CALL_METHOD              2\n\n135          52 STORE_FAST               5 (positions)\n\n139          54 LOAD_GLOBAL              7 (super)\n             56 CALL_FUNCTION            0\n             58 LOAD_METHOD              8 (forward)\n             60 LOAD_FAST                5 (positions)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                9 (offset)\n             66 BINARY_ADD\n             68 CALL_METHOD              1\n             70 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (past_key_values)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (past_key_values)\n\n  5          12 LOAD_FAST                3 (hidden_states)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (hidden_states)\n\n  6          18 LOAD_FAST                4 (attentions)\n             20 LOAD_FAST                0 (self)\n             22 STORE_ATTR               3 (attentions)\n\n  7          24 LOAD_FAST                5 (cross_attentions)\n             26 LOAD_FAST                0 (self)\n             28 STORE_ATTR               4 (cross_attentions)\n\n  8          30 LOAD_FAST                0 (self)\n             32 LOAD_METHOD              5 (__post_init__)\n             34 CALL_METHOD              0\n             36 POP_TOP\n             38 LOAD_CONST               0 (None)\n             40 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 3 \n  3           0 JUMP_ABSOLUTE            4 (to 8)\n              2 LOAD_FAST                5 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n\n  4     >>    8 LOAD_FAST                1 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5          14 LOAD_FAST                2 (hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (hidden_states)\n\n  6          20 LOAD_FAST                3 (attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (attentions)\n\n  7          26 LOAD_FAST                4 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                5 (__post_init__)\n             36 CALL_FUNCTION            0\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 1884 \n1884           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           49 (to 98)\n               4 LOAD_FAST               13 (output_attentions)\n               6 LOAD_CONST               1 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST               13 (output_attentions)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (output_attentions)\n         >>   22 STORE_FAST              13 (output_attentions)\n              24 LOAD_FAST               14 (output_hidden_states)\n              26 LOAD_CONST               1 (None)\n              28 IS_OP                    1\n              30 POP_JUMP_IF_FALSE       18 (to 36)\n              32 LOAD_FAST               14 (output_hidden_states)\n              34 JUMP_FORWARD             3 (to 42)\n         >>   36 LOAD_FAST                1 (self)\n              38 LOAD_ATTR                0 (config)\n              40 LOAD_ATTR                2 (output_hidden_states)\n         >>   42 STORE_FAST              14 (output_hidden_states)\n              44 LOAD_FAST                3 (return_dict)\n              46 LOAD_CONST               1 (None)\n              48 IS_OP                    1\n              50 POP_JUMP_IF_FALSE       28 (to 56)\n              52 LOAD_FAST                3 (return_dict)\n              54 JUMP_FORWARD             3 (to 62)\n         >>   56 LOAD_FAST                1 (self)\n              58 LOAD_ATTR                0 (config)\n              60 LOAD_ATTR                3 (use_return_dict)\n         >>   62 STORE_FAST               3 (return_dict)\n              64 LOAD_FAST                1 (self)\n              66 LOAD_ATTR                4 (model)\n              68 LOAD_ATTR                5 (decoder)\n              70 LOAD_FAST                4 (input_ids)\n              72 LOAD_FAST                5 (attention_mask)\n              74 LOAD_FAST                6 (encoder_hidden_states)\n              76 LOAD_FAST                7 (encoder_attention_mask)\n              78 LOAD_FAST                8 (head_mask)\n              80 LOAD_FAST                9 (cross_attn_head_mask)\n              82 LOAD_FAST               10 (past_key_values)\n              84 LOAD_FAST               11 (inputs_embeds)\n              86 LOAD_FAST               12 (use_cache)\n              88 LOAD_FAST               13 (output_attentions)\n              90 LOAD_FAST               14 (output_hidden_states)\n              92 LOAD_FAST                3 (return_dict)\n              94 LOAD_CONST               2 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              96 CALL_FUNCTION_KW        12\n         >>   98 STORE_FAST              15 (outputs)\n\n1899         100 LOAD_FAST                1 (self)\n             102 LOAD_ATTR                6 (lm_head)\n             104 LOAD_FAST               15 (outputs)\n             106 LOAD_CONST               3 (0)\n             108 BINARY_SUBSCR\n             110 CALL_FUNCTION            1\n             112 STORE_FAST              16 (logits)\n\n1901         114 LOAD_CONST               1 (None)\n             116 STORE_FAST              17 (loss)\n\n1902         118 LOAD_FAST                2 (labels)\n             120 LOAD_CONST               1 (None)\n             122 IS_OP                    1\n             124 POP_JUMP_IF_FALSE       86 (to 172)\n\n1903         126 LOAD_FAST                2 (labels)\n             128 LOAD_ATTR                7 (to)\n             130 LOAD_FAST               16 (logits)\n             132 LOAD_ATTR                8 (device)\n             134 CALL_FUNCTION            1\n             136 STORE_FAST               2 (labels)\n\n1904         138 LOAD_GLOBAL              9 (CrossEntropyLoss)\n             140 CALL_FUNCTION            0\n             142 STORE_FAST              18 (loss_fct)\n\n1905         144 LOAD_FAST               18 (loss_fct)\n             146 LOAD_FAST               16 (logits)\n             148 LOAD_ATTR               10 (view)\n             150 LOAD_CONST               4 (-1)\n             152 LOAD_FAST                1 (self)\n             154 LOAD_ATTR                0 (config)\n             156 LOAD_ATTR               11 (vocab_size)\n             158 CALL_FUNCTION            2\n             160 LOAD_FAST                2 (labels)\n             162 LOAD_ATTR               10 (view)\n             164 LOAD_CONST               4 (-1)\n             166 CALL_FUNCTION            1\n             168 CALL_FUNCTION            2\n             170 STORE_FAST              17 (loss)\n\n1907     >>  172 LOAD_FAST                3 (return_dict)\n             174 POP_JUMP_IF_TRUE       108 (to 216)\n\n1908         176 LOAD_FAST               16 (logits)\n             178 BUILD_TUPLE              1\n             180 LOAD_FAST               15 (outputs)\n             182 LOAD_CONST               5 (1)\n             184 LOAD_CONST               1 (None)\n             186 BUILD_SLICE              2\n             188 BINARY_SUBSCR\n             190 BINARY_ADD\n             192 STORE_FAST              19 (output)\n\n1909         194 LOAD_FAST               17 (loss)\n             196 LOAD_CONST               1 (None)\n             198 IS_OP                    1\n             200 POP_JUMP_IF_FALSE      106 (to 212)\n             202 LOAD_FAST               17 (loss)\n             204 BUILD_TUPLE              1\n             206 LOAD_FAST               19 (output)\n             208 BINARY_ADD\n             210 RETURN_VALUE\n         >>  212 LOAD_FAST               19 (output)\n             214 RETURN_VALUE\n\n1911     >>  216 LOAD_GLOBAL             12 (CausalLMOutputWithCrossAttentions)\n\n1912         218 LOAD_FAST               17 (loss)\n\n1913         220 LOAD_FAST               16 (logits)\n\n1914         222 LOAD_FAST               15 (outputs)\n             224 LOAD_ATTR               13 (past_key_values)\n\n1915         226 LOAD_FAST               15 (outputs)\n             228 LOAD_ATTR               14 (hidden_states)\n\n1916         230 LOAD_FAST               15 (outputs)\n             232 LOAD_ATTR               15 (attentions)\n\n1917         234 LOAD_FAST               15 (outputs)\n             236 LOAD_ATTR               16 (cross_attentions)\n\n1911         238 LOAD_CONST               6 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n             240 CALL_FUNCTION_KW         6\n             242 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 557 \n557           0 LOAD_FAST                0 (___stack0)\n              2 CALL_FUNCTION            0\n              4 SETUP_WITH              10 (to 26)\n              6 POP_TOP\n              8 LOAD_FAST                1 (___stack1)\n             10 JUMP_ABSOLUTE           44 (to 88)\n             12 POP_BLOCK\n             14 LOAD_CONST               0 (None)\n             16 DUP_TOP\n             18 DUP_TOP\n             20 CALL_FUNCTION            3\n             22 POP_TOP\n             24 JUMP_FORWARD             8 (to 42)\n        >>   26 WITH_EXCEPT_START\n             28 POP_JUMP_IF_TRUE        16 (to 32)\n             30 RERAISE                  0\n        >>   32 POP_TOP\n             34 POP_TOP\n             36 POP_TOP\n             38 POP_EXCEPT\n             40 POP_TOP\n        >>   42 NOP\n             44 LOAD_CONST               0 (None)\n             46 RAISE_VARARGS            1\n             48 LOAD_GLOBAL              0 (clone_inputs)\n             50 LOAD_FAST                6 (inputs)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (cloned_inputs)\n             56 LOAD_FAST                2 (self)\n             58 LOAD_ATTR                1 (optimizer_zero_grad)\n             60 LOAD_FAST                3 (mod)\n             62 CALL_FUNCTION            1\n             64 POP_TOP\n             66 LOAD_FAST                2 (self)\n             68 LOAD_ATTR                2 (autocast)\n             70 CALL_FUNCTION            0\n             72 SETUP_WITH              20 (to 114)\n             74 POP_TOP\n             76 LOAD_FAST                3 (mod)\n             78 LOAD_CONST               1 (())\n             80 BUILD_MAP                0\n             82 LOAD_FAST                5 (cloned_inputs)\n             84 DICT_MERGE               1\n             86 CALL_FUNCTION_EX         1\n        >>   88 STORE_FAST               7 (pred)\n\n558          90 LOAD_FAST                2 (self)\n             92 LOAD_ATTR                3 (compute_loss)\n             94 LOAD_FAST                7 (pred)\n             96 CALL_FUNCTION            1\n             98 STORE_FAST               8 (loss)\n            100 POP_BLOCK\n\n556         102 LOAD_CONST               0 (None)\n            104 DUP_TOP\n            106 DUP_TOP\n            108 CALL_FUNCTION            3\n            110 POP_TOP\n            112 JUMP_FORWARD             8 (to 130)\n        >>  114 WITH_EXCEPT_START\n            116 POP_JUMP_IF_TRUE        60 (to 120)\n            118 RERAISE                  1\n        >>  120 POP_TOP\n            122 POP_TOP\n            124 POP_TOP\n            126 POP_EXCEPT\n            128 POP_TOP\n\n559     >>  130 LOAD_FAST                2 (self)\n            132 LOAD_ATTR                4 (grad_scaler)\n            134 LOAD_ATTR                5 (scale)\n            136 LOAD_FAST                8 (loss)\n            138 CALL_FUNCTION            1\n            140 LOAD_ATTR                6 (backward)\n            142 CALL_FUNCTION            0\n            144 POP_TOP\n\n560         146 LOAD_FAST                2 (self)\n            148 LOAD_ATTR                7 (optimizer_step)\n            150 CALL_FUNCTION            0\n            152 POP_TOP\n\n561         154 LOAD_FAST                4 (collect_outputs)\n            156 POP_JUMP_IF_FALSE       86 (to 172)\n\n562         158 LOAD_GLOBAL              8 (collect_results)\n            160 LOAD_FAST                3 (mod)\n            162 LOAD_FAST                7 (pred)\n            164 LOAD_FAST                8 (loss)\n            166 LOAD_FAST                5 (cloned_inputs)\n            168 CALL_FUNCTION            4\n            170 RETURN_VALUE\n\n563     >>  172 LOAD_CONST               0 (None)\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 1339 \n1369           0 LOAD_FAST               16 (return_dict)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               16 (return_dict)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (use_return_dict)\n         >>   18 STORE_FAST              16 (return_dict)\n\n1371          20 LOAD_FAST               12 (labels)\n              22 LOAD_CONST               1 (None)\n              24 IS_OP                    1\n              26 POP_JUMP_IF_FALSE       41 (to 82)\n\n1372          28 LOAD_FAST               13 (use_cache)\n              30 POP_JUMP_IF_FALSE       21 (to 42)\n\n1373          32 LOAD_GLOBAL              2 (logger)\n              34 LOAD_METHOD              3 (warning)\n              36 LOAD_CONST               2 ('The `use_cache` argument is changed to `False` since `labels` is provided.')\n              38 CALL_METHOD              1\n              40 POP_TOP\n\n1374     >>   42 LOAD_CONST               3 (False)\n              44 STORE_FAST              13 (use_cache)\n\n1375          46 LOAD_FAST                3 (decoder_input_ids)\n              48 LOAD_CONST               1 (None)\n              50 IS_OP                    0\n              52 POP_JUMP_IF_FALSE       41 (to 82)\n              54 LOAD_FAST               11 (decoder_inputs_embeds)\n              56 LOAD_CONST               1 (None)\n              58 IS_OP                    0\n              60 POP_JUMP_IF_FALSE       41 (to 82)\n\n1376          62 LOAD_GLOBAL              4 (shift_tokens_right)\n\n1377          64 LOAD_FAST               12 (labels)\n              66 LOAD_FAST                0 (self)\n              68 LOAD_ATTR                0 (config)\n              70 LOAD_ATTR                5 (pad_token_id)\n              72 LOAD_FAST                0 (self)\n              74 LOAD_ATTR                0 (config)\n              76 LOAD_ATTR                6 (decoder_start_token_id)\n\n1376          78 CALL_FUNCTION            3\n              80 STORE_FAST               3 (decoder_input_ids)\n\n1380     >>   82 LOAD_FAST                0 (self)\n              84 LOAD_ATTR                7 (model)\n\n1381          86 LOAD_FAST                1 (input_ids)\n\n1382          88 LOAD_FAST                2 (attention_mask)\n\n1383          90 LOAD_FAST                3 (decoder_input_ids)\n\n1384          92 LOAD_FAST                8 (encoder_outputs)\n\n1385          94 LOAD_FAST                4 (decoder_attention_mask)\n\n1386          96 LOAD_FAST                5 (head_mask)\n\n1387          98 LOAD_FAST                6 (decoder_head_mask)\n\n1388         100 LOAD_FAST                7 (cross_attn_head_mask)\n\n1389         102 LOAD_FAST                9 (past_key_values)\n\n1390         104 LOAD_FAST               10 (inputs_embeds)\n\n1391         106 LOAD_FAST               11 (decoder_inputs_embeds)\n\n1392         108 LOAD_FAST               13 (use_cache)\n\n1393         110 LOAD_FAST               14 (output_attentions)\n\n1394         112 LOAD_FAST               15 (output_hidden_states)\n\n1395         114 LOAD_FAST               16 (return_dict)\n\n1380         116 LOAD_CONST               4 (('attention_mask', 'decoder_input_ids', 'encoder_outputs', 'decoder_attention_mask', 'head_mask', 'decoder_head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'decoder_inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             118 CALL_FUNCTION_KW        15\n             120 STORE_FAST              17 (outputs)\n\n1398         122 LOAD_FAST                0 (self)\n             124 LOAD_METHOD              8 (lm_head)\n             126 LOAD_FAST               17 (outputs)\n             128 LOAD_CONST               5 (0)\n             130 BINARY_SUBSCR\n             132 CALL_METHOD              1\n             134 STORE_FAST              18 (lm_logits)\n\n1399         136 LOAD_FAST               18 (lm_logits)\n             138 LOAD_FAST                0 (self)\n             140 LOAD_ATTR                9 (final_logits_bias)\n             142 LOAD_METHOD             10 (to)\n             144 LOAD_FAST               18 (lm_logits)\n             146 LOAD_ATTR               11 (device)\n             148 CALL_METHOD              1\n             150 BINARY_ADD\n             152 STORE_FAST              18 (lm_logits)\n\n1401         154 LOAD_CONST               1 (None)\n             156 STORE_FAST              19 (masked_lm_loss)\n\n1402         158 LOAD_FAST               12 (labels)\n             160 LOAD_CONST               1 (None)\n             162 IS_OP                    1\n             164 POP_JUMP_IF_FALSE      106 (to 212)\n\n1403         166 LOAD_FAST               12 (labels)\n             168 LOAD_METHOD             10 (to)\n             170 LOAD_FAST               18 (lm_logits)\n             172 LOAD_ATTR               11 (device)\n             174 CALL_METHOD              1\n             176 STORE_FAST              12 (labels)\n\n1404         178 LOAD_GLOBAL             12 (CrossEntropyLoss)\n             180 CALL_FUNCTION            0\n             182 STORE_FAST              20 (loss_fct)\n\n1405         184 LOAD_FAST               20 (loss_fct)\n             186 LOAD_FAST               18 (lm_logits)\n             188 LOAD_METHOD             13 (view)\n             190 LOAD_CONST               6 (-1)\n             192 LOAD_FAST                0 (self)\n             194 LOAD_ATTR                0 (config)\n             196 LOAD_ATTR               14 (vocab_size)\n             198 CALL_METHOD              2\n             200 LOAD_FAST               12 (labels)\n             202 LOAD_METHOD             13 (view)\n             204 LOAD_CONST               6 (-1)\n             206 CALL_METHOD              1\n             208 CALL_FUNCTION            2\n             210 STORE_FAST              19 (masked_lm_loss)\n\n1407     >>  212 LOAD_FAST               16 (return_dict)\n             214 POP_JUMP_IF_TRUE       128 (to 256)\n\n1408         216 LOAD_FAST               18 (lm_logits)\n             218 BUILD_TUPLE              1\n             220 LOAD_FAST               17 (outputs)\n             222 LOAD_CONST               7 (1)\n             224 LOAD_CONST               1 (None)\n             226 BUILD_SLICE              2\n             228 BINARY_SUBSCR\n             230 BINARY_ADD\n             232 STORE_FAST              21 (output)\n\n1409         234 LOAD_FAST               19 (masked_lm_loss)\n             236 LOAD_CONST               1 (None)\n             238 IS_OP                    1\n             240 POP_JUMP_IF_FALSE      126 (to 252)\n             242 LOAD_FAST               19 (masked_lm_loss)\n             244 BUILD_TUPLE              1\n             246 LOAD_FAST               21 (output)\n             248 BINARY_ADD\n             250 RETURN_VALUE\n         >>  252 LOAD_FAST               21 (output)\n             254 RETURN_VALUE\n\n1411     >>  256 LOAD_GLOBAL             15 (Seq2SeqLMOutput)\n\n1412         258 LOAD_FAST               19 (masked_lm_loss)\n\n1413         260 LOAD_FAST               18 (lm_logits)\n\n1414         262 LOAD_FAST               17 (outputs)\n             264 LOAD_ATTR               16 (past_key_values)\n\n1415         266 LOAD_FAST               17 (outputs)\n             268 LOAD_ATTR               17 (decoder_hidden_states)\n\n1416         270 LOAD_FAST               17 (outputs)\n             272 LOAD_ATTR               18 (decoder_attentions)\n\n1417         274 LOAD_FAST               17 (outputs)\n             276 LOAD_ATTR               19 (cross_attentions)\n\n1418         278 LOAD_FAST               17 (outputs)\n             280 LOAD_ATTR               20 (encoder_last_hidden_state)\n\n1419         282 LOAD_FAST               17 (outputs)\n             284 LOAD_ATTR               21 (encoder_hidden_states)\n\n1420         286 LOAD_FAST               17 (outputs)\n             288 LOAD_ATTR               22 (encoder_attentions)\n\n1411         290 LOAD_CONST               8 (('loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             292 CALL_FUNCTION_KW         9\n             294 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 1201 \n1228           0 LOAD_FAST                3 (decoder_input_ids)\n               2 LOAD_CONST               0 (None)\n               4 IS_OP                    0\n               6 POP_JUMP_IF_FALSE       26 (to 52)\n               8 LOAD_FAST               11 (decoder_inputs_embeds)\n              10 LOAD_CONST               0 (None)\n              12 IS_OP                    0\n              14 POP_JUMP_IF_FALSE       26 (to 52)\n\n1229          16 LOAD_FAST                1 (input_ids)\n              18 LOAD_CONST               0 (None)\n              20 IS_OP                    0\n              22 POP_JUMP_IF_FALSE       16 (to 32)\n\n1230          24 LOAD_GLOBAL              0 (ValueError)\n\n1231          26 LOAD_CONST               1 ('If no `decoder_input_ids` or `decoder_inputs_embeds` are passed, `input_ids` cannot be `None`. Please pass either `input_ids` or `decoder_input_ids` or `decoder_inputs_embeds`.')\n\n1230          28 CALL_FUNCTION            1\n              30 RAISE_VARARGS            1\n\n1236     >>   32 LOAD_GLOBAL              1 (shift_tokens_right)\n\n1237          34 LOAD_FAST                1 (input_ids)\n              36 LOAD_FAST                0 (self)\n              38 LOAD_ATTR                2 (config)\n              40 LOAD_ATTR                3 (pad_token_id)\n              42 LOAD_FAST                0 (self)\n              44 LOAD_ATTR                2 (config)\n              46 LOAD_ATTR                4 (decoder_start_token_id)\n\n1236          48 CALL_FUNCTION            3\n              50 STORE_FAST               3 (decoder_input_ids)\n\n1240     >>   52 LOAD_FAST               13 (output_attentions)\n              54 LOAD_CONST               0 (None)\n              56 IS_OP                    1\n              58 POP_JUMP_IF_FALSE       32 (to 64)\n              60 LOAD_FAST               13 (output_attentions)\n              62 JUMP_FORWARD             3 (to 70)\n         >>   64 LOAD_FAST                0 (self)\n              66 LOAD_ATTR                2 (config)\n              68 LOAD_ATTR                5 (output_attentions)\n         >>   70 STORE_FAST              13 (output_attentions)\n\n1242          72 LOAD_FAST               14 (output_hidden_states)\n              74 LOAD_CONST               0 (None)\n              76 IS_OP                    1\n              78 POP_JUMP_IF_FALSE       42 (to 84)\n              80 LOAD_FAST               14 (output_hidden_states)\n              82 JUMP_FORWARD             3 (to 90)\n         >>   84 LOAD_FAST                0 (self)\n              86 LOAD_ATTR                2 (config)\n              88 LOAD_ATTR                6 (output_hidden_states)\n\n1241     >>   90 STORE_FAST              14 (output_hidden_states)\n\n1244          92 LOAD_FAST               12 (use_cache)\n              94 LOAD_CONST               0 (None)\n              96 IS_OP                    1\n              98 POP_JUMP_IF_FALSE       52 (to 104)\n             100 LOAD_FAST               12 (use_cache)\n             102 JUMP_FORWARD             3 (to 110)\n         >>  104 LOAD_FAST                0 (self)\n             106 LOAD_ATTR                2 (config)\n             108 LOAD_ATTR                7 (use_cache)\n         >>  110 STORE_FAST              12 (use_cache)\n\n1245         112 LOAD_FAST               15 (return_dict)\n             114 LOAD_CONST               0 (None)\n             116 IS_OP                    1\n             118 POP_JUMP_IF_FALSE       62 (to 124)\n             120 LOAD_FAST               15 (return_dict)\n             122 JUMP_FORWARD             3 (to 130)\n         >>  124 LOAD_FAST                0 (self)\n             126 LOAD_ATTR                2 (config)\n             128 LOAD_ATTR                8 (use_return_dict)\n         >>  130 STORE_FAST              15 (return_dict)\n\n1247         132 LOAD_FAST                8 (encoder_outputs)\n             134 LOAD_CONST               0 (None)\n             136 IS_OP                    0\n             138 POP_JUMP_IF_FALSE       83 (to 166)\n\n1248         140 LOAD_FAST                0 (self)\n             142 LOAD_ATTR                9 (encoder)\n\n1249         144 LOAD_FAST                1 (input_ids)\n\n1250         146 LOAD_FAST                2 (attention_mask)\n\n1251         148 LOAD_FAST                5 (head_mask)\n\n1252         150 LOAD_FAST               10 (inputs_embeds)\n\n1253         152 LOAD_FAST               13 (output_attentions)\n\n1254         154 LOAD_FAST               14 (output_hidden_states)\n\n1255         156 LOAD_FAST               15 (return_dict)\n\n1248         158 LOAD_CONST               2 (('input_ids', 'attention_mask', 'head_mask', 'inputs_embeds', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             160 CALL_FUNCTION_KW         7\n             162 STORE_FAST               8 (encoder_outputs)\n             164 JUMP_FORWARD            36 (to 238)\n\n1258     >>  166 LOAD_FAST               15 (return_dict)\n             168 POP_JUMP_IF_FALSE      119 (to 238)\n             170 LOAD_GLOBAL             10 (isinstance)\n             172 LOAD_FAST                8 (encoder_outputs)\n             174 LOAD_GLOBAL             11 (BaseModelOutput)\n             176 CALL_FUNCTION            2\n             178 POP_JUMP_IF_TRUE       119 (to 238)\n\n1259         180 LOAD_GLOBAL             11 (BaseModelOutput)\n\n1260         182 LOAD_FAST                8 (encoder_outputs)\n             184 LOAD_CONST               3 (0)\n             186 BINARY_SUBSCR\n\n1261         188 LOAD_GLOBAL             12 (len)\n             190 LOAD_FAST                8 (encoder_outputs)\n             192 CALL_FUNCTION            1\n             194 LOAD_CONST               4 (1)\n             196 COMPARE_OP               4 (>)\n             198 POP_JUMP_IF_FALSE      104 (to 208)\n             200 LOAD_FAST                8 (encoder_outputs)\n             202 LOAD_CONST               4 (1)\n             204 BINARY_SUBSCR\n             206 JUMP_FORWARD             1 (to 210)\n         >>  208 LOAD_CONST               0 (None)\n\n1262     >>  210 LOAD_GLOBAL             12 (len)\n             212 LOAD_FAST                8 (encoder_outputs)\n             214 CALL_FUNCTION            1\n             216 LOAD_CONST               5 (2)\n             218 COMPARE_OP               4 (>)\n             220 POP_JUMP_IF_FALSE      115 (to 230)\n             222 LOAD_FAST                8 (encoder_outputs)\n             224 LOAD_CONST               5 (2)\n             226 BINARY_SUBSCR\n             228 JUMP_FORWARD             1 (to 232)\n         >>  230 LOAD_CONST               0 (None)\n\n1259     >>  232 LOAD_CONST               6 (('last_hidden_state', 'hidden_states', 'attentions'))\n             234 CALL_FUNCTION_KW         3\n             236 STORE_FAST               8 (encoder_outputs)\n\n1266     >>  238 LOAD_FAST                0 (self)\n             240 LOAD_ATTR               13 (decoder)\n\n1267         242 LOAD_FAST                3 (decoder_input_ids)\n\n1268         244 LOAD_FAST                4 (decoder_attention_mask)\n\n1269         246 LOAD_FAST                8 (encoder_outputs)\n             248 LOAD_CONST               3 (0)\n             250 BINARY_SUBSCR\n\n1270         252 LOAD_FAST                2 (attention_mask)\n\n1271         254 LOAD_FAST                6 (decoder_head_mask)\n\n1272         256 LOAD_FAST                7 (cross_attn_head_mask)\n\n1273         258 LOAD_FAST                9 (past_key_values)\n\n1274         260 LOAD_FAST               11 (decoder_inputs_embeds)\n\n1275         262 LOAD_FAST               12 (use_cache)\n\n1276         264 LOAD_FAST               13 (output_attentions)\n\n1277         266 LOAD_FAST               14 (output_hidden_states)\n\n1278         268 LOAD_FAST               15 (return_dict)\n\n1266         270 LOAD_CONST               7 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             272 CALL_FUNCTION_KW        12\n             274 STORE_FAST              16 (decoder_outputs)\n\n1281         276 LOAD_FAST               15 (return_dict)\n             278 POP_JUMP_IF_TRUE       144 (to 288)\n\n1282         280 LOAD_FAST               16 (decoder_outputs)\n             282 LOAD_FAST                8 (encoder_outputs)\n             284 BINARY_ADD\n             286 RETURN_VALUE\n\n1284     >>  288 LOAD_GLOBAL             14 (Seq2SeqModelOutput)\n\n1285         290 LOAD_FAST               16 (decoder_outputs)\n             292 LOAD_ATTR               15 (last_hidden_state)\n\n1286         294 LOAD_FAST               16 (decoder_outputs)\n             296 LOAD_ATTR               16 (past_key_values)\n\n1287         298 LOAD_FAST               16 (decoder_outputs)\n             300 LOAD_ATTR               17 (hidden_states)\n\n1288         302 LOAD_FAST               16 (decoder_outputs)\n             304 LOAD_ATTR               18 (attentions)\n\n1289         306 LOAD_FAST               16 (decoder_outputs)\n             308 LOAD_ATTR               19 (cross_attentions)\n\n1290         310 LOAD_FAST                8 (encoder_outputs)\n             312 LOAD_ATTR               15 (last_hidden_state)\n\n1291         314 LOAD_FAST                8 (encoder_outputs)\n             316 LOAD_ATTR               17 (hidden_states)\n\n1292         318 LOAD_FAST                8 (encoder_outputs)\n             320 LOAD_ATTR               18 (attentions)\n\n1284         322 LOAD_CONST               8 (('last_hidden_state', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             324 CALL_FUNCTION_KW         8\n             326 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 131 \n134           0 LOAD_FAST                1 (input_ids)\n              2 LOAD_ATTR                0 (shape)\n              4 LOAD_CONST               1 (None)\n              6 LOAD_CONST               2 (2)\n              8 BUILD_SLICE              2\n             10 BINARY_SUBSCR\n             12 UNPACK_SEQUENCE          2\n             14 STORE_FAST               3 (bsz)\n             16 STORE_FAST               4 (seq_len)\n\n135          18 LOAD_GLOBAL              1 (torch)\n             20 LOAD_ATTR                2 (arange)\n\n136          22 LOAD_FAST                2 (past_key_values_length)\n             24 LOAD_FAST                2 (past_key_values_length)\n             26 LOAD_FAST                4 (seq_len)\n             28 BINARY_ADD\n             30 LOAD_GLOBAL              1 (torch)\n             32 LOAD_ATTR                3 (long)\n             34 LOAD_FAST                0 (self)\n             36 LOAD_ATTR                4 (weight)\n             38 LOAD_ATTR                5 (device)\n\n135          40 LOAD_CONST               3 (('dtype', 'device'))\n             42 CALL_FUNCTION_KW         4\n\n137          44 LOAD_METHOD              6 (expand)\n             46 LOAD_FAST                3 (bsz)\n             48 LOAD_CONST               4 (-1)\n             50 CALL_METHOD              2\n\n135          52 STORE_FAST               5 (positions)\n\n139          54 LOAD_GLOBAL              7 (super)\n             56 CALL_FUNCTION            0\n             58 LOAD_METHOD              8 (forward)\n             60 LOAD_FAST                5 (positions)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                9 (offset)\n             66 BINARY_ADD\n             68 CALL_METHOD              1\n             70 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 313 \n331           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n332           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n333           8 LOAD_FAST                1 (hidden_states)\n\n334          10 LOAD_FAST                2 (attention_mask)\n\n335          12 LOAD_FAST                3 (layer_head_mask)\n\n336          14 LOAD_FAST                4 (output_attentions)\n\n332          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n338          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n339          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n340          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n342          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n343          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n344          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n345         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n346         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n347         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n348         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n350         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n351         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n350         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n351         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n350         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n353     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n354         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n356     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n358         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n359         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n361     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 313 \n331           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n332           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n333           8 LOAD_FAST                1 (hidden_states)\n\n334          10 LOAD_FAST                2 (attention_mask)\n\n335          12 LOAD_FAST                3 (layer_head_mask)\n\n336          14 LOAD_FAST                4 (output_attentions)\n\n332          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n338          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n339          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n340          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n342          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n343          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n344          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n345         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n346         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n347         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n348         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n350         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n351         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n350         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n351         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n350         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n353     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n354         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n356     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n358         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n359         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n361     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 313 \n331           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n332           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n333           8 LOAD_FAST                1 (hidden_states)\n\n334          10 LOAD_FAST                2 (attention_mask)\n\n335          12 LOAD_FAST                3 (layer_head_mask)\n\n336          14 LOAD_FAST                4 (output_attentions)\n\n332          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n338          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n339          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n340          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n342          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n343          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n344          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n345         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n346         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n347         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n348         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n350         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n351         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n350         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n351         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n350         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n353     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n354         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n356     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n358         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n359         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n361     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 313 \n331           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n332           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n333           8 LOAD_FAST                1 (hidden_states)\n\n334          10 LOAD_FAST                2 (attention_mask)\n\n335          12 LOAD_FAST                3 (layer_head_mask)\n\n336          14 LOAD_FAST                4 (output_attentions)\n\n332          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n338          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n339          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n340          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n342          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n343          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n344          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n345         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n346         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n347         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n348         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n350         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n351         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n350         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n351         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n350         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n353     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n354         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n356     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n358         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n359         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n361     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 313 \n331           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n332           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n333           8 LOAD_FAST                1 (hidden_states)\n\n334          10 LOAD_FAST                2 (attention_mask)\n\n335          12 LOAD_FAST                3 (layer_head_mask)\n\n336          14 LOAD_FAST                4 (output_attentions)\n\n332          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n338          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n339          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n340          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n342          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n343          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n344          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n345         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n346         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n347         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n348         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n350         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n351         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n350         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n351         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n350         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n353     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n354         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n356     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n358         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n359         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n361     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 313 \n331           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n332           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n333           8 LOAD_FAST                1 (hidden_states)\n\n334          10 LOAD_FAST                2 (attention_mask)\n\n335          12 LOAD_FAST                3 (layer_head_mask)\n\n336          14 LOAD_FAST                4 (output_attentions)\n\n332          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n338          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n339          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n340          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n342          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n343          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n344          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n345         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n346         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n347         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n348         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n350         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n351         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n350         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n351         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n350         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n353     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n354         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n356     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n358         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n359         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n361     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 313 \n331           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n332           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n333           8 LOAD_FAST                1 (hidden_states)\n\n334          10 LOAD_FAST                2 (attention_mask)\n\n335          12 LOAD_FAST                3 (layer_head_mask)\n\n336          14 LOAD_FAST                4 (output_attentions)\n\n332          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n338          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n339          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n340          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n342          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n343          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n344          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n345         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n346         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n347         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n348         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n350         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n351         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n350         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n351         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n350         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n353     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n354         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n356     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n358         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n359         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n361     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 313 \n331           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n332           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n333           8 LOAD_FAST                1 (hidden_states)\n\n334          10 LOAD_FAST                2 (attention_mask)\n\n335          12 LOAD_FAST                3 (layer_head_mask)\n\n336          14 LOAD_FAST                4 (output_attentions)\n\n332          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n338          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n339          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n340          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n342          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n343          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n344          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n345         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n346         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n347         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n348         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n350         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n351         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n350         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n351         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n350         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n353     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n354         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n356     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n358         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n359         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n361     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 313 \n331           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n332           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n333           8 LOAD_FAST                1 (hidden_states)\n\n334          10 LOAD_FAST                2 (attention_mask)\n\n335          12 LOAD_FAST                3 (layer_head_mask)\n\n336          14 LOAD_FAST                4 (output_attentions)\n\n332          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n338          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n339          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n340          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n342          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n343          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n344          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n345         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n346         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n347         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n348         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n350         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n351         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n350         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n351         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n350         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n353     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n354         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n356     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n358         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n359         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n361     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 313 \n331           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n332           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n333           8 LOAD_FAST                1 (hidden_states)\n\n334          10 LOAD_FAST                2 (attention_mask)\n\n335          12 LOAD_FAST                3 (layer_head_mask)\n\n336          14 LOAD_FAST                4 (output_attentions)\n\n332          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n338          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n339          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n340          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n342          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n343          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n344          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n345         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n346         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n347         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n348         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n350         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n351         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n350         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n351         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n350         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n353     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n354         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n356     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n358         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n359         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n361     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 313 \n331           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n332           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n333           8 LOAD_FAST                1 (hidden_states)\n\n334          10 LOAD_FAST                2 (attention_mask)\n\n335          12 LOAD_FAST                3 (layer_head_mask)\n\n336          14 LOAD_FAST                4 (output_attentions)\n\n332          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n338          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n339          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n340          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n342          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n343          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n344          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n345         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n346         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n347         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n348         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n350         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n351         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n350         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n351         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n350         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n353     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n354         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n356     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n358         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n359         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n361     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 313 \n331           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n332           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n333           8 LOAD_FAST                1 (hidden_states)\n\n334          10 LOAD_FAST                2 (attention_mask)\n\n335          12 LOAD_FAST                3 (layer_head_mask)\n\n336          14 LOAD_FAST                4 (output_attentions)\n\n332          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n338          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n339          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n340          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n342          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n343          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n344          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n345         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n346         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n347         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n348         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n350         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n351         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n350         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n351         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n350         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n353     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n354         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n356     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n358         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n359         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n361     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (hidden_states)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (hidden_states)\n\n  5          12 LOAD_FAST                3 (attentions)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (attentions)\n\n  6          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              3 (__post_init__)\n             22 CALL_METHOD              0\n             24 POP_TOP\n             26 LOAD_CONST               0 (None)\n             28 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 1248 \n1248           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           83 (to 166)\n               4 LOAD_FAST                3 (decoder_input_ids)\n               6 LOAD_CONST               0 (None)\n               8 IS_OP                    0\n              10 POP_JUMP_IF_FALSE       28 (to 56)\n              12 LOAD_FAST                8 (decoder_inputs_embeds)\n              14 LOAD_CONST               0 (None)\n              16 IS_OP                    0\n              18 POP_JUMP_IF_FALSE       28 (to 56)\n              20 LOAD_FAST               13 (input_ids)\n              22 LOAD_CONST               0 (None)\n              24 IS_OP                    0\n              26 POP_JUMP_IF_FALSE       18 (to 36)\n              28 LOAD_GLOBAL              0 (ValueError)\n              30 LOAD_CONST               1 ('If no `decoder_input_ids` or `decoder_inputs_embeds` are passed, `input_ids` cannot be `None`. Please pass either `input_ids` or `decoder_input_ids` or `decoder_inputs_embeds`.')\n              32 CALL_FUNCTION            1\n              34 RAISE_VARARGS            1\n         >>   36 LOAD_GLOBAL              1 (shift_tokens_right)\n              38 LOAD_FAST               13 (input_ids)\n              40 LOAD_FAST                1 (self)\n              42 LOAD_ATTR                2 (config)\n              44 LOAD_ATTR                3 (pad_token_id)\n              46 LOAD_FAST                1 (self)\n              48 LOAD_ATTR                2 (config)\n              50 LOAD_ATTR                4 (decoder_start_token_id)\n              52 CALL_FUNCTION            3\n              54 STORE_FAST               3 (decoder_input_ids)\n         >>   56 LOAD_FAST               10 (output_attentions)\n              58 LOAD_CONST               0 (None)\n              60 IS_OP                    1\n              62 POP_JUMP_IF_FALSE       34 (to 68)\n              64 LOAD_FAST               10 (output_attentions)\n              66 JUMP_FORWARD             3 (to 74)\n         >>   68 LOAD_FAST                1 (self)\n              70 LOAD_ATTR                2 (config)\n              72 LOAD_ATTR                5 (output_attentions)\n         >>   74 STORE_FAST              10 (output_attentions)\n              76 LOAD_FAST               11 (output_hidden_states)\n              78 LOAD_CONST               0 (None)\n              80 IS_OP                    1\n              82 POP_JUMP_IF_FALSE       44 (to 88)\n              84 LOAD_FAST               11 (output_hidden_states)\n              86 JUMP_FORWARD             3 (to 94)\n         >>   88 LOAD_FAST                1 (self)\n              90 LOAD_ATTR                2 (config)\n              92 LOAD_ATTR                6 (output_hidden_states)\n         >>   94 STORE_FAST              11 (output_hidden_states)\n              96 LOAD_FAST                9 (use_cache)\n              98 LOAD_CONST               0 (None)\n             100 IS_OP                    1\n             102 POP_JUMP_IF_FALSE       54 (to 108)\n             104 LOAD_FAST                9 (use_cache)\n             106 JUMP_FORWARD             3 (to 114)\n         >>  108 LOAD_FAST                1 (self)\n             110 LOAD_ATTR                2 (config)\n             112 LOAD_ATTR                7 (use_cache)\n         >>  114 STORE_FAST               9 (use_cache)\n             116 LOAD_FAST               12 (return_dict)\n             118 LOAD_CONST               0 (None)\n             120 IS_OP                    1\n             122 POP_JUMP_IF_FALSE       64 (to 128)\n             124 LOAD_FAST               12 (return_dict)\n             126 JUMP_FORWARD             3 (to 134)\n         >>  128 LOAD_FAST                1 (self)\n             130 LOAD_ATTR                2 (config)\n             132 LOAD_ATTR                8 (use_return_dict)\n         >>  134 STORE_FAST              12 (return_dict)\n             136 LOAD_FAST               15 (encoder_outputs)\n             138 LOAD_CONST               0 (None)\n             140 IS_OP                    0\n             142 POP_JUMP_IF_FALSE       85 (to 170)\n             144 LOAD_FAST                1 (self)\n             146 LOAD_ATTR                9 (encoder)\n             148 LOAD_FAST               13 (input_ids)\n             150 LOAD_FAST                2 (attention_mask)\n             152 LOAD_FAST               14 (head_mask)\n             154 LOAD_FAST               16 (inputs_embeds)\n             156 LOAD_FAST               10 (output_attentions)\n             158 LOAD_FAST               11 (output_hidden_states)\n             160 LOAD_FAST               12 (return_dict)\n             162 LOAD_CONST               2 (('input_ids', 'attention_mask', 'head_mask', 'inputs_embeds', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             164 CALL_FUNCTION_KW         7\n         >>  166 STORE_FAST              15 (encoder_outputs)\n             168 JUMP_FORWARD            36 (to 242)\n\n1258     >>  170 LOAD_FAST               12 (return_dict)\n             172 POP_JUMP_IF_FALSE      121 (to 242)\n             174 LOAD_GLOBAL             10 (isinstance)\n             176 LOAD_FAST               15 (encoder_outputs)\n             178 LOAD_GLOBAL             11 (BaseModelOutput)\n             180 CALL_FUNCTION            2\n             182 POP_JUMP_IF_TRUE       121 (to 242)\n\n1259         184 LOAD_GLOBAL             11 (BaseModelOutput)\n\n1260         186 LOAD_FAST               15 (encoder_outputs)\n             188 LOAD_CONST               3 (0)\n             190 BINARY_SUBSCR\n\n1261         192 LOAD_GLOBAL             12 (len)\n             194 LOAD_FAST               15 (encoder_outputs)\n             196 CALL_FUNCTION            1\n             198 LOAD_CONST               4 (1)\n             200 COMPARE_OP               4 (>)\n             202 POP_JUMP_IF_FALSE      106 (to 212)\n             204 LOAD_FAST               15 (encoder_outputs)\n             206 LOAD_CONST               4 (1)\n             208 BINARY_SUBSCR\n             210 JUMP_FORWARD             1 (to 214)\n         >>  212 LOAD_CONST               0 (None)\n\n1262     >>  214 LOAD_GLOBAL             12 (len)\n             216 LOAD_FAST               15 (encoder_outputs)\n             218 CALL_FUNCTION            1\n             220 LOAD_CONST               5 (2)\n             222 COMPARE_OP               4 (>)\n             224 POP_JUMP_IF_FALSE      117 (to 234)\n             226 LOAD_FAST               15 (encoder_outputs)\n             228 LOAD_CONST               5 (2)\n             230 BINARY_SUBSCR\n             232 JUMP_FORWARD             1 (to 236)\n         >>  234 LOAD_CONST               0 (None)\n\n1259     >>  236 LOAD_CONST               6 (('last_hidden_state', 'hidden_states', 'attentions'))\n             238 CALL_FUNCTION_KW         3\n             240 STORE_FAST              15 (encoder_outputs)\n\n1266     >>  242 LOAD_FAST                1 (self)\n             244 LOAD_ATTR               13 (decoder)\n\n1267         246 LOAD_FAST                3 (decoder_input_ids)\n\n1268         248 LOAD_FAST                4 (decoder_attention_mask)\n\n1269         250 LOAD_FAST               15 (encoder_outputs)\n             252 LOAD_CONST               3 (0)\n             254 BINARY_SUBSCR\n\n1270         256 LOAD_FAST                2 (attention_mask)\n\n1271         258 LOAD_FAST                5 (decoder_head_mask)\n\n1272         260 LOAD_FAST                6 (cross_attn_head_mask)\n\n1273         262 LOAD_FAST                7 (past_key_values)\n\n1274         264 LOAD_FAST                8 (decoder_inputs_embeds)\n\n1275         266 LOAD_FAST                9 (use_cache)\n\n1276         268 LOAD_FAST               10 (output_attentions)\n\n1277         270 LOAD_FAST               11 (output_hidden_states)\n\n1278         272 LOAD_FAST               12 (return_dict)\n\n1266         274 LOAD_CONST               7 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             276 CALL_FUNCTION_KW        12\n             278 STORE_FAST              17 (decoder_outputs)\n\n1281         280 LOAD_FAST               12 (return_dict)\n             282 POP_JUMP_IF_TRUE       146 (to 292)\n\n1282         284 LOAD_FAST               17 (decoder_outputs)\n             286 LOAD_FAST               15 (encoder_outputs)\n             288 BINARY_ADD\n             290 RETURN_VALUE\n\n1284     >>  292 LOAD_GLOBAL             14 (Seq2SeqModelOutput)\n\n1285         294 LOAD_FAST               17 (decoder_outputs)\n             296 LOAD_ATTR               15 (last_hidden_state)\n\n1286         298 LOAD_FAST               17 (decoder_outputs)\n             300 LOAD_ATTR               16 (past_key_values)\n\n1287         302 LOAD_FAST               17 (decoder_outputs)\n             304 LOAD_ATTR               17 (hidden_states)\n\n1288         306 LOAD_FAST               17 (decoder_outputs)\n             308 LOAD_ATTR               18 (attentions)\n\n1289         310 LOAD_FAST               17 (decoder_outputs)\n             312 LOAD_ATTR               19 (cross_attentions)\n\n1290         314 LOAD_FAST               15 (encoder_outputs)\n             316 LOAD_ATTR               15 (last_hidden_state)\n\n1291         318 LOAD_FAST               15 (encoder_outputs)\n             320 LOAD_ATTR               17 (hidden_states)\n\n1292         322 LOAD_FAST               15 (encoder_outputs)\n             324 LOAD_ATTR               18 (attentions)\n\n1284         326 LOAD_CONST               8 (('last_hidden_state', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             328 CALL_FUNCTION_KW         8\n             330 RETURN_VALUE\n\n", "ORIGINAL BYTECODE _prepare_decoder_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 924 \n927           0 LOAD_CONST               0 (None)\n              2 STORE_FAST               5 (combined_attention_mask)\n\n928           4 LOAD_FAST                2 (input_shape)\n              6 LOAD_CONST               1 (-1)\n              8 BINARY_SUBSCR\n             10 LOAD_CONST               2 (1)\n             12 COMPARE_OP               4 (>)\n             14 POP_JUMP_IF_FALSE       18 (to 36)\n\n929          16 LOAD_GLOBAL              0 (_make_causal_mask)\n\n930          18 LOAD_FAST                2 (input_shape)\n\n931          20 LOAD_FAST                3 (inputs_embeds)\n             22 LOAD_ATTR                1 (dtype)\n\n932          24 LOAD_FAST                3 (inputs_embeds)\n             26 LOAD_ATTR                2 (device)\n\n933          28 LOAD_FAST                4 (past_key_values_length)\n\n929          30 LOAD_CONST               3 (('device', 'past_key_values_length'))\n             32 CALL_FUNCTION_KW         4\n             34 STORE_FAST               5 (combined_attention_mask)\n\n936     >>   36 LOAD_FAST                1 (attention_mask)\n             38 LOAD_CONST               0 (None)\n             40 IS_OP                    1\n             42 POP_JUMP_IF_FALSE       46 (to 92)\n\n938          44 LOAD_GLOBAL              3 (_expand_mask)\n             46 LOAD_FAST                1 (attention_mask)\n             48 LOAD_FAST                3 (inputs_embeds)\n             50 LOAD_ATTR                1 (dtype)\n             52 LOAD_FAST                2 (input_shape)\n             54 LOAD_CONST               1 (-1)\n             56 BINARY_SUBSCR\n             58 LOAD_CONST               4 (('tgt_len',))\n             60 CALL_FUNCTION_KW         3\n             62 LOAD_METHOD              4 (to)\n\n939          64 LOAD_FAST                3 (inputs_embeds)\n             66 LOAD_ATTR                2 (device)\n\n938          68 CALL_METHOD              1\n             70 STORE_FAST               6 (expanded_attn_mask)\n\n942          72 LOAD_FAST                5 (combined_attention_mask)\n             74 LOAD_CONST               0 (None)\n             76 IS_OP                    0\n             78 POP_JUMP_IF_FALSE       42 (to 84)\n             80 LOAD_FAST                6 (expanded_attn_mask)\n             82 JUMP_FORWARD             3 (to 90)\n        >>   84 LOAD_FAST                6 (expanded_attn_mask)\n             86 LOAD_FAST                5 (combined_attention_mask)\n             88 BINARY_ADD\n\n941     >>   90 STORE_FAST               5 (combined_attention_mask)\n\n945     >>   92 LOAD_FAST                5 (combined_attention_mask)\n             94 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 131 \n134           0 LOAD_FAST                1 (input_ids)\n              2 LOAD_ATTR                0 (shape)\n              4 LOAD_CONST               1 (None)\n              6 LOAD_CONST               2 (2)\n              8 BUILD_SLICE              2\n             10 BINARY_SUBSCR\n             12 UNPACK_SEQUENCE          2\n             14 STORE_FAST               3 (bsz)\n             16 STORE_FAST               4 (seq_len)\n\n135          18 LOAD_GLOBAL              1 (torch)\n             20 LOAD_ATTR                2 (arange)\n\n136          22 LOAD_FAST                2 (past_key_values_length)\n             24 LOAD_FAST                2 (past_key_values_length)\n             26 LOAD_FAST                4 (seq_len)\n             28 BINARY_ADD\n             30 LOAD_GLOBAL              1 (torch)\n             32 LOAD_ATTR                3 (long)\n             34 LOAD_FAST                0 (self)\n             36 LOAD_ATTR                4 (weight)\n             38 LOAD_ATTR                5 (device)\n\n135          40 LOAD_CONST               3 (('dtype', 'device'))\n             42 CALL_FUNCTION_KW         4\n\n137          44 LOAD_METHOD              6 (expand)\n             46 LOAD_FAST                3 (bsz)\n             48 LOAD_CONST               4 (-1)\n             50 CALL_METHOD              2\n\n135          52 STORE_FAST               5 (positions)\n\n139          54 LOAD_GLOBAL              7 (super)\n             56 CALL_FUNCTION            0\n             58 LOAD_METHOD              8 (forward)\n             60 LOAD_FAST                5 (positions)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                9 (offset)\n             66 BINARY_ADD\n             68 CALL_METHOD              1\n             70 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 391 \n421           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n425           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n427          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n428          32 LOAD_FAST                1 (hidden_states)\n\n429          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n430          36 LOAD_FAST                2 (attention_mask)\n\n431          38 LOAD_FAST                5 (layer_head_mask)\n\n432          40 LOAD_FAST                8 (output_attentions)\n\n427          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n434          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n435          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n436          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n439          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n440          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n441         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n442         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n445         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n446         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n447         142 LOAD_FAST                1 (hidden_states)\n\n448         144 LOAD_FAST                3 (encoder_hidden_states)\n\n449         146 LOAD_FAST                4 (encoder_attention_mask)\n\n450         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n451         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n452         152 LOAD_FAST                8 (output_attentions)\n\n446         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n454         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n455         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n456         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n459         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n462     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n463         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n464         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n465         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n466         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n467         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n468         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n470         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n472         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n473         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n475     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n476         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n478     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (past_key_values)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (past_key_values)\n\n  5          12 LOAD_FAST                3 (hidden_states)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (hidden_states)\n\n  6          18 LOAD_FAST                4 (attentions)\n             20 LOAD_FAST                0 (self)\n             22 STORE_ATTR               3 (attentions)\n\n  7          24 LOAD_FAST                5 (cross_attentions)\n             26 LOAD_FAST                0 (self)\n             28 STORE_ATTR               4 (cross_attentions)\n\n  8          30 LOAD_FAST                0 (self)\n             32 LOAD_METHOD              5 (__post_init__)\n             34 CALL_METHOD              0\n             36 POP_TOP\n             38 LOAD_CONST               0 (None)\n             40 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (past_key_values)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (past_key_values)\n\n  5          12 LOAD_FAST                3 (decoder_hidden_states)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (decoder_hidden_states)\n\n  6          18 LOAD_FAST                4 (decoder_attentions)\n             20 LOAD_FAST                0 (self)\n             22 STORE_ATTR               3 (decoder_attentions)\n\n  7          24 LOAD_FAST                5 (cross_attentions)\n             26 LOAD_FAST                0 (self)\n             28 STORE_ATTR               4 (cross_attentions)\n\n  8          30 LOAD_FAST                6 (encoder_last_hidden_state)\n             32 LOAD_FAST                0 (self)\n             34 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          36 LOAD_FAST                7 (encoder_hidden_states)\n             38 LOAD_FAST                0 (self)\n             40 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          42 LOAD_FAST                8 (encoder_attentions)\n             44 LOAD_FAST                0 (self)\n             46 STORE_ATTR               7 (encoder_attentions)\n\n 11          48 LOAD_FAST                0 (self)\n             50 LOAD_METHOD              8 (__post_init__)\n             52 CALL_METHOD              0\n             54 POP_TOP\n             56 LOAD_CONST               0 (None)\n             58 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 3 \n  3           0 JUMP_ABSOLUTE            4 (to 8)\n              2 LOAD_FAST                8 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n\n  4     >>    8 LOAD_FAST                1 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5          14 LOAD_FAST                2 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n\n  6          20 LOAD_FAST                3 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7          26 LOAD_FAST                4 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                5 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                6 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                7 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 4 \n  4           0 JUMP_ABSOLUTE            7 (to 14)\n              2 LOAD_FAST                7 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                8 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5     >>   14 LOAD_FAST                1 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n\n  6          20 LOAD_FAST                2 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7          26 LOAD_FAST                3 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                4 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                5 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                6 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 5 \n  5           0 JUMP_ABSOLUTE           10 (to 20)\n              2 LOAD_FAST                6 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                7 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n             14 LOAD_FAST                8 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n\n  6     >>   20 LOAD_FAST                1 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7          26 LOAD_FAST                2 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                3 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                4 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                5 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 6 \n  6           0 JUMP_ABSOLUTE           13 (to 26)\n              2 LOAD_FAST                5 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                6 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n             14 LOAD_FAST                7 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n             20 LOAD_FAST                8 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7     >>   26 LOAD_FAST                1 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                2 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                3 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                4 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 7 \n  7           0 JUMP_ABSOLUTE           16 (to 32)\n              2 LOAD_FAST                4 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                5 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n             14 LOAD_FAST                6 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n             20 LOAD_FAST                7 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n             26 LOAD_FAST                8 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8     >>   32 LOAD_FAST                1 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                2 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                3 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py line 1380 \n1380           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           62 (to 124)\n               4 LOAD_FAST                3 (return_dict)\n               6 LOAD_CONST               1 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST                3 (return_dict)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (use_return_dict)\n         >>   22 STORE_FAST               3 (return_dict)\n              24 LOAD_FAST                2 (labels)\n              26 LOAD_CONST               1 (None)\n              28 IS_OP                    1\n              30 POP_JUMP_IF_FALSE       43 (to 86)\n              32 LOAD_FAST               15 (use_cache)\n              34 POP_JUMP_IF_FALSE       23 (to 46)\n              36 LOAD_GLOBAL              2 (logger)\n              38 LOAD_ATTR                3 (warning)\n              40 LOAD_CONST               2 ('The `use_cache` argument is changed to `False` since `labels` is provided.')\n              42 CALL_FUNCTION            1\n              44 POP_TOP\n         >>   46 LOAD_CONST               3 (False)\n              48 STORE_FAST              15 (use_cache)\n              50 LOAD_FAST                6 (decoder_input_ids)\n              52 LOAD_CONST               1 (None)\n              54 IS_OP                    0\n              56 POP_JUMP_IF_FALSE       43 (to 86)\n              58 LOAD_FAST               14 (decoder_inputs_embeds)\n              60 LOAD_CONST               1 (None)\n              62 IS_OP                    0\n              64 POP_JUMP_IF_FALSE       43 (to 86)\n              66 LOAD_GLOBAL              4 (shift_tokens_right)\n              68 LOAD_FAST                2 (labels)\n              70 LOAD_FAST                1 (self)\n              72 LOAD_ATTR                0 (config)\n              74 LOAD_ATTR                5 (pad_token_id)\n              76 LOAD_FAST                1 (self)\n              78 LOAD_ATTR                0 (config)\n              80 LOAD_ATTR                6 (decoder_start_token_id)\n              82 CALL_FUNCTION            3\n              84 STORE_FAST               6 (decoder_input_ids)\n         >>   86 LOAD_FAST                1 (self)\n              88 LOAD_ATTR                7 (model)\n              90 LOAD_FAST                4 (input_ids)\n              92 LOAD_FAST                5 (attention_mask)\n              94 LOAD_FAST                6 (decoder_input_ids)\n              96 LOAD_FAST               11 (encoder_outputs)\n              98 LOAD_FAST                7 (decoder_attention_mask)\n             100 LOAD_FAST                8 (head_mask)\n             102 LOAD_FAST                9 (decoder_head_mask)\n             104 LOAD_FAST               10 (cross_attn_head_mask)\n             106 LOAD_FAST               12 (past_key_values)\n             108 LOAD_FAST               13 (inputs_embeds)\n             110 LOAD_FAST               14 (decoder_inputs_embeds)\n             112 LOAD_FAST               15 (use_cache)\n             114 LOAD_FAST               16 (output_attentions)\n             116 LOAD_FAST               17 (output_hidden_states)\n             118 LOAD_FAST                3 (return_dict)\n             120 LOAD_CONST               4 (('attention_mask', 'decoder_input_ids', 'encoder_outputs', 'decoder_attention_mask', 'head_mask', 'decoder_head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'decoder_inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             122 CALL_FUNCTION_KW        15\n         >>  124 STORE_FAST              18 (outputs)\n\n1398         126 LOAD_FAST                1 (self)\n             128 LOAD_ATTR                8 (lm_head)\n             130 LOAD_FAST               18 (outputs)\n             132 LOAD_CONST               5 (0)\n             134 BINARY_SUBSCR\n             136 CALL_FUNCTION            1\n             138 STORE_FAST              19 (lm_logits)\n\n1399         140 LOAD_FAST               19 (lm_logits)\n             142 LOAD_FAST                1 (self)\n             144 LOAD_ATTR                9 (final_logits_bias)\n             146 LOAD_ATTR               10 (to)\n             148 LOAD_FAST               19 (lm_logits)\n             150 LOAD_ATTR               11 (device)\n             152 CALL_FUNCTION            1\n             154 BINARY_ADD\n             156 STORE_FAST              19 (lm_logits)\n\n1401         158 LOAD_CONST               1 (None)\n             160 STORE_FAST              20 (masked_lm_loss)\n\n1402         162 LOAD_FAST                2 (labels)\n             164 LOAD_CONST               1 (None)\n             166 IS_OP                    1\n             168 POP_JUMP_IF_FALSE      108 (to 216)\n\n1403         170 LOAD_FAST                2 (labels)\n             172 LOAD_ATTR               10 (to)\n             174 LOAD_FAST               19 (lm_logits)\n             176 LOAD_ATTR               11 (device)\n             178 CALL_FUNCTION            1\n             180 STORE_FAST               2 (labels)\n\n1404         182 LOAD_GLOBAL             12 (CrossEntropyLoss)\n             184 CALL_FUNCTION            0\n             186 STORE_FAST              21 (loss_fct)\n\n1405         188 LOAD_FAST               21 (loss_fct)\n             190 LOAD_FAST               19 (lm_logits)\n             192 LOAD_ATTR               13 (view)\n             194 LOAD_CONST               6 (-1)\n             196 LOAD_FAST                1 (self)\n             198 LOAD_ATTR                0 (config)\n             200 LOAD_ATTR               14 (vocab_size)\n             202 CALL_FUNCTION            2\n             204 LOAD_FAST                2 (labels)\n             206 LOAD_ATTR               13 (view)\n             208 LOAD_CONST               6 (-1)\n             210 CALL_FUNCTION            1\n             212 CALL_FUNCTION            2\n             214 STORE_FAST              20 (masked_lm_loss)\n\n1407     >>  216 LOAD_FAST                3 (return_dict)\n             218 POP_JUMP_IF_TRUE       130 (to 260)\n\n1408         220 LOAD_FAST               19 (lm_logits)\n             222 BUILD_TUPLE              1\n             224 LOAD_FAST               18 (outputs)\n             226 LOAD_CONST               7 (1)\n             228 LOAD_CONST               1 (None)\n             230 BUILD_SLICE              2\n             232 BINARY_SUBSCR\n             234 BINARY_ADD\n             236 STORE_FAST              22 (output)\n\n1409         238 LOAD_FAST               20 (masked_lm_loss)\n             240 LOAD_CONST               1 (None)\n             242 IS_OP                    1\n             244 POP_JUMP_IF_FALSE      128 (to 256)\n             246 LOAD_FAST               20 (masked_lm_loss)\n             248 BUILD_TUPLE              1\n             250 LOAD_FAST               22 (output)\n             252 BINARY_ADD\n             254 RETURN_VALUE\n         >>  256 LOAD_FAST               22 (output)\n             258 RETURN_VALUE\n\n1411     >>  260 LOAD_GLOBAL             15 (Seq2SeqLMOutput)\n\n1412         262 LOAD_FAST               20 (masked_lm_loss)\n\n1413         264 LOAD_FAST               19 (lm_logits)\n\n1414         266 LOAD_FAST               18 (outputs)\n             268 LOAD_ATTR               16 (past_key_values)\n\n1415         270 LOAD_FAST               18 (outputs)\n             272 LOAD_ATTR               17 (decoder_hidden_states)\n\n1416         274 LOAD_FAST               18 (outputs)\n             276 LOAD_ATTR               18 (decoder_attentions)\n\n1417         278 LOAD_FAST               18 (outputs)\n             280 LOAD_ATTR               19 (cross_attentions)\n\n1418         282 LOAD_FAST               18 (outputs)\n             284 LOAD_ATTR               20 (encoder_last_hidden_state)\n\n1419         286 LOAD_FAST               18 (outputs)\n             288 LOAD_ATTR               21 (encoder_hidden_states)\n\n1420         290 LOAD_FAST               18 (outputs)\n             292 LOAD_ATTR               22 (encoder_attentions)\n\n1411         294 LOAD_CONST               8 (('loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             296 CALL_FUNCTION_KW         9\n             298 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 557 \n557           0 LOAD_FAST                0 (___stack0)\n              2 CALL_FUNCTION            0\n              4 SETUP_WITH              10 (to 26)\n              6 POP_TOP\n              8 LOAD_FAST                1 (___stack1)\n             10 JUMP_ABSOLUTE           44 (to 88)\n             12 POP_BLOCK\n             14 LOAD_CONST               0 (None)\n             16 DUP_TOP\n             18 DUP_TOP\n             20 CALL_FUNCTION            3\n             22 POP_TOP\n             24 JUMP_FORWARD             8 (to 42)\n        >>   26 WITH_EXCEPT_START\n             28 POP_JUMP_IF_TRUE        16 (to 32)\n             30 RERAISE                  0\n        >>   32 POP_TOP\n             34 POP_TOP\n             36 POP_TOP\n             38 POP_EXCEPT\n             40 POP_TOP\n        >>   42 NOP\n             44 LOAD_CONST               0 (None)\n             46 RAISE_VARARGS            1\n             48 LOAD_GLOBAL              0 (clone_inputs)\n             50 LOAD_FAST                6 (inputs)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (cloned_inputs)\n             56 LOAD_FAST                2 (self)\n             58 LOAD_ATTR                1 (optimizer_zero_grad)\n             60 LOAD_FAST                3 (mod)\n             62 CALL_FUNCTION            1\n             64 POP_TOP\n             66 LOAD_FAST                2 (self)\n             68 LOAD_ATTR                2 (autocast)\n             70 CALL_FUNCTION            0\n             72 SETUP_WITH              20 (to 114)\n             74 POP_TOP\n             76 LOAD_FAST                3 (mod)\n             78 LOAD_CONST               1 (())\n             80 BUILD_MAP                0\n             82 LOAD_FAST                5 (cloned_inputs)\n             84 DICT_MERGE               1\n             86 CALL_FUNCTION_EX         1\n        >>   88 STORE_FAST               7 (pred)\n\n558          90 LOAD_FAST                2 (self)\n             92 LOAD_ATTR                3 (compute_loss)\n             94 LOAD_FAST                7 (pred)\n             96 CALL_FUNCTION            1\n             98 STORE_FAST               8 (loss)\n            100 POP_BLOCK\n\n556         102 LOAD_CONST               0 (None)\n            104 DUP_TOP\n            106 DUP_TOP\n            108 CALL_FUNCTION            3\n            110 POP_TOP\n            112 JUMP_FORWARD             8 (to 130)\n        >>  114 WITH_EXCEPT_START\n            116 POP_JUMP_IF_TRUE        60 (to 120)\n            118 RERAISE                  1\n        >>  120 POP_TOP\n            122 POP_TOP\n            124 POP_TOP\n            126 POP_EXCEPT\n            128 POP_TOP\n\n559     >>  130 LOAD_FAST                2 (self)\n            132 LOAD_ATTR                4 (grad_scaler)\n            134 LOAD_ATTR                5 (scale)\n            136 LOAD_FAST                8 (loss)\n            138 CALL_FUNCTION            1\n            140 LOAD_ATTR                6 (backward)\n            142 CALL_FUNCTION            0\n            144 POP_TOP\n\n560         146 LOAD_FAST                2 (self)\n            148 LOAD_ATTR                7 (optimizer_step)\n            150 CALL_FUNCTION            0\n            152 POP_TOP\n\n561         154 LOAD_FAST                4 (collect_outputs)\n            156 POP_JUMP_IF_FALSE       86 (to 172)\n\n562         158 LOAD_GLOBAL              8 (collect_results)\n            160 LOAD_FAST                3 (mod)\n            162 LOAD_FAST                7 (pred)\n            164 LOAD_FAST                8 (loss)\n            166 LOAD_FAST                5 (cloned_inputs)\n            168 CALL_FUNCTION            4\n            170 RETURN_VALUE\n\n563     >>  172 LOAD_CONST               0 (None)\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py line 1326 \n1356           0 LOAD_FAST               12 (return_dict)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               12 (return_dict)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (use_return_dict)\n         >>   18 STORE_FAST              12 (return_dict)\n\n1358          20 LOAD_FAST                0 (self)\n              22 LOAD_ATTR                2 (bert)\n\n1359          24 LOAD_FAST                1 (input_ids)\n\n1360          26 LOAD_FAST                2 (attention_mask)\n\n1361          28 LOAD_FAST                3 (token_type_ids)\n\n1362          30 LOAD_FAST                4 (position_ids)\n\n1363          32 LOAD_FAST                5 (head_mask)\n\n1364          34 LOAD_FAST                6 (inputs_embeds)\n\n1365          36 LOAD_FAST                7 (encoder_hidden_states)\n\n1366          38 LOAD_FAST                8 (encoder_attention_mask)\n\n1367          40 LOAD_FAST               10 (output_attentions)\n\n1368          42 LOAD_FAST               11 (output_hidden_states)\n\n1369          44 LOAD_FAST               12 (return_dict)\n\n1358          46 LOAD_CONST               2 (('attention_mask', 'token_type_ids', 'position_ids', 'head_mask', 'inputs_embeds', 'encoder_hidden_states', 'encoder_attention_mask', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              48 CALL_FUNCTION_KW        11\n              50 STORE_FAST              13 (outputs)\n\n1372          52 LOAD_FAST               13 (outputs)\n              54 LOAD_CONST               3 (0)\n              56 BINARY_SUBSCR\n              58 STORE_FAST              14 (sequence_output)\n\n1373          60 LOAD_FAST                0 (self)\n              62 LOAD_METHOD              3 (cls)\n              64 LOAD_FAST               14 (sequence_output)\n              66 CALL_METHOD              1\n              68 STORE_FAST              15 (prediction_scores)\n\n1375          70 LOAD_CONST               1 (None)\n              72 STORE_FAST              16 (masked_lm_loss)\n\n1376          74 LOAD_FAST                9 (labels)\n              76 LOAD_CONST               1 (None)\n              78 IS_OP                    1\n              80 POP_JUMP_IF_FALSE       58 (to 116)\n\n1377          82 LOAD_GLOBAL              4 (CrossEntropyLoss)\n              84 CALL_FUNCTION            0\n              86 STORE_FAST              17 (loss_fct)\n\n1378          88 LOAD_FAST               17 (loss_fct)\n              90 LOAD_FAST               15 (prediction_scores)\n              92 LOAD_METHOD              5 (view)\n              94 LOAD_CONST               4 (-1)\n              96 LOAD_FAST                0 (self)\n              98 LOAD_ATTR                0 (config)\n             100 LOAD_ATTR                6 (vocab_size)\n             102 CALL_METHOD              2\n             104 LOAD_FAST                9 (labels)\n             106 LOAD_METHOD              5 (view)\n             108 LOAD_CONST               4 (-1)\n             110 CALL_METHOD              1\n             112 CALL_FUNCTION            2\n             114 STORE_FAST              16 (masked_lm_loss)\n\n1380     >>  116 LOAD_FAST               12 (return_dict)\n             118 POP_JUMP_IF_TRUE        80 (to 160)\n\n1381         120 LOAD_FAST               15 (prediction_scores)\n             122 BUILD_TUPLE              1\n             124 LOAD_FAST               13 (outputs)\n             126 LOAD_CONST               5 (2)\n             128 LOAD_CONST               1 (None)\n             130 BUILD_SLICE              2\n             132 BINARY_SUBSCR\n             134 BINARY_ADD\n             136 STORE_FAST              18 (output)\n\n1382         138 LOAD_FAST               16 (masked_lm_loss)\n             140 LOAD_CONST               1 (None)\n             142 IS_OP                    1\n             144 POP_JUMP_IF_FALSE       78 (to 156)\n             146 LOAD_FAST               16 (masked_lm_loss)\n             148 BUILD_TUPLE              1\n             150 LOAD_FAST               18 (output)\n             152 BINARY_ADD\n             154 RETURN_VALUE\n         >>  156 LOAD_FAST               18 (output)\n             158 RETURN_VALUE\n\n1384     >>  160 LOAD_GLOBAL              7 (MaskedLMOutput)\n\n1385         162 LOAD_FAST               16 (masked_lm_loss)\n\n1386         164 LOAD_FAST               15 (prediction_scores)\n\n1387         166 LOAD_FAST               13 (outputs)\n             168 LOAD_ATTR                8 (hidden_states)\n\n1388         170 LOAD_FAST               13 (outputs)\n             172 LOAD_ATTR                9 (attentions)\n\n1384         174 LOAD_CONST               6 (('loss', 'logits', 'hidden_states', 'attentions'))\n             176 CALL_FUNCTION_KW         4\n             178 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py line 913 \n 955           0 LOAD_FAST               11 (output_attentions)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               11 (output_attentions)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (output_attentions)\n         >>   18 STORE_FAST              11 (output_attentions)\n\n 957          20 LOAD_FAST               12 (output_hidden_states)\n              22 LOAD_CONST               1 (None)\n              24 IS_OP                    1\n              26 POP_JUMP_IF_FALSE       16 (to 32)\n              28 LOAD_FAST               12 (output_hidden_states)\n              30 JUMP_FORWARD             3 (to 38)\n         >>   32 LOAD_FAST                0 (self)\n              34 LOAD_ATTR                0 (config)\n              36 LOAD_ATTR                2 (output_hidden_states)\n\n 956     >>   38 STORE_FAST              12 (output_hidden_states)\n\n 959          40 LOAD_FAST               13 (return_dict)\n              42 LOAD_CONST               1 (None)\n              44 IS_OP                    1\n              46 POP_JUMP_IF_FALSE       26 (to 52)\n              48 LOAD_FAST               13 (return_dict)\n              50 JUMP_FORWARD             3 (to 58)\n         >>   52 LOAD_FAST                0 (self)\n              54 LOAD_ATTR                0 (config)\n              56 LOAD_ATTR                3 (use_return_dict)\n         >>   58 STORE_FAST              13 (return_dict)\n\n 961          60 LOAD_FAST                0 (self)\n              62 LOAD_ATTR                0 (config)\n              64 LOAD_ATTR                4 (is_decoder)\n              66 POP_JUMP_IF_FALSE       45 (to 90)\n\n 962          68 LOAD_FAST               10 (use_cache)\n              70 LOAD_CONST               1 (None)\n              72 IS_OP                    1\n              74 POP_JUMP_IF_FALSE       40 (to 80)\n              76 LOAD_FAST               10 (use_cache)\n              78 JUMP_FORWARD             3 (to 86)\n         >>   80 LOAD_FAST                0 (self)\n              82 LOAD_ATTR                0 (config)\n              84 LOAD_ATTR                5 (use_cache)\n         >>   86 STORE_FAST              10 (use_cache)\n              88 JUMP_FORWARD             2 (to 94)\n\n 964     >>   90 LOAD_CONST               2 (False)\n              92 STORE_FAST              10 (use_cache)\n\n 966     >>   94 LOAD_FAST                1 (input_ids)\n              96 LOAD_CONST               1 (None)\n              98 IS_OP                    1\n             100 POP_JUMP_IF_FALSE       59 (to 118)\n             102 LOAD_FAST                6 (inputs_embeds)\n             104 LOAD_CONST               1 (None)\n             106 IS_OP                    1\n             108 POP_JUMP_IF_FALSE       59 (to 118)\n\n 967         110 LOAD_GLOBAL              6 (ValueError)\n             112 LOAD_CONST               3 ('You cannot specify both input_ids and inputs_embeds at the same time')\n             114 CALL_FUNCTION            1\n             116 RAISE_VARARGS            1\n\n 968     >>  118 LOAD_FAST                1 (input_ids)\n             120 LOAD_CONST               1 (None)\n             122 IS_OP                    1\n             124 POP_JUMP_IF_FALSE       74 (to 148)\n\n 969         126 LOAD_FAST                1 (input_ids)\n             128 LOAD_METHOD              7 (size)\n             130 CALL_METHOD              0\n             132 STORE_FAST              14 (input_shape)\n\n 970         134 LOAD_FAST                0 (self)\n             136 LOAD_METHOD              8 (warn_if_padding_and_no_attention_mask)\n             138 LOAD_FAST                1 (input_ids)\n             140 LOAD_FAST                2 (attention_mask)\n             142 CALL_METHOD              2\n             144 POP_TOP\n             146 JUMP_FORWARD            17 (to 182)\n\n 971     >>  148 LOAD_FAST                6 (inputs_embeds)\n             150 LOAD_CONST               1 (None)\n             152 IS_OP                    1\n             154 POP_JUMP_IF_FALSE       87 (to 174)\n\n 972         156 LOAD_FAST                6 (inputs_embeds)\n             158 LOAD_METHOD              7 (size)\n             160 CALL_METHOD              0\n             162 LOAD_CONST               1 (None)\n             164 LOAD_CONST               4 (-1)\n             166 BUILD_SLICE              2\n             168 BINARY_SUBSCR\n             170 STORE_FAST              14 (input_shape)\n             172 JUMP_FORWARD             4 (to 182)\n\n 974     >>  174 LOAD_GLOBAL              6 (ValueError)\n             176 LOAD_CONST               5 ('You have to specify either input_ids or inputs_embeds')\n             178 CALL_FUNCTION            1\n             180 RAISE_VARARGS            1\n\n 976     >>  182 LOAD_FAST               14 (input_shape)\n             184 UNPACK_SEQUENCE          2\n             186 STORE_FAST              15 (batch_size)\n             188 STORE_FAST              16 (seq_length)\n\n 977         190 LOAD_FAST                1 (input_ids)\n             192 LOAD_CONST               1 (None)\n             194 IS_OP                    1\n             196 POP_JUMP_IF_FALSE      102 (to 204)\n             198 LOAD_FAST                1 (input_ids)\n             200 LOAD_ATTR                9 (device)\n             202 JUMP_FORWARD             2 (to 208)\n         >>  204 LOAD_FAST                6 (inputs_embeds)\n             206 LOAD_ATTR                9 (device)\n         >>  208 STORE_FAST              17 (device)\n\n 980         210 LOAD_FAST                9 (past_key_values)\n             212 LOAD_CONST               1 (None)\n             214 IS_OP                    1\n             216 POP_JUMP_IF_FALSE      118 (to 236)\n             218 LOAD_FAST                9 (past_key_values)\n             220 LOAD_CONST               6 (0)\n             222 BINARY_SUBSCR\n             224 LOAD_CONST               6 (0)\n             226 BINARY_SUBSCR\n             228 LOAD_ATTR               10 (shape)\n             230 LOAD_CONST               7 (2)\n             232 BINARY_SUBSCR\n             234 JUMP_FORWARD             1 (to 238)\n         >>  236 LOAD_CONST               6 (0)\n         >>  238 STORE_FAST              18 (past_key_values_length)\n\n 982         240 LOAD_FAST                2 (attention_mask)\n             242 LOAD_CONST               1 (None)\n             244 IS_OP                    0\n             246 POP_JUMP_IF_FALSE      135 (to 270)\n\n 983         248 LOAD_GLOBAL             11 (torch)\n             250 LOAD_ATTR               12 (ones)\n             252 LOAD_FAST               15 (batch_size)\n             254 LOAD_FAST               16 (seq_length)\n             256 LOAD_FAST               18 (past_key_values_length)\n             258 BINARY_ADD\n             260 BUILD_TUPLE              2\n             262 LOAD_FAST               17 (device)\n             264 LOAD_CONST               8 (('device',))\n             266 CALL_FUNCTION_KW         2\n             268 STORE_FAST               2 (attention_mask)\n\n 985     >>  270 LOAD_FAST                3 (token_type_ids)\n             272 LOAD_CONST               1 (None)\n             274 IS_OP                    0\n             276 POP_JUMP_IF_FALSE      175 (to 350)\n\n 986         278 LOAD_GLOBAL             13 (hasattr)\n             280 LOAD_FAST                0 (self)\n             282 LOAD_ATTR               14 (embeddings)\n             284 LOAD_CONST               9 ('token_type_ids')\n             286 CALL_FUNCTION            2\n             288 POP_JUMP_IF_FALSE      166 (to 332)\n\n 987         290 LOAD_FAST                0 (self)\n             292 LOAD_ATTR               14 (embeddings)\n             294 LOAD_ATTR               15 (token_type_ids)\n             296 LOAD_CONST               1 (None)\n             298 LOAD_CONST               1 (None)\n             300 BUILD_SLICE              2\n             302 LOAD_CONST               1 (None)\n             304 LOAD_FAST               16 (seq_length)\n             306 BUILD_SLICE              2\n             308 BUILD_TUPLE              2\n             310 BINARY_SUBSCR\n             312 STORE_FAST              19 (buffered_token_type_ids)\n\n 988         314 LOAD_FAST               19 (buffered_token_type_ids)\n             316 LOAD_METHOD             16 (expand)\n             318 LOAD_FAST               15 (batch_size)\n             320 LOAD_FAST               16 (seq_length)\n             322 CALL_METHOD              2\n             324 STORE_FAST              20 (buffered_token_type_ids_expanded)\n\n 989         326 LOAD_FAST               20 (buffered_token_type_ids_expanded)\n             328 STORE_FAST               3 (token_type_ids)\n             330 JUMP_FORWARD             9 (to 350)\n\n 991     >>  332 LOAD_GLOBAL             11 (torch)\n             334 LOAD_ATTR               17 (zeros)\n             336 LOAD_FAST               14 (input_shape)\n             338 LOAD_GLOBAL             11 (torch)\n             340 LOAD_ATTR               18 (long)\n             342 LOAD_FAST               17 (device)\n             344 LOAD_CONST              10 (('dtype', 'device'))\n             346 CALL_FUNCTION_KW         3\n             348 STORE_FAST               3 (token_type_ids)\n\n 995     >>  350 LOAD_FAST                0 (self)\n             352 LOAD_METHOD             19 (get_extended_attention_mask)\n             354 LOAD_FAST                2 (attention_mask)\n             356 LOAD_FAST               14 (input_shape)\n             358 CALL_METHOD              2\n             360 STORE_FAST              21 (extended_attention_mask)\n\n 999         362 LOAD_FAST                0 (self)\n             364 LOAD_ATTR                0 (config)\n             366 LOAD_ATTR                4 (is_decoder)\n             368 POP_JUMP_IF_FALSE      217 (to 434)\n             370 LOAD_FAST                7 (encoder_hidden_states)\n             372 LOAD_CONST               1 (None)\n             374 IS_OP                    1\n             376 POP_JUMP_IF_FALSE      217 (to 434)\n\n1000         378 LOAD_FAST                7 (encoder_hidden_states)\n             380 LOAD_METHOD              7 (size)\n             382 CALL_METHOD              0\n             384 UNPACK_SEQUENCE          3\n             386 STORE_FAST              22 (encoder_batch_size)\n             388 STORE_FAST              23 (encoder_sequence_length)\n             390 STORE_FAST              24 (_)\n\n1001         392 LOAD_FAST               22 (encoder_batch_size)\n             394 LOAD_FAST               23 (encoder_sequence_length)\n             396 BUILD_TUPLE              2\n             398 STORE_FAST              25 (encoder_hidden_shape)\n\n1002         400 LOAD_FAST                8 (encoder_attention_mask)\n             402 LOAD_CONST               1 (None)\n             404 IS_OP                    0\n             406 POP_JUMP_IF_FALSE      211 (to 422)\n\n1003         408 LOAD_GLOBAL             11 (torch)\n             410 LOAD_ATTR               12 (ones)\n             412 LOAD_FAST               25 (encoder_hidden_shape)\n             414 LOAD_FAST               17 (device)\n             416 LOAD_CONST               8 (('device',))\n             418 CALL_FUNCTION_KW         2\n             420 STORE_FAST               8 (encoder_attention_mask)\n\n1004     >>  422 LOAD_FAST                0 (self)\n             424 LOAD_METHOD             20 (invert_attention_mask)\n             426 LOAD_FAST                8 (encoder_attention_mask)\n             428 CALL_METHOD              1\n             430 STORE_FAST              26 (encoder_extended_attention_mask)\n             432 JUMP_FORWARD             2 (to 438)\n\n1006     >>  434 LOAD_CONST               1 (None)\n             436 STORE_FAST              26 (encoder_extended_attention_mask)\n\n1013     >>  438 LOAD_FAST                0 (self)\n             440 LOAD_METHOD             21 (get_head_mask)\n             442 LOAD_FAST                5 (head_mask)\n             444 LOAD_FAST                0 (self)\n             446 LOAD_ATTR                0 (config)\n             448 LOAD_ATTR               22 (num_hidden_layers)\n             450 CALL_METHOD              2\n             452 STORE_FAST               5 (head_mask)\n\n1015         454 LOAD_FAST                0 (self)\n             456 LOAD_ATTR               14 (embeddings)\n\n1016         458 LOAD_FAST                1 (input_ids)\n\n1017         460 LOAD_FAST                4 (position_ids)\n\n1018         462 LOAD_FAST                3 (token_type_ids)\n\n1019         464 LOAD_FAST                6 (inputs_embeds)\n\n1020         466 LOAD_FAST               18 (past_key_values_length)\n\n1015         468 LOAD_CONST              11 (('input_ids', 'position_ids', 'token_type_ids', 'inputs_embeds', 'past_key_values_length'))\n             470 CALL_FUNCTION_KW         5\n             472 STORE_FAST              27 (embedding_output)\n\n1022         474 LOAD_FAST                0 (self)\n             476 LOAD_ATTR               23 (encoder)\n\n1023         478 LOAD_FAST               27 (embedding_output)\n\n1024         480 LOAD_FAST               21 (extended_attention_mask)\n\n1025         482 LOAD_FAST                5 (head_mask)\n\n1026         484 LOAD_FAST                7 (encoder_hidden_states)\n\n1027         486 LOAD_FAST               26 (encoder_extended_attention_mask)\n\n1028         488 LOAD_FAST                9 (past_key_values)\n\n1029         490 LOAD_FAST               10 (use_cache)\n\n1030         492 LOAD_FAST               11 (output_attentions)\n\n1031         494 LOAD_FAST               12 (output_hidden_states)\n\n1032         496 LOAD_FAST               13 (return_dict)\n\n1022         498 LOAD_CONST              12 (('attention_mask', 'head_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'past_key_values', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             500 CALL_FUNCTION_KW        10\n             502 STORE_FAST              28 (encoder_outputs)\n\n1034         504 LOAD_FAST               28 (encoder_outputs)\n             506 LOAD_CONST               6 (0)\n             508 BINARY_SUBSCR\n             510 STORE_FAST              29 (sequence_output)\n\n1035         512 LOAD_FAST                0 (self)\n             514 LOAD_ATTR               24 (pooler)\n             516 LOAD_CONST               1 (None)\n             518 IS_OP                    1\n             520 EXTENDED_ARG             1\n             522 POP_JUMP_IF_FALSE      267 (to 534)\n             524 LOAD_FAST                0 (self)\n             526 LOAD_METHOD             24 (pooler)\n             528 LOAD_FAST               29 (sequence_output)\n             530 CALL_METHOD              1\n             532 JUMP_FORWARD             1 (to 536)\n         >>  534 LOAD_CONST               1 (None)\n         >>  536 STORE_FAST              30 (pooled_output)\n\n1037         538 LOAD_FAST               13 (return_dict)\n             540 EXTENDED_ARG             1\n             542 POP_JUMP_IF_TRUE       282 (to 564)\n\n1038         544 LOAD_FAST               29 (sequence_output)\n             546 LOAD_FAST               30 (pooled_output)\n             548 BUILD_TUPLE              2\n             550 LOAD_FAST               28 (encoder_outputs)\n             552 LOAD_CONST              13 (1)\n             554 LOAD_CONST               1 (None)\n             556 BUILD_SLICE              2\n             558 BINARY_SUBSCR\n             560 BINARY_ADD\n             562 RETURN_VALUE\n\n1040     >>  564 LOAD_GLOBAL             25 (BaseModelOutputWithPoolingAndCrossAttentions)\n\n1041         566 LOAD_FAST               29 (sequence_output)\n\n1042         568 LOAD_FAST               30 (pooled_output)\n\n1043         570 LOAD_FAST               28 (encoder_outputs)\n             572 LOAD_ATTR               26 (past_key_values)\n\n1044         574 LOAD_FAST               28 (encoder_outputs)\n             576 LOAD_ATTR               27 (hidden_states)\n\n1045         578 LOAD_FAST               28 (encoder_outputs)\n             580 LOAD_ATTR               28 (attentions)\n\n1046         582 LOAD_FAST               28 (encoder_outputs)\n             584 LOAD_ATTR               29 (cross_attentions)\n\n1040         586 LOAD_CONST              14 (('last_hidden_state', 'pooler_output', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n             588 CALL_FUNCTION_KW         6\n             590 RETURN_VALUE\n\n", "ORIGINAL BYTECODE warn_if_padding_and_no_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/modeling_utils.py line 3482 \n3486           0 LOAD_FAST                2 (attention_mask)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_TRUE        10 (to 20)\n               8 LOAD_FAST                0 (self)\n              10 LOAD_ATTR                0 (config)\n              12 LOAD_ATTR                1 (pad_token_id)\n              14 LOAD_CONST               1 (None)\n              16 IS_OP                    0\n              18 POP_JUMP_IF_FALSE       12 (to 24)\n\n3487     >>   20 LOAD_CONST               1 (None)\n              22 RETURN_VALUE\n\n3490     >>   24 LOAD_FAST                0 (self)\n              26 LOAD_ATTR                0 (config)\n              28 LOAD_ATTR                1 (pad_token_id)\n              30 LOAD_FAST                1 (input_ids)\n              32 LOAD_CONST               1 (None)\n              34 LOAD_CONST               1 (None)\n              36 BUILD_SLICE              2\n              38 LOAD_CONST               2 (-1)\n              40 LOAD_CONST               3 (0)\n              42 BUILD_LIST               2\n              44 BUILD_TUPLE              2\n              46 BINARY_SUBSCR\n              48 CONTAINS_OP              0\n              50 POP_JUMP_IF_FALSE      102 (to 204)\n\n3492          52 LOAD_CONST               4 ('We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.')\n\n3491          54 STORE_FAST               3 (warn_string)\n\n3500          56 LOAD_FAST                0 (self)\n              58 LOAD_ATTR                0 (config)\n              60 LOAD_ATTR                2 (bos_token_id)\n              62 LOAD_CONST               1 (None)\n              64 IS_OP                    1\n              66 POP_JUMP_IF_FALSE       42 (to 84)\n              68 LOAD_FAST                0 (self)\n              70 LOAD_ATTR                0 (config)\n              72 LOAD_ATTR                2 (bos_token_id)\n              74 LOAD_FAST                0 (self)\n              76 LOAD_ATTR                0 (config)\n              78 LOAD_ATTR                1 (pad_token_id)\n              80 COMPARE_OP               2 (==)\n              82 POP_JUMP_IF_TRUE        70 (to 140)\n\n3501     >>   84 LOAD_FAST                0 (self)\n              86 LOAD_ATTR                0 (config)\n              88 LOAD_ATTR                3 (eos_token_id)\n              90 LOAD_CONST               1 (None)\n              92 IS_OP                    1\n              94 POP_JUMP_IF_FALSE       56 (to 112)\n              96 LOAD_FAST                0 (self)\n              98 LOAD_ATTR                0 (config)\n             100 LOAD_ATTR                3 (eos_token_id)\n             102 LOAD_FAST                0 (self)\n             104 LOAD_ATTR                0 (config)\n             106 LOAD_ATTR                1 (pad_token_id)\n             108 COMPARE_OP               2 (==)\n             110 POP_JUMP_IF_TRUE        70 (to 140)\n\n3502     >>  112 LOAD_FAST                0 (self)\n             114 LOAD_ATTR                0 (config)\n             116 LOAD_ATTR                4 (sep_token_id)\n             118 LOAD_CONST               1 (None)\n             120 IS_OP                    1\n             122 POP_JUMP_IF_FALSE       95 (to 190)\n             124 LOAD_FAST                0 (self)\n             126 LOAD_ATTR                0 (config)\n             128 LOAD_ATTR                4 (sep_token_id)\n             130 LOAD_FAST                0 (self)\n             132 LOAD_ATTR                0 (config)\n             134 LOAD_ATTR                1 (pad_token_id)\n             136 COMPARE_OP               2 (==)\n             138 POP_JUMP_IF_FALSE       95 (to 190)\n\n3504     >>  140 LOAD_FAST                3 (warn_string)\n\n3505         142 LOAD_CONST               5 ('\\nYou may ignore this warning if your `pad_token_id` (')\n             144 LOAD_FAST                0 (self)\n             146 LOAD_ATTR                0 (config)\n             148 LOAD_ATTR                1 (pad_token_id)\n             150 FORMAT_VALUE             0\n             152 LOAD_CONST               6 (') is identical to the `bos_token_id` (')\n\n3506         154 LOAD_FAST                0 (self)\n             156 LOAD_ATTR                0 (config)\n             158 LOAD_ATTR                2 (bos_token_id)\n\n3505         160 FORMAT_VALUE             0\n             162 LOAD_CONST               7 ('), `eos_token_id` (')\n\n3506         164 LOAD_FAST                0 (self)\n             166 LOAD_ATTR                0 (config)\n             168 LOAD_ATTR                3 (eos_token_id)\n\n3505         170 FORMAT_VALUE             0\n             172 LOAD_CONST               8 ('), or the `sep_token_id` (')\n\n3507         174 LOAD_FAST                0 (self)\n             176 LOAD_ATTR                0 (config)\n             178 LOAD_ATTR                4 (sep_token_id)\n\n3505         180 FORMAT_VALUE             0\n             182 LOAD_CONST               9 ('), and your input is not padded.')\n             184 BUILD_STRING             9\n\n3504         186 INPLACE_ADD\n             188 STORE_FAST               3 (warn_string)\n\n3510     >>  190 LOAD_GLOBAL              5 (logger)\n             192 LOAD_METHOD              6 (warning_once)\n             194 LOAD_FAST                3 (warn_string)\n             196 CALL_METHOD              1\n             198 POP_TOP\n             200 LOAD_CONST               1 (None)\n             202 RETURN_VALUE\n\n3490     >>  204 LOAD_CONST               1 (None)\n             206 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py line 970 \n 970           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           74 (to 148)\n               4 LOAD_FAST               12 (output_attentions)\n               6 LOAD_CONST               1 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST               12 (output_attentions)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (output_attentions)\n         >>   22 STORE_FAST              12 (output_attentions)\n              24 LOAD_FAST               13 (output_hidden_states)\n              26 LOAD_CONST               1 (None)\n              28 IS_OP                    1\n              30 POP_JUMP_IF_FALSE       18 (to 36)\n              32 LOAD_FAST               13 (output_hidden_states)\n              34 JUMP_FORWARD             3 (to 42)\n         >>   36 LOAD_FAST                1 (self)\n              38 LOAD_ATTR                0 (config)\n              40 LOAD_ATTR                2 (output_hidden_states)\n         >>   42 STORE_FAST              13 (output_hidden_states)\n              44 LOAD_FAST               14 (return_dict)\n              46 LOAD_CONST               1 (None)\n              48 IS_OP                    1\n              50 POP_JUMP_IF_FALSE       28 (to 56)\n              52 LOAD_FAST               14 (return_dict)\n              54 JUMP_FORWARD             3 (to 62)\n         >>   56 LOAD_FAST                1 (self)\n              58 LOAD_ATTR                0 (config)\n              60 LOAD_ATTR                3 (use_return_dict)\n         >>   62 STORE_FAST              14 (return_dict)\n              64 LOAD_FAST                1 (self)\n              66 LOAD_ATTR                0 (config)\n              68 LOAD_ATTR                4 (is_decoder)\n              70 POP_JUMP_IF_FALSE       47 (to 94)\n              72 LOAD_FAST               11 (use_cache)\n              74 LOAD_CONST               1 (None)\n              76 IS_OP                    1\n              78 POP_JUMP_IF_FALSE       42 (to 84)\n              80 LOAD_FAST               11 (use_cache)\n              82 JUMP_FORWARD             3 (to 90)\n         >>   84 LOAD_FAST                1 (self)\n              86 LOAD_ATTR                0 (config)\n              88 LOAD_ATTR                5 (use_cache)\n         >>   90 STORE_FAST              11 (use_cache)\n              92 JUMP_FORWARD             2 (to 98)\n         >>   94 LOAD_CONST               2 (False)\n              96 STORE_FAST              11 (use_cache)\n         >>   98 LOAD_FAST                2 (input_ids)\n             100 LOAD_CONST               1 (None)\n             102 IS_OP                    1\n             104 POP_JUMP_IF_FALSE       61 (to 122)\n             106 LOAD_FAST                7 (inputs_embeds)\n             108 LOAD_CONST               1 (None)\n             110 IS_OP                    1\n             112 POP_JUMP_IF_FALSE       61 (to 122)\n             114 LOAD_GLOBAL              6 (ValueError)\n             116 LOAD_CONST               3 ('You cannot specify both input_ids and inputs_embeds at the same time')\n             118 CALL_FUNCTION            1\n             120 RAISE_VARARGS            1\n         >>  122 LOAD_FAST                2 (input_ids)\n             124 LOAD_CONST               1 (None)\n             126 IS_OP                    1\n             128 POP_JUMP_IF_FALSE       76 (to 152)\n             130 LOAD_FAST                2 (input_ids)\n             132 LOAD_ATTR                7 (size)\n             134 CALL_FUNCTION            0\n             136 STORE_FAST              15 (input_shape)\n             138 LOAD_FAST                1 (self)\n             140 LOAD_ATTR                8 (warn_if_padding_and_no_attention_mask)\n             142 LOAD_FAST                2 (input_ids)\n             144 LOAD_FAST                3 (attention_mask)\n             146 CALL_FUNCTION            2\n         >>  148 POP_TOP\n             150 JUMP_FORWARD            17 (to 186)\n\n 971     >>  152 LOAD_FAST                7 (inputs_embeds)\n             154 LOAD_CONST               1 (None)\n             156 IS_OP                    1\n             158 POP_JUMP_IF_FALSE       89 (to 178)\n\n 972         160 LOAD_FAST                7 (inputs_embeds)\n             162 LOAD_ATTR                7 (size)\n             164 CALL_FUNCTION            0\n             166 LOAD_CONST               1 (None)\n             168 LOAD_CONST               4 (-1)\n             170 BUILD_SLICE              2\n             172 BINARY_SUBSCR\n             174 STORE_FAST              15 (input_shape)\n             176 JUMP_FORWARD             4 (to 186)\n\n 974     >>  178 LOAD_GLOBAL              6 (ValueError)\n             180 LOAD_CONST               5 ('You have to specify either input_ids or inputs_embeds')\n             182 CALL_FUNCTION            1\n             184 RAISE_VARARGS            1\n\n 976     >>  186 LOAD_FAST               15 (input_shape)\n             188 UNPACK_SEQUENCE          2\n             190 STORE_FAST              16 (batch_size)\n             192 STORE_FAST              17 (seq_length)\n\n 977         194 LOAD_FAST                2 (input_ids)\n             196 LOAD_CONST               1 (None)\n             198 IS_OP                    1\n             200 POP_JUMP_IF_FALSE      104 (to 208)\n             202 LOAD_FAST                2 (input_ids)\n             204 LOAD_ATTR                9 (device)\n             206 JUMP_FORWARD             2 (to 212)\n         >>  208 LOAD_FAST                7 (inputs_embeds)\n             210 LOAD_ATTR                9 (device)\n         >>  212 STORE_FAST              18 (device)\n\n 980         214 LOAD_FAST               10 (past_key_values)\n             216 LOAD_CONST               1 (None)\n             218 IS_OP                    1\n             220 POP_JUMP_IF_FALSE      120 (to 240)\n             222 LOAD_FAST               10 (past_key_values)\n             224 LOAD_CONST               6 (0)\n             226 BINARY_SUBSCR\n             228 LOAD_CONST               6 (0)\n             230 BINARY_SUBSCR\n             232 LOAD_ATTR               10 (shape)\n             234 LOAD_CONST               7 (2)\n             236 BINARY_SUBSCR\n             238 JUMP_FORWARD             1 (to 242)\n         >>  240 LOAD_CONST               6 (0)\n         >>  242 STORE_FAST              19 (past_key_values_length)\n\n 982         244 LOAD_FAST                3 (attention_mask)\n             246 LOAD_CONST               1 (None)\n             248 IS_OP                    0\n             250 POP_JUMP_IF_FALSE      137 (to 274)\n\n 983         252 LOAD_GLOBAL             11 (torch)\n             254 LOAD_ATTR               12 (ones)\n             256 LOAD_FAST               16 (batch_size)\n             258 LOAD_FAST               17 (seq_length)\n             260 LOAD_FAST               19 (past_key_values_length)\n             262 BINARY_ADD\n             264 BUILD_TUPLE              2\n             266 LOAD_FAST               18 (device)\n             268 LOAD_CONST               8 (('device',))\n             270 CALL_FUNCTION_KW         2\n             272 STORE_FAST               3 (attention_mask)\n\n 985     >>  274 LOAD_FAST                4 (token_type_ids)\n             276 LOAD_CONST               1 (None)\n             278 IS_OP                    0\n             280 POP_JUMP_IF_FALSE      177 (to 354)\n\n 986         282 LOAD_GLOBAL             13 (hasattr)\n             284 LOAD_FAST                1 (self)\n             286 LOAD_ATTR               14 (embeddings)\n             288 LOAD_CONST               9 ('token_type_ids')\n             290 CALL_FUNCTION            2\n             292 POP_JUMP_IF_FALSE      168 (to 336)\n\n 987         294 LOAD_FAST                1 (self)\n             296 LOAD_ATTR               14 (embeddings)\n             298 LOAD_ATTR               15 (token_type_ids)\n             300 LOAD_CONST               1 (None)\n             302 LOAD_CONST               1 (None)\n             304 BUILD_SLICE              2\n             306 LOAD_CONST               1 (None)\n             308 LOAD_FAST               17 (seq_length)\n             310 BUILD_SLICE              2\n             312 BUILD_TUPLE              2\n             314 BINARY_SUBSCR\n             316 STORE_FAST              20 (buffered_token_type_ids)\n\n 988         318 LOAD_FAST               20 (buffered_token_type_ids)\n             320 LOAD_ATTR               16 (expand)\n             322 LOAD_FAST               16 (batch_size)\n             324 LOAD_FAST               17 (seq_length)\n             326 CALL_FUNCTION            2\n             328 STORE_FAST              21 (buffered_token_type_ids_expanded)\n\n 989         330 LOAD_FAST               21 (buffered_token_type_ids_expanded)\n             332 STORE_FAST               4 (token_type_ids)\n             334 JUMP_FORWARD             9 (to 354)\n\n 991     >>  336 LOAD_GLOBAL             11 (torch)\n             338 LOAD_ATTR               17 (zeros)\n             340 LOAD_FAST               15 (input_shape)\n             342 LOAD_GLOBAL             11 (torch)\n             344 LOAD_ATTR               18 (long)\n             346 LOAD_FAST               18 (device)\n             348 LOAD_CONST              10 (('dtype', 'device'))\n             350 CALL_FUNCTION_KW         3\n             352 STORE_FAST               4 (token_type_ids)\n\n 995     >>  354 LOAD_FAST                1 (self)\n             356 LOAD_ATTR               19 (get_extended_attention_mask)\n             358 LOAD_FAST                3 (attention_mask)\n             360 LOAD_FAST               15 (input_shape)\n             362 CALL_FUNCTION            2\n             364 STORE_FAST              22 (extended_attention_mask)\n\n 999         366 LOAD_FAST                1 (self)\n             368 LOAD_ATTR                0 (config)\n             370 LOAD_ATTR                4 (is_decoder)\n             372 POP_JUMP_IF_FALSE      219 (to 438)\n             374 LOAD_FAST                8 (encoder_hidden_states)\n             376 LOAD_CONST               1 (None)\n             378 IS_OP                    1\n             380 POP_JUMP_IF_FALSE      219 (to 438)\n\n1000         382 LOAD_FAST                8 (encoder_hidden_states)\n             384 LOAD_ATTR                7 (size)\n             386 CALL_FUNCTION            0\n             388 UNPACK_SEQUENCE          3\n             390 STORE_FAST              23 (encoder_batch_size)\n             392 STORE_FAST              24 (encoder_sequence_length)\n             394 STORE_FAST              25 (_)\n\n1001         396 LOAD_FAST               23 (encoder_batch_size)\n             398 LOAD_FAST               24 (encoder_sequence_length)\n             400 BUILD_TUPLE              2\n             402 STORE_FAST              26 (encoder_hidden_shape)\n\n1002         404 LOAD_FAST                9 (encoder_attention_mask)\n             406 LOAD_CONST               1 (None)\n             408 IS_OP                    0\n             410 POP_JUMP_IF_FALSE      213 (to 426)\n\n1003         412 LOAD_GLOBAL             11 (torch)\n             414 LOAD_ATTR               12 (ones)\n             416 LOAD_FAST               26 (encoder_hidden_shape)\n             418 LOAD_FAST               18 (device)\n             420 LOAD_CONST               8 (('device',))\n             422 CALL_FUNCTION_KW         2\n             424 STORE_FAST               9 (encoder_attention_mask)\n\n1004     >>  426 LOAD_FAST                1 (self)\n             428 LOAD_ATTR               20 (invert_attention_mask)\n             430 LOAD_FAST                9 (encoder_attention_mask)\n             432 CALL_FUNCTION            1\n             434 STORE_FAST              27 (encoder_extended_attention_mask)\n             436 JUMP_FORWARD             2 (to 442)\n\n1006     >>  438 LOAD_CONST               1 (None)\n             440 STORE_FAST              27 (encoder_extended_attention_mask)\n\n1013     >>  442 LOAD_FAST                1 (self)\n             444 LOAD_ATTR               21 (get_head_mask)\n             446 LOAD_FAST                6 (head_mask)\n             448 LOAD_FAST                1 (self)\n             450 LOAD_ATTR                0 (config)\n             452 LOAD_ATTR               22 (num_hidden_layers)\n             454 CALL_FUNCTION            2\n             456 STORE_FAST               6 (head_mask)\n\n1015         458 LOAD_FAST                1 (self)\n             460 LOAD_ATTR               14 (embeddings)\n\n1016         462 LOAD_FAST                2 (input_ids)\n\n1017         464 LOAD_FAST                5 (position_ids)\n\n1018         466 LOAD_FAST                4 (token_type_ids)\n\n1019         468 LOAD_FAST                7 (inputs_embeds)\n\n1020         470 LOAD_FAST               19 (past_key_values_length)\n\n1015         472 LOAD_CONST              11 (('input_ids', 'position_ids', 'token_type_ids', 'inputs_embeds', 'past_key_values_length'))\n             474 CALL_FUNCTION_KW         5\n             476 STORE_FAST              28 (embedding_output)\n\n1022         478 LOAD_FAST                1 (self)\n             480 LOAD_ATTR               23 (encoder)\n\n1023         482 LOAD_FAST               28 (embedding_output)\n\n1024         484 LOAD_FAST               22 (extended_attention_mask)\n\n1025         486 LOAD_FAST                6 (head_mask)\n\n1026         488 LOAD_FAST                8 (encoder_hidden_states)\n\n1027         490 LOAD_FAST               27 (encoder_extended_attention_mask)\n\n1028         492 LOAD_FAST               10 (past_key_values)\n\n1029         494 LOAD_FAST               11 (use_cache)\n\n1030         496 LOAD_FAST               12 (output_attentions)\n\n1031         498 LOAD_FAST               13 (output_hidden_states)\n\n1032         500 LOAD_FAST               14 (return_dict)\n\n1022         502 LOAD_CONST              12 (('attention_mask', 'head_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'past_key_values', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             504 CALL_FUNCTION_KW        10\n             506 STORE_FAST              29 (encoder_outputs)\n\n1034         508 LOAD_FAST               29 (encoder_outputs)\n             510 LOAD_CONST               6 (0)\n             512 BINARY_SUBSCR\n             514 STORE_FAST              30 (sequence_output)\n\n1035         516 LOAD_FAST                1 (self)\n             518 LOAD_ATTR               24 (pooler)\n             520 LOAD_CONST               1 (None)\n             522 IS_OP                    1\n             524 EXTENDED_ARG             1\n             526 POP_JUMP_IF_FALSE      269 (to 538)\n             528 LOAD_FAST                1 (self)\n             530 LOAD_ATTR               24 (pooler)\n             532 LOAD_FAST               30 (sequence_output)\n             534 CALL_FUNCTION            1\n             536 JUMP_FORWARD             1 (to 540)\n         >>  538 LOAD_CONST               1 (None)\n         >>  540 STORE_FAST              31 (pooled_output)\n\n1037         542 LOAD_FAST               14 (return_dict)\n             544 EXTENDED_ARG             1\n             546 POP_JUMP_IF_TRUE       284 (to 568)\n\n1038         548 LOAD_FAST               30 (sequence_output)\n             550 LOAD_FAST               31 (pooled_output)\n             552 BUILD_TUPLE              2\n             554 LOAD_FAST               29 (encoder_outputs)\n             556 LOAD_CONST              13 (1)\n             558 LOAD_CONST               1 (None)\n             560 BUILD_SLICE              2\n             562 BINARY_SUBSCR\n             564 BINARY_ADD\n             566 RETURN_VALUE\n\n1040     >>  568 LOAD_GLOBAL             25 (BaseModelOutputWithPoolingAndCrossAttentions)\n\n1041         570 LOAD_FAST               30 (sequence_output)\n\n1042         572 LOAD_FAST               31 (pooled_output)\n\n1043         574 LOAD_FAST               29 (encoder_outputs)\n             576 LOAD_ATTR               26 (past_key_values)\n\n1044         578 LOAD_FAST               29 (encoder_outputs)\n             580 LOAD_ATTR               27 (hidden_states)\n\n1045         582 LOAD_FAST               29 (encoder_outputs)\n             584 LOAD_ATTR               28 (attentions)\n\n1046         586 LOAD_FAST               29 (encoder_outputs)\n             588 LOAD_ATTR               29 (cross_attentions)\n\n1040         590 LOAD_CONST              14 (('last_hidden_state', 'pooler_output', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n             592 CALL_FUNCTION_KW         6\n             594 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py line 1358 \n1358           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           27 (to 54)\n               4 LOAD_FAST                3 (return_dict)\n               6 LOAD_CONST               1 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST                3 (return_dict)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (use_return_dict)\n         >>   22 STORE_FAST               3 (return_dict)\n              24 LOAD_FAST                1 (self)\n              26 LOAD_ATTR                2 (bert)\n              28 LOAD_FAST                4 (input_ids)\n              30 LOAD_FAST                5 (attention_mask)\n              32 LOAD_FAST                6 (token_type_ids)\n              34 LOAD_FAST                7 (position_ids)\n              36 LOAD_FAST                8 (head_mask)\n              38 LOAD_FAST                9 (inputs_embeds)\n              40 LOAD_FAST               10 (encoder_hidden_states)\n              42 LOAD_FAST               11 (encoder_attention_mask)\n              44 LOAD_FAST               12 (output_attentions)\n              46 LOAD_FAST               13 (output_hidden_states)\n              48 LOAD_FAST                3 (return_dict)\n              50 LOAD_CONST               2 (('attention_mask', 'token_type_ids', 'position_ids', 'head_mask', 'inputs_embeds', 'encoder_hidden_states', 'encoder_attention_mask', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              52 CALL_FUNCTION_KW        11\n         >>   54 STORE_FAST              14 (outputs)\n\n1372          56 LOAD_FAST               14 (outputs)\n              58 LOAD_CONST               3 (0)\n              60 BINARY_SUBSCR\n              62 STORE_FAST              15 (sequence_output)\n\n1373          64 LOAD_FAST                1 (self)\n              66 LOAD_ATTR                3 (cls)\n              68 LOAD_FAST               15 (sequence_output)\n              70 CALL_FUNCTION            1\n              72 STORE_FAST              16 (prediction_scores)\n\n1375          74 LOAD_CONST               1 (None)\n              76 STORE_FAST              17 (masked_lm_loss)\n\n1376          78 LOAD_FAST                2 (labels)\n              80 LOAD_CONST               1 (None)\n              82 IS_OP                    1\n              84 POP_JUMP_IF_FALSE       60 (to 120)\n\n1377          86 LOAD_GLOBAL              4 (CrossEntropyLoss)\n              88 CALL_FUNCTION            0\n              90 STORE_FAST              18 (loss_fct)\n\n1378          92 LOAD_FAST               18 (loss_fct)\n              94 LOAD_FAST               16 (prediction_scores)\n              96 LOAD_ATTR                5 (view)\n              98 LOAD_CONST               4 (-1)\n             100 LOAD_FAST                1 (self)\n             102 LOAD_ATTR                0 (config)\n             104 LOAD_ATTR                6 (vocab_size)\n             106 CALL_FUNCTION            2\n             108 LOAD_FAST                2 (labels)\n             110 LOAD_ATTR                5 (view)\n             112 LOAD_CONST               4 (-1)\n             114 CALL_FUNCTION            1\n             116 CALL_FUNCTION            2\n             118 STORE_FAST              17 (masked_lm_loss)\n\n1380     >>  120 LOAD_FAST                3 (return_dict)\n             122 POP_JUMP_IF_TRUE        82 (to 164)\n\n1381         124 LOAD_FAST               16 (prediction_scores)\n             126 BUILD_TUPLE              1\n             128 LOAD_FAST               14 (outputs)\n             130 LOAD_CONST               5 (2)\n             132 LOAD_CONST               1 (None)\n             134 BUILD_SLICE              2\n             136 BINARY_SUBSCR\n             138 BINARY_ADD\n             140 STORE_FAST              19 (output)\n\n1382         142 LOAD_FAST               17 (masked_lm_loss)\n             144 LOAD_CONST               1 (None)\n             146 IS_OP                    1\n             148 POP_JUMP_IF_FALSE       80 (to 160)\n             150 LOAD_FAST               17 (masked_lm_loss)\n             152 BUILD_TUPLE              1\n             154 LOAD_FAST               19 (output)\n             156 BINARY_ADD\n             158 RETURN_VALUE\n         >>  160 LOAD_FAST               19 (output)\n             162 RETURN_VALUE\n\n1384     >>  164 LOAD_GLOBAL              7 (MaskedLMOutput)\n\n1385         166 LOAD_FAST               17 (masked_lm_loss)\n\n1386         168 LOAD_FAST               16 (prediction_scores)\n\n1387         170 LOAD_FAST               14 (outputs)\n             172 LOAD_ATTR                8 (hidden_states)\n\n1388         174 LOAD_FAST               14 (outputs)\n             176 LOAD_ATTR                9 (attentions)\n\n1384         178 LOAD_CONST               6 (('loss', 'logits', 'hidden_states', 'attentions'))\n             180 CALL_FUNCTION_KW         4\n             182 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 557 \n557           0 LOAD_FAST                0 (___stack0)\n              2 CALL_FUNCTION            0\n              4 SETUP_WITH              10 (to 26)\n              6 POP_TOP\n              8 LOAD_FAST                1 (___stack1)\n             10 JUMP_ABSOLUTE           44 (to 88)\n             12 POP_BLOCK\n             14 LOAD_CONST               0 (None)\n             16 DUP_TOP\n             18 DUP_TOP\n             20 CALL_FUNCTION            3\n             22 POP_TOP\n             24 JUMP_FORWARD             8 (to 42)\n        >>   26 WITH_EXCEPT_START\n             28 POP_JUMP_IF_TRUE        16 (to 32)\n             30 RERAISE                  0\n        >>   32 POP_TOP\n             34 POP_TOP\n             36 POP_TOP\n             38 POP_EXCEPT\n             40 POP_TOP\n        >>   42 NOP\n             44 LOAD_CONST               0 (None)\n             46 RAISE_VARARGS            1\n             48 LOAD_GLOBAL              0 (clone_inputs)\n             50 LOAD_FAST                6 (inputs)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (cloned_inputs)\n             56 LOAD_FAST                2 (self)\n             58 LOAD_ATTR                1 (optimizer_zero_grad)\n             60 LOAD_FAST                3 (mod)\n             62 CALL_FUNCTION            1\n             64 POP_TOP\n             66 LOAD_FAST                2 (self)\n             68 LOAD_ATTR                2 (autocast)\n             70 CALL_FUNCTION            0\n             72 SETUP_WITH              20 (to 114)\n             74 POP_TOP\n             76 LOAD_FAST                3 (mod)\n             78 LOAD_CONST               1 (())\n             80 BUILD_MAP                0\n             82 LOAD_FAST                5 (cloned_inputs)\n             84 DICT_MERGE               1\n             86 CALL_FUNCTION_EX         1\n        >>   88 STORE_FAST               7 (pred)\n\n558          90 LOAD_FAST                2 (self)\n             92 LOAD_ATTR                3 (compute_loss)\n             94 LOAD_FAST                7 (pred)\n             96 CALL_FUNCTION            1\n             98 STORE_FAST               8 (loss)\n            100 POP_BLOCK\n\n556         102 LOAD_CONST               0 (None)\n            104 DUP_TOP\n            106 DUP_TOP\n            108 CALL_FUNCTION            3\n            110 POP_TOP\n            112 JUMP_FORWARD             8 (to 130)\n        >>  114 WITH_EXCEPT_START\n            116 POP_JUMP_IF_TRUE        60 (to 120)\n            118 RERAISE                  1\n        >>  120 POP_TOP\n            122 POP_TOP\n            124 POP_TOP\n            126 POP_EXCEPT\n            128 POP_TOP\n\n559     >>  130 LOAD_FAST                2 (self)\n            132 LOAD_ATTR                4 (grad_scaler)\n            134 LOAD_ATTR                5 (scale)\n            136 LOAD_FAST                8 (loss)\n            138 CALL_FUNCTION            1\n            140 LOAD_ATTR                6 (backward)\n            142 CALL_FUNCTION            0\n            144 POP_TOP\n\n560         146 LOAD_FAST                2 (self)\n            148 LOAD_ATTR                7 (optimizer_step)\n            150 CALL_FUNCTION            0\n            152 POP_TOP\n\n561         154 LOAD_FAST                4 (collect_outputs)\n            156 POP_JUMP_IF_FALSE       86 (to 172)\n\n562         158 LOAD_GLOBAL              8 (collect_results)\n            160 LOAD_FAST                3 (mod)\n            162 LOAD_FAST                7 (pred)\n            164 LOAD_FAST                8 (loss)\n            166 LOAD_FAST                5 (cloned_inputs)\n            168 CALL_FUNCTION            4\n            170 RETURN_VALUE\n\n563     >>  172 LOAD_CONST               0 (None)\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py line 1808 \n1842           0 LOAD_FAST               11 (return_dict)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               11 (return_dict)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (use_return_dict)\n         >>   18 STORE_FAST              11 (return_dict)\n\n1844          20 LOAD_FAST                0 (self)\n              22 LOAD_ATTR                2 (bert)\n\n1845          24 LOAD_FAST                1 (input_ids)\n\n1846          26 LOAD_FAST                2 (attention_mask)\n\n1847          28 LOAD_FAST                3 (token_type_ids)\n\n1848          30 LOAD_FAST                4 (position_ids)\n\n1849          32 LOAD_FAST                5 (head_mask)\n\n1850          34 LOAD_FAST                6 (inputs_embeds)\n\n1851          36 LOAD_FAST                9 (output_attentions)\n\n1852          38 LOAD_FAST               10 (output_hidden_states)\n\n1853          40 LOAD_FAST               11 (return_dict)\n\n1844          42 LOAD_CONST               2 (('attention_mask', 'token_type_ids', 'position_ids', 'head_mask', 'inputs_embeds', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              44 CALL_FUNCTION_KW         9\n              46 STORE_FAST              12 (outputs)\n\n1856          48 LOAD_FAST               12 (outputs)\n              50 LOAD_CONST               3 (0)\n              52 BINARY_SUBSCR\n              54 STORE_FAST              13 (sequence_output)\n\n1858          56 LOAD_FAST                0 (self)\n              58 LOAD_METHOD              3 (qa_outputs)\n              60 LOAD_FAST               13 (sequence_output)\n              62 CALL_METHOD              1\n              64 STORE_FAST              14 (logits)\n\n1859          66 LOAD_FAST               14 (logits)\n              68 LOAD_ATTR                4 (split)\n              70 LOAD_CONST               4 (1)\n              72 LOAD_CONST               5 (-1)\n              74 LOAD_CONST               6 (('dim',))\n              76 CALL_FUNCTION_KW         2\n              78 UNPACK_SEQUENCE          2\n              80 STORE_FAST              15 (start_logits)\n              82 STORE_FAST              16 (end_logits)\n\n1860          84 LOAD_FAST               15 (start_logits)\n              86 LOAD_METHOD              5 (squeeze)\n              88 LOAD_CONST               5 (-1)\n              90 CALL_METHOD              1\n              92 LOAD_METHOD              6 (contiguous)\n              94 CALL_METHOD              0\n              96 STORE_FAST              15 (start_logits)\n\n1861          98 LOAD_FAST               16 (end_logits)\n             100 LOAD_METHOD              5 (squeeze)\n             102 LOAD_CONST               5 (-1)\n             104 CALL_METHOD              1\n             106 LOAD_METHOD              6 (contiguous)\n             108 CALL_METHOD              0\n             110 STORE_FAST              16 (end_logits)\n\n1863         112 LOAD_CONST               1 (None)\n             114 STORE_FAST              17 (total_loss)\n\n1864         116 LOAD_FAST                7 (start_positions)\n             118 LOAD_CONST               1 (None)\n             120 IS_OP                    1\n             122 POP_JUMP_IF_FALSE      130 (to 260)\n             124 LOAD_FAST                8 (end_positions)\n             126 LOAD_CONST               1 (None)\n             128 IS_OP                    1\n             130 POP_JUMP_IF_FALSE      130 (to 260)\n\n1866         132 LOAD_GLOBAL              7 (len)\n             134 LOAD_FAST                7 (start_positions)\n             136 LOAD_METHOD              8 (size)\n             138 CALL_METHOD              0\n             140 CALL_FUNCTION            1\n             142 LOAD_CONST               4 (1)\n             144 COMPARE_OP               4 (>)\n             146 POP_JUMP_IF_FALSE       79 (to 158)\n\n1867         148 LOAD_FAST                7 (start_positions)\n             150 LOAD_METHOD              5 (squeeze)\n             152 LOAD_CONST               5 (-1)\n             154 CALL_METHOD              1\n             156 STORE_FAST               7 (start_positions)\n\n1868     >>  158 LOAD_GLOBAL              7 (len)\n             160 LOAD_FAST                8 (end_positions)\n             162 LOAD_METHOD              8 (size)\n             164 CALL_METHOD              0\n             166 CALL_FUNCTION            1\n             168 LOAD_CONST               4 (1)\n             170 COMPARE_OP               4 (>)\n             172 POP_JUMP_IF_FALSE       92 (to 184)\n\n1869         174 LOAD_FAST                8 (end_positions)\n             176 LOAD_METHOD              5 (squeeze)\n             178 LOAD_CONST               5 (-1)\n             180 CALL_METHOD              1\n             182 STORE_FAST               8 (end_positions)\n\n1871     >>  184 LOAD_FAST               15 (start_logits)\n             186 LOAD_METHOD              8 (size)\n             188 LOAD_CONST               4 (1)\n             190 CALL_METHOD              1\n             192 STORE_FAST              18 (ignored_index)\n\n1872         194 LOAD_FAST                7 (start_positions)\n             196 LOAD_METHOD              9 (clamp)\n             198 LOAD_CONST               3 (0)\n             200 LOAD_FAST               18 (ignored_index)\n             202 CALL_METHOD              2\n             204 STORE_FAST               7 (start_positions)\n\n1873         206 LOAD_FAST                8 (end_positions)\n             208 LOAD_METHOD              9 (clamp)\n             210 LOAD_CONST               3 (0)\n             212 LOAD_FAST               18 (ignored_index)\n             214 CALL_METHOD              2\n             216 STORE_FAST               8 (end_positions)\n\n1875         218 LOAD_GLOBAL             10 (CrossEntropyLoss)\n             220 LOAD_FAST               18 (ignored_index)\n             222 LOAD_CONST               7 (('ignore_index',))\n             224 CALL_FUNCTION_KW         1\n             226 STORE_FAST              19 (loss_fct)\n\n1876         228 LOAD_FAST               19 (loss_fct)\n             230 LOAD_FAST               15 (start_logits)\n             232 LOAD_FAST                7 (start_positions)\n             234 CALL_FUNCTION            2\n             236 STORE_FAST              20 (start_loss)\n\n1877         238 LOAD_FAST               19 (loss_fct)\n             240 LOAD_FAST               16 (end_logits)\n             242 LOAD_FAST                8 (end_positions)\n             244 CALL_FUNCTION            2\n             246 STORE_FAST              21 (end_loss)\n\n1878         248 LOAD_FAST               20 (start_loss)\n             250 LOAD_FAST               21 (end_loss)\n             252 BINARY_ADD\n             254 LOAD_CONST               8 (2)\n             256 BINARY_TRUE_DIVIDE\n             258 STORE_FAST              17 (total_loss)\n\n1880     >>  260 LOAD_FAST               11 (return_dict)\n             262 POP_JUMP_IF_TRUE       153 (to 306)\n\n1881         264 LOAD_FAST               15 (start_logits)\n             266 LOAD_FAST               16 (end_logits)\n             268 BUILD_TUPLE              2\n             270 LOAD_FAST               12 (outputs)\n             272 LOAD_CONST               8 (2)\n             274 LOAD_CONST               1 (None)\n             276 BUILD_SLICE              2\n             278 BINARY_SUBSCR\n             280 BINARY_ADD\n             282 STORE_FAST              22 (output)\n\n1882         284 LOAD_FAST               17 (total_loss)\n             286 LOAD_CONST               1 (None)\n             288 IS_OP                    1\n             290 POP_JUMP_IF_FALSE      151 (to 302)\n             292 LOAD_FAST               17 (total_loss)\n             294 BUILD_TUPLE              1\n             296 LOAD_FAST               22 (output)\n             298 BINARY_ADD\n             300 RETURN_VALUE\n         >>  302 LOAD_FAST               22 (output)\n             304 RETURN_VALUE\n\n1884     >>  306 LOAD_GLOBAL             11 (QuestionAnsweringModelOutput)\n\n1885         308 LOAD_FAST               17 (total_loss)\n\n1886         310 LOAD_FAST               15 (start_logits)\n\n1887         312 LOAD_FAST               16 (end_logits)\n\n1888         314 LOAD_FAST               12 (outputs)\n             316 LOAD_ATTR               12 (hidden_states)\n\n1889         318 LOAD_FAST               12 (outputs)\n             320 LOAD_ATTR               13 (attentions)\n\n1884         322 LOAD_CONST               9 (('loss', 'start_logits', 'end_logits', 'hidden_states', 'attentions'))\n             324 CALL_FUNCTION_KW         5\n             326 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py line 913 \n 955           0 LOAD_FAST               11 (output_attentions)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               11 (output_attentions)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (output_attentions)\n         >>   18 STORE_FAST              11 (output_attentions)\n\n 957          20 LOAD_FAST               12 (output_hidden_states)\n              22 LOAD_CONST               1 (None)\n              24 IS_OP                    1\n              26 POP_JUMP_IF_FALSE       16 (to 32)\n              28 LOAD_FAST               12 (output_hidden_states)\n              30 JUMP_FORWARD             3 (to 38)\n         >>   32 LOAD_FAST                0 (self)\n              34 LOAD_ATTR                0 (config)\n              36 LOAD_ATTR                2 (output_hidden_states)\n\n 956     >>   38 STORE_FAST              12 (output_hidden_states)\n\n 959          40 LOAD_FAST               13 (return_dict)\n              42 LOAD_CONST               1 (None)\n              44 IS_OP                    1\n              46 POP_JUMP_IF_FALSE       26 (to 52)\n              48 LOAD_FAST               13 (return_dict)\n              50 JUMP_FORWARD             3 (to 58)\n         >>   52 LOAD_FAST                0 (self)\n              54 LOAD_ATTR                0 (config)\n              56 LOAD_ATTR                3 (use_return_dict)\n         >>   58 STORE_FAST              13 (return_dict)\n\n 961          60 LOAD_FAST                0 (self)\n              62 LOAD_ATTR                0 (config)\n              64 LOAD_ATTR                4 (is_decoder)\n              66 POP_JUMP_IF_FALSE       45 (to 90)\n\n 962          68 LOAD_FAST               10 (use_cache)\n              70 LOAD_CONST               1 (None)\n              72 IS_OP                    1\n              74 POP_JUMP_IF_FALSE       40 (to 80)\n              76 LOAD_FAST               10 (use_cache)\n              78 JUMP_FORWARD             3 (to 86)\n         >>   80 LOAD_FAST                0 (self)\n              82 LOAD_ATTR                0 (config)\n              84 LOAD_ATTR                5 (use_cache)\n         >>   86 STORE_FAST              10 (use_cache)\n              88 JUMP_FORWARD             2 (to 94)\n\n 964     >>   90 LOAD_CONST               2 (False)\n              92 STORE_FAST              10 (use_cache)\n\n 966     >>   94 LOAD_FAST                1 (input_ids)\n              96 LOAD_CONST               1 (None)\n              98 IS_OP                    1\n             100 POP_JUMP_IF_FALSE       59 (to 118)\n             102 LOAD_FAST                6 (inputs_embeds)\n             104 LOAD_CONST               1 (None)\n             106 IS_OP                    1\n             108 POP_JUMP_IF_FALSE       59 (to 118)\n\n 967         110 LOAD_GLOBAL              6 (ValueError)\n             112 LOAD_CONST               3 ('You cannot specify both input_ids and inputs_embeds at the same time')\n             114 CALL_FUNCTION            1\n             116 RAISE_VARARGS            1\n\n 968     >>  118 LOAD_FAST                1 (input_ids)\n             120 LOAD_CONST               1 (None)\n             122 IS_OP                    1\n             124 POP_JUMP_IF_FALSE       74 (to 148)\n\n 969         126 LOAD_FAST                1 (input_ids)\n             128 LOAD_METHOD              7 (size)\n             130 CALL_METHOD              0\n             132 STORE_FAST              14 (input_shape)\n\n 970         134 LOAD_FAST                0 (self)\n             136 LOAD_METHOD              8 (warn_if_padding_and_no_attention_mask)\n             138 LOAD_FAST                1 (input_ids)\n             140 LOAD_FAST                2 (attention_mask)\n             142 CALL_METHOD              2\n             144 POP_TOP\n             146 JUMP_FORWARD            17 (to 182)\n\n 971     >>  148 LOAD_FAST                6 (inputs_embeds)\n             150 LOAD_CONST               1 (None)\n             152 IS_OP                    1\n             154 POP_JUMP_IF_FALSE       87 (to 174)\n\n 972         156 LOAD_FAST                6 (inputs_embeds)\n             158 LOAD_METHOD              7 (size)\n             160 CALL_METHOD              0\n             162 LOAD_CONST               1 (None)\n             164 LOAD_CONST               4 (-1)\n             166 BUILD_SLICE              2\n             168 BINARY_SUBSCR\n             170 STORE_FAST              14 (input_shape)\n             172 JUMP_FORWARD             4 (to 182)\n\n 974     >>  174 LOAD_GLOBAL              6 (ValueError)\n             176 LOAD_CONST               5 ('You have to specify either input_ids or inputs_embeds')\n             178 CALL_FUNCTION            1\n             180 RAISE_VARARGS            1\n\n 976     >>  182 LOAD_FAST               14 (input_shape)\n             184 UNPACK_SEQUENCE          2\n             186 STORE_FAST              15 (batch_size)\n             188 STORE_FAST              16 (seq_length)\n\n 977         190 LOAD_FAST                1 (input_ids)\n             192 LOAD_CONST               1 (None)\n             194 IS_OP                    1\n             196 POP_JUMP_IF_FALSE      102 (to 204)\n             198 LOAD_FAST                1 (input_ids)\n             200 LOAD_ATTR                9 (device)\n             202 JUMP_FORWARD             2 (to 208)\n         >>  204 LOAD_FAST                6 (inputs_embeds)\n             206 LOAD_ATTR                9 (device)\n         >>  208 STORE_FAST              17 (device)\n\n 980         210 LOAD_FAST                9 (past_key_values)\n             212 LOAD_CONST               1 (None)\n             214 IS_OP                    1\n             216 POP_JUMP_IF_FALSE      118 (to 236)\n             218 LOAD_FAST                9 (past_key_values)\n             220 LOAD_CONST               6 (0)\n             222 BINARY_SUBSCR\n             224 LOAD_CONST               6 (0)\n             226 BINARY_SUBSCR\n             228 LOAD_ATTR               10 (shape)\n             230 LOAD_CONST               7 (2)\n             232 BINARY_SUBSCR\n             234 JUMP_FORWARD             1 (to 238)\n         >>  236 LOAD_CONST               6 (0)\n         >>  238 STORE_FAST              18 (past_key_values_length)\n\n 982         240 LOAD_FAST                2 (attention_mask)\n             242 LOAD_CONST               1 (None)\n             244 IS_OP                    0\n             246 POP_JUMP_IF_FALSE      135 (to 270)\n\n 983         248 LOAD_GLOBAL             11 (torch)\n             250 LOAD_ATTR               12 (ones)\n             252 LOAD_FAST               15 (batch_size)\n             254 LOAD_FAST               16 (seq_length)\n             256 LOAD_FAST               18 (past_key_values_length)\n             258 BINARY_ADD\n             260 BUILD_TUPLE              2\n             262 LOAD_FAST               17 (device)\n             264 LOAD_CONST               8 (('device',))\n             266 CALL_FUNCTION_KW         2\n             268 STORE_FAST               2 (attention_mask)\n\n 985     >>  270 LOAD_FAST                3 (token_type_ids)\n             272 LOAD_CONST               1 (None)\n             274 IS_OP                    0\n             276 POP_JUMP_IF_FALSE      175 (to 350)\n\n 986         278 LOAD_GLOBAL             13 (hasattr)\n             280 LOAD_FAST                0 (self)\n             282 LOAD_ATTR               14 (embeddings)\n             284 LOAD_CONST               9 ('token_type_ids')\n             286 CALL_FUNCTION            2\n             288 POP_JUMP_IF_FALSE      166 (to 332)\n\n 987         290 LOAD_FAST                0 (self)\n             292 LOAD_ATTR               14 (embeddings)\n             294 LOAD_ATTR               15 (token_type_ids)\n             296 LOAD_CONST               1 (None)\n             298 LOAD_CONST               1 (None)\n             300 BUILD_SLICE              2\n             302 LOAD_CONST               1 (None)\n             304 LOAD_FAST               16 (seq_length)\n             306 BUILD_SLICE              2\n             308 BUILD_TUPLE              2\n             310 BINARY_SUBSCR\n             312 STORE_FAST              19 (buffered_token_type_ids)\n\n 988         314 LOAD_FAST               19 (buffered_token_type_ids)\n             316 LOAD_METHOD             16 (expand)\n             318 LOAD_FAST               15 (batch_size)\n             320 LOAD_FAST               16 (seq_length)\n             322 CALL_METHOD              2\n             324 STORE_FAST              20 (buffered_token_type_ids_expanded)\n\n 989         326 LOAD_FAST               20 (buffered_token_type_ids_expanded)\n             328 STORE_FAST               3 (token_type_ids)\n             330 JUMP_FORWARD             9 (to 350)\n\n 991     >>  332 LOAD_GLOBAL             11 (torch)\n             334 LOAD_ATTR               17 (zeros)\n             336 LOAD_FAST               14 (input_shape)\n             338 LOAD_GLOBAL             11 (torch)\n             340 LOAD_ATTR               18 (long)\n             342 LOAD_FAST               17 (device)\n             344 LOAD_CONST              10 (('dtype', 'device'))\n             346 CALL_FUNCTION_KW         3\n             348 STORE_FAST               3 (token_type_ids)\n\n 995     >>  350 LOAD_FAST                0 (self)\n             352 LOAD_METHOD             19 (get_extended_attention_mask)\n             354 LOAD_FAST                2 (attention_mask)\n             356 LOAD_FAST               14 (input_shape)\n             358 CALL_METHOD              2\n             360 STORE_FAST              21 (extended_attention_mask)\n\n 999         362 LOAD_FAST                0 (self)\n             364 LOAD_ATTR                0 (config)\n             366 LOAD_ATTR                4 (is_decoder)\n             368 POP_JUMP_IF_FALSE      217 (to 434)\n             370 LOAD_FAST                7 (encoder_hidden_states)\n             372 LOAD_CONST               1 (None)\n             374 IS_OP                    1\n             376 POP_JUMP_IF_FALSE      217 (to 434)\n\n1000         378 LOAD_FAST                7 (encoder_hidden_states)\n             380 LOAD_METHOD              7 (size)\n             382 CALL_METHOD              0\n             384 UNPACK_SEQUENCE          3\n             386 STORE_FAST              22 (encoder_batch_size)\n             388 STORE_FAST              23 (encoder_sequence_length)\n             390 STORE_FAST              24 (_)\n\n1001         392 LOAD_FAST               22 (encoder_batch_size)\n             394 LOAD_FAST               23 (encoder_sequence_length)\n             396 BUILD_TUPLE              2\n             398 STORE_FAST              25 (encoder_hidden_shape)\n\n1002         400 LOAD_FAST                8 (encoder_attention_mask)\n             402 LOAD_CONST               1 (None)\n             404 IS_OP                    0\n             406 POP_JUMP_IF_FALSE      211 (to 422)\n\n1003         408 LOAD_GLOBAL             11 (torch)\n             410 LOAD_ATTR               12 (ones)\n             412 LOAD_FAST               25 (encoder_hidden_shape)\n             414 LOAD_FAST               17 (device)\n             416 LOAD_CONST               8 (('device',))\n             418 CALL_FUNCTION_KW         2\n             420 STORE_FAST               8 (encoder_attention_mask)\n\n1004     >>  422 LOAD_FAST                0 (self)\n             424 LOAD_METHOD             20 (invert_attention_mask)\n             426 LOAD_FAST                8 (encoder_attention_mask)\n             428 CALL_METHOD              1\n             430 STORE_FAST              26 (encoder_extended_attention_mask)\n             432 JUMP_FORWARD             2 (to 438)\n\n1006     >>  434 LOAD_CONST               1 (None)\n             436 STORE_FAST              26 (encoder_extended_attention_mask)\n\n1013     >>  438 LOAD_FAST                0 (self)\n             440 LOAD_METHOD             21 (get_head_mask)\n             442 LOAD_FAST                5 (head_mask)\n             444 LOAD_FAST                0 (self)\n             446 LOAD_ATTR                0 (config)\n             448 LOAD_ATTR               22 (num_hidden_layers)\n             450 CALL_METHOD              2\n             452 STORE_FAST               5 (head_mask)\n\n1015         454 LOAD_FAST                0 (self)\n             456 LOAD_ATTR               14 (embeddings)\n\n1016         458 LOAD_FAST                1 (input_ids)\n\n1017         460 LOAD_FAST                4 (position_ids)\n\n1018         462 LOAD_FAST                3 (token_type_ids)\n\n1019         464 LOAD_FAST                6 (inputs_embeds)\n\n1020         466 LOAD_FAST               18 (past_key_values_length)\n\n1015         468 LOAD_CONST              11 (('input_ids', 'position_ids', 'token_type_ids', 'inputs_embeds', 'past_key_values_length'))\n             470 CALL_FUNCTION_KW         5\n             472 STORE_FAST              27 (embedding_output)\n\n1022         474 LOAD_FAST                0 (self)\n             476 LOAD_ATTR               23 (encoder)\n\n1023         478 LOAD_FAST               27 (embedding_output)\n\n1024         480 LOAD_FAST               21 (extended_attention_mask)\n\n1025         482 LOAD_FAST                5 (head_mask)\n\n1026         484 LOAD_FAST                7 (encoder_hidden_states)\n\n1027         486 LOAD_FAST               26 (encoder_extended_attention_mask)\n\n1028         488 LOAD_FAST                9 (past_key_values)\n\n1029         490 LOAD_FAST               10 (use_cache)\n\n1030         492 LOAD_FAST               11 (output_attentions)\n\n1031         494 LOAD_FAST               12 (output_hidden_states)\n\n1032         496 LOAD_FAST               13 (return_dict)\n\n1022         498 LOAD_CONST              12 (('attention_mask', 'head_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'past_key_values', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             500 CALL_FUNCTION_KW        10\n             502 STORE_FAST              28 (encoder_outputs)\n\n1034         504 LOAD_FAST               28 (encoder_outputs)\n             506 LOAD_CONST               6 (0)\n             508 BINARY_SUBSCR\n             510 STORE_FAST              29 (sequence_output)\n\n1035         512 LOAD_FAST                0 (self)\n             514 LOAD_ATTR               24 (pooler)\n             516 LOAD_CONST               1 (None)\n             518 IS_OP                    1\n             520 EXTENDED_ARG             1\n             522 POP_JUMP_IF_FALSE      267 (to 534)\n             524 LOAD_FAST                0 (self)\n             526 LOAD_METHOD             24 (pooler)\n             528 LOAD_FAST               29 (sequence_output)\n             530 CALL_METHOD              1\n             532 JUMP_FORWARD             1 (to 536)\n         >>  534 LOAD_CONST               1 (None)\n         >>  536 STORE_FAST              30 (pooled_output)\n\n1037         538 LOAD_FAST               13 (return_dict)\n             540 EXTENDED_ARG             1\n             542 POP_JUMP_IF_TRUE       282 (to 564)\n\n1038         544 LOAD_FAST               29 (sequence_output)\n             546 LOAD_FAST               30 (pooled_output)\n             548 BUILD_TUPLE              2\n             550 LOAD_FAST               28 (encoder_outputs)\n             552 LOAD_CONST              13 (1)\n             554 LOAD_CONST               1 (None)\n             556 BUILD_SLICE              2\n             558 BINARY_SUBSCR\n             560 BINARY_ADD\n             562 RETURN_VALUE\n\n1040     >>  564 LOAD_GLOBAL             25 (BaseModelOutputWithPoolingAndCrossAttentions)\n\n1041         566 LOAD_FAST               29 (sequence_output)\n\n1042         568 LOAD_FAST               30 (pooled_output)\n\n1043         570 LOAD_FAST               28 (encoder_outputs)\n             572 LOAD_ATTR               26 (past_key_values)\n\n1044         574 LOAD_FAST               28 (encoder_outputs)\n             576 LOAD_ATTR               27 (hidden_states)\n\n1045         578 LOAD_FAST               28 (encoder_outputs)\n             580 LOAD_ATTR               28 (attentions)\n\n1046         582 LOAD_FAST               28 (encoder_outputs)\n             584 LOAD_ATTR               29 (cross_attentions)\n\n1040         586 LOAD_CONST              14 (('last_hidden_state', 'pooler_output', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n             588 CALL_FUNCTION_KW         6\n             590 RETURN_VALUE\n\n", "ORIGINAL BYTECODE warn_if_padding_and_no_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/modeling_utils.py line 3482 \n3486           0 LOAD_FAST                2 (attention_mask)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_TRUE        10 (to 20)\n               8 LOAD_FAST                0 (self)\n              10 LOAD_ATTR                0 (config)\n              12 LOAD_ATTR                1 (pad_token_id)\n              14 LOAD_CONST               1 (None)\n              16 IS_OP                    0\n              18 POP_JUMP_IF_FALSE       12 (to 24)\n\n3487     >>   20 LOAD_CONST               1 (None)\n              22 RETURN_VALUE\n\n3490     >>   24 LOAD_FAST                0 (self)\n              26 LOAD_ATTR                0 (config)\n              28 LOAD_ATTR                1 (pad_token_id)\n              30 LOAD_FAST                1 (input_ids)\n              32 LOAD_CONST               1 (None)\n              34 LOAD_CONST               1 (None)\n              36 BUILD_SLICE              2\n              38 LOAD_CONST               2 (-1)\n              40 LOAD_CONST               3 (0)\n              42 BUILD_LIST               2\n              44 BUILD_TUPLE              2\n              46 BINARY_SUBSCR\n              48 CONTAINS_OP              0\n              50 POP_JUMP_IF_FALSE      102 (to 204)\n\n3492          52 LOAD_CONST               4 ('We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.')\n\n3491          54 STORE_FAST               3 (warn_string)\n\n3500          56 LOAD_FAST                0 (self)\n              58 LOAD_ATTR                0 (config)\n              60 LOAD_ATTR                2 (bos_token_id)\n              62 LOAD_CONST               1 (None)\n              64 IS_OP                    1\n              66 POP_JUMP_IF_FALSE       42 (to 84)\n              68 LOAD_FAST                0 (self)\n              70 LOAD_ATTR                0 (config)\n              72 LOAD_ATTR                2 (bos_token_id)\n              74 LOAD_FAST                0 (self)\n              76 LOAD_ATTR                0 (config)\n              78 LOAD_ATTR                1 (pad_token_id)\n              80 COMPARE_OP               2 (==)\n              82 POP_JUMP_IF_TRUE        70 (to 140)\n\n3501     >>   84 LOAD_FAST                0 (self)\n              86 LOAD_ATTR                0 (config)\n              88 LOAD_ATTR                3 (eos_token_id)\n              90 LOAD_CONST               1 (None)\n              92 IS_OP                    1\n              94 POP_JUMP_IF_FALSE       56 (to 112)\n              96 LOAD_FAST                0 (self)\n              98 LOAD_ATTR                0 (config)\n             100 LOAD_ATTR                3 (eos_token_id)\n             102 LOAD_FAST                0 (self)\n             104 LOAD_ATTR                0 (config)\n             106 LOAD_ATTR                1 (pad_token_id)\n             108 COMPARE_OP               2 (==)\n             110 POP_JUMP_IF_TRUE        70 (to 140)\n\n3502     >>  112 LOAD_FAST                0 (self)\n             114 LOAD_ATTR                0 (config)\n             116 LOAD_ATTR                4 (sep_token_id)\n             118 LOAD_CONST               1 (None)\n             120 IS_OP                    1\n             122 POP_JUMP_IF_FALSE       95 (to 190)\n             124 LOAD_FAST                0 (self)\n             126 LOAD_ATTR                0 (config)\n             128 LOAD_ATTR                4 (sep_token_id)\n             130 LOAD_FAST                0 (self)\n             132 LOAD_ATTR                0 (config)\n             134 LOAD_ATTR                1 (pad_token_id)\n             136 COMPARE_OP               2 (==)\n             138 POP_JUMP_IF_FALSE       95 (to 190)\n\n3504     >>  140 LOAD_FAST                3 (warn_string)\n\n3505         142 LOAD_CONST               5 ('\\nYou may ignore this warning if your `pad_token_id` (')\n             144 LOAD_FAST                0 (self)\n             146 LOAD_ATTR                0 (config)\n             148 LOAD_ATTR                1 (pad_token_id)\n             150 FORMAT_VALUE             0\n             152 LOAD_CONST               6 (') is identical to the `bos_token_id` (')\n\n3506         154 LOAD_FAST                0 (self)\n             156 LOAD_ATTR                0 (config)\n             158 LOAD_ATTR                2 (bos_token_id)\n\n3505         160 FORMAT_VALUE             0\n             162 LOAD_CONST               7 ('), `eos_token_id` (')\n\n3506         164 LOAD_FAST                0 (self)\n             166 LOAD_ATTR                0 (config)\n             168 LOAD_ATTR                3 (eos_token_id)\n\n3505         170 FORMAT_VALUE             0\n             172 LOAD_CONST               8 ('), or the `sep_token_id` (')\n\n3507         174 LOAD_FAST                0 (self)\n             176 LOAD_ATTR                0 (config)\n             178 LOAD_ATTR                4 (sep_token_id)\n\n3505         180 FORMAT_VALUE             0\n             182 LOAD_CONST               9 ('), and your input is not padded.')\n             184 BUILD_STRING             9\n\n3504         186 INPLACE_ADD\n             188 STORE_FAST               3 (warn_string)\n\n3510     >>  190 LOAD_GLOBAL              5 (logger)\n             192 LOAD_METHOD              6 (warning_once)\n             194 LOAD_FAST                3 (warn_string)\n             196 CALL_METHOD              1\n             198 POP_TOP\n             200 LOAD_CONST               1 (None)\n             202 RETURN_VALUE\n\n3490     >>  204 LOAD_CONST               1 (None)\n             206 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py line 970 \n 970           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           74 (to 148)\n               4 LOAD_FAST               12 (output_attentions)\n               6 LOAD_CONST               1 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST               12 (output_attentions)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (output_attentions)\n         >>   22 STORE_FAST              12 (output_attentions)\n              24 LOAD_FAST               13 (output_hidden_states)\n              26 LOAD_CONST               1 (None)\n              28 IS_OP                    1\n              30 POP_JUMP_IF_FALSE       18 (to 36)\n              32 LOAD_FAST               13 (output_hidden_states)\n              34 JUMP_FORWARD             3 (to 42)\n         >>   36 LOAD_FAST                1 (self)\n              38 LOAD_ATTR                0 (config)\n              40 LOAD_ATTR                2 (output_hidden_states)\n         >>   42 STORE_FAST              13 (output_hidden_states)\n              44 LOAD_FAST               14 (return_dict)\n              46 LOAD_CONST               1 (None)\n              48 IS_OP                    1\n              50 POP_JUMP_IF_FALSE       28 (to 56)\n              52 LOAD_FAST               14 (return_dict)\n              54 JUMP_FORWARD             3 (to 62)\n         >>   56 LOAD_FAST                1 (self)\n              58 LOAD_ATTR                0 (config)\n              60 LOAD_ATTR                3 (use_return_dict)\n         >>   62 STORE_FAST              14 (return_dict)\n              64 LOAD_FAST                1 (self)\n              66 LOAD_ATTR                0 (config)\n              68 LOAD_ATTR                4 (is_decoder)\n              70 POP_JUMP_IF_FALSE       47 (to 94)\n              72 LOAD_FAST               11 (use_cache)\n              74 LOAD_CONST               1 (None)\n              76 IS_OP                    1\n              78 POP_JUMP_IF_FALSE       42 (to 84)\n              80 LOAD_FAST               11 (use_cache)\n              82 JUMP_FORWARD             3 (to 90)\n         >>   84 LOAD_FAST                1 (self)\n              86 LOAD_ATTR                0 (config)\n              88 LOAD_ATTR                5 (use_cache)\n         >>   90 STORE_FAST              11 (use_cache)\n              92 JUMP_FORWARD             2 (to 98)\n         >>   94 LOAD_CONST               2 (False)\n              96 STORE_FAST              11 (use_cache)\n         >>   98 LOAD_FAST                2 (input_ids)\n             100 LOAD_CONST               1 (None)\n             102 IS_OP                    1\n             104 POP_JUMP_IF_FALSE       61 (to 122)\n             106 LOAD_FAST                7 (inputs_embeds)\n             108 LOAD_CONST               1 (None)\n             110 IS_OP                    1\n             112 POP_JUMP_IF_FALSE       61 (to 122)\n             114 LOAD_GLOBAL              6 (ValueError)\n             116 LOAD_CONST               3 ('You cannot specify both input_ids and inputs_embeds at the same time')\n             118 CALL_FUNCTION            1\n             120 RAISE_VARARGS            1\n         >>  122 LOAD_FAST                2 (input_ids)\n             124 LOAD_CONST               1 (None)\n             126 IS_OP                    1\n             128 POP_JUMP_IF_FALSE       76 (to 152)\n             130 LOAD_FAST                2 (input_ids)\n             132 LOAD_ATTR                7 (size)\n             134 CALL_FUNCTION            0\n             136 STORE_FAST              15 (input_shape)\n             138 LOAD_FAST                1 (self)\n             140 LOAD_ATTR                8 (warn_if_padding_and_no_attention_mask)\n             142 LOAD_FAST                2 (input_ids)\n             144 LOAD_FAST                3 (attention_mask)\n             146 CALL_FUNCTION            2\n         >>  148 POP_TOP\n             150 JUMP_FORWARD            17 (to 186)\n\n 971     >>  152 LOAD_FAST                7 (inputs_embeds)\n             154 LOAD_CONST               1 (None)\n             156 IS_OP                    1\n             158 POP_JUMP_IF_FALSE       89 (to 178)\n\n 972         160 LOAD_FAST                7 (inputs_embeds)\n             162 LOAD_ATTR                7 (size)\n             164 CALL_FUNCTION            0\n             166 LOAD_CONST               1 (None)\n             168 LOAD_CONST               4 (-1)\n             170 BUILD_SLICE              2\n             172 BINARY_SUBSCR\n             174 STORE_FAST              15 (input_shape)\n             176 JUMP_FORWARD             4 (to 186)\n\n 974     >>  178 LOAD_GLOBAL              6 (ValueError)\n             180 LOAD_CONST               5 ('You have to specify either input_ids or inputs_embeds')\n             182 CALL_FUNCTION            1\n             184 RAISE_VARARGS            1\n\n 976     >>  186 LOAD_FAST               15 (input_shape)\n             188 UNPACK_SEQUENCE          2\n             190 STORE_FAST              16 (batch_size)\n             192 STORE_FAST              17 (seq_length)\n\n 977         194 LOAD_FAST                2 (input_ids)\n             196 LOAD_CONST               1 (None)\n             198 IS_OP                    1\n             200 POP_JUMP_IF_FALSE      104 (to 208)\n             202 LOAD_FAST                2 (input_ids)\n             204 LOAD_ATTR                9 (device)\n             206 JUMP_FORWARD             2 (to 212)\n         >>  208 LOAD_FAST                7 (inputs_embeds)\n             210 LOAD_ATTR                9 (device)\n         >>  212 STORE_FAST              18 (device)\n\n 980         214 LOAD_FAST               10 (past_key_values)\n             216 LOAD_CONST               1 (None)\n             218 IS_OP                    1\n             220 POP_JUMP_IF_FALSE      120 (to 240)\n             222 LOAD_FAST               10 (past_key_values)\n             224 LOAD_CONST               6 (0)\n             226 BINARY_SUBSCR\n             228 LOAD_CONST               6 (0)\n             230 BINARY_SUBSCR\n             232 LOAD_ATTR               10 (shape)\n             234 LOAD_CONST               7 (2)\n             236 BINARY_SUBSCR\n             238 JUMP_FORWARD             1 (to 242)\n         >>  240 LOAD_CONST               6 (0)\n         >>  242 STORE_FAST              19 (past_key_values_length)\n\n 982         244 LOAD_FAST                3 (attention_mask)\n             246 LOAD_CONST               1 (None)\n             248 IS_OP                    0\n             250 POP_JUMP_IF_FALSE      137 (to 274)\n\n 983         252 LOAD_GLOBAL             11 (torch)\n             254 LOAD_ATTR               12 (ones)\n             256 LOAD_FAST               16 (batch_size)\n             258 LOAD_FAST               17 (seq_length)\n             260 LOAD_FAST               19 (past_key_values_length)\n             262 BINARY_ADD\n             264 BUILD_TUPLE              2\n             266 LOAD_FAST               18 (device)\n             268 LOAD_CONST               8 (('device',))\n             270 CALL_FUNCTION_KW         2\n             272 STORE_FAST               3 (attention_mask)\n\n 985     >>  274 LOAD_FAST                4 (token_type_ids)\n             276 LOAD_CONST               1 (None)\n             278 IS_OP                    0\n             280 POP_JUMP_IF_FALSE      177 (to 354)\n\n 986         282 LOAD_GLOBAL             13 (hasattr)\n             284 LOAD_FAST                1 (self)\n             286 LOAD_ATTR               14 (embeddings)\n             288 LOAD_CONST               9 ('token_type_ids')\n             290 CALL_FUNCTION            2\n             292 POP_JUMP_IF_FALSE      168 (to 336)\n\n 987         294 LOAD_FAST                1 (self)\n             296 LOAD_ATTR               14 (embeddings)\n             298 LOAD_ATTR               15 (token_type_ids)\n             300 LOAD_CONST               1 (None)\n             302 LOAD_CONST               1 (None)\n             304 BUILD_SLICE              2\n             306 LOAD_CONST               1 (None)\n             308 LOAD_FAST               17 (seq_length)\n             310 BUILD_SLICE              2\n             312 BUILD_TUPLE              2\n             314 BINARY_SUBSCR\n             316 STORE_FAST              20 (buffered_token_type_ids)\n\n 988         318 LOAD_FAST               20 (buffered_token_type_ids)\n             320 LOAD_ATTR               16 (expand)\n             322 LOAD_FAST               16 (batch_size)\n             324 LOAD_FAST               17 (seq_length)\n             326 CALL_FUNCTION            2\n             328 STORE_FAST              21 (buffered_token_type_ids_expanded)\n\n 989         330 LOAD_FAST               21 (buffered_token_type_ids_expanded)\n             332 STORE_FAST               4 (token_type_ids)\n             334 JUMP_FORWARD             9 (to 354)\n\n 991     >>  336 LOAD_GLOBAL             11 (torch)\n             338 LOAD_ATTR               17 (zeros)\n             340 LOAD_FAST               15 (input_shape)\n             342 LOAD_GLOBAL             11 (torch)\n             344 LOAD_ATTR               18 (long)\n             346 LOAD_FAST               18 (device)\n             348 LOAD_CONST              10 (('dtype', 'device'))\n             350 CALL_FUNCTION_KW         3\n             352 STORE_FAST               4 (token_type_ids)\n\n 995     >>  354 LOAD_FAST                1 (self)\n             356 LOAD_ATTR               19 (get_extended_attention_mask)\n             358 LOAD_FAST                3 (attention_mask)\n             360 LOAD_FAST               15 (input_shape)\n             362 CALL_FUNCTION            2\n             364 STORE_FAST              22 (extended_attention_mask)\n\n 999         366 LOAD_FAST                1 (self)\n             368 LOAD_ATTR                0 (config)\n             370 LOAD_ATTR                4 (is_decoder)\n             372 POP_JUMP_IF_FALSE      219 (to 438)\n             374 LOAD_FAST                8 (encoder_hidden_states)\n             376 LOAD_CONST               1 (None)\n             378 IS_OP                    1\n             380 POP_JUMP_IF_FALSE      219 (to 438)\n\n1000         382 LOAD_FAST                8 (encoder_hidden_states)\n             384 LOAD_ATTR                7 (size)\n             386 CALL_FUNCTION            0\n             388 UNPACK_SEQUENCE          3\n             390 STORE_FAST              23 (encoder_batch_size)\n             392 STORE_FAST              24 (encoder_sequence_length)\n             394 STORE_FAST              25 (_)\n\n1001         396 LOAD_FAST               23 (encoder_batch_size)\n             398 LOAD_FAST               24 (encoder_sequence_length)\n             400 BUILD_TUPLE              2\n             402 STORE_FAST              26 (encoder_hidden_shape)\n\n1002         404 LOAD_FAST                9 (encoder_attention_mask)\n             406 LOAD_CONST               1 (None)\n             408 IS_OP                    0\n             410 POP_JUMP_IF_FALSE      213 (to 426)\n\n1003         412 LOAD_GLOBAL             11 (torch)\n             414 LOAD_ATTR               12 (ones)\n             416 LOAD_FAST               26 (encoder_hidden_shape)\n             418 LOAD_FAST               18 (device)\n             420 LOAD_CONST               8 (('device',))\n             422 CALL_FUNCTION_KW         2\n             424 STORE_FAST               9 (encoder_attention_mask)\n\n1004     >>  426 LOAD_FAST                1 (self)\n             428 LOAD_ATTR               20 (invert_attention_mask)\n             430 LOAD_FAST                9 (encoder_attention_mask)\n             432 CALL_FUNCTION            1\n             434 STORE_FAST              27 (encoder_extended_attention_mask)\n             436 JUMP_FORWARD             2 (to 442)\n\n1006     >>  438 LOAD_CONST               1 (None)\n             440 STORE_FAST              27 (encoder_extended_attention_mask)\n\n1013     >>  442 LOAD_FAST                1 (self)\n             444 LOAD_ATTR               21 (get_head_mask)\n             446 LOAD_FAST                6 (head_mask)\n             448 LOAD_FAST                1 (self)\n             450 LOAD_ATTR                0 (config)\n             452 LOAD_ATTR               22 (num_hidden_layers)\n             454 CALL_FUNCTION            2\n             456 STORE_FAST               6 (head_mask)\n\n1015         458 LOAD_FAST                1 (self)\n             460 LOAD_ATTR               14 (embeddings)\n\n1016         462 LOAD_FAST                2 (input_ids)\n\n1017         464 LOAD_FAST                5 (position_ids)\n\n1018         466 LOAD_FAST                4 (token_type_ids)\n\n1019         468 LOAD_FAST                7 (inputs_embeds)\n\n1020         470 LOAD_FAST               19 (past_key_values_length)\n\n1015         472 LOAD_CONST              11 (('input_ids', 'position_ids', 'token_type_ids', 'inputs_embeds', 'past_key_values_length'))\n             474 CALL_FUNCTION_KW         5\n             476 STORE_FAST              28 (embedding_output)\n\n1022         478 LOAD_FAST                1 (self)\n             480 LOAD_ATTR               23 (encoder)\n\n1023         482 LOAD_FAST               28 (embedding_output)\n\n1024         484 LOAD_FAST               22 (extended_attention_mask)\n\n1025         486 LOAD_FAST                6 (head_mask)\n\n1026         488 LOAD_FAST                8 (encoder_hidden_states)\n\n1027         490 LOAD_FAST               27 (encoder_extended_attention_mask)\n\n1028         492 LOAD_FAST               10 (past_key_values)\n\n1029         494 LOAD_FAST               11 (use_cache)\n\n1030         496 LOAD_FAST               12 (output_attentions)\n\n1031         498 LOAD_FAST               13 (output_hidden_states)\n\n1032         500 LOAD_FAST               14 (return_dict)\n\n1022         502 LOAD_CONST              12 (('attention_mask', 'head_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'past_key_values', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             504 CALL_FUNCTION_KW        10\n             506 STORE_FAST              29 (encoder_outputs)\n\n1034         508 LOAD_FAST               29 (encoder_outputs)\n             510 LOAD_CONST               6 (0)\n             512 BINARY_SUBSCR\n             514 STORE_FAST              30 (sequence_output)\n\n1035         516 LOAD_FAST                1 (self)\n             518 LOAD_ATTR               24 (pooler)\n             520 LOAD_CONST               1 (None)\n             522 IS_OP                    1\n             524 EXTENDED_ARG             1\n             526 POP_JUMP_IF_FALSE      269 (to 538)\n             528 LOAD_FAST                1 (self)\n             530 LOAD_ATTR               24 (pooler)\n             532 LOAD_FAST               30 (sequence_output)\n             534 CALL_FUNCTION            1\n             536 JUMP_FORWARD             1 (to 540)\n         >>  538 LOAD_CONST               1 (None)\n         >>  540 STORE_FAST              31 (pooled_output)\n\n1037         542 LOAD_FAST               14 (return_dict)\n             544 EXTENDED_ARG             1\n             546 POP_JUMP_IF_TRUE       284 (to 568)\n\n1038         548 LOAD_FAST               30 (sequence_output)\n             550 LOAD_FAST               31 (pooled_output)\n             552 BUILD_TUPLE              2\n             554 LOAD_FAST               29 (encoder_outputs)\n             556 LOAD_CONST              13 (1)\n             558 LOAD_CONST               1 (None)\n             560 BUILD_SLICE              2\n             562 BINARY_SUBSCR\n             564 BINARY_ADD\n             566 RETURN_VALUE\n\n1040     >>  568 LOAD_GLOBAL             25 (BaseModelOutputWithPoolingAndCrossAttentions)\n\n1041         570 LOAD_FAST               30 (sequence_output)\n\n1042         572 LOAD_FAST               31 (pooled_output)\n\n1043         574 LOAD_FAST               29 (encoder_outputs)\n             576 LOAD_ATTR               26 (past_key_values)\n\n1044         578 LOAD_FAST               29 (encoder_outputs)\n             580 LOAD_ATTR               27 (hidden_states)\n\n1045         582 LOAD_FAST               29 (encoder_outputs)\n             584 LOAD_ATTR               28 (attentions)\n\n1046         586 LOAD_FAST               29 (encoder_outputs)\n             588 LOAD_ATTR               29 (cross_attentions)\n\n1040         590 LOAD_CONST              14 (('last_hidden_state', 'pooler_output', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n             592 CALL_FUNCTION_KW         6\n             594 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py line 1844 \n1844           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           25 (to 50)\n               4 LOAD_FAST                4 (return_dict)\n               6 LOAD_CONST               1 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST                4 (return_dict)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (use_return_dict)\n         >>   22 STORE_FAST               4 (return_dict)\n              24 LOAD_FAST                1 (self)\n              26 LOAD_ATTR                2 (bert)\n              28 LOAD_FAST                5 (input_ids)\n              30 LOAD_FAST                6 (attention_mask)\n              32 LOAD_FAST                7 (token_type_ids)\n              34 LOAD_FAST                8 (position_ids)\n              36 LOAD_FAST                9 (head_mask)\n              38 LOAD_FAST               10 (inputs_embeds)\n              40 LOAD_FAST               11 (output_attentions)\n              42 LOAD_FAST               12 (output_hidden_states)\n              44 LOAD_FAST                4 (return_dict)\n              46 LOAD_CONST               2 (('attention_mask', 'token_type_ids', 'position_ids', 'head_mask', 'inputs_embeds', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              48 CALL_FUNCTION_KW         9\n         >>   50 STORE_FAST              13 (outputs)\n\n1856          52 LOAD_FAST               13 (outputs)\n              54 LOAD_CONST               3 (0)\n              56 BINARY_SUBSCR\n              58 STORE_FAST              14 (sequence_output)\n\n1858          60 LOAD_FAST                1 (self)\n              62 LOAD_ATTR                3 (qa_outputs)\n              64 LOAD_FAST               14 (sequence_output)\n              66 CALL_FUNCTION            1\n              68 STORE_FAST              15 (logits)\n\n1859          70 LOAD_FAST               15 (logits)\n              72 LOAD_ATTR                4 (split)\n              74 LOAD_CONST               4 (1)\n              76 LOAD_CONST               5 (-1)\n              78 LOAD_CONST               6 (('dim',))\n              80 CALL_FUNCTION_KW         2\n              82 UNPACK_SEQUENCE          2\n              84 STORE_FAST              16 (start_logits)\n              86 STORE_FAST              17 (end_logits)\n\n1860          88 LOAD_FAST               16 (start_logits)\n              90 LOAD_ATTR                5 (squeeze)\n              92 LOAD_CONST               5 (-1)\n              94 CALL_FUNCTION            1\n              96 LOAD_ATTR                6 (contiguous)\n              98 CALL_FUNCTION            0\n             100 STORE_FAST              16 (start_logits)\n\n1861         102 LOAD_FAST               17 (end_logits)\n             104 LOAD_ATTR                5 (squeeze)\n             106 LOAD_CONST               5 (-1)\n             108 CALL_FUNCTION            1\n             110 LOAD_ATTR                6 (contiguous)\n             112 CALL_FUNCTION            0\n             114 STORE_FAST              17 (end_logits)\n\n1863         116 LOAD_CONST               1 (None)\n             118 STORE_FAST              18 (total_loss)\n\n1864         120 LOAD_FAST                2 (start_positions)\n             122 LOAD_CONST               1 (None)\n             124 IS_OP                    1\n             126 POP_JUMP_IF_FALSE      132 (to 264)\n             128 LOAD_FAST                3 (end_positions)\n             130 LOAD_CONST               1 (None)\n             132 IS_OP                    1\n             134 POP_JUMP_IF_FALSE      132 (to 264)\n\n1866         136 LOAD_GLOBAL              7 (len)\n             138 LOAD_FAST                2 (start_positions)\n             140 LOAD_ATTR                8 (size)\n             142 CALL_FUNCTION            0\n             144 CALL_FUNCTION            1\n             146 LOAD_CONST               4 (1)\n             148 COMPARE_OP               4 (>)\n             150 POP_JUMP_IF_FALSE       81 (to 162)\n\n1867         152 LOAD_FAST                2 (start_positions)\n             154 LOAD_ATTR                5 (squeeze)\n             156 LOAD_CONST               5 (-1)\n             158 CALL_FUNCTION            1\n             160 STORE_FAST               2 (start_positions)\n\n1868     >>  162 LOAD_GLOBAL              7 (len)\n             164 LOAD_FAST                3 (end_positions)\n             166 LOAD_ATTR                8 (size)\n             168 CALL_FUNCTION            0\n             170 CALL_FUNCTION            1\n             172 LOAD_CONST               4 (1)\n             174 COMPARE_OP               4 (>)\n             176 POP_JUMP_IF_FALSE       94 (to 188)\n\n1869         178 LOAD_FAST                3 (end_positions)\n             180 LOAD_ATTR                5 (squeeze)\n             182 LOAD_CONST               5 (-1)\n             184 CALL_FUNCTION            1\n             186 STORE_FAST               3 (end_positions)\n\n1871     >>  188 LOAD_FAST               16 (start_logits)\n             190 LOAD_ATTR                8 (size)\n             192 LOAD_CONST               4 (1)\n             194 CALL_FUNCTION            1\n             196 STORE_FAST              19 (ignored_index)\n\n1872         198 LOAD_FAST                2 (start_positions)\n             200 LOAD_ATTR                9 (clamp)\n             202 LOAD_CONST               3 (0)\n             204 LOAD_FAST               19 (ignored_index)\n             206 CALL_FUNCTION            2\n             208 STORE_FAST               2 (start_positions)\n\n1873         210 LOAD_FAST                3 (end_positions)\n             212 LOAD_ATTR                9 (clamp)\n             214 LOAD_CONST               3 (0)\n             216 LOAD_FAST               19 (ignored_index)\n             218 CALL_FUNCTION            2\n             220 STORE_FAST               3 (end_positions)\n\n1875         222 LOAD_GLOBAL             10 (CrossEntropyLoss)\n             224 LOAD_FAST               19 (ignored_index)\n             226 LOAD_CONST               7 (('ignore_index',))\n             228 CALL_FUNCTION_KW         1\n             230 STORE_FAST              20 (loss_fct)\n\n1876         232 LOAD_FAST               20 (loss_fct)\n             234 LOAD_FAST               16 (start_logits)\n             236 LOAD_FAST                2 (start_positions)\n             238 CALL_FUNCTION            2\n             240 STORE_FAST              21 (start_loss)\n\n1877         242 LOAD_FAST               20 (loss_fct)\n             244 LOAD_FAST               17 (end_logits)\n             246 LOAD_FAST                3 (end_positions)\n             248 CALL_FUNCTION            2\n             250 STORE_FAST              22 (end_loss)\n\n1878         252 LOAD_FAST               21 (start_loss)\n             254 LOAD_FAST               22 (end_loss)\n             256 BINARY_ADD\n             258 LOAD_CONST               8 (2)\n             260 BINARY_TRUE_DIVIDE\n             262 STORE_FAST              18 (total_loss)\n\n1880     >>  264 LOAD_FAST                4 (return_dict)\n             266 POP_JUMP_IF_TRUE       155 (to 310)\n\n1881         268 LOAD_FAST               16 (start_logits)\n             270 LOAD_FAST               17 (end_logits)\n             272 BUILD_TUPLE              2\n             274 LOAD_FAST               13 (outputs)\n             276 LOAD_CONST               8 (2)\n             278 LOAD_CONST               1 (None)\n             280 BUILD_SLICE              2\n             282 BINARY_SUBSCR\n             284 BINARY_ADD\n             286 STORE_FAST              23 (output)\n\n1882         288 LOAD_FAST               18 (total_loss)\n             290 LOAD_CONST               1 (None)\n             292 IS_OP                    1\n             294 POP_JUMP_IF_FALSE      153 (to 306)\n             296 LOAD_FAST               18 (total_loss)\n             298 BUILD_TUPLE              1\n             300 LOAD_FAST               23 (output)\n             302 BINARY_ADD\n             304 RETURN_VALUE\n         >>  306 LOAD_FAST               23 (output)\n             308 RETURN_VALUE\n\n1884     >>  310 LOAD_GLOBAL             11 (QuestionAnsweringModelOutput)\n\n1885         312 LOAD_FAST               18 (total_loss)\n\n1886         314 LOAD_FAST               16 (start_logits)\n\n1887         316 LOAD_FAST               17 (end_logits)\n\n1888         318 LOAD_FAST               13 (outputs)\n             320 LOAD_ATTR               12 (hidden_states)\n\n1889         322 LOAD_FAST               13 (outputs)\n             324 LOAD_ATTR               13 (attentions)\n\n1884         326 LOAD_CONST               9 (('loss', 'start_logits', 'end_logits', 'hidden_states', 'attentions'))\n             328 CALL_FUNCTION_KW         5\n             330 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 557 \n557           0 LOAD_FAST                0 (___stack0)\n              2 CALL_FUNCTION            0\n              4 SETUP_WITH              10 (to 26)\n              6 POP_TOP\n              8 LOAD_FAST                1 (___stack1)\n             10 JUMP_ABSOLUTE           44 (to 88)\n             12 POP_BLOCK\n             14 LOAD_CONST               0 (None)\n             16 DUP_TOP\n             18 DUP_TOP\n             20 CALL_FUNCTION            3\n             22 POP_TOP\n             24 JUMP_FORWARD             8 (to 42)\n        >>   26 WITH_EXCEPT_START\n             28 POP_JUMP_IF_TRUE        16 (to 32)\n             30 RERAISE                  0\n        >>   32 POP_TOP\n             34 POP_TOP\n             36 POP_TOP\n             38 POP_EXCEPT\n             40 POP_TOP\n        >>   42 NOP\n             44 LOAD_CONST               0 (None)\n             46 RAISE_VARARGS            1\n             48 LOAD_GLOBAL              0 (clone_inputs)\n             50 LOAD_FAST                6 (inputs)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (cloned_inputs)\n             56 LOAD_FAST                2 (self)\n             58 LOAD_ATTR                1 (optimizer_zero_grad)\n             60 LOAD_FAST                3 (mod)\n             62 CALL_FUNCTION            1\n             64 POP_TOP\n             66 LOAD_FAST                2 (self)\n             68 LOAD_ATTR                2 (autocast)\n             70 CALL_FUNCTION            0\n             72 SETUP_WITH              20 (to 114)\n             74 POP_TOP\n             76 LOAD_FAST                3 (mod)\n             78 LOAD_CONST               1 (())\n             80 BUILD_MAP                0\n             82 LOAD_FAST                5 (cloned_inputs)\n             84 DICT_MERGE               1\n             86 CALL_FUNCTION_EX         1\n        >>   88 STORE_FAST               7 (pred)\n\n558          90 LOAD_FAST                2 (self)\n             92 LOAD_ATTR                3 (compute_loss)\n             94 LOAD_FAST                7 (pred)\n             96 CALL_FUNCTION            1\n             98 STORE_FAST               8 (loss)\n            100 POP_BLOCK\n\n556         102 LOAD_CONST               0 (None)\n            104 DUP_TOP\n            106 DUP_TOP\n            108 CALL_FUNCTION            3\n            110 POP_TOP\n            112 JUMP_FORWARD             8 (to 130)\n        >>  114 WITH_EXCEPT_START\n            116 POP_JUMP_IF_TRUE        60 (to 120)\n            118 RERAISE                  1\n        >>  120 POP_TOP\n            122 POP_TOP\n            124 POP_TOP\n            126 POP_EXCEPT\n            128 POP_TOP\n\n559     >>  130 LOAD_FAST                2 (self)\n            132 LOAD_ATTR                4 (grad_scaler)\n            134 LOAD_ATTR                5 (scale)\n            136 LOAD_FAST                8 (loss)\n            138 CALL_FUNCTION            1\n            140 LOAD_ATTR                6 (backward)\n            142 CALL_FUNCTION            0\n            144 POP_TOP\n\n560         146 LOAD_FAST                2 (self)\n            148 LOAD_ATTR                7 (optimizer_step)\n            150 CALL_FUNCTION            0\n            152 POP_TOP\n\n561         154 LOAD_FAST                4 (collect_outputs)\n            156 POP_JUMP_IF_FALSE       86 (to 172)\n\n562         158 LOAD_GLOBAL              8 (collect_results)\n            160 LOAD_FAST                3 (mod)\n            162 LOAD_FAST                7 (pred)\n            164 LOAD_FAST                8 (loss)\n            166 LOAD_FAST                5 (cloned_inputs)\n            168 CALL_FUNCTION            4\n            170 RETURN_VALUE\n\n563     >>  172 LOAD_CONST               0 (None)\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 1435 \n1539           0 LOAD_FAST               11 (output_attentions)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               11 (output_attentions)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (output_attentions)\n         >>   18 STORE_FAST              11 (output_attentions)\n\n1541          20 LOAD_FAST               12 (output_hidden_states)\n              22 LOAD_CONST               1 (None)\n              24 IS_OP                    1\n              26 POP_JUMP_IF_FALSE       16 (to 32)\n              28 LOAD_FAST               12 (output_hidden_states)\n              30 JUMP_FORWARD             3 (to 38)\n         >>   32 LOAD_FAST                0 (self)\n              34 LOAD_ATTR                0 (config)\n              36 LOAD_ATTR                2 (output_hidden_states)\n\n1540     >>   38 STORE_FAST              12 (output_hidden_states)\n\n1543          40 LOAD_FAST               13 (return_dict)\n              42 LOAD_CONST               1 (None)\n              44 IS_OP                    1\n              46 POP_JUMP_IF_FALSE       26 (to 52)\n              48 LOAD_FAST               13 (return_dict)\n              50 JUMP_FORWARD             3 (to 58)\n         >>   52 LOAD_FAST                0 (self)\n              54 LOAD_ATTR                0 (config)\n              56 LOAD_ATTR                3 (use_return_dict)\n         >>   58 STORE_FAST              13 (return_dict)\n\n1546          60 LOAD_FAST                0 (self)\n              62 LOAD_ATTR                4 (model)\n              64 LOAD_ATTR                5 (decoder)\n\n1547          66 LOAD_FAST                1 (input_ids)\n\n1548          68 LOAD_FAST                2 (attention_mask)\n\n1549          70 LOAD_FAST                3 (encoder_hidden_states)\n\n1550          72 LOAD_FAST                4 (encoder_attention_mask)\n\n1551          74 LOAD_FAST                5 (head_mask)\n\n1552          76 LOAD_FAST                6 (cross_attn_head_mask)\n\n1553          78 LOAD_FAST                7 (past_key_values)\n\n1554          80 LOAD_FAST                8 (inputs_embeds)\n\n1555          82 LOAD_FAST               10 (use_cache)\n\n1556          84 LOAD_FAST               11 (output_attentions)\n\n1557          86 LOAD_FAST               12 (output_hidden_states)\n\n1558          88 LOAD_FAST               13 (return_dict)\n\n1546          90 LOAD_CONST               2 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              92 CALL_FUNCTION_KW        12\n              94 STORE_FAST              14 (outputs)\n\n1561          96 LOAD_FAST                0 (self)\n              98 LOAD_METHOD              6 (lm_head)\n             100 LOAD_FAST               14 (outputs)\n             102 LOAD_CONST               3 (0)\n             104 BINARY_SUBSCR\n             106 CALL_METHOD              1\n             108 STORE_FAST              15 (logits)\n\n1563         110 LOAD_CONST               1 (None)\n             112 STORE_FAST              16 (loss)\n\n1564         114 LOAD_FAST                9 (labels)\n             116 LOAD_CONST               1 (None)\n             118 IS_OP                    1\n             120 POP_JUMP_IF_FALSE       84 (to 168)\n\n1565         122 LOAD_FAST                9 (labels)\n             124 LOAD_METHOD              7 (to)\n             126 LOAD_FAST               15 (logits)\n             128 LOAD_ATTR                8 (device)\n             130 CALL_METHOD              1\n             132 STORE_FAST               9 (labels)\n\n1566         134 LOAD_GLOBAL              9 (CrossEntropyLoss)\n             136 CALL_FUNCTION            0\n             138 STORE_FAST              17 (loss_fct)\n\n1567         140 LOAD_FAST               17 (loss_fct)\n             142 LOAD_FAST               15 (logits)\n             144 LOAD_METHOD             10 (view)\n             146 LOAD_CONST               4 (-1)\n             148 LOAD_FAST                0 (self)\n             150 LOAD_ATTR                0 (config)\n             152 LOAD_ATTR               11 (vocab_size)\n             154 CALL_METHOD              2\n             156 LOAD_FAST                9 (labels)\n             158 LOAD_METHOD             10 (view)\n             160 LOAD_CONST               4 (-1)\n             162 CALL_METHOD              1\n             164 CALL_FUNCTION            2\n             166 STORE_FAST              16 (loss)\n\n1569     >>  168 LOAD_FAST               13 (return_dict)\n             170 POP_JUMP_IF_TRUE       106 (to 212)\n\n1570         172 LOAD_FAST               15 (logits)\n             174 BUILD_TUPLE              1\n             176 LOAD_FAST               14 (outputs)\n             178 LOAD_CONST               5 (1)\n             180 LOAD_CONST               1 (None)\n             182 BUILD_SLICE              2\n             184 BINARY_SUBSCR\n             186 BINARY_ADD\n             188 STORE_FAST              18 (output)\n\n1571         190 LOAD_FAST               16 (loss)\n             192 LOAD_CONST               1 (None)\n             194 IS_OP                    1\n             196 POP_JUMP_IF_FALSE      104 (to 208)\n             198 LOAD_FAST               16 (loss)\n             200 BUILD_TUPLE              1\n             202 LOAD_FAST               18 (output)\n             204 BINARY_ADD\n             206 RETURN_VALUE\n         >>  208 LOAD_FAST               18 (output)\n             210 RETURN_VALUE\n\n1573     >>  212 LOAD_GLOBAL             12 (CausalLMOutputWithCrossAttentions)\n\n1574         214 LOAD_FAST               16 (loss)\n\n1575         216 LOAD_FAST               15 (logits)\n\n1576         218 LOAD_FAST               14 (outputs)\n             220 LOAD_ATTR               13 (past_key_values)\n\n1577         222 LOAD_FAST               14 (outputs)\n             224 LOAD_ATTR               14 (hidden_states)\n\n1578         226 LOAD_FAST               14 (outputs)\n             228 LOAD_ATTR               15 (attentions)\n\n1579         230 LOAD_FAST               14 (outputs)\n             232 LOAD_ATTR               16 (cross_attentions)\n\n1573         234 LOAD_CONST               6 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n             236 CALL_FUNCTION_KW         6\n             238 RETURN_VALUE\n\n", "ORIGINAL BYTECODE _prepare_decoder_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 853 \n856           0 LOAD_CONST               0 (None)\n              2 STORE_FAST               5 (combined_attention_mask)\n\n857           4 LOAD_FAST                2 (input_shape)\n              6 LOAD_CONST               1 (-1)\n              8 BINARY_SUBSCR\n             10 LOAD_CONST               2 (1)\n             12 COMPARE_OP               4 (>)\n             14 POP_JUMP_IF_FALSE       18 (to 36)\n\n858          16 LOAD_GLOBAL              0 (_make_causal_mask)\n\n859          18 LOAD_FAST                2 (input_shape)\n\n860          20 LOAD_FAST                3 (inputs_embeds)\n             22 LOAD_ATTR                1 (dtype)\n\n861          24 LOAD_FAST                3 (inputs_embeds)\n             26 LOAD_ATTR                2 (device)\n\n862          28 LOAD_FAST                4 (past_key_values_length)\n\n858          30 LOAD_CONST               3 (('device', 'past_key_values_length'))\n             32 CALL_FUNCTION_KW         4\n             34 STORE_FAST               5 (combined_attention_mask)\n\n865     >>   36 LOAD_FAST                1 (attention_mask)\n             38 LOAD_CONST               0 (None)\n             40 IS_OP                    1\n             42 POP_JUMP_IF_FALSE       46 (to 92)\n\n867          44 LOAD_GLOBAL              3 (_expand_mask)\n             46 LOAD_FAST                1 (attention_mask)\n             48 LOAD_FAST                3 (inputs_embeds)\n             50 LOAD_ATTR                1 (dtype)\n             52 LOAD_FAST                2 (input_shape)\n             54 LOAD_CONST               1 (-1)\n             56 BINARY_SUBSCR\n             58 LOAD_CONST               4 (('tgt_len',))\n             60 CALL_FUNCTION_KW         3\n             62 LOAD_METHOD              4 (to)\n\n868          64 LOAD_FAST                3 (inputs_embeds)\n             66 LOAD_ATTR                2 (device)\n\n867          68 CALL_METHOD              1\n             70 STORE_FAST               6 (expanded_attn_mask)\n\n871          72 LOAD_FAST                5 (combined_attention_mask)\n             74 LOAD_CONST               0 (None)\n             76 IS_OP                    0\n             78 POP_JUMP_IF_FALSE       42 (to 84)\n             80 LOAD_FAST                6 (expanded_attn_mask)\n             82 JUMP_FORWARD             3 (to 90)\n        >>   84 LOAD_FAST                6 (expanded_attn_mask)\n             86 LOAD_FAST                5 (combined_attention_mask)\n             88 BINARY_ADD\n\n870     >>   90 STORE_FAST               5 (combined_attention_mask)\n\n874     >>   92 LOAD_FAST                5 (combined_attention_mask)\n             94 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 116 \n118           0 LOAD_FAST                1 (input_ids_shape)\n              2 LOAD_CONST               1 (None)\n              4 LOAD_CONST               2 (2)\n              6 BUILD_SLICE              2\n              8 BINARY_SUBSCR\n             10 UNPACK_SEQUENCE          2\n             12 STORE_FAST               3 (bsz)\n             14 STORE_FAST               4 (seq_len)\n\n119          16 LOAD_GLOBAL              0 (torch)\n             18 LOAD_ATTR                1 (arange)\n\n120          20 LOAD_FAST                2 (past_key_values_length)\n             22 LOAD_FAST                2 (past_key_values_length)\n             24 LOAD_FAST                4 (seq_len)\n             26 BINARY_ADD\n             28 LOAD_GLOBAL              0 (torch)\n             30 LOAD_ATTR                2 (long)\n             32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                3 (weight)\n             36 LOAD_ATTR                4 (device)\n\n119          38 LOAD_CONST               3 (('dtype', 'device'))\n             40 CALL_FUNCTION_KW         4\n             42 STORE_FAST               5 (positions)\n\n122          44 LOAD_GLOBAL              5 (super)\n             46 CALL_FUNCTION            0\n             48 LOAD_METHOD              6 (forward)\n             50 LOAD_FAST                5 (positions)\n             52 CALL_METHOD              1\n             54 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 377 \n407           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n411           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n413          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n414          32 LOAD_FAST                1 (hidden_states)\n\n415          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n416          36 LOAD_FAST                2 (attention_mask)\n\n417          38 LOAD_FAST                5 (layer_head_mask)\n\n418          40 LOAD_FAST                8 (output_attentions)\n\n413          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n420          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n421          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n422          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n425          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n426          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n427         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n428         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n431         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n432         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n433         142 LOAD_FAST                1 (hidden_states)\n\n434         144 LOAD_FAST                3 (encoder_hidden_states)\n\n435         146 LOAD_FAST                4 (encoder_attention_mask)\n\n436         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n437         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n438         152 LOAD_FAST                8 (output_attentions)\n\n432         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n440         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n441         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n442         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n445         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n448     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n449         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n450         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n451         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n452         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n453         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n454         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n456         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n458         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n459         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n461     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n462         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n464     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 377 \n407           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n411           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n413          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n414          32 LOAD_FAST                1 (hidden_states)\n\n415          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n416          36 LOAD_FAST                2 (attention_mask)\n\n417          38 LOAD_FAST                5 (layer_head_mask)\n\n418          40 LOAD_FAST                8 (output_attentions)\n\n413          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n420          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n421          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n422          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n425          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n426          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n427         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n428         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n431         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n432         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n433         142 LOAD_FAST                1 (hidden_states)\n\n434         144 LOAD_FAST                3 (encoder_hidden_states)\n\n435         146 LOAD_FAST                4 (encoder_attention_mask)\n\n436         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n437         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n438         152 LOAD_FAST                8 (output_attentions)\n\n432         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n440         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n441         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n442         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n445         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n448     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n449         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n450         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n451         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n452         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n453         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n454         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n456         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n458         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n459         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n461     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n462         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n464     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 377 \n407           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n411           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n413          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n414          32 LOAD_FAST                1 (hidden_states)\n\n415          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n416          36 LOAD_FAST                2 (attention_mask)\n\n417          38 LOAD_FAST                5 (layer_head_mask)\n\n418          40 LOAD_FAST                8 (output_attentions)\n\n413          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n420          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n421          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n422          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n425          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n426          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n427         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n428         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n431         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n432         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n433         142 LOAD_FAST                1 (hidden_states)\n\n434         144 LOAD_FAST                3 (encoder_hidden_states)\n\n435         146 LOAD_FAST                4 (encoder_attention_mask)\n\n436         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n437         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n438         152 LOAD_FAST                8 (output_attentions)\n\n432         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n440         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n441         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n442         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n445         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n448     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n449         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n450         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n451         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n452         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n453         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n454         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n456         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n458         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n459         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n461     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n462         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n464     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 377 \n407           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n411           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n413          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n414          32 LOAD_FAST                1 (hidden_states)\n\n415          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n416          36 LOAD_FAST                2 (attention_mask)\n\n417          38 LOAD_FAST                5 (layer_head_mask)\n\n418          40 LOAD_FAST                8 (output_attentions)\n\n413          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n420          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n421          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n422          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n425          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n426          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n427         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n428         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n431         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n432         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n433         142 LOAD_FAST                1 (hidden_states)\n\n434         144 LOAD_FAST                3 (encoder_hidden_states)\n\n435         146 LOAD_FAST                4 (encoder_attention_mask)\n\n436         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n437         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n438         152 LOAD_FAST                8 (output_attentions)\n\n432         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n440         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n441         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n442         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n445         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n448     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n449         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n450         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n451         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n452         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n453         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n454         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n456         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n458         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n459         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n461     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n462         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n464     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 377 \n407           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n411           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n413          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n414          32 LOAD_FAST                1 (hidden_states)\n\n415          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n416          36 LOAD_FAST                2 (attention_mask)\n\n417          38 LOAD_FAST                5 (layer_head_mask)\n\n418          40 LOAD_FAST                8 (output_attentions)\n\n413          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n420          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n421          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n422          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n425          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n426          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n427         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n428         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n431         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n432         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n433         142 LOAD_FAST                1 (hidden_states)\n\n434         144 LOAD_FAST                3 (encoder_hidden_states)\n\n435         146 LOAD_FAST                4 (encoder_attention_mask)\n\n436         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n437         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n438         152 LOAD_FAST                8 (output_attentions)\n\n432         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n440         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n441         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n442         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n445         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n448     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n449         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n450         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n451         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n452         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n453         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n454         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n456         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n458         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n459         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n461     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n462         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n464     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 377 \n407           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n411           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n413          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n414          32 LOAD_FAST                1 (hidden_states)\n\n415          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n416          36 LOAD_FAST                2 (attention_mask)\n\n417          38 LOAD_FAST                5 (layer_head_mask)\n\n418          40 LOAD_FAST                8 (output_attentions)\n\n413          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n420          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n421          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n422          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n425          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n426          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n427         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n428         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n431         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n432         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n433         142 LOAD_FAST                1 (hidden_states)\n\n434         144 LOAD_FAST                3 (encoder_hidden_states)\n\n435         146 LOAD_FAST                4 (encoder_attention_mask)\n\n436         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n437         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n438         152 LOAD_FAST                8 (output_attentions)\n\n432         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n440         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n441         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n442         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n445         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n448     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n449         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n450         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n451         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n452         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n453         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n454         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n456         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n458         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n459         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n461     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n462         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n464     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 377 \n407           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n411           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n413          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n414          32 LOAD_FAST                1 (hidden_states)\n\n415          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n416          36 LOAD_FAST                2 (attention_mask)\n\n417          38 LOAD_FAST                5 (layer_head_mask)\n\n418          40 LOAD_FAST                8 (output_attentions)\n\n413          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n420          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n421          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n422          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n425          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n426          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n427         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n428         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n431         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n432         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n433         142 LOAD_FAST                1 (hidden_states)\n\n434         144 LOAD_FAST                3 (encoder_hidden_states)\n\n435         146 LOAD_FAST                4 (encoder_attention_mask)\n\n436         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n437         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n438         152 LOAD_FAST                8 (output_attentions)\n\n432         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n440         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n441         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n442         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n445         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n448     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n449         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n450         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n451         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n452         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n453         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n454         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n456         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n458         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n459         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n461     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n462         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n464     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 377 \n407           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n411           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n413          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n414          32 LOAD_FAST                1 (hidden_states)\n\n415          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n416          36 LOAD_FAST                2 (attention_mask)\n\n417          38 LOAD_FAST                5 (layer_head_mask)\n\n418          40 LOAD_FAST                8 (output_attentions)\n\n413          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n420          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n421          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n422          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n425          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n426          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n427         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n428         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n431         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n432         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n433         142 LOAD_FAST                1 (hidden_states)\n\n434         144 LOAD_FAST                3 (encoder_hidden_states)\n\n435         146 LOAD_FAST                4 (encoder_attention_mask)\n\n436         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n437         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n438         152 LOAD_FAST                8 (output_attentions)\n\n432         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n440         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n441         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n442         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n445         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n448     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n449         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n450         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n451         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n452         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n453         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n454         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n456         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n458         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n459         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n461     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n462         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n464     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (past_key_values)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (past_key_values)\n\n  5          12 LOAD_FAST                3 (hidden_states)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (hidden_states)\n\n  6          18 LOAD_FAST                4 (attentions)\n             20 LOAD_FAST                0 (self)\n             22 STORE_ATTR               3 (attentions)\n\n  7          24 LOAD_FAST                5 (cross_attentions)\n             26 LOAD_FAST                0 (self)\n             28 STORE_ATTR               4 (cross_attentions)\n\n  8          30 LOAD_FAST                0 (self)\n             32 LOAD_METHOD              5 (__post_init__)\n             34 CALL_METHOD              0\n             36 POP_TOP\n             38 LOAD_CONST               0 (None)\n             40 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 3 \n  3           0 JUMP_ABSOLUTE            4 (to 8)\n              2 LOAD_FAST                5 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n\n  4     >>    8 LOAD_FAST                1 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5          14 LOAD_FAST                2 (hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (hidden_states)\n\n  6          20 LOAD_FAST                3 (attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (attentions)\n\n  7          26 LOAD_FAST                4 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                5 (__post_init__)\n             36 CALL_FUNCTION            0\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 1546 \n1546           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           49 (to 98)\n               4 LOAD_FAST               13 (output_attentions)\n               6 LOAD_CONST               1 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST               13 (output_attentions)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (output_attentions)\n         >>   22 STORE_FAST              13 (output_attentions)\n              24 LOAD_FAST               14 (output_hidden_states)\n              26 LOAD_CONST               1 (None)\n              28 IS_OP                    1\n              30 POP_JUMP_IF_FALSE       18 (to 36)\n              32 LOAD_FAST               14 (output_hidden_states)\n              34 JUMP_FORWARD             3 (to 42)\n         >>   36 LOAD_FAST                1 (self)\n              38 LOAD_ATTR                0 (config)\n              40 LOAD_ATTR                2 (output_hidden_states)\n         >>   42 STORE_FAST              14 (output_hidden_states)\n              44 LOAD_FAST                3 (return_dict)\n              46 LOAD_CONST               1 (None)\n              48 IS_OP                    1\n              50 POP_JUMP_IF_FALSE       28 (to 56)\n              52 LOAD_FAST                3 (return_dict)\n              54 JUMP_FORWARD             3 (to 62)\n         >>   56 LOAD_FAST                1 (self)\n              58 LOAD_ATTR                0 (config)\n              60 LOAD_ATTR                3 (use_return_dict)\n         >>   62 STORE_FAST               3 (return_dict)\n              64 LOAD_FAST                1 (self)\n              66 LOAD_ATTR                4 (model)\n              68 LOAD_ATTR                5 (decoder)\n              70 LOAD_FAST                4 (input_ids)\n              72 LOAD_FAST                5 (attention_mask)\n              74 LOAD_FAST                6 (encoder_hidden_states)\n              76 LOAD_FAST                7 (encoder_attention_mask)\n              78 LOAD_FAST                8 (head_mask)\n              80 LOAD_FAST                9 (cross_attn_head_mask)\n              82 LOAD_FAST               10 (past_key_values)\n              84 LOAD_FAST               11 (inputs_embeds)\n              86 LOAD_FAST               12 (use_cache)\n              88 LOAD_FAST               13 (output_attentions)\n              90 LOAD_FAST               14 (output_hidden_states)\n              92 LOAD_FAST                3 (return_dict)\n              94 LOAD_CONST               2 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              96 CALL_FUNCTION_KW        12\n         >>   98 STORE_FAST              15 (outputs)\n\n1561         100 LOAD_FAST                1 (self)\n             102 LOAD_ATTR                6 (lm_head)\n             104 LOAD_FAST               15 (outputs)\n             106 LOAD_CONST               3 (0)\n             108 BINARY_SUBSCR\n             110 CALL_FUNCTION            1\n             112 STORE_FAST              16 (logits)\n\n1563         114 LOAD_CONST               1 (None)\n             116 STORE_FAST              17 (loss)\n\n1564         118 LOAD_FAST                2 (labels)\n             120 LOAD_CONST               1 (None)\n             122 IS_OP                    1\n             124 POP_JUMP_IF_FALSE       86 (to 172)\n\n1565         126 LOAD_FAST                2 (labels)\n             128 LOAD_ATTR                7 (to)\n             130 LOAD_FAST               16 (logits)\n             132 LOAD_ATTR                8 (device)\n             134 CALL_FUNCTION            1\n             136 STORE_FAST               2 (labels)\n\n1566         138 LOAD_GLOBAL              9 (CrossEntropyLoss)\n             140 CALL_FUNCTION            0\n             142 STORE_FAST              18 (loss_fct)\n\n1567         144 LOAD_FAST               18 (loss_fct)\n             146 LOAD_FAST               16 (logits)\n             148 LOAD_ATTR               10 (view)\n             150 LOAD_CONST               4 (-1)\n             152 LOAD_FAST                1 (self)\n             154 LOAD_ATTR                0 (config)\n             156 LOAD_ATTR               11 (vocab_size)\n             158 CALL_FUNCTION            2\n             160 LOAD_FAST                2 (labels)\n             162 LOAD_ATTR               10 (view)\n             164 LOAD_CONST               4 (-1)\n             166 CALL_FUNCTION            1\n             168 CALL_FUNCTION            2\n             170 STORE_FAST              17 (loss)\n\n1569     >>  172 LOAD_FAST                3 (return_dict)\n             174 POP_JUMP_IF_TRUE       108 (to 216)\n\n1570         176 LOAD_FAST               16 (logits)\n             178 BUILD_TUPLE              1\n             180 LOAD_FAST               15 (outputs)\n             182 LOAD_CONST               5 (1)\n             184 LOAD_CONST               1 (None)\n             186 BUILD_SLICE              2\n             188 BINARY_SUBSCR\n             190 BINARY_ADD\n             192 STORE_FAST              19 (output)\n\n1571         194 LOAD_FAST               17 (loss)\n             196 LOAD_CONST               1 (None)\n             198 IS_OP                    1\n             200 POP_JUMP_IF_FALSE      106 (to 212)\n             202 LOAD_FAST               17 (loss)\n             204 BUILD_TUPLE              1\n             206 LOAD_FAST               19 (output)\n             208 BINARY_ADD\n             210 RETURN_VALUE\n         >>  212 LOAD_FAST               19 (output)\n             214 RETURN_VALUE\n\n1573     >>  216 LOAD_GLOBAL             12 (CausalLMOutputWithCrossAttentions)\n\n1574         218 LOAD_FAST               17 (loss)\n\n1575         220 LOAD_FAST               16 (logits)\n\n1576         222 LOAD_FAST               15 (outputs)\n             224 LOAD_ATTR               13 (past_key_values)\n\n1577         226 LOAD_FAST               15 (outputs)\n             228 LOAD_ATTR               14 (hidden_states)\n\n1578         230 LOAD_FAST               15 (outputs)\n             232 LOAD_ATTR               15 (attentions)\n\n1579         234 LOAD_FAST               15 (outputs)\n             236 LOAD_ATTR               16 (cross_attentions)\n\n1573         238 LOAD_CONST               6 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n             240 CALL_FUNCTION_KW         6\n             242 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 557 \n557           0 LOAD_FAST                0 (___stack0)\n              2 CALL_FUNCTION            0\n              4 SETUP_WITH              10 (to 26)\n              6 POP_TOP\n              8 LOAD_FAST                1 (___stack1)\n             10 JUMP_ABSOLUTE           44 (to 88)\n             12 POP_BLOCK\n             14 LOAD_CONST               0 (None)\n             16 DUP_TOP\n             18 DUP_TOP\n             20 CALL_FUNCTION            3\n             22 POP_TOP\n             24 JUMP_FORWARD             8 (to 42)\n        >>   26 WITH_EXCEPT_START\n             28 POP_JUMP_IF_TRUE        16 (to 32)\n             30 RERAISE                  0\n        >>   32 POP_TOP\n             34 POP_TOP\n             36 POP_TOP\n             38 POP_EXCEPT\n             40 POP_TOP\n        >>   42 NOP\n             44 LOAD_CONST               0 (None)\n             46 RAISE_VARARGS            1\n             48 LOAD_GLOBAL              0 (clone_inputs)\n             50 LOAD_FAST                6 (inputs)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (cloned_inputs)\n             56 LOAD_FAST                2 (self)\n             58 LOAD_ATTR                1 (optimizer_zero_grad)\n             60 LOAD_FAST                3 (mod)\n             62 CALL_FUNCTION            1\n             64 POP_TOP\n             66 LOAD_FAST                2 (self)\n             68 LOAD_ATTR                2 (autocast)\n             70 CALL_FUNCTION            0\n             72 SETUP_WITH              20 (to 114)\n             74 POP_TOP\n             76 LOAD_FAST                3 (mod)\n             78 LOAD_CONST               1 (())\n             80 BUILD_MAP                0\n             82 LOAD_FAST                5 (cloned_inputs)\n             84 DICT_MERGE               1\n             86 CALL_FUNCTION_EX         1\n        >>   88 STORE_FAST               7 (pred)\n\n558          90 LOAD_FAST                2 (self)\n             92 LOAD_ATTR                3 (compute_loss)\n             94 LOAD_FAST                7 (pred)\n             96 CALL_FUNCTION            1\n             98 STORE_FAST               8 (loss)\n            100 POP_BLOCK\n\n556         102 LOAD_CONST               0 (None)\n            104 DUP_TOP\n            106 DUP_TOP\n            108 CALL_FUNCTION            3\n            110 POP_TOP\n            112 JUMP_FORWARD             8 (to 130)\n        >>  114 WITH_EXCEPT_START\n            116 POP_JUMP_IF_TRUE        60 (to 120)\n            118 RERAISE                  1\n        >>  120 POP_TOP\n            122 POP_TOP\n            124 POP_TOP\n            126 POP_EXCEPT\n            128 POP_TOP\n\n559     >>  130 LOAD_FAST                2 (self)\n            132 LOAD_ATTR                4 (grad_scaler)\n            134 LOAD_ATTR                5 (scale)\n            136 LOAD_FAST                8 (loss)\n            138 CALL_FUNCTION            1\n            140 LOAD_ATTR                6 (backward)\n            142 CALL_FUNCTION            0\n            144 POP_TOP\n\n560         146 LOAD_FAST                2 (self)\n            148 LOAD_ATTR                7 (optimizer_step)\n            150 CALL_FUNCTION            0\n            152 POP_TOP\n\n561         154 LOAD_FAST                4 (collect_outputs)\n            156 POP_JUMP_IF_FALSE       86 (to 172)\n\n562         158 LOAD_GLOBAL              8 (collect_results)\n            160 LOAD_FAST                3 (mod)\n            162 LOAD_FAST                7 (pred)\n            164 LOAD_FAST                8 (loss)\n            166 LOAD_FAST                5 (cloned_inputs)\n            168 CALL_FUNCTION            4\n            170 RETURN_VALUE\n\n563     >>  172 LOAD_CONST               0 (None)\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 1266 \n1296           0 LOAD_FAST               16 (return_dict)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               16 (return_dict)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (use_return_dict)\n         >>   18 STORE_FAST              16 (return_dict)\n\n1298          20 LOAD_FAST               12 (labels)\n              22 LOAD_CONST               1 (None)\n              24 IS_OP                    1\n              26 POP_JUMP_IF_FALSE       41 (to 82)\n\n1299          28 LOAD_FAST               13 (use_cache)\n              30 POP_JUMP_IF_FALSE       21 (to 42)\n\n1300          32 LOAD_GLOBAL              2 (logger)\n              34 LOAD_METHOD              3 (warning)\n              36 LOAD_CONST               2 ('The `use_cache` argument is changed to `False` since `labels` is provided.')\n              38 CALL_METHOD              1\n              40 POP_TOP\n\n1301     >>   42 LOAD_CONST               3 (False)\n              44 STORE_FAST              13 (use_cache)\n\n1302          46 LOAD_FAST                3 (decoder_input_ids)\n              48 LOAD_CONST               1 (None)\n              50 IS_OP                    0\n              52 POP_JUMP_IF_FALSE       41 (to 82)\n              54 LOAD_FAST               11 (decoder_inputs_embeds)\n              56 LOAD_CONST               1 (None)\n              58 IS_OP                    0\n              60 POP_JUMP_IF_FALSE       41 (to 82)\n\n1303          62 LOAD_GLOBAL              4 (shift_tokens_right)\n\n1304          64 LOAD_FAST               12 (labels)\n              66 LOAD_FAST                0 (self)\n              68 LOAD_ATTR                0 (config)\n              70 LOAD_ATTR                5 (pad_token_id)\n              72 LOAD_FAST                0 (self)\n              74 LOAD_ATTR                0 (config)\n              76 LOAD_ATTR                6 (decoder_start_token_id)\n\n1303          78 CALL_FUNCTION            3\n              80 STORE_FAST               3 (decoder_input_ids)\n\n1307     >>   82 LOAD_FAST                0 (self)\n              84 LOAD_ATTR                7 (model)\n\n1308          86 LOAD_FAST                1 (input_ids)\n\n1309          88 LOAD_FAST                2 (attention_mask)\n\n1310          90 LOAD_FAST                3 (decoder_input_ids)\n\n1311          92 LOAD_FAST                8 (encoder_outputs)\n\n1312          94 LOAD_FAST                4 (decoder_attention_mask)\n\n1313          96 LOAD_FAST                5 (head_mask)\n\n1314          98 LOAD_FAST                6 (decoder_head_mask)\n\n1315         100 LOAD_FAST                7 (cross_attn_head_mask)\n\n1316         102 LOAD_FAST                9 (past_key_values)\n\n1317         104 LOAD_FAST               10 (inputs_embeds)\n\n1318         106 LOAD_FAST               11 (decoder_inputs_embeds)\n\n1319         108 LOAD_FAST               13 (use_cache)\n\n1320         110 LOAD_FAST               14 (output_attentions)\n\n1321         112 LOAD_FAST               15 (output_hidden_states)\n\n1322         114 LOAD_FAST               16 (return_dict)\n\n1307         116 LOAD_CONST               4 (('attention_mask', 'decoder_input_ids', 'encoder_outputs', 'decoder_attention_mask', 'head_mask', 'decoder_head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'decoder_inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             118 CALL_FUNCTION_KW        15\n             120 STORE_FAST              17 (outputs)\n\n1324         122 LOAD_FAST                0 (self)\n             124 LOAD_METHOD              8 (lm_head)\n             126 LOAD_FAST               17 (outputs)\n             128 LOAD_CONST               5 (0)\n             130 BINARY_SUBSCR\n             132 CALL_METHOD              1\n             134 LOAD_FAST                0 (self)\n             136 LOAD_ATTR                9 (final_logits_bias)\n             138 BINARY_ADD\n             140 STORE_FAST              18 (lm_logits)\n\n1326         142 LOAD_CONST               1 (None)\n             144 STORE_FAST              19 (masked_lm_loss)\n\n1327         146 LOAD_FAST               12 (labels)\n             148 LOAD_CONST               1 (None)\n             150 IS_OP                    1\n             152 POP_JUMP_IF_FALSE       94 (to 188)\n\n1328         154 LOAD_GLOBAL             10 (CrossEntropyLoss)\n             156 CALL_FUNCTION            0\n             158 STORE_FAST              20 (loss_fct)\n\n1329         160 LOAD_FAST               20 (loss_fct)\n             162 LOAD_FAST               18 (lm_logits)\n             164 LOAD_METHOD             11 (view)\n             166 LOAD_CONST               6 (-1)\n             168 LOAD_FAST                0 (self)\n             170 LOAD_ATTR                0 (config)\n             172 LOAD_ATTR               12 (vocab_size)\n             174 CALL_METHOD              2\n             176 LOAD_FAST               12 (labels)\n             178 LOAD_METHOD             11 (view)\n             180 LOAD_CONST               6 (-1)\n             182 CALL_METHOD              1\n             184 CALL_FUNCTION            2\n             186 STORE_FAST              19 (masked_lm_loss)\n\n1331     >>  188 LOAD_FAST               16 (return_dict)\n             190 POP_JUMP_IF_TRUE       116 (to 232)\n\n1332         192 LOAD_FAST               18 (lm_logits)\n             194 BUILD_TUPLE              1\n             196 LOAD_FAST               17 (outputs)\n             198 LOAD_CONST               7 (1)\n             200 LOAD_CONST               1 (None)\n             202 BUILD_SLICE              2\n             204 BINARY_SUBSCR\n             206 BINARY_ADD\n             208 STORE_FAST              21 (output)\n\n1333         210 LOAD_FAST               19 (masked_lm_loss)\n             212 LOAD_CONST               1 (None)\n             214 IS_OP                    1\n             216 POP_JUMP_IF_FALSE      114 (to 228)\n             218 LOAD_FAST               19 (masked_lm_loss)\n             220 BUILD_TUPLE              1\n             222 LOAD_FAST               21 (output)\n             224 BINARY_ADD\n             226 RETURN_VALUE\n         >>  228 LOAD_FAST               21 (output)\n             230 RETURN_VALUE\n\n1335     >>  232 LOAD_GLOBAL             13 (Seq2SeqLMOutput)\n\n1336         234 LOAD_FAST               19 (masked_lm_loss)\n\n1337         236 LOAD_FAST               18 (lm_logits)\n\n1338         238 LOAD_FAST               17 (outputs)\n             240 LOAD_ATTR               14 (past_key_values)\n\n1339         242 LOAD_FAST               17 (outputs)\n             244 LOAD_ATTR               15 (decoder_hidden_states)\n\n1340         246 LOAD_FAST               17 (outputs)\n             248 LOAD_ATTR               16 (decoder_attentions)\n\n1341         250 LOAD_FAST               17 (outputs)\n             252 LOAD_ATTR               17 (cross_attentions)\n\n1342         254 LOAD_FAST               17 (outputs)\n             256 LOAD_ATTR               18 (encoder_last_hidden_state)\n\n1343         258 LOAD_FAST               17 (outputs)\n             260 LOAD_ATTR               19 (encoder_hidden_states)\n\n1344         262 LOAD_FAST               17 (outputs)\n             264 LOAD_ATTR               20 (encoder_attentions)\n\n1335         266 LOAD_CONST               8 (('loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             268 CALL_FUNCTION_KW         9\n             270 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 1127 \n1166           0 LOAD_FAST               13 (output_attentions)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               13 (output_attentions)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (output_attentions)\n         >>   18 STORE_FAST              13 (output_attentions)\n\n1168          20 LOAD_FAST               14 (output_hidden_states)\n              22 LOAD_CONST               1 (None)\n              24 IS_OP                    1\n              26 POP_JUMP_IF_FALSE       16 (to 32)\n              28 LOAD_FAST               14 (output_hidden_states)\n              30 JUMP_FORWARD             3 (to 38)\n         >>   32 LOAD_FAST                0 (self)\n              34 LOAD_ATTR                0 (config)\n              36 LOAD_ATTR                2 (output_hidden_states)\n\n1167     >>   38 STORE_FAST              14 (output_hidden_states)\n\n1170          40 LOAD_FAST               12 (use_cache)\n              42 LOAD_CONST               1 (None)\n              44 IS_OP                    1\n              46 POP_JUMP_IF_FALSE       26 (to 52)\n              48 LOAD_FAST               12 (use_cache)\n              50 JUMP_FORWARD             3 (to 58)\n         >>   52 LOAD_FAST                0 (self)\n              54 LOAD_ATTR                0 (config)\n              56 LOAD_ATTR                3 (use_cache)\n         >>   58 STORE_FAST              12 (use_cache)\n\n1171          60 LOAD_FAST               15 (return_dict)\n              62 LOAD_CONST               1 (None)\n              64 IS_OP                    1\n              66 POP_JUMP_IF_FALSE       36 (to 72)\n              68 LOAD_FAST               15 (return_dict)\n              70 JUMP_FORWARD             3 (to 78)\n         >>   72 LOAD_FAST                0 (self)\n              74 LOAD_ATTR                0 (config)\n              76 LOAD_ATTR                4 (use_return_dict)\n         >>   78 STORE_FAST              15 (return_dict)\n\n1173          80 LOAD_FAST                8 (encoder_outputs)\n              82 LOAD_CONST               1 (None)\n              84 IS_OP                    0\n              86 POP_JUMP_IF_FALSE       57 (to 114)\n\n1174          88 LOAD_FAST                0 (self)\n              90 LOAD_ATTR                5 (encoder)\n\n1175          92 LOAD_FAST                1 (input_ids)\n\n1176          94 LOAD_FAST                2 (attention_mask)\n\n1177          96 LOAD_FAST                5 (head_mask)\n\n1178          98 LOAD_FAST               10 (inputs_embeds)\n\n1179         100 LOAD_FAST               13 (output_attentions)\n\n1180         102 LOAD_FAST               14 (output_hidden_states)\n\n1181         104 LOAD_FAST               15 (return_dict)\n\n1174         106 LOAD_CONST               2 (('input_ids', 'attention_mask', 'head_mask', 'inputs_embeds', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             108 CALL_FUNCTION_KW         7\n             110 STORE_FAST               8 (encoder_outputs)\n             112 JUMP_FORWARD            36 (to 186)\n\n1184     >>  114 LOAD_FAST               15 (return_dict)\n             116 POP_JUMP_IF_FALSE       93 (to 186)\n             118 LOAD_GLOBAL              6 (isinstance)\n             120 LOAD_FAST                8 (encoder_outputs)\n             122 LOAD_GLOBAL              7 (BaseModelOutput)\n             124 CALL_FUNCTION            2\n             126 POP_JUMP_IF_TRUE        93 (to 186)\n\n1185         128 LOAD_GLOBAL              7 (BaseModelOutput)\n\n1186         130 LOAD_FAST                8 (encoder_outputs)\n             132 LOAD_CONST               3 (0)\n             134 BINARY_SUBSCR\n\n1187         136 LOAD_GLOBAL              8 (len)\n             138 LOAD_FAST                8 (encoder_outputs)\n             140 CALL_FUNCTION            1\n             142 LOAD_CONST               4 (1)\n             144 COMPARE_OP               4 (>)\n             146 POP_JUMP_IF_FALSE       78 (to 156)\n             148 LOAD_FAST                8 (encoder_outputs)\n             150 LOAD_CONST               4 (1)\n             152 BINARY_SUBSCR\n             154 JUMP_FORWARD             1 (to 158)\n         >>  156 LOAD_CONST               1 (None)\n\n1188     >>  158 LOAD_GLOBAL              8 (len)\n             160 LOAD_FAST                8 (encoder_outputs)\n             162 CALL_FUNCTION            1\n             164 LOAD_CONST               5 (2)\n             166 COMPARE_OP               4 (>)\n             168 POP_JUMP_IF_FALSE       89 (to 178)\n             170 LOAD_FAST                8 (encoder_outputs)\n             172 LOAD_CONST               5 (2)\n             174 BINARY_SUBSCR\n             176 JUMP_FORWARD             1 (to 180)\n         >>  178 LOAD_CONST               1 (None)\n\n1185     >>  180 LOAD_CONST               6 (('last_hidden_state', 'hidden_states', 'attentions'))\n             182 CALL_FUNCTION_KW         3\n             184 STORE_FAST               8 (encoder_outputs)\n\n1192     >>  186 LOAD_FAST                0 (self)\n             188 LOAD_ATTR                9 (decoder)\n\n1193         190 LOAD_FAST                3 (decoder_input_ids)\n\n1194         192 LOAD_FAST                4 (decoder_attention_mask)\n\n1195         194 LOAD_FAST                8 (encoder_outputs)\n             196 LOAD_CONST               3 (0)\n             198 BINARY_SUBSCR\n\n1196         200 LOAD_FAST                2 (attention_mask)\n\n1197         202 LOAD_FAST                6 (decoder_head_mask)\n\n1198         204 LOAD_FAST                7 (cross_attn_head_mask)\n\n1199         206 LOAD_FAST                9 (past_key_values)\n\n1200         208 LOAD_FAST               11 (decoder_inputs_embeds)\n\n1201         210 LOAD_FAST               12 (use_cache)\n\n1202         212 LOAD_FAST               13 (output_attentions)\n\n1203         214 LOAD_FAST               14 (output_hidden_states)\n\n1204         216 LOAD_FAST               15 (return_dict)\n\n1192         218 LOAD_CONST               7 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             220 CALL_FUNCTION_KW        12\n             222 STORE_FAST              16 (decoder_outputs)\n\n1207         224 LOAD_FAST               15 (return_dict)\n             226 POP_JUMP_IF_TRUE       118 (to 236)\n\n1208         228 LOAD_FAST               16 (decoder_outputs)\n             230 LOAD_FAST                8 (encoder_outputs)\n             232 BINARY_ADD\n             234 RETURN_VALUE\n\n1210     >>  236 LOAD_GLOBAL             10 (Seq2SeqModelOutput)\n\n1211         238 LOAD_FAST               16 (decoder_outputs)\n             240 LOAD_ATTR               11 (last_hidden_state)\n\n1212         242 LOAD_FAST               16 (decoder_outputs)\n             244 LOAD_ATTR               12 (past_key_values)\n\n1213         246 LOAD_FAST               16 (decoder_outputs)\n             248 LOAD_ATTR               13 (hidden_states)\n\n1214         250 LOAD_FAST               16 (decoder_outputs)\n             252 LOAD_ATTR               14 (attentions)\n\n1215         254 LOAD_FAST               16 (decoder_outputs)\n             256 LOAD_ATTR               15 (cross_attentions)\n\n1216         258 LOAD_FAST                8 (encoder_outputs)\n             260 LOAD_ATTR               11 (last_hidden_state)\n\n1217         262 LOAD_FAST                8 (encoder_outputs)\n             264 LOAD_ATTR               13 (hidden_states)\n\n1218         266 LOAD_FAST                8 (encoder_outputs)\n             268 LOAD_ATTR               14 (attentions)\n\n1210         270 LOAD_CONST               8 (('last_hidden_state', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             272 CALL_FUNCTION_KW         8\n             274 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 116 \n118           0 LOAD_FAST                1 (input_ids_shape)\n              2 LOAD_CONST               1 (None)\n              4 LOAD_CONST               2 (2)\n              6 BUILD_SLICE              2\n              8 BINARY_SUBSCR\n             10 UNPACK_SEQUENCE          2\n             12 STORE_FAST               3 (bsz)\n             14 STORE_FAST               4 (seq_len)\n\n119          16 LOAD_GLOBAL              0 (torch)\n             18 LOAD_ATTR                1 (arange)\n\n120          20 LOAD_FAST                2 (past_key_values_length)\n             22 LOAD_FAST                2 (past_key_values_length)\n             24 LOAD_FAST                4 (seq_len)\n             26 BINARY_ADD\n             28 LOAD_GLOBAL              0 (torch)\n             30 LOAD_ATTR                2 (long)\n             32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                3 (weight)\n             36 LOAD_ATTR                4 (device)\n\n119          38 LOAD_CONST               3 (('dtype', 'device'))\n             40 CALL_FUNCTION_KW         4\n             42 STORE_FAST               5 (positions)\n\n122          44 LOAD_GLOBAL              5 (super)\n             46 CALL_FUNCTION            0\n             48 LOAD_METHOD              6 (forward)\n             50 LOAD_FAST                5 (positions)\n             52 CALL_METHOD              1\n             54 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 298 \n316           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n317           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n318           8 LOAD_FAST                1 (hidden_states)\n\n319          10 LOAD_FAST                2 (attention_mask)\n\n320          12 LOAD_FAST                3 (layer_head_mask)\n\n321          14 LOAD_FAST                4 (output_attentions)\n\n317          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n323          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n324          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n325          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n327          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n328          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n329          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n330         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n331         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n332         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n333         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n335         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n336         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n335         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n336         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n335         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n338     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n339         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n341     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n343         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n344         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n346     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 298 \n316           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n317           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n318           8 LOAD_FAST                1 (hidden_states)\n\n319          10 LOAD_FAST                2 (attention_mask)\n\n320          12 LOAD_FAST                3 (layer_head_mask)\n\n321          14 LOAD_FAST                4 (output_attentions)\n\n317          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n323          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n324          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n325          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n327          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n328          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n329          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n330         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n331         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n332         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n333         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n335         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n336         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n335         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n336         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n335         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n338     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n339         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n341     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n343         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n344         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n346     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 298 \n316           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n317           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n318           8 LOAD_FAST                1 (hidden_states)\n\n319          10 LOAD_FAST                2 (attention_mask)\n\n320          12 LOAD_FAST                3 (layer_head_mask)\n\n321          14 LOAD_FAST                4 (output_attentions)\n\n317          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n323          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n324          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n325          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n327          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n328          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n329          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n330         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n331         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n332         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n333         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n335         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n336         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n335         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n336         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n335         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n338     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n339         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n341     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n343         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n344         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n346     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 298 \n316           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n317           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n318           8 LOAD_FAST                1 (hidden_states)\n\n319          10 LOAD_FAST                2 (attention_mask)\n\n320          12 LOAD_FAST                3 (layer_head_mask)\n\n321          14 LOAD_FAST                4 (output_attentions)\n\n317          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n323          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n324          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n325          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n327          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n328          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n329          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n330         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n331         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n332         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n333         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n335         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n336         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n335         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n336         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n335         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n338     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n339         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n341     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n343         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n344         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n346     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 298 \n316           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n317           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n318           8 LOAD_FAST                1 (hidden_states)\n\n319          10 LOAD_FAST                2 (attention_mask)\n\n320          12 LOAD_FAST                3 (layer_head_mask)\n\n321          14 LOAD_FAST                4 (output_attentions)\n\n317          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n323          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n324          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n325          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n327          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n328          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n329          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n330         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n331         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n332         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n333         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n335         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n336         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n335         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n336         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n335         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n338     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n339         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n341     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n343         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n344         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n346     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 298 \n316           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n317           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n318           8 LOAD_FAST                1 (hidden_states)\n\n319          10 LOAD_FAST                2 (attention_mask)\n\n320          12 LOAD_FAST                3 (layer_head_mask)\n\n321          14 LOAD_FAST                4 (output_attentions)\n\n317          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n323          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n324          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n325          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n327          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n328          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n329          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n330         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n331         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n332         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n333         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n335         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n336         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n335         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n336         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n335         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n338     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n339         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n341     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n343         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n344         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n346     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 298 \n316           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n317           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n318           8 LOAD_FAST                1 (hidden_states)\n\n319          10 LOAD_FAST                2 (attention_mask)\n\n320          12 LOAD_FAST                3 (layer_head_mask)\n\n321          14 LOAD_FAST                4 (output_attentions)\n\n317          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n323          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n324          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n325          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n327          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n328          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n329          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n330         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n331         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n332         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n333         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n335         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n336         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n335         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n336         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n335         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n338     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n339         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n341     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n343         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n344         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n346     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 298 \n316           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n317           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n318           8 LOAD_FAST                1 (hidden_states)\n\n319          10 LOAD_FAST                2 (attention_mask)\n\n320          12 LOAD_FAST                3 (layer_head_mask)\n\n321          14 LOAD_FAST                4 (output_attentions)\n\n317          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n323          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n324          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n325          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n327          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n328          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n329          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n330         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n331         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n332         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n333         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n335         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n336         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n335         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n336         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n335         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n338     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n339         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n341     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n343         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n344         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n346     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (hidden_states)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (hidden_states)\n\n  5          12 LOAD_FAST                3 (attentions)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (attentions)\n\n  6          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              3 (__post_init__)\n             22 CALL_METHOD              0\n             24 POP_TOP\n             26 LOAD_CONST               0 (None)\n             28 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 1174 \n1174           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           57 (to 114)\n               4 LOAD_FAST               10 (output_attentions)\n               6 LOAD_CONST               1 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST               10 (output_attentions)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (output_attentions)\n         >>   22 STORE_FAST              10 (output_attentions)\n              24 LOAD_FAST               11 (output_hidden_states)\n              26 LOAD_CONST               1 (None)\n              28 IS_OP                    1\n              30 POP_JUMP_IF_FALSE       18 (to 36)\n              32 LOAD_FAST               11 (output_hidden_states)\n              34 JUMP_FORWARD             3 (to 42)\n         >>   36 LOAD_FAST                1 (self)\n              38 LOAD_ATTR                0 (config)\n              40 LOAD_ATTR                2 (output_hidden_states)\n         >>   42 STORE_FAST              11 (output_hidden_states)\n              44 LOAD_FAST                9 (use_cache)\n              46 LOAD_CONST               1 (None)\n              48 IS_OP                    1\n              50 POP_JUMP_IF_FALSE       28 (to 56)\n              52 LOAD_FAST                9 (use_cache)\n              54 JUMP_FORWARD             3 (to 62)\n         >>   56 LOAD_FAST                1 (self)\n              58 LOAD_ATTR                0 (config)\n              60 LOAD_ATTR                3 (use_cache)\n         >>   62 STORE_FAST               9 (use_cache)\n              64 LOAD_FAST               12 (return_dict)\n              66 LOAD_CONST               1 (None)\n              68 IS_OP                    1\n              70 POP_JUMP_IF_FALSE       38 (to 76)\n              72 LOAD_FAST               12 (return_dict)\n              74 JUMP_FORWARD             3 (to 82)\n         >>   76 LOAD_FAST                1 (self)\n              78 LOAD_ATTR                0 (config)\n              80 LOAD_ATTR                4 (use_return_dict)\n         >>   82 STORE_FAST              12 (return_dict)\n              84 LOAD_FAST               15 (encoder_outputs)\n              86 LOAD_CONST               1 (None)\n              88 IS_OP                    0\n              90 POP_JUMP_IF_FALSE       59 (to 118)\n              92 LOAD_FAST                1 (self)\n              94 LOAD_ATTR                5 (encoder)\n              96 LOAD_FAST               13 (input_ids)\n              98 LOAD_FAST                2 (attention_mask)\n             100 LOAD_FAST               14 (head_mask)\n             102 LOAD_FAST               16 (inputs_embeds)\n             104 LOAD_FAST               10 (output_attentions)\n             106 LOAD_FAST               11 (output_hidden_states)\n             108 LOAD_FAST               12 (return_dict)\n             110 LOAD_CONST               2 (('input_ids', 'attention_mask', 'head_mask', 'inputs_embeds', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             112 CALL_FUNCTION_KW         7\n         >>  114 STORE_FAST              15 (encoder_outputs)\n             116 JUMP_FORWARD            36 (to 190)\n\n1184     >>  118 LOAD_FAST               12 (return_dict)\n             120 POP_JUMP_IF_FALSE       95 (to 190)\n             122 LOAD_GLOBAL              6 (isinstance)\n             124 LOAD_FAST               15 (encoder_outputs)\n             126 LOAD_GLOBAL              7 (BaseModelOutput)\n             128 CALL_FUNCTION            2\n             130 POP_JUMP_IF_TRUE        95 (to 190)\n\n1185         132 LOAD_GLOBAL              7 (BaseModelOutput)\n\n1186         134 LOAD_FAST               15 (encoder_outputs)\n             136 LOAD_CONST               3 (0)\n             138 BINARY_SUBSCR\n\n1187         140 LOAD_GLOBAL              8 (len)\n             142 LOAD_FAST               15 (encoder_outputs)\n             144 CALL_FUNCTION            1\n             146 LOAD_CONST               4 (1)\n             148 COMPARE_OP               4 (>)\n             150 POP_JUMP_IF_FALSE       80 (to 160)\n             152 LOAD_FAST               15 (encoder_outputs)\n             154 LOAD_CONST               4 (1)\n             156 BINARY_SUBSCR\n             158 JUMP_FORWARD             1 (to 162)\n         >>  160 LOAD_CONST               1 (None)\n\n1188     >>  162 LOAD_GLOBAL              8 (len)\n             164 LOAD_FAST               15 (encoder_outputs)\n             166 CALL_FUNCTION            1\n             168 LOAD_CONST               5 (2)\n             170 COMPARE_OP               4 (>)\n             172 POP_JUMP_IF_FALSE       91 (to 182)\n             174 LOAD_FAST               15 (encoder_outputs)\n             176 LOAD_CONST               5 (2)\n             178 BINARY_SUBSCR\n             180 JUMP_FORWARD             1 (to 184)\n         >>  182 LOAD_CONST               1 (None)\n\n1185     >>  184 LOAD_CONST               6 (('last_hidden_state', 'hidden_states', 'attentions'))\n             186 CALL_FUNCTION_KW         3\n             188 STORE_FAST              15 (encoder_outputs)\n\n1192     >>  190 LOAD_FAST                1 (self)\n             192 LOAD_ATTR                9 (decoder)\n\n1193         194 LOAD_FAST                3 (decoder_input_ids)\n\n1194         196 LOAD_FAST                4 (decoder_attention_mask)\n\n1195         198 LOAD_FAST               15 (encoder_outputs)\n             200 LOAD_CONST               3 (0)\n             202 BINARY_SUBSCR\n\n1196         204 LOAD_FAST                2 (attention_mask)\n\n1197         206 LOAD_FAST                5 (decoder_head_mask)\n\n1198         208 LOAD_FAST                6 (cross_attn_head_mask)\n\n1199         210 LOAD_FAST                7 (past_key_values)\n\n1200         212 LOAD_FAST                8 (decoder_inputs_embeds)\n\n1201         214 LOAD_FAST                9 (use_cache)\n\n1202         216 LOAD_FAST               10 (output_attentions)\n\n1203         218 LOAD_FAST               11 (output_hidden_states)\n\n1204         220 LOAD_FAST               12 (return_dict)\n\n1192         222 LOAD_CONST               7 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             224 CALL_FUNCTION_KW        12\n             226 STORE_FAST              17 (decoder_outputs)\n\n1207         228 LOAD_FAST               12 (return_dict)\n             230 POP_JUMP_IF_TRUE       120 (to 240)\n\n1208         232 LOAD_FAST               17 (decoder_outputs)\n             234 LOAD_FAST               15 (encoder_outputs)\n             236 BINARY_ADD\n             238 RETURN_VALUE\n\n1210     >>  240 LOAD_GLOBAL             10 (Seq2SeqModelOutput)\n\n1211         242 LOAD_FAST               17 (decoder_outputs)\n             244 LOAD_ATTR               11 (last_hidden_state)\n\n1212         246 LOAD_FAST               17 (decoder_outputs)\n             248 LOAD_ATTR               12 (past_key_values)\n\n1213         250 LOAD_FAST               17 (decoder_outputs)\n             252 LOAD_ATTR               13 (hidden_states)\n\n1214         254 LOAD_FAST               17 (decoder_outputs)\n             256 LOAD_ATTR               14 (attentions)\n\n1215         258 LOAD_FAST               17 (decoder_outputs)\n             260 LOAD_ATTR               15 (cross_attentions)\n\n1216         262 LOAD_FAST               15 (encoder_outputs)\n             264 LOAD_ATTR               11 (last_hidden_state)\n\n1217         266 LOAD_FAST               15 (encoder_outputs)\n             268 LOAD_ATTR               13 (hidden_states)\n\n1218         270 LOAD_FAST               15 (encoder_outputs)\n             272 LOAD_ATTR               14 (attentions)\n\n1210         274 LOAD_CONST               8 (('last_hidden_state', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             276 CALL_FUNCTION_KW         8\n             278 RETURN_VALUE\n\n", "ORIGINAL BYTECODE _prepare_decoder_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 853 \n856           0 LOAD_CONST               0 (None)\n              2 STORE_FAST               5 (combined_attention_mask)\n\n857           4 LOAD_FAST                2 (input_shape)\n              6 LOAD_CONST               1 (-1)\n              8 BINARY_SUBSCR\n             10 LOAD_CONST               2 (1)\n             12 COMPARE_OP               4 (>)\n             14 POP_JUMP_IF_FALSE       18 (to 36)\n\n858          16 LOAD_GLOBAL              0 (_make_causal_mask)\n\n859          18 LOAD_FAST                2 (input_shape)\n\n860          20 LOAD_FAST                3 (inputs_embeds)\n             22 LOAD_ATTR                1 (dtype)\n\n861          24 LOAD_FAST                3 (inputs_embeds)\n             26 LOAD_ATTR                2 (device)\n\n862          28 LOAD_FAST                4 (past_key_values_length)\n\n858          30 LOAD_CONST               3 (('device', 'past_key_values_length'))\n             32 CALL_FUNCTION_KW         4\n             34 STORE_FAST               5 (combined_attention_mask)\n\n865     >>   36 LOAD_FAST                1 (attention_mask)\n             38 LOAD_CONST               0 (None)\n             40 IS_OP                    1\n             42 POP_JUMP_IF_FALSE       46 (to 92)\n\n867          44 LOAD_GLOBAL              3 (_expand_mask)\n             46 LOAD_FAST                1 (attention_mask)\n             48 LOAD_FAST                3 (inputs_embeds)\n             50 LOAD_ATTR                1 (dtype)\n             52 LOAD_FAST                2 (input_shape)\n             54 LOAD_CONST               1 (-1)\n             56 BINARY_SUBSCR\n             58 LOAD_CONST               4 (('tgt_len',))\n             60 CALL_FUNCTION_KW         3\n             62 LOAD_METHOD              4 (to)\n\n868          64 LOAD_FAST                3 (inputs_embeds)\n             66 LOAD_ATTR                2 (device)\n\n867          68 CALL_METHOD              1\n             70 STORE_FAST               6 (expanded_attn_mask)\n\n871          72 LOAD_FAST                5 (combined_attention_mask)\n             74 LOAD_CONST               0 (None)\n             76 IS_OP                    0\n             78 POP_JUMP_IF_FALSE       42 (to 84)\n             80 LOAD_FAST                6 (expanded_attn_mask)\n             82 JUMP_FORWARD             3 (to 90)\n        >>   84 LOAD_FAST                6 (expanded_attn_mask)\n             86 LOAD_FAST                5 (combined_attention_mask)\n             88 BINARY_ADD\n\n870     >>   90 STORE_FAST               5 (combined_attention_mask)\n\n874     >>   92 LOAD_FAST                5 (combined_attention_mask)\n             94 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 116 \n118           0 LOAD_FAST                1 (input_ids_shape)\n              2 LOAD_CONST               1 (None)\n              4 LOAD_CONST               2 (2)\n              6 BUILD_SLICE              2\n              8 BINARY_SUBSCR\n             10 UNPACK_SEQUENCE          2\n             12 STORE_FAST               3 (bsz)\n             14 STORE_FAST               4 (seq_len)\n\n119          16 LOAD_GLOBAL              0 (torch)\n             18 LOAD_ATTR                1 (arange)\n\n120          20 LOAD_FAST                2 (past_key_values_length)\n             22 LOAD_FAST                2 (past_key_values_length)\n             24 LOAD_FAST                4 (seq_len)\n             26 BINARY_ADD\n             28 LOAD_GLOBAL              0 (torch)\n             30 LOAD_ATTR                2 (long)\n             32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                3 (weight)\n             36 LOAD_ATTR                4 (device)\n\n119          38 LOAD_CONST               3 (('dtype', 'device'))\n             40 CALL_FUNCTION_KW         4\n             42 STORE_FAST               5 (positions)\n\n122          44 LOAD_GLOBAL              5 (super)\n             46 CALL_FUNCTION            0\n             48 LOAD_METHOD              6 (forward)\n             50 LOAD_FAST                5 (positions)\n             52 CALL_METHOD              1\n             54 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 377 \n407           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n411           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n413          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n414          32 LOAD_FAST                1 (hidden_states)\n\n415          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n416          36 LOAD_FAST                2 (attention_mask)\n\n417          38 LOAD_FAST                5 (layer_head_mask)\n\n418          40 LOAD_FAST                8 (output_attentions)\n\n413          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n420          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n421          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n422          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n425          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n426          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n427         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n428         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n431         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n432         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n433         142 LOAD_FAST                1 (hidden_states)\n\n434         144 LOAD_FAST                3 (encoder_hidden_states)\n\n435         146 LOAD_FAST                4 (encoder_attention_mask)\n\n436         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n437         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n438         152 LOAD_FAST                8 (output_attentions)\n\n432         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n440         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n441         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n442         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n445         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n448     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n449         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n450         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n451         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n452         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n453         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n454         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n456         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n458         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n459         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n461     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n462         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n464     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 377 \n407           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n411           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n413          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n414          32 LOAD_FAST                1 (hidden_states)\n\n415          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n416          36 LOAD_FAST                2 (attention_mask)\n\n417          38 LOAD_FAST                5 (layer_head_mask)\n\n418          40 LOAD_FAST                8 (output_attentions)\n\n413          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n420          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n421          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n422          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n425          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n426          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n427         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n428         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n431         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n432         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n433         142 LOAD_FAST                1 (hidden_states)\n\n434         144 LOAD_FAST                3 (encoder_hidden_states)\n\n435         146 LOAD_FAST                4 (encoder_attention_mask)\n\n436         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n437         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n438         152 LOAD_FAST                8 (output_attentions)\n\n432         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n440         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n441         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n442         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n445         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n448     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n449         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n450         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n451         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n452         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n453         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n454         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n456         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n458         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n459         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n461     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n462         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n464     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 377 \n407           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n411           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n413          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n414          32 LOAD_FAST                1 (hidden_states)\n\n415          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n416          36 LOAD_FAST                2 (attention_mask)\n\n417          38 LOAD_FAST                5 (layer_head_mask)\n\n418          40 LOAD_FAST                8 (output_attentions)\n\n413          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n420          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n421          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n422          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n425          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n426          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n427         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n428         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n431         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n432         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n433         142 LOAD_FAST                1 (hidden_states)\n\n434         144 LOAD_FAST                3 (encoder_hidden_states)\n\n435         146 LOAD_FAST                4 (encoder_attention_mask)\n\n436         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n437         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n438         152 LOAD_FAST                8 (output_attentions)\n\n432         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n440         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n441         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n442         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n445         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n448     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n449         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n450         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n451         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n452         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n453         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n454         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n456         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n458         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n459         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n461     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n462         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n464     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 377 \n407           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n411           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n413          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n414          32 LOAD_FAST                1 (hidden_states)\n\n415          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n416          36 LOAD_FAST                2 (attention_mask)\n\n417          38 LOAD_FAST                5 (layer_head_mask)\n\n418          40 LOAD_FAST                8 (output_attentions)\n\n413          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n420          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n421          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n422          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n425          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n426          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n427         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n428         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n431         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n432         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n433         142 LOAD_FAST                1 (hidden_states)\n\n434         144 LOAD_FAST                3 (encoder_hidden_states)\n\n435         146 LOAD_FAST                4 (encoder_attention_mask)\n\n436         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n437         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n438         152 LOAD_FAST                8 (output_attentions)\n\n432         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n440         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n441         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n442         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n445         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n448     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n449         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n450         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n451         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n452         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n453         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n454         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n456         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n458         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n459         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n461     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n462         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n464     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 377 \n407           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n411           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n413          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n414          32 LOAD_FAST                1 (hidden_states)\n\n415          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n416          36 LOAD_FAST                2 (attention_mask)\n\n417          38 LOAD_FAST                5 (layer_head_mask)\n\n418          40 LOAD_FAST                8 (output_attentions)\n\n413          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n420          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n421          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n422          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n425          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n426          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n427         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n428         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n431         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n432         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n433         142 LOAD_FAST                1 (hidden_states)\n\n434         144 LOAD_FAST                3 (encoder_hidden_states)\n\n435         146 LOAD_FAST                4 (encoder_attention_mask)\n\n436         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n437         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n438         152 LOAD_FAST                8 (output_attentions)\n\n432         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n440         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n441         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n442         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n445         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n448     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n449         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n450         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n451         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n452         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n453         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n454         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n456         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n458         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n459         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n461     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n462         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n464     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 377 \n407           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n411           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n413          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n414          32 LOAD_FAST                1 (hidden_states)\n\n415          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n416          36 LOAD_FAST                2 (attention_mask)\n\n417          38 LOAD_FAST                5 (layer_head_mask)\n\n418          40 LOAD_FAST                8 (output_attentions)\n\n413          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n420          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n421          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n422          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n425          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n426          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n427         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n428         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n431         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n432         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n433         142 LOAD_FAST                1 (hidden_states)\n\n434         144 LOAD_FAST                3 (encoder_hidden_states)\n\n435         146 LOAD_FAST                4 (encoder_attention_mask)\n\n436         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n437         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n438         152 LOAD_FAST                8 (output_attentions)\n\n432         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n440         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n441         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n442         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n445         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n448     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n449         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n450         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n451         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n452         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n453         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n454         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n456         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n458         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n459         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n461     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n462         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n464     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 377 \n407           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n411           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n413          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n414          32 LOAD_FAST                1 (hidden_states)\n\n415          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n416          36 LOAD_FAST                2 (attention_mask)\n\n417          38 LOAD_FAST                5 (layer_head_mask)\n\n418          40 LOAD_FAST                8 (output_attentions)\n\n413          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n420          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n421          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n422          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n425          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n426          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n427         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n428         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n431         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n432         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n433         142 LOAD_FAST                1 (hidden_states)\n\n434         144 LOAD_FAST                3 (encoder_hidden_states)\n\n435         146 LOAD_FAST                4 (encoder_attention_mask)\n\n436         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n437         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n438         152 LOAD_FAST                8 (output_attentions)\n\n432         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n440         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n441         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n442         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n445         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n448     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n449         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n450         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n451         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n452         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n453         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n454         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n456         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n458         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n459         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n461     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n462         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n464     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 377 \n407           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n411           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n413          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n414          32 LOAD_FAST                1 (hidden_states)\n\n415          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n416          36 LOAD_FAST                2 (attention_mask)\n\n417          38 LOAD_FAST                5 (layer_head_mask)\n\n418          40 LOAD_FAST                8 (output_attentions)\n\n413          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n420          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n421          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n422          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n425          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n426          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n427         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n428         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n431         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n432         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n433         142 LOAD_FAST                1 (hidden_states)\n\n434         144 LOAD_FAST                3 (encoder_hidden_states)\n\n435         146 LOAD_FAST                4 (encoder_attention_mask)\n\n436         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n437         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n438         152 LOAD_FAST                8 (output_attentions)\n\n432         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n440         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n441         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n442         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n445         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n448     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n449         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n450         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n451         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n452         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n453         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n454         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n456         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n458         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n459         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n461     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n462         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n464     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (past_key_values)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (past_key_values)\n\n  5          12 LOAD_FAST                3 (hidden_states)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (hidden_states)\n\n  6          18 LOAD_FAST                4 (attentions)\n             20 LOAD_FAST                0 (self)\n             22 STORE_ATTR               3 (attentions)\n\n  7          24 LOAD_FAST                5 (cross_attentions)\n             26 LOAD_FAST                0 (self)\n             28 STORE_ATTR               4 (cross_attentions)\n\n  8          30 LOAD_FAST                0 (self)\n             32 LOAD_METHOD              5 (__post_init__)\n             34 CALL_METHOD              0\n             36 POP_TOP\n             38 LOAD_CONST               0 (None)\n             40 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (past_key_values)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (past_key_values)\n\n  5          12 LOAD_FAST                3 (decoder_hidden_states)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (decoder_hidden_states)\n\n  6          18 LOAD_FAST                4 (decoder_attentions)\n             20 LOAD_FAST                0 (self)\n             22 STORE_ATTR               3 (decoder_attentions)\n\n  7          24 LOAD_FAST                5 (cross_attentions)\n             26 LOAD_FAST                0 (self)\n             28 STORE_ATTR               4 (cross_attentions)\n\n  8          30 LOAD_FAST                6 (encoder_last_hidden_state)\n             32 LOAD_FAST                0 (self)\n             34 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          36 LOAD_FAST                7 (encoder_hidden_states)\n             38 LOAD_FAST                0 (self)\n             40 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          42 LOAD_FAST                8 (encoder_attentions)\n             44 LOAD_FAST                0 (self)\n             46 STORE_ATTR               7 (encoder_attentions)\n\n 11          48 LOAD_FAST                0 (self)\n             50 LOAD_METHOD              8 (__post_init__)\n             52 CALL_METHOD              0\n             54 POP_TOP\n             56 LOAD_CONST               0 (None)\n             58 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 3 \n  3           0 JUMP_ABSOLUTE            4 (to 8)\n              2 LOAD_FAST                8 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n\n  4     >>    8 LOAD_FAST                1 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5          14 LOAD_FAST                2 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n\n  6          20 LOAD_FAST                3 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7          26 LOAD_FAST                4 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                5 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                6 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                7 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 4 \n  4           0 JUMP_ABSOLUTE            7 (to 14)\n              2 LOAD_FAST                7 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                8 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5     >>   14 LOAD_FAST                1 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n\n  6          20 LOAD_FAST                2 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7          26 LOAD_FAST                3 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                4 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                5 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                6 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 5 \n  5           0 JUMP_ABSOLUTE           10 (to 20)\n              2 LOAD_FAST                6 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                7 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n             14 LOAD_FAST                8 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n\n  6     >>   20 LOAD_FAST                1 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7          26 LOAD_FAST                2 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                3 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                4 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                5 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 6 \n  6           0 JUMP_ABSOLUTE           13 (to 26)\n              2 LOAD_FAST                5 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                6 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n             14 LOAD_FAST                7 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n             20 LOAD_FAST                8 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7     >>   26 LOAD_FAST                1 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                2 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                3 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                4 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 7 \n  7           0 JUMP_ABSOLUTE           16 (to 32)\n              2 LOAD_FAST                4 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                5 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n             14 LOAD_FAST                6 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n             20 LOAD_FAST                7 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n             26 LOAD_FAST                8 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8     >>   32 LOAD_FAST                1 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                2 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                3 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/blenderbot_small/modeling_blenderbot_small.py line 1307 \n1307           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           62 (to 124)\n               4 LOAD_FAST                3 (return_dict)\n               6 LOAD_CONST               1 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST                3 (return_dict)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (use_return_dict)\n         >>   22 STORE_FAST               3 (return_dict)\n              24 LOAD_FAST                2 (labels)\n              26 LOAD_CONST               1 (None)\n              28 IS_OP                    1\n              30 POP_JUMP_IF_FALSE       43 (to 86)\n              32 LOAD_FAST               15 (use_cache)\n              34 POP_JUMP_IF_FALSE       23 (to 46)\n              36 LOAD_GLOBAL              2 (logger)\n              38 LOAD_ATTR                3 (warning)\n              40 LOAD_CONST               2 ('The `use_cache` argument is changed to `False` since `labels` is provided.')\n              42 CALL_FUNCTION            1\n              44 POP_TOP\n         >>   46 LOAD_CONST               3 (False)\n              48 STORE_FAST              15 (use_cache)\n              50 LOAD_FAST                6 (decoder_input_ids)\n              52 LOAD_CONST               1 (None)\n              54 IS_OP                    0\n              56 POP_JUMP_IF_FALSE       43 (to 86)\n              58 LOAD_FAST               14 (decoder_inputs_embeds)\n              60 LOAD_CONST               1 (None)\n              62 IS_OP                    0\n              64 POP_JUMP_IF_FALSE       43 (to 86)\n              66 LOAD_GLOBAL              4 (shift_tokens_right)\n              68 LOAD_FAST                2 (labels)\n              70 LOAD_FAST                1 (self)\n              72 LOAD_ATTR                0 (config)\n              74 LOAD_ATTR                5 (pad_token_id)\n              76 LOAD_FAST                1 (self)\n              78 LOAD_ATTR                0 (config)\n              80 LOAD_ATTR                6 (decoder_start_token_id)\n              82 CALL_FUNCTION            3\n              84 STORE_FAST               6 (decoder_input_ids)\n         >>   86 LOAD_FAST                1 (self)\n              88 LOAD_ATTR                7 (model)\n              90 LOAD_FAST                4 (input_ids)\n              92 LOAD_FAST                5 (attention_mask)\n              94 LOAD_FAST                6 (decoder_input_ids)\n              96 LOAD_FAST               11 (encoder_outputs)\n              98 LOAD_FAST                7 (decoder_attention_mask)\n             100 LOAD_FAST                8 (head_mask)\n             102 LOAD_FAST                9 (decoder_head_mask)\n             104 LOAD_FAST               10 (cross_attn_head_mask)\n             106 LOAD_FAST               12 (past_key_values)\n             108 LOAD_FAST               13 (inputs_embeds)\n             110 LOAD_FAST               14 (decoder_inputs_embeds)\n             112 LOAD_FAST               15 (use_cache)\n             114 LOAD_FAST               16 (output_attentions)\n             116 LOAD_FAST               17 (output_hidden_states)\n             118 LOAD_FAST                3 (return_dict)\n             120 LOAD_CONST               4 (('attention_mask', 'decoder_input_ids', 'encoder_outputs', 'decoder_attention_mask', 'head_mask', 'decoder_head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'decoder_inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             122 CALL_FUNCTION_KW        15\n         >>  124 STORE_FAST              18 (outputs)\n\n1324         126 LOAD_FAST                1 (self)\n             128 LOAD_ATTR                8 (lm_head)\n             130 LOAD_FAST               18 (outputs)\n             132 LOAD_CONST               5 (0)\n             134 BINARY_SUBSCR\n             136 CALL_FUNCTION            1\n             138 LOAD_FAST                1 (self)\n             140 LOAD_ATTR                9 (final_logits_bias)\n             142 BINARY_ADD\n             144 STORE_FAST              19 (lm_logits)\n\n1326         146 LOAD_CONST               1 (None)\n             148 STORE_FAST              20 (masked_lm_loss)\n\n1327         150 LOAD_FAST                2 (labels)\n             152 LOAD_CONST               1 (None)\n             154 IS_OP                    1\n             156 POP_JUMP_IF_FALSE       96 (to 192)\n\n1328         158 LOAD_GLOBAL             10 (CrossEntropyLoss)\n             160 CALL_FUNCTION            0\n             162 STORE_FAST              21 (loss_fct)\n\n1329         164 LOAD_FAST               21 (loss_fct)\n             166 LOAD_FAST               19 (lm_logits)\n             168 LOAD_ATTR               11 (view)\n             170 LOAD_CONST               6 (-1)\n             172 LOAD_FAST                1 (self)\n             174 LOAD_ATTR                0 (config)\n             176 LOAD_ATTR               12 (vocab_size)\n             178 CALL_FUNCTION            2\n             180 LOAD_FAST                2 (labels)\n             182 LOAD_ATTR               11 (view)\n             184 LOAD_CONST               6 (-1)\n             186 CALL_FUNCTION            1\n             188 CALL_FUNCTION            2\n             190 STORE_FAST              20 (masked_lm_loss)\n\n1331     >>  192 LOAD_FAST                3 (return_dict)\n             194 POP_JUMP_IF_TRUE       118 (to 236)\n\n1332         196 LOAD_FAST               19 (lm_logits)\n             198 BUILD_TUPLE              1\n             200 LOAD_FAST               18 (outputs)\n             202 LOAD_CONST               7 (1)\n             204 LOAD_CONST               1 (None)\n             206 BUILD_SLICE              2\n             208 BINARY_SUBSCR\n             210 BINARY_ADD\n             212 STORE_FAST              22 (output)\n\n1333         214 LOAD_FAST               20 (masked_lm_loss)\n             216 LOAD_CONST               1 (None)\n             218 IS_OP                    1\n             220 POP_JUMP_IF_FALSE      116 (to 232)\n             222 LOAD_FAST               20 (masked_lm_loss)\n             224 BUILD_TUPLE              1\n             226 LOAD_FAST               22 (output)\n             228 BINARY_ADD\n             230 RETURN_VALUE\n         >>  232 LOAD_FAST               22 (output)\n             234 RETURN_VALUE\n\n1335     >>  236 LOAD_GLOBAL             13 (Seq2SeqLMOutput)\n\n1336         238 LOAD_FAST               20 (masked_lm_loss)\n\n1337         240 LOAD_FAST               19 (lm_logits)\n\n1338         242 LOAD_FAST               18 (outputs)\n             244 LOAD_ATTR               14 (past_key_values)\n\n1339         246 LOAD_FAST               18 (outputs)\n             248 LOAD_ATTR               15 (decoder_hidden_states)\n\n1340         250 LOAD_FAST               18 (outputs)\n             252 LOAD_ATTR               16 (decoder_attentions)\n\n1341         254 LOAD_FAST               18 (outputs)\n             256 LOAD_ATTR               17 (cross_attentions)\n\n1342         258 LOAD_FAST               18 (outputs)\n             260 LOAD_ATTR               18 (encoder_last_hidden_state)\n\n1343         262 LOAD_FAST               18 (outputs)\n             264 LOAD_ATTR               19 (encoder_hidden_states)\n\n1344         266 LOAD_FAST               18 (outputs)\n             268 LOAD_ATTR               20 (encoder_attentions)\n\n1335         270 LOAD_CONST               8 (('loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             272 CALL_FUNCTION_KW         9\n             274 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 557 \n557           0 LOAD_FAST                0 (___stack0)\n              2 CALL_FUNCTION            0\n              4 SETUP_WITH              10 (to 26)\n              6 POP_TOP\n              8 LOAD_FAST                1 (___stack1)\n             10 JUMP_ABSOLUTE           44 (to 88)\n             12 POP_BLOCK\n             14 LOAD_CONST               0 (None)\n             16 DUP_TOP\n             18 DUP_TOP\n             20 CALL_FUNCTION            3\n             22 POP_TOP\n             24 JUMP_FORWARD             8 (to 42)\n        >>   26 WITH_EXCEPT_START\n             28 POP_JUMP_IF_TRUE        16 (to 32)\n             30 RERAISE                  0\n        >>   32 POP_TOP\n             34 POP_TOP\n             36 POP_TOP\n             38 POP_EXCEPT\n             40 POP_TOP\n        >>   42 NOP\n             44 LOAD_CONST               0 (None)\n             46 RAISE_VARARGS            1\n             48 LOAD_GLOBAL              0 (clone_inputs)\n             50 LOAD_FAST                6 (inputs)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (cloned_inputs)\n             56 LOAD_FAST                2 (self)\n             58 LOAD_ATTR                1 (optimizer_zero_grad)\n             60 LOAD_FAST                3 (mod)\n             62 CALL_FUNCTION            1\n             64 POP_TOP\n             66 LOAD_FAST                2 (self)\n             68 LOAD_ATTR                2 (autocast)\n             70 CALL_FUNCTION            0\n             72 SETUP_WITH              20 (to 114)\n             74 POP_TOP\n             76 LOAD_FAST                3 (mod)\n             78 LOAD_CONST               1 (())\n             80 BUILD_MAP                0\n             82 LOAD_FAST                5 (cloned_inputs)\n             84 DICT_MERGE               1\n             86 CALL_FUNCTION_EX         1\n        >>   88 STORE_FAST               7 (pred)\n\n558          90 LOAD_FAST                2 (self)\n             92 LOAD_ATTR                3 (compute_loss)\n             94 LOAD_FAST                7 (pred)\n             96 CALL_FUNCTION            1\n             98 STORE_FAST               8 (loss)\n            100 POP_BLOCK\n\n556         102 LOAD_CONST               0 (None)\n            104 DUP_TOP\n            106 DUP_TOP\n            108 CALL_FUNCTION            3\n            110 POP_TOP\n            112 JUMP_FORWARD             8 (to 130)\n        >>  114 WITH_EXCEPT_START\n            116 POP_JUMP_IF_TRUE        60 (to 120)\n            118 RERAISE                  1\n        >>  120 POP_TOP\n            122 POP_TOP\n            124 POP_TOP\n            126 POP_EXCEPT\n            128 POP_TOP\n\n559     >>  130 LOAD_FAST                2 (self)\n            132 LOAD_ATTR                4 (grad_scaler)\n            134 LOAD_ATTR                5 (scale)\n            136 LOAD_FAST                8 (loss)\n            138 CALL_FUNCTION            1\n            140 LOAD_ATTR                6 (backward)\n            142 CALL_FUNCTION            0\n            144 POP_TOP\n\n560         146 LOAD_FAST                2 (self)\n            148 LOAD_ATTR                7 (optimizer_step)\n            150 CALL_FUNCTION            0\n            152 POP_TOP\n\n561         154 LOAD_FAST                4 (collect_outputs)\n            156 POP_JUMP_IF_FALSE       86 (to 172)\n\n562         158 LOAD_GLOBAL              8 (collect_results)\n            160 LOAD_FAST                3 (mod)\n            162 LOAD_FAST                7 (pred)\n            164 LOAD_FAST                8 (loss)\n            166 LOAD_FAST                5 (cloned_inputs)\n            168 CALL_FUNCTION            4\n            170 RETURN_VALUE\n\n563     >>  172 LOAD_CONST               0 (None)\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py line 954 \n 986           0 LOAD_FAST               12 (return_dict)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               12 (return_dict)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (use_return_dict)\n         >>   18 STORE_FAST              12 (return_dict)\n\n 988          20 LOAD_FAST                0 (self)\n              22 LOAD_ATTR                2 (roberta)\n\n 989          24 LOAD_FAST                1 (input_ids)\n\n 990          26 LOAD_FAST                2 (attention_mask)\n\n 991          28 LOAD_FAST                3 (token_type_ids)\n\n 992          30 LOAD_FAST                4 (position_ids)\n\n 993          32 LOAD_FAST                5 (head_mask)\n\n 994          34 LOAD_FAST                6 (inputs_embeds)\n\n 995          36 LOAD_FAST                7 (encoder_hidden_states)\n\n 996          38 LOAD_FAST                8 (encoder_attention_mask)\n\n 997          40 LOAD_FAST               10 (output_attentions)\n\n 998          42 LOAD_FAST               11 (output_hidden_states)\n\n 999          44 LOAD_FAST               12 (return_dict)\n\n 988          46 LOAD_CONST               2 (('attention_mask', 'token_type_ids', 'position_ids', 'head_mask', 'inputs_embeds', 'encoder_hidden_states', 'encoder_attention_mask', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              48 CALL_FUNCTION_KW        11\n              50 STORE_FAST              13 (outputs)\n\n1001          52 LOAD_FAST               13 (outputs)\n              54 LOAD_CONST               3 (0)\n              56 BINARY_SUBSCR\n              58 STORE_FAST              14 (sequence_output)\n\n1002          60 LOAD_FAST                0 (self)\n              62 LOAD_METHOD              3 (lm_head)\n              64 LOAD_FAST               14 (sequence_output)\n              66 CALL_METHOD              1\n              68 STORE_FAST              15 (prediction_scores)\n\n1004          70 LOAD_CONST               1 (None)\n              72 STORE_FAST              16 (masked_lm_loss)\n\n1005          74 LOAD_FAST                9 (labels)\n              76 LOAD_CONST               1 (None)\n              78 IS_OP                    1\n              80 POP_JUMP_IF_FALSE       64 (to 128)\n\n1007          82 LOAD_FAST                9 (labels)\n              84 LOAD_METHOD              4 (to)\n              86 LOAD_FAST               15 (prediction_scores)\n              88 LOAD_ATTR                5 (device)\n              90 CALL_METHOD              1\n              92 STORE_FAST               9 (labels)\n\n1008          94 LOAD_GLOBAL              6 (CrossEntropyLoss)\n              96 CALL_FUNCTION            0\n              98 STORE_FAST              17 (loss_fct)\n\n1009         100 LOAD_FAST               17 (loss_fct)\n             102 LOAD_FAST               15 (prediction_scores)\n             104 LOAD_METHOD              7 (view)\n             106 LOAD_CONST               4 (-1)\n             108 LOAD_FAST                0 (self)\n             110 LOAD_ATTR                0 (config)\n             112 LOAD_ATTR                8 (vocab_size)\n             114 CALL_METHOD              2\n             116 LOAD_FAST                9 (labels)\n             118 LOAD_METHOD              7 (view)\n             120 LOAD_CONST               4 (-1)\n             122 CALL_METHOD              1\n             124 CALL_FUNCTION            2\n             126 STORE_FAST              16 (masked_lm_loss)\n\n1011     >>  128 LOAD_FAST               12 (return_dict)\n             130 POP_JUMP_IF_TRUE        86 (to 172)\n\n1012         132 LOAD_FAST               15 (prediction_scores)\n             134 BUILD_TUPLE              1\n             136 LOAD_FAST               13 (outputs)\n             138 LOAD_CONST               5 (2)\n             140 LOAD_CONST               1 (None)\n             142 BUILD_SLICE              2\n             144 BINARY_SUBSCR\n             146 BINARY_ADD\n             148 STORE_FAST              18 (output)\n\n1013         150 LOAD_FAST               16 (masked_lm_loss)\n             152 LOAD_CONST               1 (None)\n             154 IS_OP                    1\n             156 POP_JUMP_IF_FALSE       84 (to 168)\n             158 LOAD_FAST               16 (masked_lm_loss)\n             160 BUILD_TUPLE              1\n             162 LOAD_FAST               18 (output)\n             164 BINARY_ADD\n             166 RETURN_VALUE\n         >>  168 LOAD_FAST               18 (output)\n             170 RETURN_VALUE\n\n1015     >>  172 LOAD_GLOBAL              9 (MaskedLMOutput)\n\n1016         174 LOAD_FAST               16 (masked_lm_loss)\n\n1017         176 LOAD_FAST               15 (prediction_scores)\n\n1018         178 LOAD_FAST               13 (outputs)\n             180 LOAD_ATTR               10 (hidden_states)\n\n1019         182 LOAD_FAST               13 (outputs)\n             184 LOAD_ATTR               11 (attentions)\n\n1015         186 LOAD_CONST               6 (('loss', 'logits', 'hidden_states', 'attentions'))\n             188 CALL_FUNCTION_KW         4\n             190 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py line 787 \n830           0 LOAD_FAST               11 (output_attentions)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    1\n              6 POP_JUMP_IF_FALSE        6 (to 12)\n              8 LOAD_FAST               11 (output_attentions)\n             10 JUMP_FORWARD             3 (to 18)\n        >>   12 LOAD_FAST                0 (self)\n             14 LOAD_ATTR                0 (config)\n             16 LOAD_ATTR                1 (output_attentions)\n        >>   18 STORE_FAST              11 (output_attentions)\n\n832          20 LOAD_FAST               12 (output_hidden_states)\n             22 LOAD_CONST               1 (None)\n             24 IS_OP                    1\n             26 POP_JUMP_IF_FALSE       16 (to 32)\n             28 LOAD_FAST               12 (output_hidden_states)\n             30 JUMP_FORWARD             3 (to 38)\n        >>   32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                0 (config)\n             36 LOAD_ATTR                2 (output_hidden_states)\n\n831     >>   38 STORE_FAST              12 (output_hidden_states)\n\n834          40 LOAD_FAST               13 (return_dict)\n             42 LOAD_CONST               1 (None)\n             44 IS_OP                    1\n             46 POP_JUMP_IF_FALSE       26 (to 52)\n             48 LOAD_FAST               13 (return_dict)\n             50 JUMP_FORWARD             3 (to 58)\n        >>   52 LOAD_FAST                0 (self)\n             54 LOAD_ATTR                0 (config)\n             56 LOAD_ATTR                3 (use_return_dict)\n        >>   58 STORE_FAST              13 (return_dict)\n\n836          60 LOAD_FAST                0 (self)\n             62 LOAD_ATTR                0 (config)\n             64 LOAD_ATTR                4 (is_decoder)\n             66 POP_JUMP_IF_FALSE       45 (to 90)\n\n837          68 LOAD_FAST               10 (use_cache)\n             70 LOAD_CONST               1 (None)\n             72 IS_OP                    1\n             74 POP_JUMP_IF_FALSE       40 (to 80)\n             76 LOAD_FAST               10 (use_cache)\n             78 JUMP_FORWARD             3 (to 86)\n        >>   80 LOAD_FAST                0 (self)\n             82 LOAD_ATTR                0 (config)\n             84 LOAD_ATTR                5 (use_cache)\n        >>   86 STORE_FAST              10 (use_cache)\n             88 JUMP_FORWARD             2 (to 94)\n\n839     >>   90 LOAD_CONST               2 (False)\n             92 STORE_FAST              10 (use_cache)\n\n841     >>   94 LOAD_FAST                1 (input_ids)\n             96 LOAD_CONST               1 (None)\n             98 IS_OP                    1\n            100 POP_JUMP_IF_FALSE       59 (to 118)\n            102 LOAD_FAST                6 (inputs_embeds)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE       59 (to 118)\n\n842         110 LOAD_GLOBAL              6 (ValueError)\n            112 LOAD_CONST               3 ('You cannot specify both input_ids and inputs_embeds at the same time')\n            114 CALL_FUNCTION            1\n            116 RAISE_VARARGS            1\n\n843     >>  118 LOAD_FAST                1 (input_ids)\n            120 LOAD_CONST               1 (None)\n            122 IS_OP                    1\n            124 POP_JUMP_IF_FALSE       74 (to 148)\n\n844         126 LOAD_FAST                1 (input_ids)\n            128 LOAD_METHOD              7 (size)\n            130 CALL_METHOD              0\n            132 STORE_FAST              14 (input_shape)\n\n845         134 LOAD_FAST                0 (self)\n            136 LOAD_METHOD              8 (warn_if_padding_and_no_attention_mask)\n            138 LOAD_FAST                1 (input_ids)\n            140 LOAD_FAST                2 (attention_mask)\n            142 CALL_METHOD              2\n            144 POP_TOP\n            146 JUMP_FORWARD            17 (to 182)\n\n846     >>  148 LOAD_FAST                6 (inputs_embeds)\n            150 LOAD_CONST               1 (None)\n            152 IS_OP                    1\n            154 POP_JUMP_IF_FALSE       87 (to 174)\n\n847         156 LOAD_FAST                6 (inputs_embeds)\n            158 LOAD_METHOD              7 (size)\n            160 CALL_METHOD              0\n            162 LOAD_CONST               1 (None)\n            164 LOAD_CONST               4 (-1)\n            166 BUILD_SLICE              2\n            168 BINARY_SUBSCR\n            170 STORE_FAST              14 (input_shape)\n            172 JUMP_FORWARD             4 (to 182)\n\n849     >>  174 LOAD_GLOBAL              6 (ValueError)\n            176 LOAD_CONST               5 ('You have to specify either input_ids or inputs_embeds')\n            178 CALL_FUNCTION            1\n            180 RAISE_VARARGS            1\n\n851     >>  182 LOAD_FAST               14 (input_shape)\n            184 UNPACK_SEQUENCE          2\n            186 STORE_FAST              15 (batch_size)\n            188 STORE_FAST              16 (seq_length)\n\n852         190 LOAD_FAST                1 (input_ids)\n            192 LOAD_CONST               1 (None)\n            194 IS_OP                    1\n            196 POP_JUMP_IF_FALSE      102 (to 204)\n            198 LOAD_FAST                1 (input_ids)\n            200 LOAD_ATTR                9 (device)\n            202 JUMP_FORWARD             2 (to 208)\n        >>  204 LOAD_FAST                6 (inputs_embeds)\n            206 LOAD_ATTR                9 (device)\n        >>  208 STORE_FAST              17 (device)\n\n855         210 LOAD_FAST                9 (past_key_values)\n            212 LOAD_CONST               1 (None)\n            214 IS_OP                    1\n            216 POP_JUMP_IF_FALSE      118 (to 236)\n            218 LOAD_FAST                9 (past_key_values)\n            220 LOAD_CONST               6 (0)\n            222 BINARY_SUBSCR\n            224 LOAD_CONST               6 (0)\n            226 BINARY_SUBSCR\n            228 LOAD_ATTR               10 (shape)\n            230 LOAD_CONST               7 (2)\n            232 BINARY_SUBSCR\n            234 JUMP_FORWARD             1 (to 238)\n        >>  236 LOAD_CONST               6 (0)\n        >>  238 STORE_FAST              18 (past_key_values_length)\n\n857         240 LOAD_FAST                2 (attention_mask)\n            242 LOAD_CONST               1 (None)\n            244 IS_OP                    0\n            246 POP_JUMP_IF_FALSE      135 (to 270)\n\n858         248 LOAD_GLOBAL             11 (torch)\n            250 LOAD_ATTR               12 (ones)\n            252 LOAD_FAST               15 (batch_size)\n            254 LOAD_FAST               16 (seq_length)\n            256 LOAD_FAST               18 (past_key_values_length)\n            258 BINARY_ADD\n            260 BUILD_TUPLE              2\n            262 LOAD_FAST               17 (device)\n            264 LOAD_CONST               8 (('device',))\n            266 CALL_FUNCTION_KW         2\n            268 STORE_FAST               2 (attention_mask)\n\n860     >>  270 LOAD_FAST                3 (token_type_ids)\n            272 LOAD_CONST               1 (None)\n            274 IS_OP                    0\n            276 POP_JUMP_IF_FALSE      175 (to 350)\n\n861         278 LOAD_GLOBAL             13 (hasattr)\n            280 LOAD_FAST                0 (self)\n            282 LOAD_ATTR               14 (embeddings)\n            284 LOAD_CONST               9 ('token_type_ids')\n            286 CALL_FUNCTION            2\n            288 POP_JUMP_IF_FALSE      166 (to 332)\n\n862         290 LOAD_FAST                0 (self)\n            292 LOAD_ATTR               14 (embeddings)\n            294 LOAD_ATTR               15 (token_type_ids)\n            296 LOAD_CONST               1 (None)\n            298 LOAD_CONST               1 (None)\n            300 BUILD_SLICE              2\n            302 LOAD_CONST               1 (None)\n            304 LOAD_FAST               16 (seq_length)\n            306 BUILD_SLICE              2\n            308 BUILD_TUPLE              2\n            310 BINARY_SUBSCR\n            312 STORE_FAST              19 (buffered_token_type_ids)\n\n863         314 LOAD_FAST               19 (buffered_token_type_ids)\n            316 LOAD_METHOD             16 (expand)\n            318 LOAD_FAST               15 (batch_size)\n            320 LOAD_FAST               16 (seq_length)\n            322 CALL_METHOD              2\n            324 STORE_FAST              20 (buffered_token_type_ids_expanded)\n\n864         326 LOAD_FAST               20 (buffered_token_type_ids_expanded)\n            328 STORE_FAST               3 (token_type_ids)\n            330 JUMP_FORWARD             9 (to 350)\n\n866     >>  332 LOAD_GLOBAL             11 (torch)\n            334 LOAD_ATTR               17 (zeros)\n            336 LOAD_FAST               14 (input_shape)\n            338 LOAD_GLOBAL             11 (torch)\n            340 LOAD_ATTR               18 (long)\n            342 LOAD_FAST               17 (device)\n            344 LOAD_CONST              10 (('dtype', 'device'))\n            346 CALL_FUNCTION_KW         3\n            348 STORE_FAST               3 (token_type_ids)\n\n870     >>  350 LOAD_FAST                0 (self)\n            352 LOAD_METHOD             19 (get_extended_attention_mask)\n            354 LOAD_FAST                2 (attention_mask)\n            356 LOAD_FAST               14 (input_shape)\n            358 CALL_METHOD              2\n            360 STORE_FAST              21 (extended_attention_mask)\n\n874         362 LOAD_FAST                0 (self)\n            364 LOAD_ATTR                0 (config)\n            366 LOAD_ATTR                4 (is_decoder)\n            368 POP_JUMP_IF_FALSE      217 (to 434)\n            370 LOAD_FAST                7 (encoder_hidden_states)\n            372 LOAD_CONST               1 (None)\n            374 IS_OP                    1\n            376 POP_JUMP_IF_FALSE      217 (to 434)\n\n875         378 LOAD_FAST                7 (encoder_hidden_states)\n            380 LOAD_METHOD              7 (size)\n            382 CALL_METHOD              0\n            384 UNPACK_SEQUENCE          3\n            386 STORE_FAST              22 (encoder_batch_size)\n            388 STORE_FAST              23 (encoder_sequence_length)\n            390 STORE_FAST              24 (_)\n\n876         392 LOAD_FAST               22 (encoder_batch_size)\n            394 LOAD_FAST               23 (encoder_sequence_length)\n            396 BUILD_TUPLE              2\n            398 STORE_FAST              25 (encoder_hidden_shape)\n\n877         400 LOAD_FAST                8 (encoder_attention_mask)\n            402 LOAD_CONST               1 (None)\n            404 IS_OP                    0\n            406 POP_JUMP_IF_FALSE      211 (to 422)\n\n878         408 LOAD_GLOBAL             11 (torch)\n            410 LOAD_ATTR               12 (ones)\n            412 LOAD_FAST               25 (encoder_hidden_shape)\n            414 LOAD_FAST               17 (device)\n            416 LOAD_CONST               8 (('device',))\n            418 CALL_FUNCTION_KW         2\n            420 STORE_FAST               8 (encoder_attention_mask)\n\n879     >>  422 LOAD_FAST                0 (self)\n            424 LOAD_METHOD             20 (invert_attention_mask)\n            426 LOAD_FAST                8 (encoder_attention_mask)\n            428 CALL_METHOD              1\n            430 STORE_FAST              26 (encoder_extended_attention_mask)\n            432 JUMP_FORWARD             2 (to 438)\n\n881     >>  434 LOAD_CONST               1 (None)\n            436 STORE_FAST              26 (encoder_extended_attention_mask)\n\n888     >>  438 LOAD_FAST                0 (self)\n            440 LOAD_METHOD             21 (get_head_mask)\n            442 LOAD_FAST                5 (head_mask)\n            444 LOAD_FAST                0 (self)\n            446 LOAD_ATTR                0 (config)\n            448 LOAD_ATTR               22 (num_hidden_layers)\n            450 CALL_METHOD              2\n            452 STORE_FAST               5 (head_mask)\n\n890         454 LOAD_FAST                0 (self)\n            456 LOAD_ATTR               14 (embeddings)\n\n891         458 LOAD_FAST                1 (input_ids)\n\n892         460 LOAD_FAST                4 (position_ids)\n\n893         462 LOAD_FAST                3 (token_type_ids)\n\n894         464 LOAD_FAST                6 (inputs_embeds)\n\n895         466 LOAD_FAST               18 (past_key_values_length)\n\n890         468 LOAD_CONST              11 (('input_ids', 'position_ids', 'token_type_ids', 'inputs_embeds', 'past_key_values_length'))\n            470 CALL_FUNCTION_KW         5\n            472 STORE_FAST              27 (embedding_output)\n\n897         474 LOAD_FAST                0 (self)\n            476 LOAD_ATTR               23 (encoder)\n\n898         478 LOAD_FAST               27 (embedding_output)\n\n899         480 LOAD_FAST               21 (extended_attention_mask)\n\n900         482 LOAD_FAST                5 (head_mask)\n\n901         484 LOAD_FAST                7 (encoder_hidden_states)\n\n902         486 LOAD_FAST               26 (encoder_extended_attention_mask)\n\n903         488 LOAD_FAST                9 (past_key_values)\n\n904         490 LOAD_FAST               10 (use_cache)\n\n905         492 LOAD_FAST               11 (output_attentions)\n\n906         494 LOAD_FAST               12 (output_hidden_states)\n\n907         496 LOAD_FAST               13 (return_dict)\n\n897         498 LOAD_CONST              12 (('attention_mask', 'head_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'past_key_values', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n            500 CALL_FUNCTION_KW        10\n            502 STORE_FAST              28 (encoder_outputs)\n\n909         504 LOAD_FAST               28 (encoder_outputs)\n            506 LOAD_CONST               6 (0)\n            508 BINARY_SUBSCR\n            510 STORE_FAST              29 (sequence_output)\n\n910         512 LOAD_FAST                0 (self)\n            514 LOAD_ATTR               24 (pooler)\n            516 LOAD_CONST               1 (None)\n            518 IS_OP                    1\n            520 EXTENDED_ARG             1\n            522 POP_JUMP_IF_FALSE      267 (to 534)\n            524 LOAD_FAST                0 (self)\n            526 LOAD_METHOD             24 (pooler)\n            528 LOAD_FAST               29 (sequence_output)\n            530 CALL_METHOD              1\n            532 JUMP_FORWARD             1 (to 536)\n        >>  534 LOAD_CONST               1 (None)\n        >>  536 STORE_FAST              30 (pooled_output)\n\n912         538 LOAD_FAST               13 (return_dict)\n            540 EXTENDED_ARG             1\n            542 POP_JUMP_IF_TRUE       282 (to 564)\n\n913         544 LOAD_FAST               29 (sequence_output)\n            546 LOAD_FAST               30 (pooled_output)\n            548 BUILD_TUPLE              2\n            550 LOAD_FAST               28 (encoder_outputs)\n            552 LOAD_CONST              13 (1)\n            554 LOAD_CONST               1 (None)\n            556 BUILD_SLICE              2\n            558 BINARY_SUBSCR\n            560 BINARY_ADD\n            562 RETURN_VALUE\n\n915     >>  564 LOAD_GLOBAL             25 (BaseModelOutputWithPoolingAndCrossAttentions)\n\n916         566 LOAD_FAST               29 (sequence_output)\n\n917         568 LOAD_FAST               30 (pooled_output)\n\n918         570 LOAD_FAST               28 (encoder_outputs)\n            572 LOAD_ATTR               26 (past_key_values)\n\n919         574 LOAD_FAST               28 (encoder_outputs)\n            576 LOAD_ATTR               27 (hidden_states)\n\n920         578 LOAD_FAST               28 (encoder_outputs)\n            580 LOAD_ATTR               28 (attentions)\n\n921         582 LOAD_FAST               28 (encoder_outputs)\n            584 LOAD_ATTR               29 (cross_attentions)\n\n915         586 LOAD_CONST              14 (('last_hidden_state', 'pooler_output', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n            588 CALL_FUNCTION_KW         6\n            590 RETURN_VALUE\n\n", "ORIGINAL BYTECODE warn_if_padding_and_no_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/modeling_utils.py line 3482 \n3486           0 LOAD_FAST                2 (attention_mask)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_TRUE        10 (to 20)\n               8 LOAD_FAST                0 (self)\n              10 LOAD_ATTR                0 (config)\n              12 LOAD_ATTR                1 (pad_token_id)\n              14 LOAD_CONST               1 (None)\n              16 IS_OP                    0\n              18 POP_JUMP_IF_FALSE       12 (to 24)\n\n3487     >>   20 LOAD_CONST               1 (None)\n              22 RETURN_VALUE\n\n3490     >>   24 LOAD_FAST                0 (self)\n              26 LOAD_ATTR                0 (config)\n              28 LOAD_ATTR                1 (pad_token_id)\n              30 LOAD_FAST                1 (input_ids)\n              32 LOAD_CONST               1 (None)\n              34 LOAD_CONST               1 (None)\n              36 BUILD_SLICE              2\n              38 LOAD_CONST               2 (-1)\n              40 LOAD_CONST               3 (0)\n              42 BUILD_LIST               2\n              44 BUILD_TUPLE              2\n              46 BINARY_SUBSCR\n              48 CONTAINS_OP              0\n              50 POP_JUMP_IF_FALSE      102 (to 204)\n\n3492          52 LOAD_CONST               4 ('We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.')\n\n3491          54 STORE_FAST               3 (warn_string)\n\n3500          56 LOAD_FAST                0 (self)\n              58 LOAD_ATTR                0 (config)\n              60 LOAD_ATTR                2 (bos_token_id)\n              62 LOAD_CONST               1 (None)\n              64 IS_OP                    1\n              66 POP_JUMP_IF_FALSE       42 (to 84)\n              68 LOAD_FAST                0 (self)\n              70 LOAD_ATTR                0 (config)\n              72 LOAD_ATTR                2 (bos_token_id)\n              74 LOAD_FAST                0 (self)\n              76 LOAD_ATTR                0 (config)\n              78 LOAD_ATTR                1 (pad_token_id)\n              80 COMPARE_OP               2 (==)\n              82 POP_JUMP_IF_TRUE        70 (to 140)\n\n3501     >>   84 LOAD_FAST                0 (self)\n              86 LOAD_ATTR                0 (config)\n              88 LOAD_ATTR                3 (eos_token_id)\n              90 LOAD_CONST               1 (None)\n              92 IS_OP                    1\n              94 POP_JUMP_IF_FALSE       56 (to 112)\n              96 LOAD_FAST                0 (self)\n              98 LOAD_ATTR                0 (config)\n             100 LOAD_ATTR                3 (eos_token_id)\n             102 LOAD_FAST                0 (self)\n             104 LOAD_ATTR                0 (config)\n             106 LOAD_ATTR                1 (pad_token_id)\n             108 COMPARE_OP               2 (==)\n             110 POP_JUMP_IF_TRUE        70 (to 140)\n\n3502     >>  112 LOAD_FAST                0 (self)\n             114 LOAD_ATTR                0 (config)\n             116 LOAD_ATTR                4 (sep_token_id)\n             118 LOAD_CONST               1 (None)\n             120 IS_OP                    1\n             122 POP_JUMP_IF_FALSE       95 (to 190)\n             124 LOAD_FAST                0 (self)\n             126 LOAD_ATTR                0 (config)\n             128 LOAD_ATTR                4 (sep_token_id)\n             130 LOAD_FAST                0 (self)\n             132 LOAD_ATTR                0 (config)\n             134 LOAD_ATTR                1 (pad_token_id)\n             136 COMPARE_OP               2 (==)\n             138 POP_JUMP_IF_FALSE       95 (to 190)\n\n3504     >>  140 LOAD_FAST                3 (warn_string)\n\n3505         142 LOAD_CONST               5 ('\\nYou may ignore this warning if your `pad_token_id` (')\n             144 LOAD_FAST                0 (self)\n             146 LOAD_ATTR                0 (config)\n             148 LOAD_ATTR                1 (pad_token_id)\n             150 FORMAT_VALUE             0\n             152 LOAD_CONST               6 (') is identical to the `bos_token_id` (')\n\n3506         154 LOAD_FAST                0 (self)\n             156 LOAD_ATTR                0 (config)\n             158 LOAD_ATTR                2 (bos_token_id)\n\n3505         160 FORMAT_VALUE             0\n             162 LOAD_CONST               7 ('), `eos_token_id` (')\n\n3506         164 LOAD_FAST                0 (self)\n             166 LOAD_ATTR                0 (config)\n             168 LOAD_ATTR                3 (eos_token_id)\n\n3505         170 FORMAT_VALUE             0\n             172 LOAD_CONST               8 ('), or the `sep_token_id` (')\n\n3507         174 LOAD_FAST                0 (self)\n             176 LOAD_ATTR                0 (config)\n             178 LOAD_ATTR                4 (sep_token_id)\n\n3505         180 FORMAT_VALUE             0\n             182 LOAD_CONST               9 ('), and your input is not padded.')\n             184 BUILD_STRING             9\n\n3504         186 INPLACE_ADD\n             188 STORE_FAST               3 (warn_string)\n\n3510     >>  190 LOAD_GLOBAL              5 (logger)\n             192 LOAD_METHOD              6 (warning_once)\n             194 LOAD_FAST                3 (warn_string)\n             196 CALL_METHOD              1\n             198 POP_TOP\n             200 LOAD_CONST               1 (None)\n             202 RETURN_VALUE\n\n3490     >>  204 LOAD_CONST               1 (None)\n             206 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py line 845 \n845           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           74 (to 148)\n              4 LOAD_FAST               12 (output_attentions)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE        8 (to 16)\n             12 LOAD_FAST               12 (output_attentions)\n             14 JUMP_FORWARD             3 (to 22)\n        >>   16 LOAD_FAST                1 (self)\n             18 LOAD_ATTR                0 (config)\n             20 LOAD_ATTR                1 (output_attentions)\n        >>   22 STORE_FAST              12 (output_attentions)\n             24 LOAD_FAST               13 (output_hidden_states)\n             26 LOAD_CONST               1 (None)\n             28 IS_OP                    1\n             30 POP_JUMP_IF_FALSE       18 (to 36)\n             32 LOAD_FAST               13 (output_hidden_states)\n             34 JUMP_FORWARD             3 (to 42)\n        >>   36 LOAD_FAST                1 (self)\n             38 LOAD_ATTR                0 (config)\n             40 LOAD_ATTR                2 (output_hidden_states)\n        >>   42 STORE_FAST              13 (output_hidden_states)\n             44 LOAD_FAST               14 (return_dict)\n             46 LOAD_CONST               1 (None)\n             48 IS_OP                    1\n             50 POP_JUMP_IF_FALSE       28 (to 56)\n             52 LOAD_FAST               14 (return_dict)\n             54 JUMP_FORWARD             3 (to 62)\n        >>   56 LOAD_FAST                1 (self)\n             58 LOAD_ATTR                0 (config)\n             60 LOAD_ATTR                3 (use_return_dict)\n        >>   62 STORE_FAST              14 (return_dict)\n             64 LOAD_FAST                1 (self)\n             66 LOAD_ATTR                0 (config)\n             68 LOAD_ATTR                4 (is_decoder)\n             70 POP_JUMP_IF_FALSE       47 (to 94)\n             72 LOAD_FAST               11 (use_cache)\n             74 LOAD_CONST               1 (None)\n             76 IS_OP                    1\n             78 POP_JUMP_IF_FALSE       42 (to 84)\n             80 LOAD_FAST               11 (use_cache)\n             82 JUMP_FORWARD             3 (to 90)\n        >>   84 LOAD_FAST                1 (self)\n             86 LOAD_ATTR                0 (config)\n             88 LOAD_ATTR                5 (use_cache)\n        >>   90 STORE_FAST              11 (use_cache)\n             92 JUMP_FORWARD             2 (to 98)\n        >>   94 LOAD_CONST               2 (False)\n             96 STORE_FAST              11 (use_cache)\n        >>   98 LOAD_FAST                2 (input_ids)\n            100 LOAD_CONST               1 (None)\n            102 IS_OP                    1\n            104 POP_JUMP_IF_FALSE       61 (to 122)\n            106 LOAD_FAST                7 (inputs_embeds)\n            108 LOAD_CONST               1 (None)\n            110 IS_OP                    1\n            112 POP_JUMP_IF_FALSE       61 (to 122)\n            114 LOAD_GLOBAL              6 (ValueError)\n            116 LOAD_CONST               3 ('You cannot specify both input_ids and inputs_embeds at the same time')\n            118 CALL_FUNCTION            1\n            120 RAISE_VARARGS            1\n        >>  122 LOAD_FAST                2 (input_ids)\n            124 LOAD_CONST               1 (None)\n            126 IS_OP                    1\n            128 POP_JUMP_IF_FALSE       76 (to 152)\n            130 LOAD_FAST                2 (input_ids)\n            132 LOAD_ATTR                7 (size)\n            134 CALL_FUNCTION            0\n            136 STORE_FAST              15 (input_shape)\n            138 LOAD_FAST                1 (self)\n            140 LOAD_ATTR                8 (warn_if_padding_and_no_attention_mask)\n            142 LOAD_FAST                2 (input_ids)\n            144 LOAD_FAST                3 (attention_mask)\n            146 CALL_FUNCTION            2\n        >>  148 POP_TOP\n            150 JUMP_FORWARD            17 (to 186)\n\n846     >>  152 LOAD_FAST                7 (inputs_embeds)\n            154 LOAD_CONST               1 (None)\n            156 IS_OP                    1\n            158 POP_JUMP_IF_FALSE       89 (to 178)\n\n847         160 LOAD_FAST                7 (inputs_embeds)\n            162 LOAD_ATTR                7 (size)\n            164 CALL_FUNCTION            0\n            166 LOAD_CONST               1 (None)\n            168 LOAD_CONST               4 (-1)\n            170 BUILD_SLICE              2\n            172 BINARY_SUBSCR\n            174 STORE_FAST              15 (input_shape)\n            176 JUMP_FORWARD             4 (to 186)\n\n849     >>  178 LOAD_GLOBAL              6 (ValueError)\n            180 LOAD_CONST               5 ('You have to specify either input_ids or inputs_embeds')\n            182 CALL_FUNCTION            1\n            184 RAISE_VARARGS            1\n\n851     >>  186 LOAD_FAST               15 (input_shape)\n            188 UNPACK_SEQUENCE          2\n            190 STORE_FAST              16 (batch_size)\n            192 STORE_FAST              17 (seq_length)\n\n852         194 LOAD_FAST                2 (input_ids)\n            196 LOAD_CONST               1 (None)\n            198 IS_OP                    1\n            200 POP_JUMP_IF_FALSE      104 (to 208)\n            202 LOAD_FAST                2 (input_ids)\n            204 LOAD_ATTR                9 (device)\n            206 JUMP_FORWARD             2 (to 212)\n        >>  208 LOAD_FAST                7 (inputs_embeds)\n            210 LOAD_ATTR                9 (device)\n        >>  212 STORE_FAST              18 (device)\n\n855         214 LOAD_FAST               10 (past_key_values)\n            216 LOAD_CONST               1 (None)\n            218 IS_OP                    1\n            220 POP_JUMP_IF_FALSE      120 (to 240)\n            222 LOAD_FAST               10 (past_key_values)\n            224 LOAD_CONST               6 (0)\n            226 BINARY_SUBSCR\n            228 LOAD_CONST               6 (0)\n            230 BINARY_SUBSCR\n            232 LOAD_ATTR               10 (shape)\n            234 LOAD_CONST               7 (2)\n            236 BINARY_SUBSCR\n            238 JUMP_FORWARD             1 (to 242)\n        >>  240 LOAD_CONST               6 (0)\n        >>  242 STORE_FAST              19 (past_key_values_length)\n\n857         244 LOAD_FAST                3 (attention_mask)\n            246 LOAD_CONST               1 (None)\n            248 IS_OP                    0\n            250 POP_JUMP_IF_FALSE      137 (to 274)\n\n858         252 LOAD_GLOBAL             11 (torch)\n            254 LOAD_ATTR               12 (ones)\n            256 LOAD_FAST               16 (batch_size)\n            258 LOAD_FAST               17 (seq_length)\n            260 LOAD_FAST               19 (past_key_values_length)\n            262 BINARY_ADD\n            264 BUILD_TUPLE              2\n            266 LOAD_FAST               18 (device)\n            268 LOAD_CONST               8 (('device',))\n            270 CALL_FUNCTION_KW         2\n            272 STORE_FAST               3 (attention_mask)\n\n860     >>  274 LOAD_FAST                4 (token_type_ids)\n            276 LOAD_CONST               1 (None)\n            278 IS_OP                    0\n            280 POP_JUMP_IF_FALSE      177 (to 354)\n\n861         282 LOAD_GLOBAL             13 (hasattr)\n            284 LOAD_FAST                1 (self)\n            286 LOAD_ATTR               14 (embeddings)\n            288 LOAD_CONST               9 ('token_type_ids')\n            290 CALL_FUNCTION            2\n            292 POP_JUMP_IF_FALSE      168 (to 336)\n\n862         294 LOAD_FAST                1 (self)\n            296 LOAD_ATTR               14 (embeddings)\n            298 LOAD_ATTR               15 (token_type_ids)\n            300 LOAD_CONST               1 (None)\n            302 LOAD_CONST               1 (None)\n            304 BUILD_SLICE              2\n            306 LOAD_CONST               1 (None)\n            308 LOAD_FAST               17 (seq_length)\n            310 BUILD_SLICE              2\n            312 BUILD_TUPLE              2\n            314 BINARY_SUBSCR\n            316 STORE_FAST              20 (buffered_token_type_ids)\n\n863         318 LOAD_FAST               20 (buffered_token_type_ids)\n            320 LOAD_ATTR               16 (expand)\n            322 LOAD_FAST               16 (batch_size)\n            324 LOAD_FAST               17 (seq_length)\n            326 CALL_FUNCTION            2\n            328 STORE_FAST              21 (buffered_token_type_ids_expanded)\n\n864         330 LOAD_FAST               21 (buffered_token_type_ids_expanded)\n            332 STORE_FAST               4 (token_type_ids)\n            334 JUMP_FORWARD             9 (to 354)\n\n866     >>  336 LOAD_GLOBAL             11 (torch)\n            338 LOAD_ATTR               17 (zeros)\n            340 LOAD_FAST               15 (input_shape)\n            342 LOAD_GLOBAL             11 (torch)\n            344 LOAD_ATTR               18 (long)\n            346 LOAD_FAST               18 (device)\n            348 LOAD_CONST              10 (('dtype', 'device'))\n            350 CALL_FUNCTION_KW         3\n            352 STORE_FAST               4 (token_type_ids)\n\n870     >>  354 LOAD_FAST                1 (self)\n            356 LOAD_ATTR               19 (get_extended_attention_mask)\n            358 LOAD_FAST                3 (attention_mask)\n            360 LOAD_FAST               15 (input_shape)\n            362 CALL_FUNCTION            2\n            364 STORE_FAST              22 (extended_attention_mask)\n\n874         366 LOAD_FAST                1 (self)\n            368 LOAD_ATTR                0 (config)\n            370 LOAD_ATTR                4 (is_decoder)\n            372 POP_JUMP_IF_FALSE      219 (to 438)\n            374 LOAD_FAST                8 (encoder_hidden_states)\n            376 LOAD_CONST               1 (None)\n            378 IS_OP                    1\n            380 POP_JUMP_IF_FALSE      219 (to 438)\n\n875         382 LOAD_FAST                8 (encoder_hidden_states)\n            384 LOAD_ATTR                7 (size)\n            386 CALL_FUNCTION            0\n            388 UNPACK_SEQUENCE          3\n            390 STORE_FAST              23 (encoder_batch_size)\n            392 STORE_FAST              24 (encoder_sequence_length)\n            394 STORE_FAST              25 (_)\n\n876         396 LOAD_FAST               23 (encoder_batch_size)\n            398 LOAD_FAST               24 (encoder_sequence_length)\n            400 BUILD_TUPLE              2\n            402 STORE_FAST              26 (encoder_hidden_shape)\n\n877         404 LOAD_FAST                9 (encoder_attention_mask)\n            406 LOAD_CONST               1 (None)\n            408 IS_OP                    0\n            410 POP_JUMP_IF_FALSE      213 (to 426)\n\n878         412 LOAD_GLOBAL             11 (torch)\n            414 LOAD_ATTR               12 (ones)\n            416 LOAD_FAST               26 (encoder_hidden_shape)\n            418 LOAD_FAST               18 (device)\n            420 LOAD_CONST               8 (('device',))\n            422 CALL_FUNCTION_KW         2\n            424 STORE_FAST               9 (encoder_attention_mask)\n\n879     >>  426 LOAD_FAST                1 (self)\n            428 LOAD_ATTR               20 (invert_attention_mask)\n            430 LOAD_FAST                9 (encoder_attention_mask)\n            432 CALL_FUNCTION            1\n            434 STORE_FAST              27 (encoder_extended_attention_mask)\n            436 JUMP_FORWARD             2 (to 442)\n\n881     >>  438 LOAD_CONST               1 (None)\n            440 STORE_FAST              27 (encoder_extended_attention_mask)\n\n888     >>  442 LOAD_FAST                1 (self)\n            444 LOAD_ATTR               21 (get_head_mask)\n            446 LOAD_FAST                6 (head_mask)\n            448 LOAD_FAST                1 (self)\n            450 LOAD_ATTR                0 (config)\n            452 LOAD_ATTR               22 (num_hidden_layers)\n            454 CALL_FUNCTION            2\n            456 STORE_FAST               6 (head_mask)\n\n890         458 LOAD_FAST                1 (self)\n            460 LOAD_ATTR               14 (embeddings)\n\n891         462 LOAD_FAST                2 (input_ids)\n\n892         464 LOAD_FAST                5 (position_ids)\n\n893         466 LOAD_FAST                4 (token_type_ids)\n\n894         468 LOAD_FAST                7 (inputs_embeds)\n\n895         470 LOAD_FAST               19 (past_key_values_length)\n\n890         472 LOAD_CONST              11 (('input_ids', 'position_ids', 'token_type_ids', 'inputs_embeds', 'past_key_values_length'))\n            474 CALL_FUNCTION_KW         5\n            476 STORE_FAST              28 (embedding_output)\n\n897         478 LOAD_FAST                1 (self)\n            480 LOAD_ATTR               23 (encoder)\n\n898         482 LOAD_FAST               28 (embedding_output)\n\n899         484 LOAD_FAST               22 (extended_attention_mask)\n\n900         486 LOAD_FAST                6 (head_mask)\n\n901         488 LOAD_FAST                8 (encoder_hidden_states)\n\n902         490 LOAD_FAST               27 (encoder_extended_attention_mask)\n\n903         492 LOAD_FAST               10 (past_key_values)\n\n904         494 LOAD_FAST               11 (use_cache)\n\n905         496 LOAD_FAST               12 (output_attentions)\n\n906         498 LOAD_FAST               13 (output_hidden_states)\n\n907         500 LOAD_FAST               14 (return_dict)\n\n897         502 LOAD_CONST              12 (('attention_mask', 'head_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'past_key_values', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n            504 CALL_FUNCTION_KW        10\n            506 STORE_FAST              29 (encoder_outputs)\n\n909         508 LOAD_FAST               29 (encoder_outputs)\n            510 LOAD_CONST               6 (0)\n            512 BINARY_SUBSCR\n            514 STORE_FAST              30 (sequence_output)\n\n910         516 LOAD_FAST                1 (self)\n            518 LOAD_ATTR               24 (pooler)\n            520 LOAD_CONST               1 (None)\n            522 IS_OP                    1\n            524 EXTENDED_ARG             1\n            526 POP_JUMP_IF_FALSE      269 (to 538)\n            528 LOAD_FAST                1 (self)\n            530 LOAD_ATTR               24 (pooler)\n            532 LOAD_FAST               30 (sequence_output)\n            534 CALL_FUNCTION            1\n            536 JUMP_FORWARD             1 (to 540)\n        >>  538 LOAD_CONST               1 (None)\n        >>  540 STORE_FAST              31 (pooled_output)\n\n912         542 LOAD_FAST               14 (return_dict)\n            544 EXTENDED_ARG             1\n            546 POP_JUMP_IF_TRUE       284 (to 568)\n\n913         548 LOAD_FAST               30 (sequence_output)\n            550 LOAD_FAST               31 (pooled_output)\n            552 BUILD_TUPLE              2\n            554 LOAD_FAST               29 (encoder_outputs)\n            556 LOAD_CONST              13 (1)\n            558 LOAD_CONST               1 (None)\n            560 BUILD_SLICE              2\n            562 BINARY_SUBSCR\n            564 BINARY_ADD\n            566 RETURN_VALUE\n\n915     >>  568 LOAD_GLOBAL             25 (BaseModelOutputWithPoolingAndCrossAttentions)\n\n916         570 LOAD_FAST               30 (sequence_output)\n\n917         572 LOAD_FAST               31 (pooled_output)\n\n918         574 LOAD_FAST               29 (encoder_outputs)\n            576 LOAD_ATTR               26 (past_key_values)\n\n919         578 LOAD_FAST               29 (encoder_outputs)\n            580 LOAD_ATTR               27 (hidden_states)\n\n920         582 LOAD_FAST               29 (encoder_outputs)\n            584 LOAD_ATTR               28 (attentions)\n\n921         586 LOAD_FAST               29 (encoder_outputs)\n            588 LOAD_ATTR               29 (cross_attentions)\n\n915         590 LOAD_CONST              14 (('last_hidden_state', 'pooler_output', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n            592 CALL_FUNCTION_KW         6\n            594 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py line 988 \n 988           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           27 (to 54)\n               4 LOAD_FAST                3 (return_dict)\n               6 LOAD_CONST               1 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST                3 (return_dict)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (use_return_dict)\n         >>   22 STORE_FAST               3 (return_dict)\n              24 LOAD_FAST                1 (self)\n              26 LOAD_ATTR                2 (roberta)\n              28 LOAD_FAST                4 (input_ids)\n              30 LOAD_FAST                5 (attention_mask)\n              32 LOAD_FAST                6 (token_type_ids)\n              34 LOAD_FAST                7 (position_ids)\n              36 LOAD_FAST                8 (head_mask)\n              38 LOAD_FAST                9 (inputs_embeds)\n              40 LOAD_FAST               10 (encoder_hidden_states)\n              42 LOAD_FAST               11 (encoder_attention_mask)\n              44 LOAD_FAST               12 (output_attentions)\n              46 LOAD_FAST               13 (output_hidden_states)\n              48 LOAD_FAST                3 (return_dict)\n              50 LOAD_CONST               2 (('attention_mask', 'token_type_ids', 'position_ids', 'head_mask', 'inputs_embeds', 'encoder_hidden_states', 'encoder_attention_mask', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              52 CALL_FUNCTION_KW        11\n         >>   54 STORE_FAST              14 (outputs)\n\n1001          56 LOAD_FAST               14 (outputs)\n              58 LOAD_CONST               3 (0)\n              60 BINARY_SUBSCR\n              62 STORE_FAST              15 (sequence_output)\n\n1002          64 LOAD_FAST                1 (self)\n              66 LOAD_ATTR                3 (lm_head)\n              68 LOAD_FAST               15 (sequence_output)\n              70 CALL_FUNCTION            1\n              72 STORE_FAST              16 (prediction_scores)\n\n1004          74 LOAD_CONST               1 (None)\n              76 STORE_FAST              17 (masked_lm_loss)\n\n1005          78 LOAD_FAST                2 (labels)\n              80 LOAD_CONST               1 (None)\n              82 IS_OP                    1\n              84 POP_JUMP_IF_FALSE       66 (to 132)\n\n1007          86 LOAD_FAST                2 (labels)\n              88 LOAD_ATTR                4 (to)\n              90 LOAD_FAST               16 (prediction_scores)\n              92 LOAD_ATTR                5 (device)\n              94 CALL_FUNCTION            1\n              96 STORE_FAST               2 (labels)\n\n1008          98 LOAD_GLOBAL              6 (CrossEntropyLoss)\n             100 CALL_FUNCTION            0\n             102 STORE_FAST              18 (loss_fct)\n\n1009         104 LOAD_FAST               18 (loss_fct)\n             106 LOAD_FAST               16 (prediction_scores)\n             108 LOAD_ATTR                7 (view)\n             110 LOAD_CONST               4 (-1)\n             112 LOAD_FAST                1 (self)\n             114 LOAD_ATTR                0 (config)\n             116 LOAD_ATTR                8 (vocab_size)\n             118 CALL_FUNCTION            2\n             120 LOAD_FAST                2 (labels)\n             122 LOAD_ATTR                7 (view)\n             124 LOAD_CONST               4 (-1)\n             126 CALL_FUNCTION            1\n             128 CALL_FUNCTION            2\n             130 STORE_FAST              17 (masked_lm_loss)\n\n1011     >>  132 LOAD_FAST                3 (return_dict)\n             134 POP_JUMP_IF_TRUE        88 (to 176)\n\n1012         136 LOAD_FAST               16 (prediction_scores)\n             138 BUILD_TUPLE              1\n             140 LOAD_FAST               14 (outputs)\n             142 LOAD_CONST               5 (2)\n             144 LOAD_CONST               1 (None)\n             146 BUILD_SLICE              2\n             148 BINARY_SUBSCR\n             150 BINARY_ADD\n             152 STORE_FAST              19 (output)\n\n1013         154 LOAD_FAST               17 (masked_lm_loss)\n             156 LOAD_CONST               1 (None)\n             158 IS_OP                    1\n             160 POP_JUMP_IF_FALSE       86 (to 172)\n             162 LOAD_FAST               17 (masked_lm_loss)\n             164 BUILD_TUPLE              1\n             166 LOAD_FAST               19 (output)\n             168 BINARY_ADD\n             170 RETURN_VALUE\n         >>  172 LOAD_FAST               19 (output)\n             174 RETURN_VALUE\n\n1015     >>  176 LOAD_GLOBAL              9 (MaskedLMOutput)\n\n1016         178 LOAD_FAST               17 (masked_lm_loss)\n\n1017         180 LOAD_FAST               16 (prediction_scores)\n\n1018         182 LOAD_FAST               14 (outputs)\n             184 LOAD_ATTR               10 (hidden_states)\n\n1019         186 LOAD_FAST               14 (outputs)\n             188 LOAD_ATTR               11 (attentions)\n\n1015         190 LOAD_CONST               6 (('loss', 'logits', 'hidden_states', 'attentions'))\n             192 CALL_FUNCTION_KW         4\n             194 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 557 \n557           0 LOAD_FAST                0 (___stack0)\n              2 CALL_FUNCTION            0\n              4 SETUP_WITH              10 (to 26)\n              6 POP_TOP\n              8 LOAD_FAST                1 (___stack1)\n             10 JUMP_ABSOLUTE           44 (to 88)\n             12 POP_BLOCK\n             14 LOAD_CONST               0 (None)\n             16 DUP_TOP\n             18 DUP_TOP\n             20 CALL_FUNCTION            3\n             22 POP_TOP\n             24 JUMP_FORWARD             8 (to 42)\n        >>   26 WITH_EXCEPT_START\n             28 POP_JUMP_IF_TRUE        16 (to 32)\n             30 RERAISE                  0\n        >>   32 POP_TOP\n             34 POP_TOP\n             36 POP_TOP\n             38 POP_EXCEPT\n             40 POP_TOP\n        >>   42 NOP\n             44 LOAD_CONST               0 (None)\n             46 RAISE_VARARGS            1\n             48 LOAD_GLOBAL              0 (clone_inputs)\n             50 LOAD_FAST                6 (inputs)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (cloned_inputs)\n             56 LOAD_FAST                2 (self)\n             58 LOAD_ATTR                1 (optimizer_zero_grad)\n             60 LOAD_FAST                3 (mod)\n             62 CALL_FUNCTION            1\n             64 POP_TOP\n             66 LOAD_FAST                2 (self)\n             68 LOAD_ATTR                2 (autocast)\n             70 CALL_FUNCTION            0\n             72 SETUP_WITH              20 (to 114)\n             74 POP_TOP\n             76 LOAD_FAST                3 (mod)\n             78 LOAD_CONST               1 (())\n             80 BUILD_MAP                0\n             82 LOAD_FAST                5 (cloned_inputs)\n             84 DICT_MERGE               1\n             86 CALL_FUNCTION_EX         1\n        >>   88 STORE_FAST               7 (pred)\n\n558          90 LOAD_FAST                2 (self)\n             92 LOAD_ATTR                3 (compute_loss)\n             94 LOAD_FAST                7 (pred)\n             96 CALL_FUNCTION            1\n             98 STORE_FAST               8 (loss)\n            100 POP_BLOCK\n\n556         102 LOAD_CONST               0 (None)\n            104 DUP_TOP\n            106 DUP_TOP\n            108 CALL_FUNCTION            3\n            110 POP_TOP\n            112 JUMP_FORWARD             8 (to 130)\n        >>  114 WITH_EXCEPT_START\n            116 POP_JUMP_IF_TRUE        60 (to 120)\n            118 RERAISE                  1\n        >>  120 POP_TOP\n            122 POP_TOP\n            124 POP_TOP\n            126 POP_EXCEPT\n            128 POP_TOP\n\n559     >>  130 LOAD_FAST                2 (self)\n            132 LOAD_ATTR                4 (grad_scaler)\n            134 LOAD_ATTR                5 (scale)\n            136 LOAD_FAST                8 (loss)\n            138 CALL_FUNCTION            1\n            140 LOAD_ATTR                6 (backward)\n            142 CALL_FUNCTION            0\n            144 POP_TOP\n\n560         146 LOAD_FAST                2 (self)\n            148 LOAD_ATTR                7 (optimizer_step)\n            150 CALL_FUNCTION            0\n            152 POP_TOP\n\n561         154 LOAD_FAST                4 (collect_outputs)\n            156 POP_JUMP_IF_FALSE       86 (to 172)\n\n562         158 LOAD_GLOBAL              8 (collect_results)\n            160 LOAD_FAST                3 (mod)\n            162 LOAD_FAST                7 (pred)\n            164 LOAD_FAST                8 (loss)\n            166 LOAD_FAST                5 (cloned_inputs)\n            168 CALL_FUNCTION            4\n            170 RETURN_VALUE\n\n563     >>  172 LOAD_CONST               0 (None)\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 1279 \n1309           0 LOAD_FAST               16 (return_dict)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               16 (return_dict)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (use_return_dict)\n         >>   18 STORE_FAST              16 (return_dict)\n\n1311          20 LOAD_FAST               12 (labels)\n              22 LOAD_CONST               1 (None)\n              24 IS_OP                    1\n              26 POP_JUMP_IF_FALSE       28 (to 56)\n\n1312          28 LOAD_FAST                3 (decoder_input_ids)\n              30 LOAD_CONST               1 (None)\n              32 IS_OP                    0\n              34 POP_JUMP_IF_FALSE       28 (to 56)\n\n1313          36 LOAD_GLOBAL              2 (shift_tokens_right)\n\n1314          38 LOAD_FAST               12 (labels)\n              40 LOAD_FAST                0 (self)\n              42 LOAD_ATTR                0 (config)\n              44 LOAD_ATTR                3 (pad_token_id)\n              46 LOAD_FAST                0 (self)\n              48 LOAD_ATTR                0 (config)\n              50 LOAD_ATTR                4 (decoder_start_token_id)\n\n1313          52 CALL_FUNCTION            3\n              54 STORE_FAST               3 (decoder_input_ids)\n\n1317     >>   56 LOAD_FAST                0 (self)\n              58 LOAD_ATTR                5 (model)\n\n1318          60 LOAD_FAST                1 (input_ids)\n\n1319          62 LOAD_FAST                2 (attention_mask)\n\n1320          64 LOAD_FAST                3 (decoder_input_ids)\n\n1321          66 LOAD_FAST                8 (encoder_outputs)\n\n1322          68 LOAD_FAST                4 (decoder_attention_mask)\n\n1323          70 LOAD_FAST                5 (head_mask)\n\n1324          72 LOAD_FAST                6 (decoder_head_mask)\n\n1325          74 LOAD_FAST                7 (cross_attn_head_mask)\n\n1326          76 LOAD_FAST                9 (past_key_values)\n\n1327          78 LOAD_FAST               10 (inputs_embeds)\n\n1328          80 LOAD_FAST               11 (decoder_inputs_embeds)\n\n1329          82 LOAD_FAST               13 (use_cache)\n\n1330          84 LOAD_FAST               14 (output_attentions)\n\n1331          86 LOAD_FAST               15 (output_hidden_states)\n\n1332          88 LOAD_FAST               16 (return_dict)\n\n1317          90 LOAD_CONST               2 (('attention_mask', 'decoder_input_ids', 'encoder_outputs', 'decoder_attention_mask', 'head_mask', 'decoder_head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'decoder_inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              92 CALL_FUNCTION_KW        15\n              94 STORE_FAST              17 (outputs)\n\n1334          96 LOAD_FAST                0 (self)\n              98 LOAD_METHOD              6 (lm_head)\n             100 LOAD_FAST               17 (outputs)\n             102 LOAD_CONST               3 (0)\n             104 BINARY_SUBSCR\n             106 CALL_METHOD              1\n             108 STORE_FAST              18 (lm_logits)\n\n1336         110 LOAD_CONST               1 (None)\n             112 STORE_FAST              19 (masked_lm_loss)\n\n1337         114 LOAD_FAST               12 (labels)\n             116 LOAD_CONST               1 (None)\n             118 IS_OP                    1\n             120 POP_JUMP_IF_FALSE       84 (to 168)\n\n1339         122 LOAD_FAST               12 (labels)\n             124 LOAD_METHOD              7 (to)\n             126 LOAD_FAST               18 (lm_logits)\n             128 LOAD_ATTR                8 (device)\n             130 CALL_METHOD              1\n             132 STORE_FAST              12 (labels)\n\n1340         134 LOAD_GLOBAL              9 (CrossEntropyLoss)\n             136 CALL_FUNCTION            0\n             138 STORE_FAST              20 (loss_fct)\n\n1341         140 LOAD_FAST               20 (loss_fct)\n             142 LOAD_FAST               18 (lm_logits)\n             144 LOAD_METHOD             10 (view)\n             146 LOAD_CONST               4 (-1)\n             148 LOAD_FAST                0 (self)\n             150 LOAD_ATTR                0 (config)\n             152 LOAD_ATTR               11 (vocab_size)\n             154 CALL_METHOD              2\n             156 LOAD_FAST               12 (labels)\n             158 LOAD_METHOD             10 (view)\n             160 LOAD_CONST               4 (-1)\n             162 CALL_METHOD              1\n             164 CALL_FUNCTION            2\n             166 STORE_FAST              19 (masked_lm_loss)\n\n1343     >>  168 LOAD_FAST               16 (return_dict)\n             170 POP_JUMP_IF_TRUE       106 (to 212)\n\n1344         172 LOAD_FAST               18 (lm_logits)\n             174 BUILD_TUPLE              1\n             176 LOAD_FAST               17 (outputs)\n             178 LOAD_CONST               5 (1)\n             180 LOAD_CONST               1 (None)\n             182 BUILD_SLICE              2\n             184 BINARY_SUBSCR\n             186 BINARY_ADD\n             188 STORE_FAST              21 (output)\n\n1345         190 LOAD_FAST               19 (masked_lm_loss)\n             192 LOAD_CONST               1 (None)\n             194 IS_OP                    1\n             196 POP_JUMP_IF_FALSE      104 (to 208)\n             198 LOAD_FAST               19 (masked_lm_loss)\n             200 BUILD_TUPLE              1\n             202 LOAD_FAST               21 (output)\n             204 BINARY_ADD\n             206 RETURN_VALUE\n         >>  208 LOAD_FAST               21 (output)\n             210 RETURN_VALUE\n\n1347     >>  212 LOAD_GLOBAL             12 (Seq2SeqLMOutput)\n\n1348         214 LOAD_FAST               19 (masked_lm_loss)\n\n1349         216 LOAD_FAST               18 (lm_logits)\n\n1350         218 LOAD_FAST               17 (outputs)\n             220 LOAD_ATTR               13 (past_key_values)\n\n1351         222 LOAD_FAST               17 (outputs)\n             224 LOAD_ATTR               14 (decoder_hidden_states)\n\n1352         226 LOAD_FAST               17 (outputs)\n             228 LOAD_ATTR               15 (decoder_attentions)\n\n1353         230 LOAD_FAST               17 (outputs)\n             232 LOAD_ATTR               16 (cross_attentions)\n\n1354         234 LOAD_FAST               17 (outputs)\n             236 LOAD_ATTR               17 (encoder_last_hidden_state)\n\n1355         238 LOAD_FAST               17 (outputs)\n             240 LOAD_ATTR               18 (encoder_hidden_states)\n\n1356         242 LOAD_FAST               17 (outputs)\n             244 LOAD_ATTR               19 (encoder_attentions)\n\n1347         246 LOAD_CONST               6 (('loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             248 CALL_FUNCTION_KW         9\n             250 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 1168 \n1192           0 LOAD_FAST               13 (output_attentions)\n               2 LOAD_CONST               0 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               13 (output_attentions)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (output_attentions)\n         >>   18 STORE_FAST              13 (output_attentions)\n\n1194          20 LOAD_FAST               14 (output_hidden_states)\n              22 LOAD_CONST               0 (None)\n              24 IS_OP                    1\n              26 POP_JUMP_IF_FALSE       16 (to 32)\n              28 LOAD_FAST               14 (output_hidden_states)\n              30 JUMP_FORWARD             3 (to 38)\n         >>   32 LOAD_FAST                0 (self)\n              34 LOAD_ATTR                0 (config)\n              36 LOAD_ATTR                2 (output_hidden_states)\n\n1193     >>   38 STORE_FAST              14 (output_hidden_states)\n\n1196          40 LOAD_FAST               12 (use_cache)\n              42 LOAD_CONST               0 (None)\n              44 IS_OP                    1\n              46 POP_JUMP_IF_FALSE       26 (to 52)\n              48 LOAD_FAST               12 (use_cache)\n              50 JUMP_FORWARD             3 (to 58)\n         >>   52 LOAD_FAST                0 (self)\n              54 LOAD_ATTR                0 (config)\n              56 LOAD_ATTR                3 (use_cache)\n         >>   58 STORE_FAST              12 (use_cache)\n\n1197          60 LOAD_FAST               15 (return_dict)\n              62 LOAD_CONST               0 (None)\n              64 IS_OP                    1\n              66 POP_JUMP_IF_FALSE       36 (to 72)\n              68 LOAD_FAST               15 (return_dict)\n              70 JUMP_FORWARD             3 (to 78)\n         >>   72 LOAD_FAST                0 (self)\n              74 LOAD_ATTR                0 (config)\n              76 LOAD_ATTR                4 (use_return_dict)\n         >>   78 STORE_FAST              15 (return_dict)\n\n1199          80 LOAD_FAST                8 (encoder_outputs)\n              82 LOAD_CONST               0 (None)\n              84 IS_OP                    0\n              86 POP_JUMP_IF_FALSE       57 (to 114)\n\n1200          88 LOAD_FAST                0 (self)\n              90 LOAD_ATTR                5 (encoder)\n\n1201          92 LOAD_FAST                1 (input_ids)\n\n1202          94 LOAD_FAST                2 (attention_mask)\n\n1203          96 LOAD_FAST                5 (head_mask)\n\n1204          98 LOAD_FAST               10 (inputs_embeds)\n\n1205         100 LOAD_FAST               13 (output_attentions)\n\n1206         102 LOAD_FAST               14 (output_hidden_states)\n\n1207         104 LOAD_FAST               15 (return_dict)\n\n1200         106 LOAD_CONST               1 (('input_ids', 'attention_mask', 'head_mask', 'inputs_embeds', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             108 CALL_FUNCTION_KW         7\n             110 STORE_FAST               8 (encoder_outputs)\n             112 JUMP_FORWARD            36 (to 186)\n\n1210     >>  114 LOAD_FAST               15 (return_dict)\n             116 POP_JUMP_IF_FALSE       93 (to 186)\n             118 LOAD_GLOBAL              6 (isinstance)\n             120 LOAD_FAST                8 (encoder_outputs)\n             122 LOAD_GLOBAL              7 (BaseModelOutput)\n             124 CALL_FUNCTION            2\n             126 POP_JUMP_IF_TRUE        93 (to 186)\n\n1211         128 LOAD_GLOBAL              7 (BaseModelOutput)\n\n1212         130 LOAD_FAST                8 (encoder_outputs)\n             132 LOAD_CONST               2 (0)\n             134 BINARY_SUBSCR\n\n1213         136 LOAD_GLOBAL              8 (len)\n             138 LOAD_FAST                8 (encoder_outputs)\n             140 CALL_FUNCTION            1\n             142 LOAD_CONST               3 (1)\n             144 COMPARE_OP               4 (>)\n             146 POP_JUMP_IF_FALSE       78 (to 156)\n             148 LOAD_FAST                8 (encoder_outputs)\n             150 LOAD_CONST               3 (1)\n             152 BINARY_SUBSCR\n             154 JUMP_FORWARD             1 (to 158)\n         >>  156 LOAD_CONST               0 (None)\n\n1214     >>  158 LOAD_GLOBAL              8 (len)\n             160 LOAD_FAST                8 (encoder_outputs)\n             162 CALL_FUNCTION            1\n             164 LOAD_CONST               4 (2)\n             166 COMPARE_OP               4 (>)\n             168 POP_JUMP_IF_FALSE       89 (to 178)\n             170 LOAD_FAST                8 (encoder_outputs)\n             172 LOAD_CONST               4 (2)\n             174 BINARY_SUBSCR\n             176 JUMP_FORWARD             1 (to 180)\n         >>  178 LOAD_CONST               0 (None)\n\n1211     >>  180 LOAD_CONST               5 (('last_hidden_state', 'hidden_states', 'attentions'))\n             182 CALL_FUNCTION_KW         3\n             184 STORE_FAST               8 (encoder_outputs)\n\n1218     >>  186 LOAD_FAST                0 (self)\n             188 LOAD_ATTR                9 (decoder)\n\n1219         190 LOAD_FAST                3 (decoder_input_ids)\n\n1220         192 LOAD_FAST                4 (decoder_attention_mask)\n\n1221         194 LOAD_FAST                8 (encoder_outputs)\n             196 LOAD_CONST               2 (0)\n             198 BINARY_SUBSCR\n\n1222         200 LOAD_FAST                2 (attention_mask)\n\n1223         202 LOAD_FAST                6 (decoder_head_mask)\n\n1224         204 LOAD_FAST                7 (cross_attn_head_mask)\n\n1225         206 LOAD_FAST                9 (past_key_values)\n\n1226         208 LOAD_FAST               11 (decoder_inputs_embeds)\n\n1227         210 LOAD_FAST               12 (use_cache)\n\n1228         212 LOAD_FAST               13 (output_attentions)\n\n1229         214 LOAD_FAST               14 (output_hidden_states)\n\n1230         216 LOAD_FAST               15 (return_dict)\n\n1218         218 LOAD_CONST               6 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             220 CALL_FUNCTION_KW        12\n             222 STORE_FAST              16 (decoder_outputs)\n\n1233         224 LOAD_FAST               15 (return_dict)\n             226 POP_JUMP_IF_TRUE       118 (to 236)\n\n1234         228 LOAD_FAST               16 (decoder_outputs)\n             230 LOAD_FAST                8 (encoder_outputs)\n             232 BINARY_ADD\n             234 RETURN_VALUE\n\n1236     >>  236 LOAD_GLOBAL             10 (Seq2SeqModelOutput)\n\n1237         238 LOAD_FAST               16 (decoder_outputs)\n             240 LOAD_ATTR               11 (last_hidden_state)\n\n1238         242 LOAD_FAST               16 (decoder_outputs)\n             244 LOAD_ATTR               12 (past_key_values)\n\n1239         246 LOAD_FAST               16 (decoder_outputs)\n             248 LOAD_ATTR               13 (hidden_states)\n\n1240         250 LOAD_FAST               16 (decoder_outputs)\n             252 LOAD_ATTR               14 (attentions)\n\n1241         254 LOAD_FAST               16 (decoder_outputs)\n             256 LOAD_ATTR               15 (cross_attentions)\n\n1242         258 LOAD_FAST                8 (encoder_outputs)\n             260 LOAD_ATTR               11 (last_hidden_state)\n\n1243         262 LOAD_FAST                8 (encoder_outputs)\n             264 LOAD_ATTR               13 (hidden_states)\n\n1244         266 LOAD_FAST                8 (encoder_outputs)\n             268 LOAD_ATTR               14 (attentions)\n\n1236         270 LOAD_CONST               7 (('last_hidden_state', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             272 CALL_FUNCTION_KW         8\n             274 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 157 \n161           0 LOAD_FAST                1 (input_ids)\n              2 LOAD_CONST               0 (None)\n              4 IS_OP                    1\n              6 POP_JUMP_IF_FALSE       22 (to 44)\n\n162           8 LOAD_FAST                1 (input_ids)\n             10 LOAD_METHOD              0 (size)\n             12 CALL_METHOD              0\n             14 UNPACK_SEQUENCE          2\n             16 STORE_FAST               4 (bsz)\n             18 STORE_FAST               5 (seq_len)\n\n164          20 LOAD_GLOBAL              1 (create_position_ids_from_input_ids)\n             22 LOAD_FAST                1 (input_ids)\n             24 LOAD_FAST                0 (self)\n             26 LOAD_ATTR                2 (padding_idx)\n             28 LOAD_FAST                3 (past_key_values_length)\n             30 CALL_FUNCTION            3\n             32 LOAD_METHOD              3 (to)\n\n165          34 LOAD_FAST                1 (input_ids)\n             36 LOAD_ATTR                4 (device)\n\n164          38 CALL_METHOD              1\n             40 STORE_FAST               6 (position_ids)\n             42 JUMP_FORWARD            16 (to 76)\n\n168     >>   44 LOAD_FAST                2 (inputs_embeds)\n             46 LOAD_METHOD              0 (size)\n             48 CALL_METHOD              0\n             50 LOAD_CONST               0 (None)\n             52 LOAD_CONST               1 (-1)\n             54 BUILD_SLICE              2\n             56 BINARY_SUBSCR\n             58 UNPACK_SEQUENCE          2\n             60 STORE_FAST               4 (bsz)\n             62 STORE_FAST               5 (seq_len)\n\n169          64 LOAD_FAST                0 (self)\n             66 LOAD_METHOD              5 (create_position_ids_from_inputs_embeds)\n             68 LOAD_FAST                2 (inputs_embeds)\n             70 LOAD_FAST                3 (past_key_values_length)\n             72 CALL_METHOD              2\n             74 STORE_FAST               6 (position_ids)\n\n172     >>   76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                2 (padding_idx)\n             80 LOAD_CONST               2 (1)\n             82 BINARY_ADD\n             84 LOAD_FAST                5 (seq_len)\n             86 BINARY_ADD\n             88 LOAD_FAST                3 (past_key_values_length)\n             90 BINARY_ADD\n             92 STORE_FAST               7 (max_pos)\n\n173          94 LOAD_FAST                7 (max_pos)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                6 (weights)\n            100 LOAD_METHOD              0 (size)\n            102 LOAD_CONST               3 (0)\n            104 CALL_METHOD              1\n            106 COMPARE_OP               4 (>)\n            108 POP_JUMP_IF_FALSE       67 (to 134)\n\n174         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              7 (make_weights)\n            114 LOAD_FAST                7 (max_pos)\n            116 LOAD_FAST                0 (self)\n            118 LOAD_ATTR                8 (offset)\n            120 BINARY_ADD\n            122 LOAD_FAST                0 (self)\n            124 LOAD_ATTR                9 (embedding_dim)\n            126 LOAD_FAST                0 (self)\n            128 LOAD_ATTR                2 (padding_idx)\n            130 CALL_METHOD              3\n            132 POP_TOP\n\n176     >>  134 LOAD_FAST                0 (self)\n            136 LOAD_ATTR                6 (weights)\n            138 LOAD_METHOD             10 (index_select)\n            140 LOAD_CONST               3 (0)\n            142 LOAD_FAST                6 (position_ids)\n            144 LOAD_METHOD             11 (view)\n            146 LOAD_CONST               1 (-1)\n            148 CALL_METHOD              1\n            150 CALL_METHOD              2\n            152 LOAD_METHOD             11 (view)\n            154 LOAD_FAST                4 (bsz)\n            156 LOAD_FAST                5 (seq_len)\n            158 LOAD_FAST                0 (self)\n            160 LOAD_ATTR                6 (weights)\n            162 LOAD_ATTR               12 (shape)\n            164 LOAD_CONST               1 (-1)\n            166 BINARY_SUBSCR\n            168 CALL_METHOD              3\n            170 LOAD_METHOD             13 (detach)\n            172 CALL_METHOD              0\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 369 \n387           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n388           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n389          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n390          18 LOAD_FAST                1 (hidden_states)\n\n391          20 LOAD_FAST                2 (attention_mask)\n\n392          22 LOAD_FAST                3 (layer_head_mask)\n\n393          24 LOAD_FAST                4 (output_attentions)\n\n389          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n395          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n396          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n398          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n399          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n400          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n401          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n402         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n403         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n404         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n406         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n407         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n406         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n407         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n406         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n409     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n410         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n412     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n414         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n415         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n417     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 369 \n387           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n388           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n389          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n390          18 LOAD_FAST                1 (hidden_states)\n\n391          20 LOAD_FAST                2 (attention_mask)\n\n392          22 LOAD_FAST                3 (layer_head_mask)\n\n393          24 LOAD_FAST                4 (output_attentions)\n\n389          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n395          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n396          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n398          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n399          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n400          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n401          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n402         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n403         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n404         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n406         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n407         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n406         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n407         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n406         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n409     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n410         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n412     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n414         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n415         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n417     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 369 \n387           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n388           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n389          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n390          18 LOAD_FAST                1 (hidden_states)\n\n391          20 LOAD_FAST                2 (attention_mask)\n\n392          22 LOAD_FAST                3 (layer_head_mask)\n\n393          24 LOAD_FAST                4 (output_attentions)\n\n389          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n395          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n396          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n398          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n399          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n400          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n401          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n402         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n403         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n404         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n406         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n407         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n406         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n407         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n406         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n409     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n410         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n412     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n414         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n415         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n417     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 369 \n387           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n388           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n389          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n390          18 LOAD_FAST                1 (hidden_states)\n\n391          20 LOAD_FAST                2 (attention_mask)\n\n392          22 LOAD_FAST                3 (layer_head_mask)\n\n393          24 LOAD_FAST                4 (output_attentions)\n\n389          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n395          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n396          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n398          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n399          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n400          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n401          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n402         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n403         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n404         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n406         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n407         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n406         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n407         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n406         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n409     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n410         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n412     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n414         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n415         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n417     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 369 \n387           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n388           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n389          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n390          18 LOAD_FAST                1 (hidden_states)\n\n391          20 LOAD_FAST                2 (attention_mask)\n\n392          22 LOAD_FAST                3 (layer_head_mask)\n\n393          24 LOAD_FAST                4 (output_attentions)\n\n389          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n395          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n396          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n398          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n399          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n400          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n401          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n402         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n403         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n404         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n406         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n407         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n406         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n407         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n406         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n409     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n410         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n412     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n414         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n415         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n417     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 369 \n387           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n388           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n389          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n390          18 LOAD_FAST                1 (hidden_states)\n\n391          20 LOAD_FAST                2 (attention_mask)\n\n392          22 LOAD_FAST                3 (layer_head_mask)\n\n393          24 LOAD_FAST                4 (output_attentions)\n\n389          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n395          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n396          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n398          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n399          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n400          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n401          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n402         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n403         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n404         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n406         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n407         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n406         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n407         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n406         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n409     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n410         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n412     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n414         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n415         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n417     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 369 \n387           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n388           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n389          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n390          18 LOAD_FAST                1 (hidden_states)\n\n391          20 LOAD_FAST                2 (attention_mask)\n\n392          22 LOAD_FAST                3 (layer_head_mask)\n\n393          24 LOAD_FAST                4 (output_attentions)\n\n389          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n395          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n396          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n398          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n399          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n400          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n401          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n402         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n403         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n404         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n406         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n407         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n406         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n407         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n406         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n409     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n410         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n412     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n414         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n415         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n417     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 369 \n387           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n388           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n389          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n390          18 LOAD_FAST                1 (hidden_states)\n\n391          20 LOAD_FAST                2 (attention_mask)\n\n392          22 LOAD_FAST                3 (layer_head_mask)\n\n393          24 LOAD_FAST                4 (output_attentions)\n\n389          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n395          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n396          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n398          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n399          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n400          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n401          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n402         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n403         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n404         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n406         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n407         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n406         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n407         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n406         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n409     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n410         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n412     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n414         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n415         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n417     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 369 \n387           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n388           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n389          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n390          18 LOAD_FAST                1 (hidden_states)\n\n391          20 LOAD_FAST                2 (attention_mask)\n\n392          22 LOAD_FAST                3 (layer_head_mask)\n\n393          24 LOAD_FAST                4 (output_attentions)\n\n389          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n395          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n396          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n398          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n399          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n400          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n401          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n402         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n403         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n404         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n406         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n407         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n406         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n407         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n406         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n409     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n410         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n412     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n414         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n415         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n417     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 369 \n387           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n388           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n389          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n390          18 LOAD_FAST                1 (hidden_states)\n\n391          20 LOAD_FAST                2 (attention_mask)\n\n392          22 LOAD_FAST                3 (layer_head_mask)\n\n393          24 LOAD_FAST                4 (output_attentions)\n\n389          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n395          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n396          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n398          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n399          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n400          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n401          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n402         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n403         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n404         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n406         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n407         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n406         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n407         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n406         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n409     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n410         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n412     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n414         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n415         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n417     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 369 \n387           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n388           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n389          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n390          18 LOAD_FAST                1 (hidden_states)\n\n391          20 LOAD_FAST                2 (attention_mask)\n\n392          22 LOAD_FAST                3 (layer_head_mask)\n\n393          24 LOAD_FAST                4 (output_attentions)\n\n389          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n395          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n396          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n398          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n399          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n400          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n401          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n402         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n403         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n404         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n406         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n407         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n406         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n407         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n406         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n409     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n410         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n412     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n414         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n415         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n417     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 369 \n387           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n388           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n389          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n390          18 LOAD_FAST                1 (hidden_states)\n\n391          20 LOAD_FAST                2 (attention_mask)\n\n392          22 LOAD_FAST                3 (layer_head_mask)\n\n393          24 LOAD_FAST                4 (output_attentions)\n\n389          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n395          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n396          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n398          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n399          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n400          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n401          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n402         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n403         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n404         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n406         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n407         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n406         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n407         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n406         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n409     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n410         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n412     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n414         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n415         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n417     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (hidden_states)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (hidden_states)\n\n  5          12 LOAD_FAST                3 (attentions)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (attentions)\n\n  6          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              3 (__post_init__)\n             22 CALL_METHOD              0\n             24 POP_TOP\n             26 LOAD_CONST               0 (None)\n             28 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 1200 \n1200           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           57 (to 114)\n               4 LOAD_FAST               10 (output_attentions)\n               6 LOAD_CONST               0 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST               10 (output_attentions)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (output_attentions)\n         >>   22 STORE_FAST              10 (output_attentions)\n              24 LOAD_FAST               11 (output_hidden_states)\n              26 LOAD_CONST               0 (None)\n              28 IS_OP                    1\n              30 POP_JUMP_IF_FALSE       18 (to 36)\n              32 LOAD_FAST               11 (output_hidden_states)\n              34 JUMP_FORWARD             3 (to 42)\n         >>   36 LOAD_FAST                1 (self)\n              38 LOAD_ATTR                0 (config)\n              40 LOAD_ATTR                2 (output_hidden_states)\n         >>   42 STORE_FAST              11 (output_hidden_states)\n              44 LOAD_FAST                9 (use_cache)\n              46 LOAD_CONST               0 (None)\n              48 IS_OP                    1\n              50 POP_JUMP_IF_FALSE       28 (to 56)\n              52 LOAD_FAST                9 (use_cache)\n              54 JUMP_FORWARD             3 (to 62)\n         >>   56 LOAD_FAST                1 (self)\n              58 LOAD_ATTR                0 (config)\n              60 LOAD_ATTR                3 (use_cache)\n         >>   62 STORE_FAST               9 (use_cache)\n              64 LOAD_FAST               12 (return_dict)\n              66 LOAD_CONST               0 (None)\n              68 IS_OP                    1\n              70 POP_JUMP_IF_FALSE       38 (to 76)\n              72 LOAD_FAST               12 (return_dict)\n              74 JUMP_FORWARD             3 (to 82)\n         >>   76 LOAD_FAST                1 (self)\n              78 LOAD_ATTR                0 (config)\n              80 LOAD_ATTR                4 (use_return_dict)\n         >>   82 STORE_FAST              12 (return_dict)\n              84 LOAD_FAST               15 (encoder_outputs)\n              86 LOAD_CONST               0 (None)\n              88 IS_OP                    0\n              90 POP_JUMP_IF_FALSE       59 (to 118)\n              92 LOAD_FAST                1 (self)\n              94 LOAD_ATTR                5 (encoder)\n              96 LOAD_FAST               13 (input_ids)\n              98 LOAD_FAST                2 (attention_mask)\n             100 LOAD_FAST               14 (head_mask)\n             102 LOAD_FAST               16 (inputs_embeds)\n             104 LOAD_FAST               10 (output_attentions)\n             106 LOAD_FAST               11 (output_hidden_states)\n             108 LOAD_FAST               12 (return_dict)\n             110 LOAD_CONST               1 (('input_ids', 'attention_mask', 'head_mask', 'inputs_embeds', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             112 CALL_FUNCTION_KW         7\n         >>  114 STORE_FAST              15 (encoder_outputs)\n             116 JUMP_FORWARD            36 (to 190)\n\n1210     >>  118 LOAD_FAST               12 (return_dict)\n             120 POP_JUMP_IF_FALSE       95 (to 190)\n             122 LOAD_GLOBAL              6 (isinstance)\n             124 LOAD_FAST               15 (encoder_outputs)\n             126 LOAD_GLOBAL              7 (BaseModelOutput)\n             128 CALL_FUNCTION            2\n             130 POP_JUMP_IF_TRUE        95 (to 190)\n\n1211         132 LOAD_GLOBAL              7 (BaseModelOutput)\n\n1212         134 LOAD_FAST               15 (encoder_outputs)\n             136 LOAD_CONST               2 (0)\n             138 BINARY_SUBSCR\n\n1213         140 LOAD_GLOBAL              8 (len)\n             142 LOAD_FAST               15 (encoder_outputs)\n             144 CALL_FUNCTION            1\n             146 LOAD_CONST               3 (1)\n             148 COMPARE_OP               4 (>)\n             150 POP_JUMP_IF_FALSE       80 (to 160)\n             152 LOAD_FAST               15 (encoder_outputs)\n             154 LOAD_CONST               3 (1)\n             156 BINARY_SUBSCR\n             158 JUMP_FORWARD             1 (to 162)\n         >>  160 LOAD_CONST               0 (None)\n\n1214     >>  162 LOAD_GLOBAL              8 (len)\n             164 LOAD_FAST               15 (encoder_outputs)\n             166 CALL_FUNCTION            1\n             168 LOAD_CONST               4 (2)\n             170 COMPARE_OP               4 (>)\n             172 POP_JUMP_IF_FALSE       91 (to 182)\n             174 LOAD_FAST               15 (encoder_outputs)\n             176 LOAD_CONST               4 (2)\n             178 BINARY_SUBSCR\n             180 JUMP_FORWARD             1 (to 184)\n         >>  182 LOAD_CONST               0 (None)\n\n1211     >>  184 LOAD_CONST               5 (('last_hidden_state', 'hidden_states', 'attentions'))\n             186 CALL_FUNCTION_KW         3\n             188 STORE_FAST              15 (encoder_outputs)\n\n1218     >>  190 LOAD_FAST                1 (self)\n             192 LOAD_ATTR                9 (decoder)\n\n1219         194 LOAD_FAST                3 (decoder_input_ids)\n\n1220         196 LOAD_FAST                4 (decoder_attention_mask)\n\n1221         198 LOAD_FAST               15 (encoder_outputs)\n             200 LOAD_CONST               2 (0)\n             202 BINARY_SUBSCR\n\n1222         204 LOAD_FAST                2 (attention_mask)\n\n1223         206 LOAD_FAST                5 (decoder_head_mask)\n\n1224         208 LOAD_FAST                6 (cross_attn_head_mask)\n\n1225         210 LOAD_FAST                7 (past_key_values)\n\n1226         212 LOAD_FAST                8 (decoder_inputs_embeds)\n\n1227         214 LOAD_FAST                9 (use_cache)\n\n1228         216 LOAD_FAST               10 (output_attentions)\n\n1229         218 LOAD_FAST               11 (output_hidden_states)\n\n1230         220 LOAD_FAST               12 (return_dict)\n\n1218         222 LOAD_CONST               6 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             224 CALL_FUNCTION_KW        12\n             226 STORE_FAST              17 (decoder_outputs)\n\n1233         228 LOAD_FAST               12 (return_dict)\n             230 POP_JUMP_IF_TRUE       120 (to 240)\n\n1234         232 LOAD_FAST               17 (decoder_outputs)\n             234 LOAD_FAST               15 (encoder_outputs)\n             236 BINARY_ADD\n             238 RETURN_VALUE\n\n1236     >>  240 LOAD_GLOBAL             10 (Seq2SeqModelOutput)\n\n1237         242 LOAD_FAST               17 (decoder_outputs)\n             244 LOAD_ATTR               11 (last_hidden_state)\n\n1238         246 LOAD_FAST               17 (decoder_outputs)\n             248 LOAD_ATTR               12 (past_key_values)\n\n1239         250 LOAD_FAST               17 (decoder_outputs)\n             252 LOAD_ATTR               13 (hidden_states)\n\n1240         254 LOAD_FAST               17 (decoder_outputs)\n             256 LOAD_ATTR               14 (attentions)\n\n1241         258 LOAD_FAST               17 (decoder_outputs)\n             260 LOAD_ATTR               15 (cross_attentions)\n\n1242         262 LOAD_FAST               15 (encoder_outputs)\n             264 LOAD_ATTR               11 (last_hidden_state)\n\n1243         266 LOAD_FAST               15 (encoder_outputs)\n             268 LOAD_ATTR               13 (hidden_states)\n\n1244         270 LOAD_FAST               15 (encoder_outputs)\n             272 LOAD_ATTR               14 (attentions)\n\n1236         274 LOAD_CONST               7 (('last_hidden_state', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             276 CALL_FUNCTION_KW         8\n             278 RETURN_VALUE\n\n", "ORIGINAL BYTECODE _make_causal_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 75 \n 81           0 LOAD_FAST                0 (input_ids_shape)\n              2 UNPACK_SEQUENCE          2\n              4 STORE_FAST               4 (bsz)\n              6 STORE_FAST               5 (tgt_len)\n\n 82           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (full)\n             12 LOAD_FAST                5 (tgt_len)\n             14 LOAD_FAST                5 (tgt_len)\n             16 BUILD_TUPLE              2\n             18 LOAD_GLOBAL              0 (torch)\n             20 LOAD_METHOD              2 (finfo)\n             22 LOAD_FAST                1 (dtype)\n             24 CALL_METHOD              1\n             26 LOAD_ATTR                3 (min)\n             28 LOAD_FAST                2 (device)\n             30 LOAD_CONST               1 (('device',))\n             32 CALL_FUNCTION_KW         3\n             34 STORE_FAST               6 (mask)\n\n 83          36 LOAD_GLOBAL              0 (torch)\n             38 LOAD_ATTR                4 (arange)\n             40 LOAD_FAST                6 (mask)\n             42 LOAD_METHOD              5 (size)\n             44 LOAD_CONST               2 (-1)\n             46 CALL_METHOD              1\n             48 LOAD_FAST                2 (device)\n             50 LOAD_CONST               1 (('device',))\n             52 CALL_FUNCTION_KW         2\n             54 STORE_FAST               7 (mask_cond)\n\n 84          56 LOAD_FAST                6 (mask)\n             58 LOAD_METHOD              6 (masked_fill_)\n             60 LOAD_FAST                7 (mask_cond)\n             62 LOAD_FAST                7 (mask_cond)\n             64 LOAD_CONST               3 (1)\n             66 BINARY_ADD\n             68 LOAD_METHOD              7 (view)\n             70 LOAD_FAST                6 (mask)\n             72 LOAD_METHOD              5 (size)\n             74 LOAD_CONST               2 (-1)\n             76 CALL_METHOD              1\n             78 LOAD_CONST               3 (1)\n             80 CALL_METHOD              2\n             82 COMPARE_OP               0 (<)\n             84 LOAD_CONST               4 (0)\n             86 CALL_METHOD              2\n             88 POP_TOP\n\n 85          90 LOAD_FAST                6 (mask)\n             92 LOAD_METHOD              8 (to)\n             94 LOAD_FAST                1 (dtype)\n             96 CALL_METHOD              1\n             98 STORE_FAST               6 (mask)\n\n 87         100 LOAD_FAST                3 (past_key_values_length)\n            102 LOAD_CONST               4 (0)\n            104 COMPARE_OP               4 (>)\n            106 POP_JUMP_IF_FALSE       70 (to 140)\n\n 88         108 LOAD_GLOBAL              0 (torch)\n            110 LOAD_ATTR                9 (cat)\n            112 LOAD_GLOBAL              0 (torch)\n            114 LOAD_ATTR               10 (zeros)\n            116 LOAD_FAST                5 (tgt_len)\n            118 LOAD_FAST                3 (past_key_values_length)\n            120 LOAD_FAST                1 (dtype)\n            122 LOAD_FAST                2 (device)\n            124 LOAD_CONST               5 (('dtype', 'device'))\n            126 CALL_FUNCTION_KW         4\n            128 LOAD_FAST                6 (mask)\n            130 BUILD_LIST               2\n            132 LOAD_CONST               2 (-1)\n            134 LOAD_CONST               6 (('dim',))\n            136 CALL_FUNCTION_KW         2\n            138 STORE_FAST               6 (mask)\n\n 89     >>  140 LOAD_FAST                6 (mask)\n            142 LOAD_CONST               7 (None)\n            144 LOAD_CONST               7 (None)\n            146 LOAD_CONST               7 (None)\n            148 LOAD_CONST               7 (None)\n            150 BUILD_SLICE              2\n            152 LOAD_CONST               7 (None)\n            154 LOAD_CONST               7 (None)\n            156 BUILD_SLICE              2\n            158 BUILD_TUPLE              4\n            160 BINARY_SUBSCR\n            162 LOAD_METHOD             11 (expand)\n            164 LOAD_FAST                4 (bsz)\n            166 LOAD_CONST               3 (1)\n            168 LOAD_FAST                5 (tgt_len)\n            170 LOAD_FAST                5 (tgt_len)\n            172 LOAD_FAST                3 (past_key_values_length)\n            174 BINARY_ADD\n            176 CALL_METHOD              4\n            178 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 157 \n161           0 LOAD_FAST                1 (input_ids)\n              2 LOAD_CONST               0 (None)\n              4 IS_OP                    1\n              6 POP_JUMP_IF_FALSE       22 (to 44)\n\n162           8 LOAD_FAST                1 (input_ids)\n             10 LOAD_METHOD              0 (size)\n             12 CALL_METHOD              0\n             14 UNPACK_SEQUENCE          2\n             16 STORE_FAST               4 (bsz)\n             18 STORE_FAST               5 (seq_len)\n\n164          20 LOAD_GLOBAL              1 (create_position_ids_from_input_ids)\n             22 LOAD_FAST                1 (input_ids)\n             24 LOAD_FAST                0 (self)\n             26 LOAD_ATTR                2 (padding_idx)\n             28 LOAD_FAST                3 (past_key_values_length)\n             30 CALL_FUNCTION            3\n             32 LOAD_METHOD              3 (to)\n\n165          34 LOAD_FAST                1 (input_ids)\n             36 LOAD_ATTR                4 (device)\n\n164          38 CALL_METHOD              1\n             40 STORE_FAST               6 (position_ids)\n             42 JUMP_FORWARD            16 (to 76)\n\n168     >>   44 LOAD_FAST                2 (inputs_embeds)\n             46 LOAD_METHOD              0 (size)\n             48 CALL_METHOD              0\n             50 LOAD_CONST               0 (None)\n             52 LOAD_CONST               1 (-1)\n             54 BUILD_SLICE              2\n             56 BINARY_SUBSCR\n             58 UNPACK_SEQUENCE          2\n             60 STORE_FAST               4 (bsz)\n             62 STORE_FAST               5 (seq_len)\n\n169          64 LOAD_FAST                0 (self)\n             66 LOAD_METHOD              5 (create_position_ids_from_inputs_embeds)\n             68 LOAD_FAST                2 (inputs_embeds)\n             70 LOAD_FAST                3 (past_key_values_length)\n             72 CALL_METHOD              2\n             74 STORE_FAST               6 (position_ids)\n\n172     >>   76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                2 (padding_idx)\n             80 LOAD_CONST               2 (1)\n             82 BINARY_ADD\n             84 LOAD_FAST                5 (seq_len)\n             86 BINARY_ADD\n             88 LOAD_FAST                3 (past_key_values_length)\n             90 BINARY_ADD\n             92 STORE_FAST               7 (max_pos)\n\n173          94 LOAD_FAST                7 (max_pos)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                6 (weights)\n            100 LOAD_METHOD              0 (size)\n            102 LOAD_CONST               3 (0)\n            104 CALL_METHOD              1\n            106 COMPARE_OP               4 (>)\n            108 POP_JUMP_IF_FALSE       67 (to 134)\n\n174         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              7 (make_weights)\n            114 LOAD_FAST                7 (max_pos)\n            116 LOAD_FAST                0 (self)\n            118 LOAD_ATTR                8 (offset)\n            120 BINARY_ADD\n            122 LOAD_FAST                0 (self)\n            124 LOAD_ATTR                9 (embedding_dim)\n            126 LOAD_FAST                0 (self)\n            128 LOAD_ATTR                2 (padding_idx)\n            130 CALL_METHOD              3\n            132 POP_TOP\n\n176     >>  134 LOAD_FAST                0 (self)\n            136 LOAD_ATTR                6 (weights)\n            138 LOAD_METHOD             10 (index_select)\n            140 LOAD_CONST               3 (0)\n            142 LOAD_FAST                6 (position_ids)\n            144 LOAD_METHOD             11 (view)\n            146 LOAD_CONST               1 (-1)\n            148 CALL_METHOD              1\n            150 CALL_METHOD              2\n            152 LOAD_METHOD             11 (view)\n            154 LOAD_FAST                4 (bsz)\n            156 LOAD_FAST                5 (seq_len)\n            158 LOAD_FAST                0 (self)\n            160 LOAD_ATTR                6 (weights)\n            162 LOAD_ATTR               12 (shape)\n            164 LOAD_CONST               1 (-1)\n            166 BINARY_SUBSCR\n            168 CALL_METHOD              3\n            170 LOAD_METHOD             13 (detach)\n            172 CALL_METHOD              0\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 448 \n478           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n479           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n483          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n485          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n486          42 LOAD_FAST                1 (hidden_states)\n\n487          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n488          46 LOAD_FAST                2 (attention_mask)\n\n489          48 LOAD_FAST                5 (layer_head_mask)\n\n490          50 LOAD_FAST                8 (output_attentions)\n\n485          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n492          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n493          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n496          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n497          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n498         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n499         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n500         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n503         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n504         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n505         152 LOAD_FAST                1 (hidden_states)\n\n506         154 LOAD_FAST                3 (encoder_hidden_states)\n\n507         156 LOAD_FAST                4 (encoder_attention_mask)\n\n508         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n509         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n510         162 LOAD_FAST                8 (output_attentions)\n\n504         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n512         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n513         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n516         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n519     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n520         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n521         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n522         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n523         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n524         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n525         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n527         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n529         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n530         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n532     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n533         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n535     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 448 \n478           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n479           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n483          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n485          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n486          42 LOAD_FAST                1 (hidden_states)\n\n487          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n488          46 LOAD_FAST                2 (attention_mask)\n\n489          48 LOAD_FAST                5 (layer_head_mask)\n\n490          50 LOAD_FAST                8 (output_attentions)\n\n485          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n492          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n493          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n496          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n497          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n498         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n499         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n500         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n503         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n504         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n505         152 LOAD_FAST                1 (hidden_states)\n\n506         154 LOAD_FAST                3 (encoder_hidden_states)\n\n507         156 LOAD_FAST                4 (encoder_attention_mask)\n\n508         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n509         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n510         162 LOAD_FAST                8 (output_attentions)\n\n504         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n512         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n513         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n516         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n519     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n520         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n521         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n522         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n523         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n524         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n525         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n527         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n529         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n530         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n532     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n533         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n535     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 448 \n478           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n479           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n483          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n485          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n486          42 LOAD_FAST                1 (hidden_states)\n\n487          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n488          46 LOAD_FAST                2 (attention_mask)\n\n489          48 LOAD_FAST                5 (layer_head_mask)\n\n490          50 LOAD_FAST                8 (output_attentions)\n\n485          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n492          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n493          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n496          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n497          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n498         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n499         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n500         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n503         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n504         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n505         152 LOAD_FAST                1 (hidden_states)\n\n506         154 LOAD_FAST                3 (encoder_hidden_states)\n\n507         156 LOAD_FAST                4 (encoder_attention_mask)\n\n508         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n509         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n510         162 LOAD_FAST                8 (output_attentions)\n\n504         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n512         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n513         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n516         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n519     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n520         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n521         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n522         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n523         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n524         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n525         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n527         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n529         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n530         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n532     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n533         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n535     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 448 \n478           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n479           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n483          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n485          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n486          42 LOAD_FAST                1 (hidden_states)\n\n487          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n488          46 LOAD_FAST                2 (attention_mask)\n\n489          48 LOAD_FAST                5 (layer_head_mask)\n\n490          50 LOAD_FAST                8 (output_attentions)\n\n485          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n492          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n493          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n496          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n497          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n498         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n499         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n500         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n503         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n504         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n505         152 LOAD_FAST                1 (hidden_states)\n\n506         154 LOAD_FAST                3 (encoder_hidden_states)\n\n507         156 LOAD_FAST                4 (encoder_attention_mask)\n\n508         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n509         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n510         162 LOAD_FAST                8 (output_attentions)\n\n504         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n512         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n513         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n516         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n519     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n520         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n521         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n522         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n523         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n524         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n525         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n527         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n529         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n530         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n532     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n533         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n535     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 448 \n478           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n479           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n483          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n485          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n486          42 LOAD_FAST                1 (hidden_states)\n\n487          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n488          46 LOAD_FAST                2 (attention_mask)\n\n489          48 LOAD_FAST                5 (layer_head_mask)\n\n490          50 LOAD_FAST                8 (output_attentions)\n\n485          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n492          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n493          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n496          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n497          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n498         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n499         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n500         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n503         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n504         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n505         152 LOAD_FAST                1 (hidden_states)\n\n506         154 LOAD_FAST                3 (encoder_hidden_states)\n\n507         156 LOAD_FAST                4 (encoder_attention_mask)\n\n508         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n509         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n510         162 LOAD_FAST                8 (output_attentions)\n\n504         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n512         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n513         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n516         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n519     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n520         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n521         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n522         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n523         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n524         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n525         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n527         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n529         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n530         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n532     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n533         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n535     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 448 \n478           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n479           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n483          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n485          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n486          42 LOAD_FAST                1 (hidden_states)\n\n487          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n488          46 LOAD_FAST                2 (attention_mask)\n\n489          48 LOAD_FAST                5 (layer_head_mask)\n\n490          50 LOAD_FAST                8 (output_attentions)\n\n485          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n492          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n493          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n496          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n497          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n498         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n499         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n500         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n503         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n504         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n505         152 LOAD_FAST                1 (hidden_states)\n\n506         154 LOAD_FAST                3 (encoder_hidden_states)\n\n507         156 LOAD_FAST                4 (encoder_attention_mask)\n\n508         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n509         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n510         162 LOAD_FAST                8 (output_attentions)\n\n504         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n512         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n513         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n516         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n519     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n520         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n521         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n522         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n523         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n524         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n525         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n527         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n529         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n530         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n532     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n533         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n535     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 448 \n478           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n479           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n483          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n485          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n486          42 LOAD_FAST                1 (hidden_states)\n\n487          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n488          46 LOAD_FAST                2 (attention_mask)\n\n489          48 LOAD_FAST                5 (layer_head_mask)\n\n490          50 LOAD_FAST                8 (output_attentions)\n\n485          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n492          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n493          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n496          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n497          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n498         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n499         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n500         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n503         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n504         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n505         152 LOAD_FAST                1 (hidden_states)\n\n506         154 LOAD_FAST                3 (encoder_hidden_states)\n\n507         156 LOAD_FAST                4 (encoder_attention_mask)\n\n508         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n509         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n510         162 LOAD_FAST                8 (output_attentions)\n\n504         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n512         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n513         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n516         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n519     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n520         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n521         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n522         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n523         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n524         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n525         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n527         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n529         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n530         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n532     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n533         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n535     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 448 \n478           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n479           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n483          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n485          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n486          42 LOAD_FAST                1 (hidden_states)\n\n487          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n488          46 LOAD_FAST                2 (attention_mask)\n\n489          48 LOAD_FAST                5 (layer_head_mask)\n\n490          50 LOAD_FAST                8 (output_attentions)\n\n485          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n492          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n493          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n496          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n497          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n498         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n499         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n500         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n503         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n504         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n505         152 LOAD_FAST                1 (hidden_states)\n\n506         154 LOAD_FAST                3 (encoder_hidden_states)\n\n507         156 LOAD_FAST                4 (encoder_attention_mask)\n\n508         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n509         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n510         162 LOAD_FAST                8 (output_attentions)\n\n504         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n512         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n513         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n516         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n519     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n520         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n521         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n522         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n523         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n524         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n525         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n527         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n529         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n530         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n532     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n533         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n535     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 448 \n478           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n479           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n483          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n485          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n486          42 LOAD_FAST                1 (hidden_states)\n\n487          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n488          46 LOAD_FAST                2 (attention_mask)\n\n489          48 LOAD_FAST                5 (layer_head_mask)\n\n490          50 LOAD_FAST                8 (output_attentions)\n\n485          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n492          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n493          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n496          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n497          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n498         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n499         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n500         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n503         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n504         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n505         152 LOAD_FAST                1 (hidden_states)\n\n506         154 LOAD_FAST                3 (encoder_hidden_states)\n\n507         156 LOAD_FAST                4 (encoder_attention_mask)\n\n508         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n509         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n510         162 LOAD_FAST                8 (output_attentions)\n\n504         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n512         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n513         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n516         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n519     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n520         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n521         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n522         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n523         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n524         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n525         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n527         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n529         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n530         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n532     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n533         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n535     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 448 \n478           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n479           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n483          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n485          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n486          42 LOAD_FAST                1 (hidden_states)\n\n487          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n488          46 LOAD_FAST                2 (attention_mask)\n\n489          48 LOAD_FAST                5 (layer_head_mask)\n\n490          50 LOAD_FAST                8 (output_attentions)\n\n485          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n492          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n493          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n496          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n497          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n498         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n499         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n500         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n503         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n504         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n505         152 LOAD_FAST                1 (hidden_states)\n\n506         154 LOAD_FAST                3 (encoder_hidden_states)\n\n507         156 LOAD_FAST                4 (encoder_attention_mask)\n\n508         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n509         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n510         162 LOAD_FAST                8 (output_attentions)\n\n504         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n512         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n513         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n516         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n519     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n520         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n521         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n522         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n523         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n524         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n525         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n527         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n529         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n530         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n532     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n533         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n535     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 448 \n478           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n479           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n483          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n485          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n486          42 LOAD_FAST                1 (hidden_states)\n\n487          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n488          46 LOAD_FAST                2 (attention_mask)\n\n489          48 LOAD_FAST                5 (layer_head_mask)\n\n490          50 LOAD_FAST                8 (output_attentions)\n\n485          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n492          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n493          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n496          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n497          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n498         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n499         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n500         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n503         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n504         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n505         152 LOAD_FAST                1 (hidden_states)\n\n506         154 LOAD_FAST                3 (encoder_hidden_states)\n\n507         156 LOAD_FAST                4 (encoder_attention_mask)\n\n508         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n509         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n510         162 LOAD_FAST                8 (output_attentions)\n\n504         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n512         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n513         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n516         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n519     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n520         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n521         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n522         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n523         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n524         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n525         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n527         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n529         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n530         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n532     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n533         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n535     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (past_key_values)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (past_key_values)\n\n  5          12 LOAD_FAST                3 (hidden_states)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (hidden_states)\n\n  6          18 LOAD_FAST                4 (attentions)\n             20 LOAD_FAST                0 (self)\n             22 STORE_ATTR               3 (attentions)\n\n  7          24 LOAD_FAST                5 (cross_attentions)\n             26 LOAD_FAST                0 (self)\n             28 STORE_ATTR               4 (cross_attentions)\n\n  8          30 LOAD_FAST                0 (self)\n             32 LOAD_METHOD              5 (__post_init__)\n             34 CALL_METHOD              0\n             36 POP_TOP\n             38 LOAD_CONST               0 (None)\n             40 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 3 \n  3           0 JUMP_ABSOLUTE            4 (to 8)\n              2 LOAD_FAST                5 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n\n  4     >>    8 LOAD_FAST                1 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5          14 LOAD_FAST                2 (hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (hidden_states)\n\n  6          20 LOAD_FAST                3 (attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (attentions)\n\n  7          26 LOAD_FAST                4 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                5 (__post_init__)\n             36 CALL_FUNCTION            0\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (past_key_values)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (past_key_values)\n\n  5          12 LOAD_FAST                3 (decoder_hidden_states)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (decoder_hidden_states)\n\n  6          18 LOAD_FAST                4 (decoder_attentions)\n             20 LOAD_FAST                0 (self)\n             22 STORE_ATTR               3 (decoder_attentions)\n\n  7          24 LOAD_FAST                5 (cross_attentions)\n             26 LOAD_FAST                0 (self)\n             28 STORE_ATTR               4 (cross_attentions)\n\n  8          30 LOAD_FAST                6 (encoder_last_hidden_state)\n             32 LOAD_FAST                0 (self)\n             34 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          36 LOAD_FAST                7 (encoder_hidden_states)\n             38 LOAD_FAST                0 (self)\n             40 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          42 LOAD_FAST                8 (encoder_attentions)\n             44 LOAD_FAST                0 (self)\n             46 STORE_ATTR               7 (encoder_attentions)\n\n 11          48 LOAD_FAST                0 (self)\n             50 LOAD_METHOD              8 (__post_init__)\n             52 CALL_METHOD              0\n             54 POP_TOP\n             56 LOAD_CONST               0 (None)\n             58 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 3 \n  3           0 JUMP_ABSOLUTE            4 (to 8)\n              2 LOAD_FAST                8 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n\n  4     >>    8 LOAD_FAST                1 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5          14 LOAD_FAST                2 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n\n  6          20 LOAD_FAST                3 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7          26 LOAD_FAST                4 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                5 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                6 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                7 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 4 \n  4           0 JUMP_ABSOLUTE            7 (to 14)\n              2 LOAD_FAST                7 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                8 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5     >>   14 LOAD_FAST                1 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n\n  6          20 LOAD_FAST                2 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7          26 LOAD_FAST                3 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                4 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                5 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                6 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 5 \n  5           0 JUMP_ABSOLUTE           10 (to 20)\n              2 LOAD_FAST                6 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                7 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n             14 LOAD_FAST                8 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n\n  6     >>   20 LOAD_FAST                1 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7          26 LOAD_FAST                2 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                3 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                4 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                5 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 6 \n  6           0 JUMP_ABSOLUTE           13 (to 26)\n              2 LOAD_FAST                5 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                6 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n             14 LOAD_FAST                7 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n             20 LOAD_FAST                8 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7     >>   26 LOAD_FAST                1 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                2 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                3 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                4 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 7 \n  7           0 JUMP_ABSOLUTE           16 (to 32)\n              2 LOAD_FAST                4 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                5 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n             14 LOAD_FAST                6 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n             20 LOAD_FAST                7 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n             26 LOAD_FAST                8 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8     >>   32 LOAD_FAST                1 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                2 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                3 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/m2m_100/modeling_m2m_100.py line 1317 \n1317           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           49 (to 98)\n               4 LOAD_FAST                3 (return_dict)\n               6 LOAD_CONST               1 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST                3 (return_dict)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (use_return_dict)\n         >>   22 STORE_FAST               3 (return_dict)\n              24 LOAD_FAST                2 (labels)\n              26 LOAD_CONST               1 (None)\n              28 IS_OP                    1\n              30 POP_JUMP_IF_FALSE       30 (to 60)\n              32 LOAD_FAST                6 (decoder_input_ids)\n              34 LOAD_CONST               1 (None)\n              36 IS_OP                    0\n              38 POP_JUMP_IF_FALSE       30 (to 60)\n              40 LOAD_GLOBAL              2 (shift_tokens_right)\n              42 LOAD_FAST                2 (labels)\n              44 LOAD_FAST                1 (self)\n              46 LOAD_ATTR                0 (config)\n              48 LOAD_ATTR                3 (pad_token_id)\n              50 LOAD_FAST                1 (self)\n              52 LOAD_ATTR                0 (config)\n              54 LOAD_ATTR                4 (decoder_start_token_id)\n              56 CALL_FUNCTION            3\n              58 STORE_FAST               6 (decoder_input_ids)\n         >>   60 LOAD_FAST                1 (self)\n              62 LOAD_ATTR                5 (model)\n              64 LOAD_FAST                4 (input_ids)\n              66 LOAD_FAST                5 (attention_mask)\n              68 LOAD_FAST                6 (decoder_input_ids)\n              70 LOAD_FAST               11 (encoder_outputs)\n              72 LOAD_FAST                7 (decoder_attention_mask)\n              74 LOAD_FAST                8 (head_mask)\n              76 LOAD_FAST                9 (decoder_head_mask)\n              78 LOAD_FAST               10 (cross_attn_head_mask)\n              80 LOAD_FAST               12 (past_key_values)\n              82 LOAD_FAST               13 (inputs_embeds)\n              84 LOAD_FAST               14 (decoder_inputs_embeds)\n              86 LOAD_FAST               15 (use_cache)\n              88 LOAD_FAST               16 (output_attentions)\n              90 LOAD_FAST               17 (output_hidden_states)\n              92 LOAD_FAST                3 (return_dict)\n              94 LOAD_CONST               2 (('attention_mask', 'decoder_input_ids', 'encoder_outputs', 'decoder_attention_mask', 'head_mask', 'decoder_head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'decoder_inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              96 CALL_FUNCTION_KW        15\n         >>   98 STORE_FAST              18 (outputs)\n\n1334         100 LOAD_FAST                1 (self)\n             102 LOAD_ATTR                6 (lm_head)\n             104 LOAD_FAST               18 (outputs)\n             106 LOAD_CONST               3 (0)\n             108 BINARY_SUBSCR\n             110 CALL_FUNCTION            1\n             112 STORE_FAST              19 (lm_logits)\n\n1336         114 LOAD_CONST               1 (None)\n             116 STORE_FAST              20 (masked_lm_loss)\n\n1337         118 LOAD_FAST                2 (labels)\n             120 LOAD_CONST               1 (None)\n             122 IS_OP                    1\n             124 POP_JUMP_IF_FALSE       86 (to 172)\n\n1339         126 LOAD_FAST                2 (labels)\n             128 LOAD_ATTR                7 (to)\n             130 LOAD_FAST               19 (lm_logits)\n             132 LOAD_ATTR                8 (device)\n             134 CALL_FUNCTION            1\n             136 STORE_FAST               2 (labels)\n\n1340         138 LOAD_GLOBAL              9 (CrossEntropyLoss)\n             140 CALL_FUNCTION            0\n             142 STORE_FAST              21 (loss_fct)\n\n1341         144 LOAD_FAST               21 (loss_fct)\n             146 LOAD_FAST               19 (lm_logits)\n             148 LOAD_ATTR               10 (view)\n             150 LOAD_CONST               4 (-1)\n             152 LOAD_FAST                1 (self)\n             154 LOAD_ATTR                0 (config)\n             156 LOAD_ATTR               11 (vocab_size)\n             158 CALL_FUNCTION            2\n             160 LOAD_FAST                2 (labels)\n             162 LOAD_ATTR               10 (view)\n             164 LOAD_CONST               4 (-1)\n             166 CALL_FUNCTION            1\n             168 CALL_FUNCTION            2\n             170 STORE_FAST              20 (masked_lm_loss)\n\n1343     >>  172 LOAD_FAST                3 (return_dict)\n             174 POP_JUMP_IF_TRUE       108 (to 216)\n\n1344         176 LOAD_FAST               19 (lm_logits)\n             178 BUILD_TUPLE              1\n             180 LOAD_FAST               18 (outputs)\n             182 LOAD_CONST               5 (1)\n             184 LOAD_CONST               1 (None)\n             186 BUILD_SLICE              2\n             188 BINARY_SUBSCR\n             190 BINARY_ADD\n             192 STORE_FAST              22 (output)\n\n1345         194 LOAD_FAST               20 (masked_lm_loss)\n             196 LOAD_CONST               1 (None)\n             198 IS_OP                    1\n             200 POP_JUMP_IF_FALSE      106 (to 212)\n             202 LOAD_FAST               20 (masked_lm_loss)\n             204 BUILD_TUPLE              1\n             206 LOAD_FAST               22 (output)\n             208 BINARY_ADD\n             210 RETURN_VALUE\n         >>  212 LOAD_FAST               22 (output)\n             214 RETURN_VALUE\n\n1347     >>  216 LOAD_GLOBAL             12 (Seq2SeqLMOutput)\n\n1348         218 LOAD_FAST               20 (masked_lm_loss)\n\n1349         220 LOAD_FAST               19 (lm_logits)\n\n1350         222 LOAD_FAST               18 (outputs)\n             224 LOAD_ATTR               13 (past_key_values)\n\n1351         226 LOAD_FAST               18 (outputs)\n             228 LOAD_ATTR               14 (decoder_hidden_states)\n\n1352         230 LOAD_FAST               18 (outputs)\n             232 LOAD_ATTR               15 (decoder_attentions)\n\n1353         234 LOAD_FAST               18 (outputs)\n             236 LOAD_ATTR               16 (cross_attentions)\n\n1354         238 LOAD_FAST               18 (outputs)\n             240 LOAD_ATTR               17 (encoder_last_hidden_state)\n\n1355         242 LOAD_FAST               18 (outputs)\n             244 LOAD_ATTR               18 (encoder_hidden_states)\n\n1356         246 LOAD_FAST               18 (outputs)\n             248 LOAD_ATTR               19 (encoder_attentions)\n\n1347         250 LOAD_CONST               6 (('loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             252 CALL_FUNCTION_KW         9\n             254 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 557 \n557           0 LOAD_FAST                0 (___stack0)\n              2 CALL_FUNCTION            0\n              4 SETUP_WITH              10 (to 26)\n              6 POP_TOP\n              8 LOAD_FAST                1 (___stack1)\n             10 JUMP_ABSOLUTE           44 (to 88)\n             12 POP_BLOCK\n             14 LOAD_CONST               0 (None)\n             16 DUP_TOP\n             18 DUP_TOP\n             20 CALL_FUNCTION            3\n             22 POP_TOP\n             24 JUMP_FORWARD             8 (to 42)\n        >>   26 WITH_EXCEPT_START\n             28 POP_JUMP_IF_TRUE        16 (to 32)\n             30 RERAISE                  0\n        >>   32 POP_TOP\n             34 POP_TOP\n             36 POP_TOP\n             38 POP_EXCEPT\n             40 POP_TOP\n        >>   42 NOP\n             44 LOAD_CONST               0 (None)\n             46 RAISE_VARARGS            1\n             48 LOAD_GLOBAL              0 (clone_inputs)\n             50 LOAD_FAST                6 (inputs)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (cloned_inputs)\n             56 LOAD_FAST                2 (self)\n             58 LOAD_ATTR                1 (optimizer_zero_grad)\n             60 LOAD_FAST                3 (mod)\n             62 CALL_FUNCTION            1\n             64 POP_TOP\n             66 LOAD_FAST                2 (self)\n             68 LOAD_ATTR                2 (autocast)\n             70 CALL_FUNCTION            0\n             72 SETUP_WITH              20 (to 114)\n             74 POP_TOP\n             76 LOAD_FAST                3 (mod)\n             78 LOAD_CONST               1 (())\n             80 BUILD_MAP                0\n             82 LOAD_FAST                5 (cloned_inputs)\n             84 DICT_MERGE               1\n             86 CALL_FUNCTION_EX         1\n        >>   88 STORE_FAST               7 (pred)\n\n558          90 LOAD_FAST                2 (self)\n             92 LOAD_ATTR                3 (compute_loss)\n             94 LOAD_FAST                7 (pred)\n             96 CALL_FUNCTION            1\n             98 STORE_FAST               8 (loss)\n            100 POP_BLOCK\n\n556         102 LOAD_CONST               0 (None)\n            104 DUP_TOP\n            106 DUP_TOP\n            108 CALL_FUNCTION            3\n            110 POP_TOP\n            112 JUMP_FORWARD             8 (to 130)\n        >>  114 WITH_EXCEPT_START\n            116 POP_JUMP_IF_TRUE        60 (to 120)\n            118 RERAISE                  1\n        >>  120 POP_TOP\n            122 POP_TOP\n            124 POP_TOP\n            126 POP_EXCEPT\n            128 POP_TOP\n\n559     >>  130 LOAD_FAST                2 (self)\n            132 LOAD_ATTR                4 (grad_scaler)\n            134 LOAD_ATTR                5 (scale)\n            136 LOAD_FAST                8 (loss)\n            138 CALL_FUNCTION            1\n            140 LOAD_ATTR                6 (backward)\n            142 CALL_FUNCTION            0\n            144 POP_TOP\n\n560         146 LOAD_FAST                2 (self)\n            148 LOAD_ATTR                7 (optimizer_step)\n            150 CALL_FUNCTION            0\n            152 POP_TOP\n\n561         154 LOAD_FAST                4 (collect_outputs)\n            156 POP_JUMP_IF_FALSE       86 (to 172)\n\n562         158 LOAD_GLOBAL              8 (collect_results)\n            160 LOAD_FAST                3 (mod)\n            162 LOAD_FAST                7 (pred)\n            164 LOAD_FAST                8 (loss)\n            166 LOAD_FAST                5 (cloned_inputs)\n            168 CALL_FUNCTION            4\n            170 RETURN_VALUE\n\n563     >>  172 LOAD_CONST               0 (None)\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 1741 \n1843           0 LOAD_FAST               11 (output_attentions)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               11 (output_attentions)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (output_attentions)\n         >>   18 STORE_FAST              11 (output_attentions)\n\n1845          20 LOAD_FAST               12 (output_hidden_states)\n              22 LOAD_CONST               1 (None)\n              24 IS_OP                    1\n              26 POP_JUMP_IF_FALSE       16 (to 32)\n              28 LOAD_FAST               12 (output_hidden_states)\n              30 JUMP_FORWARD             3 (to 38)\n         >>   32 LOAD_FAST                0 (self)\n              34 LOAD_ATTR                0 (config)\n              36 LOAD_ATTR                2 (output_hidden_states)\n\n1844     >>   38 STORE_FAST              12 (output_hidden_states)\n\n1847          40 LOAD_FAST               13 (return_dict)\n              42 LOAD_CONST               1 (None)\n              44 IS_OP                    1\n              46 POP_JUMP_IF_FALSE       26 (to 52)\n              48 LOAD_FAST               13 (return_dict)\n              50 JUMP_FORWARD             3 (to 58)\n         >>   52 LOAD_FAST                0 (self)\n              54 LOAD_ATTR                0 (config)\n              56 LOAD_ATTR                3 (use_return_dict)\n         >>   58 STORE_FAST              13 (return_dict)\n\n1850          60 LOAD_FAST                0 (self)\n              62 LOAD_ATTR                4 (model)\n              64 LOAD_ATTR                5 (decoder)\n\n1851          66 LOAD_FAST                1 (input_ids)\n\n1852          68 LOAD_FAST                2 (attention_mask)\n\n1853          70 LOAD_FAST                3 (encoder_hidden_states)\n\n1854          72 LOAD_FAST                4 (encoder_attention_mask)\n\n1855          74 LOAD_FAST                5 (head_mask)\n\n1856          76 LOAD_FAST                6 (cross_attn_head_mask)\n\n1857          78 LOAD_FAST                7 (past_key_values)\n\n1858          80 LOAD_FAST                8 (inputs_embeds)\n\n1859          82 LOAD_FAST               10 (use_cache)\n\n1860          84 LOAD_FAST               11 (output_attentions)\n\n1861          86 LOAD_FAST               12 (output_hidden_states)\n\n1862          88 LOAD_FAST               13 (return_dict)\n\n1850          90 LOAD_CONST               2 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              92 CALL_FUNCTION_KW        12\n              94 STORE_FAST              14 (outputs)\n\n1865          96 LOAD_FAST                0 (self)\n              98 LOAD_METHOD              6 (lm_head)\n             100 LOAD_FAST               14 (outputs)\n             102 LOAD_CONST               3 (0)\n             104 BINARY_SUBSCR\n             106 CALL_METHOD              1\n             108 STORE_FAST              15 (logits)\n\n1867         110 LOAD_CONST               1 (None)\n             112 STORE_FAST              16 (loss)\n\n1868         114 LOAD_FAST                9 (labels)\n             116 LOAD_CONST               1 (None)\n             118 IS_OP                    1\n             120 POP_JUMP_IF_FALSE       84 (to 168)\n\n1869         122 LOAD_FAST                9 (labels)\n             124 LOAD_METHOD              7 (to)\n             126 LOAD_FAST               15 (logits)\n             128 LOAD_ATTR                8 (device)\n             130 CALL_METHOD              1\n             132 STORE_FAST               9 (labels)\n\n1870         134 LOAD_GLOBAL              9 (CrossEntropyLoss)\n             136 CALL_FUNCTION            0\n             138 STORE_FAST              17 (loss_fct)\n\n1871         140 LOAD_FAST               17 (loss_fct)\n             142 LOAD_FAST               15 (logits)\n             144 LOAD_METHOD             10 (view)\n             146 LOAD_CONST               4 (-1)\n             148 LOAD_FAST                0 (self)\n             150 LOAD_ATTR                0 (config)\n             152 LOAD_ATTR               11 (vocab_size)\n             154 CALL_METHOD              2\n             156 LOAD_FAST                9 (labels)\n             158 LOAD_METHOD             10 (view)\n             160 LOAD_CONST               4 (-1)\n             162 CALL_METHOD              1\n             164 CALL_FUNCTION            2\n             166 STORE_FAST              16 (loss)\n\n1873     >>  168 LOAD_FAST               13 (return_dict)\n             170 POP_JUMP_IF_TRUE       106 (to 212)\n\n1874         172 LOAD_FAST               15 (logits)\n             174 BUILD_TUPLE              1\n             176 LOAD_FAST               14 (outputs)\n             178 LOAD_CONST               5 (1)\n             180 LOAD_CONST               1 (None)\n             182 BUILD_SLICE              2\n             184 BINARY_SUBSCR\n             186 BINARY_ADD\n             188 STORE_FAST              18 (output)\n\n1875         190 LOAD_FAST               16 (loss)\n             192 LOAD_CONST               1 (None)\n             194 IS_OP                    1\n             196 POP_JUMP_IF_FALSE      104 (to 208)\n             198 LOAD_FAST               16 (loss)\n             200 BUILD_TUPLE              1\n             202 LOAD_FAST               18 (output)\n             204 BINARY_ADD\n             206 RETURN_VALUE\n         >>  208 LOAD_FAST               18 (output)\n             210 RETURN_VALUE\n\n1877     >>  212 LOAD_GLOBAL             12 (CausalLMOutputWithCrossAttentions)\n\n1878         214 LOAD_FAST               16 (loss)\n\n1879         216 LOAD_FAST               15 (logits)\n\n1880         218 LOAD_FAST               14 (outputs)\n             220 LOAD_ATTR               13 (past_key_values)\n\n1881         222 LOAD_FAST               14 (outputs)\n             224 LOAD_ATTR               14 (hidden_states)\n\n1882         226 LOAD_FAST               14 (outputs)\n             228 LOAD_ATTR               15 (attentions)\n\n1883         230 LOAD_FAST               14 (outputs)\n             232 LOAD_ATTR               16 (cross_attentions)\n\n1877         234 LOAD_CONST               6 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n             236 CALL_FUNCTION_KW         6\n             238 RETURN_VALUE\n\n", "ORIGINAL BYTECODE _prepare_decoder_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 910 \n913           0 LOAD_CONST               0 (None)\n              2 STORE_FAST               5 (combined_attention_mask)\n\n914           4 LOAD_FAST                2 (input_shape)\n              6 LOAD_CONST               1 (-1)\n              8 BINARY_SUBSCR\n             10 LOAD_CONST               2 (1)\n             12 COMPARE_OP               4 (>)\n             14 POP_JUMP_IF_FALSE       18 (to 36)\n\n915          16 LOAD_GLOBAL              0 (_make_causal_mask)\n\n916          18 LOAD_FAST                2 (input_shape)\n\n917          20 LOAD_FAST                3 (inputs_embeds)\n             22 LOAD_ATTR                1 (dtype)\n\n918          24 LOAD_FAST                3 (inputs_embeds)\n             26 LOAD_ATTR                2 (device)\n\n919          28 LOAD_FAST                4 (past_key_values_length)\n\n915          30 LOAD_CONST               3 (('device', 'past_key_values_length'))\n             32 CALL_FUNCTION_KW         4\n             34 STORE_FAST               5 (combined_attention_mask)\n\n922     >>   36 LOAD_FAST                1 (attention_mask)\n             38 LOAD_CONST               0 (None)\n             40 IS_OP                    1\n             42 POP_JUMP_IF_FALSE       46 (to 92)\n\n924          44 LOAD_GLOBAL              3 (_expand_mask)\n             46 LOAD_FAST                1 (attention_mask)\n             48 LOAD_FAST                3 (inputs_embeds)\n             50 LOAD_ATTR                1 (dtype)\n             52 LOAD_FAST                2 (input_shape)\n             54 LOAD_CONST               1 (-1)\n             56 BINARY_SUBSCR\n             58 LOAD_CONST               4 (('tgt_len',))\n             60 CALL_FUNCTION_KW         3\n             62 LOAD_METHOD              4 (to)\n\n925          64 LOAD_FAST                3 (inputs_embeds)\n             66 LOAD_ATTR                2 (device)\n\n924          68 CALL_METHOD              1\n             70 STORE_FAST               6 (expanded_attn_mask)\n\n928          72 LOAD_FAST                5 (combined_attention_mask)\n             74 LOAD_CONST               0 (None)\n             76 IS_OP                    0\n             78 POP_JUMP_IF_FALSE       42 (to 84)\n             80 LOAD_FAST                6 (expanded_attn_mask)\n             82 JUMP_FORWARD             3 (to 90)\n        >>   84 LOAD_FAST                6 (expanded_attn_mask)\n             86 LOAD_FAST                5 (combined_attention_mask)\n             88 BINARY_ADD\n\n927     >>   90 STORE_FAST               5 (combined_attention_mask)\n\n931     >>   92 LOAD_FAST                5 (combined_attention_mask)\n             94 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 126 \n129           0 LOAD_FAST                1 (input_ids)\n              2 LOAD_ATTR                0 (shape)\n              4 LOAD_CONST               1 (None)\n              6 LOAD_CONST               2 (2)\n              8 BUILD_SLICE              2\n             10 BINARY_SUBSCR\n             12 UNPACK_SEQUENCE          2\n             14 STORE_FAST               3 (bsz)\n             16 STORE_FAST               4 (seq_len)\n\n130          18 LOAD_GLOBAL              1 (torch)\n             20 LOAD_ATTR                2 (arange)\n\n131          22 LOAD_FAST                2 (past_key_values_length)\n             24 LOAD_FAST                2 (past_key_values_length)\n             26 LOAD_FAST                4 (seq_len)\n             28 BINARY_ADD\n             30 LOAD_GLOBAL              1 (torch)\n             32 LOAD_ATTR                3 (long)\n             34 LOAD_FAST                0 (self)\n             36 LOAD_ATTR                4 (weight)\n             38 LOAD_ATTR                5 (device)\n\n130          40 LOAD_CONST               3 (('dtype', 'device'))\n             42 CALL_FUNCTION_KW         4\n\n132          44 LOAD_METHOD              6 (expand)\n             46 LOAD_FAST                3 (bsz)\n             48 LOAD_CONST               4 (-1)\n             50 CALL_METHOD              2\n\n130          52 STORE_FAST               5 (positions)\n\n134          54 LOAD_GLOBAL              7 (super)\n             56 CALL_FUNCTION            0\n             58 LOAD_METHOD              8 (forward)\n             60 LOAD_FAST                5 (positions)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                9 (offset)\n             66 BINARY_ADD\n             68 CALL_METHOD              1\n             70 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (past_key_values)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (past_key_values)\n\n  5          12 LOAD_FAST                3 (hidden_states)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (hidden_states)\n\n  6          18 LOAD_FAST                4 (attentions)\n             20 LOAD_FAST                0 (self)\n             22 STORE_ATTR               3 (attentions)\n\n  7          24 LOAD_FAST                5 (cross_attentions)\n             26 LOAD_FAST                0 (self)\n             28 STORE_ATTR               4 (cross_attentions)\n\n  8          30 LOAD_FAST                0 (self)\n             32 LOAD_METHOD              5 (__post_init__)\n             34 CALL_METHOD              0\n             36 POP_TOP\n             38 LOAD_CONST               0 (None)\n             40 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 3 \n  3           0 JUMP_ABSOLUTE            4 (to 8)\n              2 LOAD_FAST                5 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n\n  4     >>    8 LOAD_FAST                1 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5          14 LOAD_FAST                2 (hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (hidden_states)\n\n  6          20 LOAD_FAST                3 (attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (attentions)\n\n  7          26 LOAD_FAST                4 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                5 (__post_init__)\n             36 CALL_FUNCTION            0\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 1850 \n1850           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           49 (to 98)\n               4 LOAD_FAST               13 (output_attentions)\n               6 LOAD_CONST               1 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST               13 (output_attentions)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (output_attentions)\n         >>   22 STORE_FAST              13 (output_attentions)\n              24 LOAD_FAST               14 (output_hidden_states)\n              26 LOAD_CONST               1 (None)\n              28 IS_OP                    1\n              30 POP_JUMP_IF_FALSE       18 (to 36)\n              32 LOAD_FAST               14 (output_hidden_states)\n              34 JUMP_FORWARD             3 (to 42)\n         >>   36 LOAD_FAST                1 (self)\n              38 LOAD_ATTR                0 (config)\n              40 LOAD_ATTR                2 (output_hidden_states)\n         >>   42 STORE_FAST              14 (output_hidden_states)\n              44 LOAD_FAST                3 (return_dict)\n              46 LOAD_CONST               1 (None)\n              48 IS_OP                    1\n              50 POP_JUMP_IF_FALSE       28 (to 56)\n              52 LOAD_FAST                3 (return_dict)\n              54 JUMP_FORWARD             3 (to 62)\n         >>   56 LOAD_FAST                1 (self)\n              58 LOAD_ATTR                0 (config)\n              60 LOAD_ATTR                3 (use_return_dict)\n         >>   62 STORE_FAST               3 (return_dict)\n              64 LOAD_FAST                1 (self)\n              66 LOAD_ATTR                4 (model)\n              68 LOAD_ATTR                5 (decoder)\n              70 LOAD_FAST                4 (input_ids)\n              72 LOAD_FAST                5 (attention_mask)\n              74 LOAD_FAST                6 (encoder_hidden_states)\n              76 LOAD_FAST                7 (encoder_attention_mask)\n              78 LOAD_FAST                8 (head_mask)\n              80 LOAD_FAST                9 (cross_attn_head_mask)\n              82 LOAD_FAST               10 (past_key_values)\n              84 LOAD_FAST               11 (inputs_embeds)\n              86 LOAD_FAST               12 (use_cache)\n              88 LOAD_FAST               13 (output_attentions)\n              90 LOAD_FAST               14 (output_hidden_states)\n              92 LOAD_FAST                3 (return_dict)\n              94 LOAD_CONST               2 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              96 CALL_FUNCTION_KW        12\n         >>   98 STORE_FAST              15 (outputs)\n\n1865         100 LOAD_FAST                1 (self)\n             102 LOAD_ATTR                6 (lm_head)\n             104 LOAD_FAST               15 (outputs)\n             106 LOAD_CONST               3 (0)\n             108 BINARY_SUBSCR\n             110 CALL_FUNCTION            1\n             112 STORE_FAST              16 (logits)\n\n1867         114 LOAD_CONST               1 (None)\n             116 STORE_FAST              17 (loss)\n\n1868         118 LOAD_FAST                2 (labels)\n             120 LOAD_CONST               1 (None)\n             122 IS_OP                    1\n             124 POP_JUMP_IF_FALSE       86 (to 172)\n\n1869         126 LOAD_FAST                2 (labels)\n             128 LOAD_ATTR                7 (to)\n             130 LOAD_FAST               16 (logits)\n             132 LOAD_ATTR                8 (device)\n             134 CALL_FUNCTION            1\n             136 STORE_FAST               2 (labels)\n\n1870         138 LOAD_GLOBAL              9 (CrossEntropyLoss)\n             140 CALL_FUNCTION            0\n             142 STORE_FAST              18 (loss_fct)\n\n1871         144 LOAD_FAST               18 (loss_fct)\n             146 LOAD_FAST               16 (logits)\n             148 LOAD_ATTR               10 (view)\n             150 LOAD_CONST               4 (-1)\n             152 LOAD_FAST                1 (self)\n             154 LOAD_ATTR                0 (config)\n             156 LOAD_ATTR               11 (vocab_size)\n             158 CALL_FUNCTION            2\n             160 LOAD_FAST                2 (labels)\n             162 LOAD_ATTR               10 (view)\n             164 LOAD_CONST               4 (-1)\n             166 CALL_FUNCTION            1\n             168 CALL_FUNCTION            2\n             170 STORE_FAST              17 (loss)\n\n1873     >>  172 LOAD_FAST                3 (return_dict)\n             174 POP_JUMP_IF_TRUE       108 (to 216)\n\n1874         176 LOAD_FAST               16 (logits)\n             178 BUILD_TUPLE              1\n             180 LOAD_FAST               15 (outputs)\n             182 LOAD_CONST               5 (1)\n             184 LOAD_CONST               1 (None)\n             186 BUILD_SLICE              2\n             188 BINARY_SUBSCR\n             190 BINARY_ADD\n             192 STORE_FAST              19 (output)\n\n1875         194 LOAD_FAST               17 (loss)\n             196 LOAD_CONST               1 (None)\n             198 IS_OP                    1\n             200 POP_JUMP_IF_FALSE      106 (to 212)\n             202 LOAD_FAST               17 (loss)\n             204 BUILD_TUPLE              1\n             206 LOAD_FAST               19 (output)\n             208 BINARY_ADD\n             210 RETURN_VALUE\n         >>  212 LOAD_FAST               19 (output)\n             214 RETURN_VALUE\n\n1877     >>  216 LOAD_GLOBAL             12 (CausalLMOutputWithCrossAttentions)\n\n1878         218 LOAD_FAST               17 (loss)\n\n1879         220 LOAD_FAST               16 (logits)\n\n1880         222 LOAD_FAST               15 (outputs)\n             224 LOAD_ATTR               13 (past_key_values)\n\n1881         226 LOAD_FAST               15 (outputs)\n             228 LOAD_ATTR               14 (hidden_states)\n\n1882         230 LOAD_FAST               15 (outputs)\n             232 LOAD_ATTR               15 (attentions)\n\n1883         234 LOAD_FAST               15 (outputs)\n             236 LOAD_ATTR               16 (cross_attentions)\n\n1877         238 LOAD_CONST               6 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n             240 CALL_FUNCTION_KW         6\n             242 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 557 \n557           0 LOAD_FAST                0 (___stack0)\n              2 CALL_FUNCTION            0\n              4 SETUP_WITH              10 (to 26)\n              6 POP_TOP\n              8 LOAD_FAST                1 (___stack1)\n             10 JUMP_ABSOLUTE           44 (to 88)\n             12 POP_BLOCK\n             14 LOAD_CONST               0 (None)\n             16 DUP_TOP\n             18 DUP_TOP\n             20 CALL_FUNCTION            3\n             22 POP_TOP\n             24 JUMP_FORWARD             8 (to 42)\n        >>   26 WITH_EXCEPT_START\n             28 POP_JUMP_IF_TRUE        16 (to 32)\n             30 RERAISE                  0\n        >>   32 POP_TOP\n             34 POP_TOP\n             36 POP_TOP\n             38 POP_EXCEPT\n             40 POP_TOP\n        >>   42 NOP\n             44 LOAD_CONST               0 (None)\n             46 RAISE_VARARGS            1\n             48 LOAD_GLOBAL              0 (clone_inputs)\n             50 LOAD_FAST                6 (inputs)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (cloned_inputs)\n             56 LOAD_FAST                2 (self)\n             58 LOAD_ATTR                1 (optimizer_zero_grad)\n             60 LOAD_FAST                3 (mod)\n             62 CALL_FUNCTION            1\n             64 POP_TOP\n             66 LOAD_FAST                2 (self)\n             68 LOAD_ATTR                2 (autocast)\n             70 CALL_FUNCTION            0\n             72 SETUP_WITH              20 (to 114)\n             74 POP_TOP\n             76 LOAD_FAST                3 (mod)\n             78 LOAD_CONST               1 (())\n             80 BUILD_MAP                0\n             82 LOAD_FAST                5 (cloned_inputs)\n             84 DICT_MERGE               1\n             86 CALL_FUNCTION_EX         1\n        >>   88 STORE_FAST               7 (pred)\n\n558          90 LOAD_FAST                2 (self)\n             92 LOAD_ATTR                3 (compute_loss)\n             94 LOAD_FAST                7 (pred)\n             96 CALL_FUNCTION            1\n             98 STORE_FAST               8 (loss)\n            100 POP_BLOCK\n\n556         102 LOAD_CONST               0 (None)\n            104 DUP_TOP\n            106 DUP_TOP\n            108 CALL_FUNCTION            3\n            110 POP_TOP\n            112 JUMP_FORWARD             8 (to 130)\n        >>  114 WITH_EXCEPT_START\n            116 POP_JUMP_IF_TRUE        60 (to 120)\n            118 RERAISE                  1\n        >>  120 POP_TOP\n            122 POP_TOP\n            124 POP_TOP\n            126 POP_EXCEPT\n            128 POP_TOP\n\n559     >>  130 LOAD_FAST                2 (self)\n            132 LOAD_ATTR                4 (grad_scaler)\n            134 LOAD_ATTR                5 (scale)\n            136 LOAD_FAST                8 (loss)\n            138 CALL_FUNCTION            1\n            140 LOAD_ATTR                6 (backward)\n            142 CALL_FUNCTION            0\n            144 POP_TOP\n\n560         146 LOAD_FAST                2 (self)\n            148 LOAD_ATTR                7 (optimizer_step)\n            150 CALL_FUNCTION            0\n            152 POP_TOP\n\n561         154 LOAD_FAST                4 (collect_outputs)\n            156 POP_JUMP_IF_FALSE       86 (to 172)\n\n562         158 LOAD_GLOBAL              8 (collect_results)\n            160 LOAD_FAST                3 (mod)\n            162 LOAD_FAST                7 (pred)\n            164 LOAD_FAST                8 (loss)\n            166 LOAD_FAST                5 (cloned_inputs)\n            168 CALL_FUNCTION            4\n            170 RETURN_VALUE\n\n563     >>  172 LOAD_CONST               0 (None)\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 1317 \n1348           0 LOAD_FAST               16 (return_dict)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               16 (return_dict)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (use_return_dict)\n         >>   18 STORE_FAST              16 (return_dict)\n\n1350          20 LOAD_FAST               12 (labels)\n              22 LOAD_CONST               1 (None)\n              24 IS_OP                    1\n              26 POP_JUMP_IF_FALSE       38 (to 76)\n\n1351          28 LOAD_FAST               13 (use_cache)\n              30 POP_JUMP_IF_FALSE       21 (to 42)\n\n1352          32 LOAD_GLOBAL              2 (logger)\n              34 LOAD_METHOD              3 (warning)\n              36 LOAD_CONST               2 ('The `use_cache` argument is changed to `False` since `labels` is provided.')\n              38 CALL_METHOD              1\n              40 POP_TOP\n\n1353     >>   42 LOAD_CONST               3 (False)\n              44 STORE_FAST              13 (use_cache)\n\n1354          46 LOAD_FAST                3 (decoder_input_ids)\n              48 LOAD_CONST               1 (None)\n              50 IS_OP                    0\n              52 POP_JUMP_IF_FALSE       38 (to 76)\n              54 LOAD_FAST               11 (decoder_inputs_embeds)\n              56 LOAD_CONST               1 (None)\n              58 IS_OP                    0\n              60 POP_JUMP_IF_FALSE       38 (to 76)\n\n1355          62 LOAD_GLOBAL              4 (shift_tokens_right)\n              64 LOAD_FAST               12 (labels)\n              66 LOAD_FAST                0 (self)\n              68 LOAD_ATTR                0 (config)\n              70 LOAD_ATTR                5 (pad_token_id)\n              72 CALL_FUNCTION            2\n              74 STORE_FAST               3 (decoder_input_ids)\n\n1357     >>   76 LOAD_FAST                0 (self)\n              78 LOAD_ATTR                6 (model)\n\n1358          80 LOAD_FAST                1 (input_ids)\n\n1359          82 LOAD_FAST                2 (attention_mask)\n\n1360          84 LOAD_FAST                3 (decoder_input_ids)\n\n1361          86 LOAD_FAST                8 (encoder_outputs)\n\n1362          88 LOAD_FAST                4 (decoder_attention_mask)\n\n1363          90 LOAD_FAST                5 (head_mask)\n\n1364          92 LOAD_FAST                6 (decoder_head_mask)\n\n1365          94 LOAD_FAST                7 (cross_attn_head_mask)\n\n1366          96 LOAD_FAST                9 (past_key_values)\n\n1367          98 LOAD_FAST               10 (inputs_embeds)\n\n1368         100 LOAD_FAST               11 (decoder_inputs_embeds)\n\n1369         102 LOAD_FAST               13 (use_cache)\n\n1370         104 LOAD_FAST               14 (output_attentions)\n\n1371         106 LOAD_FAST               15 (output_hidden_states)\n\n1372         108 LOAD_FAST               16 (return_dict)\n\n1357         110 LOAD_CONST               4 (('attention_mask', 'decoder_input_ids', 'encoder_outputs', 'decoder_attention_mask', 'head_mask', 'decoder_head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'decoder_inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             112 CALL_FUNCTION_KW        15\n             114 STORE_FAST              17 (outputs)\n\n1374         116 LOAD_FAST                0 (self)\n             118 LOAD_METHOD              7 (lm_head)\n             120 LOAD_FAST               17 (outputs)\n             122 LOAD_CONST               5 (0)\n             124 BINARY_SUBSCR\n             126 CALL_METHOD              1\n             128 LOAD_FAST                0 (self)\n             130 LOAD_ATTR                8 (final_logits_bias)\n             132 BINARY_ADD\n             134 STORE_FAST              18 (lm_logits)\n\n1376         136 LOAD_CONST               1 (None)\n             138 STORE_FAST              19 (masked_lm_loss)\n\n1377         140 LOAD_FAST               12 (labels)\n             142 LOAD_CONST               1 (None)\n             144 IS_OP                    1\n             146 POP_JUMP_IF_FALSE       91 (to 182)\n\n1378         148 LOAD_GLOBAL              9 (CrossEntropyLoss)\n             150 CALL_FUNCTION            0\n             152 STORE_FAST              20 (loss_fct)\n\n1379         154 LOAD_FAST               20 (loss_fct)\n             156 LOAD_FAST               18 (lm_logits)\n             158 LOAD_METHOD             10 (view)\n             160 LOAD_CONST               6 (-1)\n             162 LOAD_FAST                0 (self)\n             164 LOAD_ATTR                0 (config)\n             166 LOAD_ATTR               11 (vocab_size)\n             168 CALL_METHOD              2\n             170 LOAD_FAST               12 (labels)\n             172 LOAD_METHOD             10 (view)\n             174 LOAD_CONST               6 (-1)\n             176 CALL_METHOD              1\n             178 CALL_FUNCTION            2\n             180 STORE_FAST              19 (masked_lm_loss)\n\n1381     >>  182 LOAD_FAST               16 (return_dict)\n             184 POP_JUMP_IF_TRUE       113 (to 226)\n\n1382         186 LOAD_FAST               18 (lm_logits)\n             188 BUILD_TUPLE              1\n             190 LOAD_FAST               17 (outputs)\n             192 LOAD_CONST               7 (1)\n             194 LOAD_CONST               1 (None)\n             196 BUILD_SLICE              2\n             198 BINARY_SUBSCR\n             200 BINARY_ADD\n             202 STORE_FAST              21 (output)\n\n1383         204 LOAD_FAST               19 (masked_lm_loss)\n             206 LOAD_CONST               1 (None)\n             208 IS_OP                    1\n             210 POP_JUMP_IF_FALSE      111 (to 222)\n             212 LOAD_FAST               19 (masked_lm_loss)\n             214 BUILD_TUPLE              1\n             216 LOAD_FAST               21 (output)\n             218 BINARY_ADD\n             220 RETURN_VALUE\n         >>  222 LOAD_FAST               21 (output)\n             224 RETURN_VALUE\n\n1385     >>  226 LOAD_GLOBAL             12 (Seq2SeqLMOutput)\n\n1386         228 LOAD_FAST               19 (masked_lm_loss)\n\n1387         230 LOAD_FAST               18 (lm_logits)\n\n1388         232 LOAD_FAST               17 (outputs)\n             234 LOAD_ATTR               13 (past_key_values)\n\n1389         236 LOAD_FAST               17 (outputs)\n             238 LOAD_ATTR               14 (decoder_hidden_states)\n\n1390         240 LOAD_FAST               17 (outputs)\n             242 LOAD_ATTR               15 (decoder_attentions)\n\n1391         244 LOAD_FAST               17 (outputs)\n             246 LOAD_ATTR               16 (cross_attentions)\n\n1392         248 LOAD_FAST               17 (outputs)\n             250 LOAD_ATTR               17 (encoder_last_hidden_state)\n\n1393         252 LOAD_FAST               17 (outputs)\n             254 LOAD_ATTR               18 (encoder_hidden_states)\n\n1394         256 LOAD_FAST               17 (outputs)\n             258 LOAD_ATTR               19 (encoder_attentions)\n\n1385         260 LOAD_CONST               8 (('loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             262 CALL_FUNCTION_KW         9\n             264 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 1187 \n1212           0 LOAD_FAST               13 (output_attentions)\n               2 LOAD_CONST               0 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               13 (output_attentions)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (output_attentions)\n         >>   18 STORE_FAST              13 (output_attentions)\n\n1214          20 LOAD_FAST               14 (output_hidden_states)\n              22 LOAD_CONST               0 (None)\n              24 IS_OP                    1\n              26 POP_JUMP_IF_FALSE       16 (to 32)\n              28 LOAD_FAST               14 (output_hidden_states)\n              30 JUMP_FORWARD             3 (to 38)\n         >>   32 LOAD_FAST                0 (self)\n              34 LOAD_ATTR                0 (config)\n              36 LOAD_ATTR                2 (output_hidden_states)\n\n1213     >>   38 STORE_FAST              14 (output_hidden_states)\n\n1216          40 LOAD_FAST               12 (use_cache)\n              42 LOAD_CONST               0 (None)\n              44 IS_OP                    1\n              46 POP_JUMP_IF_FALSE       26 (to 52)\n              48 LOAD_FAST               12 (use_cache)\n              50 JUMP_FORWARD             3 (to 58)\n         >>   52 LOAD_FAST                0 (self)\n              54 LOAD_ATTR                0 (config)\n              56 LOAD_ATTR                3 (use_cache)\n         >>   58 STORE_FAST              12 (use_cache)\n\n1217          60 LOAD_FAST               15 (return_dict)\n              62 LOAD_CONST               0 (None)\n              64 IS_OP                    1\n              66 POP_JUMP_IF_FALSE       36 (to 72)\n              68 LOAD_FAST               15 (return_dict)\n              70 JUMP_FORWARD             3 (to 78)\n         >>   72 LOAD_FAST                0 (self)\n              74 LOAD_ATTR                0 (config)\n              76 LOAD_ATTR                4 (use_return_dict)\n         >>   78 STORE_FAST              15 (return_dict)\n\n1221          80 LOAD_FAST                3 (decoder_input_ids)\n              82 LOAD_CONST               0 (None)\n              84 IS_OP                    0\n              86 POP_JUMP_IF_FALSE       55 (to 110)\n              88 LOAD_FAST               11 (decoder_inputs_embeds)\n              90 LOAD_CONST               0 (None)\n              92 IS_OP                    0\n              94 POP_JUMP_IF_FALSE       55 (to 110)\n\n1222          96 LOAD_GLOBAL              5 (shift_tokens_right)\n              98 LOAD_FAST                1 (input_ids)\n             100 LOAD_FAST                0 (self)\n             102 LOAD_ATTR                0 (config)\n             104 LOAD_ATTR                6 (pad_token_id)\n             106 CALL_FUNCTION            2\n             108 STORE_FAST               3 (decoder_input_ids)\n\n1224     >>  110 LOAD_FAST                8 (encoder_outputs)\n             112 LOAD_CONST               0 (None)\n             114 IS_OP                    0\n             116 POP_JUMP_IF_FALSE       72 (to 144)\n\n1225         118 LOAD_FAST                0 (self)\n             120 LOAD_ATTR                7 (encoder)\n\n1226         122 LOAD_FAST                1 (input_ids)\n\n1227         124 LOAD_FAST                2 (attention_mask)\n\n1228         126 LOAD_FAST                5 (head_mask)\n\n1229         128 LOAD_FAST               10 (inputs_embeds)\n\n1230         130 LOAD_FAST               13 (output_attentions)\n\n1231         132 LOAD_FAST               14 (output_hidden_states)\n\n1232         134 LOAD_FAST               15 (return_dict)\n\n1225         136 LOAD_CONST               1 (('input_ids', 'attention_mask', 'head_mask', 'inputs_embeds', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             138 CALL_FUNCTION_KW         7\n             140 STORE_FAST               8 (encoder_outputs)\n             142 JUMP_FORWARD            36 (to 216)\n\n1235     >>  144 LOAD_FAST               15 (return_dict)\n             146 POP_JUMP_IF_FALSE      108 (to 216)\n             148 LOAD_GLOBAL              8 (isinstance)\n             150 LOAD_FAST                8 (encoder_outputs)\n             152 LOAD_GLOBAL              9 (BaseModelOutput)\n             154 CALL_FUNCTION            2\n             156 POP_JUMP_IF_TRUE       108 (to 216)\n\n1236         158 LOAD_GLOBAL              9 (BaseModelOutput)\n\n1237         160 LOAD_FAST                8 (encoder_outputs)\n             162 LOAD_CONST               2 (0)\n             164 BINARY_SUBSCR\n\n1238         166 LOAD_GLOBAL             10 (len)\n             168 LOAD_FAST                8 (encoder_outputs)\n             170 CALL_FUNCTION            1\n             172 LOAD_CONST               3 (1)\n             174 COMPARE_OP               4 (>)\n             176 POP_JUMP_IF_FALSE       93 (to 186)\n             178 LOAD_FAST                8 (encoder_outputs)\n             180 LOAD_CONST               3 (1)\n             182 BINARY_SUBSCR\n             184 JUMP_FORWARD             1 (to 188)\n         >>  186 LOAD_CONST               0 (None)\n\n1239     >>  188 LOAD_GLOBAL             10 (len)\n             190 LOAD_FAST                8 (encoder_outputs)\n             192 CALL_FUNCTION            1\n             194 LOAD_CONST               4 (2)\n             196 COMPARE_OP               4 (>)\n             198 POP_JUMP_IF_FALSE      104 (to 208)\n             200 LOAD_FAST                8 (encoder_outputs)\n             202 LOAD_CONST               4 (2)\n             204 BINARY_SUBSCR\n             206 JUMP_FORWARD             1 (to 210)\n         >>  208 LOAD_CONST               0 (None)\n\n1236     >>  210 LOAD_CONST               5 (('last_hidden_state', 'hidden_states', 'attentions'))\n             212 CALL_FUNCTION_KW         3\n             214 STORE_FAST               8 (encoder_outputs)\n\n1243     >>  216 LOAD_FAST                0 (self)\n             218 LOAD_ATTR               11 (decoder)\n\n1244         220 LOAD_FAST                3 (decoder_input_ids)\n\n1245         222 LOAD_FAST                4 (decoder_attention_mask)\n\n1246         224 LOAD_FAST                8 (encoder_outputs)\n             226 LOAD_CONST               2 (0)\n             228 BINARY_SUBSCR\n\n1247         230 LOAD_FAST                2 (attention_mask)\n\n1248         232 LOAD_FAST                6 (decoder_head_mask)\n\n1249         234 LOAD_FAST                7 (cross_attn_head_mask)\n\n1250         236 LOAD_FAST                9 (past_key_values)\n\n1251         238 LOAD_FAST               11 (decoder_inputs_embeds)\n\n1252         240 LOAD_FAST               12 (use_cache)\n\n1253         242 LOAD_FAST               13 (output_attentions)\n\n1254         244 LOAD_FAST               14 (output_hidden_states)\n\n1255         246 LOAD_FAST               15 (return_dict)\n\n1243         248 LOAD_CONST               6 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             250 CALL_FUNCTION_KW        12\n             252 STORE_FAST              16 (decoder_outputs)\n\n1258         254 LOAD_FAST               15 (return_dict)\n             256 POP_JUMP_IF_TRUE       133 (to 266)\n\n1259         258 LOAD_FAST               16 (decoder_outputs)\n             260 LOAD_FAST                8 (encoder_outputs)\n             262 BINARY_ADD\n             264 RETURN_VALUE\n\n1261     >>  266 LOAD_GLOBAL             12 (Seq2SeqModelOutput)\n\n1262         268 LOAD_FAST               16 (decoder_outputs)\n             270 LOAD_ATTR               13 (last_hidden_state)\n\n1263         272 LOAD_FAST               16 (decoder_outputs)\n             274 LOAD_ATTR               14 (past_key_values)\n\n1264         276 LOAD_FAST               16 (decoder_outputs)\n             278 LOAD_ATTR               15 (hidden_states)\n\n1265         280 LOAD_FAST               16 (decoder_outputs)\n             282 LOAD_ATTR               16 (attentions)\n\n1266         284 LOAD_FAST               16 (decoder_outputs)\n             286 LOAD_ATTR               17 (cross_attentions)\n\n1267         288 LOAD_FAST                8 (encoder_outputs)\n             290 LOAD_ATTR               13 (last_hidden_state)\n\n1268         292 LOAD_FAST                8 (encoder_outputs)\n             294 LOAD_ATTR               15 (hidden_states)\n\n1269         296 LOAD_FAST                8 (encoder_outputs)\n             298 LOAD_ATTR               16 (attentions)\n\n1261         300 LOAD_CONST               7 (('last_hidden_state', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             302 CALL_FUNCTION_KW         8\n             304 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 126 \n129           0 LOAD_FAST                1 (input_ids)\n              2 LOAD_ATTR                0 (shape)\n              4 LOAD_CONST               1 (None)\n              6 LOAD_CONST               2 (2)\n              8 BUILD_SLICE              2\n             10 BINARY_SUBSCR\n             12 UNPACK_SEQUENCE          2\n             14 STORE_FAST               3 (bsz)\n             16 STORE_FAST               4 (seq_len)\n\n130          18 LOAD_GLOBAL              1 (torch)\n             20 LOAD_ATTR                2 (arange)\n\n131          22 LOAD_FAST                2 (past_key_values_length)\n             24 LOAD_FAST                2 (past_key_values_length)\n             26 LOAD_FAST                4 (seq_len)\n             28 BINARY_ADD\n             30 LOAD_GLOBAL              1 (torch)\n             32 LOAD_ATTR                3 (long)\n             34 LOAD_FAST                0 (self)\n             36 LOAD_ATTR                4 (weight)\n             38 LOAD_ATTR                5 (device)\n\n130          40 LOAD_CONST               3 (('dtype', 'device'))\n             42 CALL_FUNCTION_KW         4\n\n132          44 LOAD_METHOD              6 (expand)\n             46 LOAD_FAST                3 (bsz)\n             48 LOAD_CONST               4 (-1)\n             50 CALL_METHOD              2\n\n130          52 STORE_FAST               5 (positions)\n\n134          54 LOAD_GLOBAL              7 (super)\n             56 CALL_FUNCTION            0\n             58 LOAD_METHOD              8 (forward)\n             60 LOAD_FAST                5 (positions)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                9 (offset)\n             66 BINARY_ADD\n             68 CALL_METHOD              1\n             70 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 309 \n327           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n328           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n329          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n330          18 LOAD_FAST                1 (hidden_states)\n\n331          20 LOAD_FAST                2 (attention_mask)\n\n332          22 LOAD_FAST                3 (layer_head_mask)\n\n333          24 LOAD_FAST                4 (output_attentions)\n\n329          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n335          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n336          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n339          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n340          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n341          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n342         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n343         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n344         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n346         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n347         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n346         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n347         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n346         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n349     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n350         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n352     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n354         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n355         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n357     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 309 \n327           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n328           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n329          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n330          18 LOAD_FAST                1 (hidden_states)\n\n331          20 LOAD_FAST                2 (attention_mask)\n\n332          22 LOAD_FAST                3 (layer_head_mask)\n\n333          24 LOAD_FAST                4 (output_attentions)\n\n329          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n335          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n336          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n339          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n340          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n341          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n342         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n343         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n344         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n346         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n347         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n346         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n347         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n346         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n349     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n350         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n352     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n354         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n355         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n357     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 309 \n327           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n328           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n329          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n330          18 LOAD_FAST                1 (hidden_states)\n\n331          20 LOAD_FAST                2 (attention_mask)\n\n332          22 LOAD_FAST                3 (layer_head_mask)\n\n333          24 LOAD_FAST                4 (output_attentions)\n\n329          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n335          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n336          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n339          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n340          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n341          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n342         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n343         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n344         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n346         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n347         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n346         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n347         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n346         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n349     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n350         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n352     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n354         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n355         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n357     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 309 \n327           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n328           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n329          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n330          18 LOAD_FAST                1 (hidden_states)\n\n331          20 LOAD_FAST                2 (attention_mask)\n\n332          22 LOAD_FAST                3 (layer_head_mask)\n\n333          24 LOAD_FAST                4 (output_attentions)\n\n329          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n335          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n336          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n339          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n340          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n341          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n342         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n343         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n344         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n346         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n347         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n346         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n347         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n346         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n349     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n350         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n352     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n354         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n355         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n357     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 309 \n327           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n328           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n329          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n330          18 LOAD_FAST                1 (hidden_states)\n\n331          20 LOAD_FAST                2 (attention_mask)\n\n332          22 LOAD_FAST                3 (layer_head_mask)\n\n333          24 LOAD_FAST                4 (output_attentions)\n\n329          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n335          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n336          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n339          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n340          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n341          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n342         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n343         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n344         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n346         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n347         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n346         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n347         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n346         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n349     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n350         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n352     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n354         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n355         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n357     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 309 \n327           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n328           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n329          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n330          18 LOAD_FAST                1 (hidden_states)\n\n331          20 LOAD_FAST                2 (attention_mask)\n\n332          22 LOAD_FAST                3 (layer_head_mask)\n\n333          24 LOAD_FAST                4 (output_attentions)\n\n329          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n335          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n336          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n339          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n340          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n341          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n342         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n343         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n344         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n346         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n347         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n346         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n347         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n346         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n349     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n350         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n352     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n354         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n355         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n357     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 309 \n327           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n328           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n329          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n330          18 LOAD_FAST                1 (hidden_states)\n\n331          20 LOAD_FAST                2 (attention_mask)\n\n332          22 LOAD_FAST                3 (layer_head_mask)\n\n333          24 LOAD_FAST                4 (output_attentions)\n\n329          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n335          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n336          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n339          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n340          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n341          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n342         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n343         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n344         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n346         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n347         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n346         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n347         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n346         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n349     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n350         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n352     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n354         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n355         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n357     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 309 \n327           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n328           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n329          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n330          18 LOAD_FAST                1 (hidden_states)\n\n331          20 LOAD_FAST                2 (attention_mask)\n\n332          22 LOAD_FAST                3 (layer_head_mask)\n\n333          24 LOAD_FAST                4 (output_attentions)\n\n329          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n335          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n336          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n339          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n340          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n341          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n342         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n343         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n344         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n346         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n347         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n346         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n347         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n346         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n349     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n350         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n352     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n354         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n355         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n357     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 309 \n327           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n328           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n329          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n330          18 LOAD_FAST                1 (hidden_states)\n\n331          20 LOAD_FAST                2 (attention_mask)\n\n332          22 LOAD_FAST                3 (layer_head_mask)\n\n333          24 LOAD_FAST                4 (output_attentions)\n\n329          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n335          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n336          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n339          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n340          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n341          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n342         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n343         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n344         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n346         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n347         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n346         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n347         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n346         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n349     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n350         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n352     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n354         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n355         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n357     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 309 \n327           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n328           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n329          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n330          18 LOAD_FAST                1 (hidden_states)\n\n331          20 LOAD_FAST                2 (attention_mask)\n\n332          22 LOAD_FAST                3 (layer_head_mask)\n\n333          24 LOAD_FAST                4 (output_attentions)\n\n329          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n335          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n336          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n339          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n340          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n341          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n342         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n343         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n344         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n346         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n347         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n346         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n347         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n346         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n349     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n350         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n352     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n354         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n355         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n357     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 309 \n327           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n328           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n329          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n330          18 LOAD_FAST                1 (hidden_states)\n\n331          20 LOAD_FAST                2 (attention_mask)\n\n332          22 LOAD_FAST                3 (layer_head_mask)\n\n333          24 LOAD_FAST                4 (output_attentions)\n\n329          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n335          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n336          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n339          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n340          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n341          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n342         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n343         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n344         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n346         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n347         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n346         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n347         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n346         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n349     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n350         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n352     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n354         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n355         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n357     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 309 \n327           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n328           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n329          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n330          18 LOAD_FAST                1 (hidden_states)\n\n331          20 LOAD_FAST                2 (attention_mask)\n\n332          22 LOAD_FAST                3 (layer_head_mask)\n\n333          24 LOAD_FAST                4 (output_attentions)\n\n329          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n335          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n336          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n339          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n340          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n341          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n342         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n343         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n344         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n346         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n347         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n346         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n347         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n346         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n349     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n350         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n352     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n354         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n355         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n357     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (hidden_states)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (hidden_states)\n\n  5          12 LOAD_FAST                3 (attentions)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (attentions)\n\n  6          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              3 (__post_init__)\n             22 CALL_METHOD              0\n             24 POP_TOP\n             26 LOAD_CONST               0 (None)\n             28 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 1225 \n1225           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           72 (to 144)\n               4 LOAD_FAST               10 (output_attentions)\n               6 LOAD_CONST               0 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST               10 (output_attentions)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (output_attentions)\n         >>   22 STORE_FAST              10 (output_attentions)\n              24 LOAD_FAST               11 (output_hidden_states)\n              26 LOAD_CONST               0 (None)\n              28 IS_OP                    1\n              30 POP_JUMP_IF_FALSE       18 (to 36)\n              32 LOAD_FAST               11 (output_hidden_states)\n              34 JUMP_FORWARD             3 (to 42)\n         >>   36 LOAD_FAST                1 (self)\n              38 LOAD_ATTR                0 (config)\n              40 LOAD_ATTR                2 (output_hidden_states)\n         >>   42 STORE_FAST              11 (output_hidden_states)\n              44 LOAD_FAST                9 (use_cache)\n              46 LOAD_CONST               0 (None)\n              48 IS_OP                    1\n              50 POP_JUMP_IF_FALSE       28 (to 56)\n              52 LOAD_FAST                9 (use_cache)\n              54 JUMP_FORWARD             3 (to 62)\n         >>   56 LOAD_FAST                1 (self)\n              58 LOAD_ATTR                0 (config)\n              60 LOAD_ATTR                3 (use_cache)\n         >>   62 STORE_FAST               9 (use_cache)\n              64 LOAD_FAST               12 (return_dict)\n              66 LOAD_CONST               0 (None)\n              68 IS_OP                    1\n              70 POP_JUMP_IF_FALSE       38 (to 76)\n              72 LOAD_FAST               12 (return_dict)\n              74 JUMP_FORWARD             3 (to 82)\n         >>   76 LOAD_FAST                1 (self)\n              78 LOAD_ATTR                0 (config)\n              80 LOAD_ATTR                4 (use_return_dict)\n         >>   82 STORE_FAST              12 (return_dict)\n              84 LOAD_FAST                3 (decoder_input_ids)\n              86 LOAD_CONST               0 (None)\n              88 IS_OP                    0\n              90 POP_JUMP_IF_FALSE       57 (to 114)\n              92 LOAD_FAST                8 (decoder_inputs_embeds)\n              94 LOAD_CONST               0 (None)\n              96 IS_OP                    0\n              98 POP_JUMP_IF_FALSE       57 (to 114)\n             100 LOAD_GLOBAL              5 (shift_tokens_right)\n             102 LOAD_FAST               13 (input_ids)\n             104 LOAD_FAST                1 (self)\n             106 LOAD_ATTR                0 (config)\n             108 LOAD_ATTR                6 (pad_token_id)\n             110 CALL_FUNCTION            2\n             112 STORE_FAST               3 (decoder_input_ids)\n         >>  114 LOAD_FAST               15 (encoder_outputs)\n             116 LOAD_CONST               0 (None)\n             118 IS_OP                    0\n             120 POP_JUMP_IF_FALSE       74 (to 148)\n             122 LOAD_FAST                1 (self)\n             124 LOAD_ATTR                7 (encoder)\n             126 LOAD_FAST               13 (input_ids)\n             128 LOAD_FAST                2 (attention_mask)\n             130 LOAD_FAST               14 (head_mask)\n             132 LOAD_FAST               16 (inputs_embeds)\n             134 LOAD_FAST               10 (output_attentions)\n             136 LOAD_FAST               11 (output_hidden_states)\n             138 LOAD_FAST               12 (return_dict)\n             140 LOAD_CONST               1 (('input_ids', 'attention_mask', 'head_mask', 'inputs_embeds', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             142 CALL_FUNCTION_KW         7\n         >>  144 STORE_FAST              15 (encoder_outputs)\n             146 JUMP_FORWARD            36 (to 220)\n\n1235     >>  148 LOAD_FAST               12 (return_dict)\n             150 POP_JUMP_IF_FALSE      110 (to 220)\n             152 LOAD_GLOBAL              8 (isinstance)\n             154 LOAD_FAST               15 (encoder_outputs)\n             156 LOAD_GLOBAL              9 (BaseModelOutput)\n             158 CALL_FUNCTION            2\n             160 POP_JUMP_IF_TRUE       110 (to 220)\n\n1236         162 LOAD_GLOBAL              9 (BaseModelOutput)\n\n1237         164 LOAD_FAST               15 (encoder_outputs)\n             166 LOAD_CONST               2 (0)\n             168 BINARY_SUBSCR\n\n1238         170 LOAD_GLOBAL             10 (len)\n             172 LOAD_FAST               15 (encoder_outputs)\n             174 CALL_FUNCTION            1\n             176 LOAD_CONST               3 (1)\n             178 COMPARE_OP               4 (>)\n             180 POP_JUMP_IF_FALSE       95 (to 190)\n             182 LOAD_FAST               15 (encoder_outputs)\n             184 LOAD_CONST               3 (1)\n             186 BINARY_SUBSCR\n             188 JUMP_FORWARD             1 (to 192)\n         >>  190 LOAD_CONST               0 (None)\n\n1239     >>  192 LOAD_GLOBAL             10 (len)\n             194 LOAD_FAST               15 (encoder_outputs)\n             196 CALL_FUNCTION            1\n             198 LOAD_CONST               4 (2)\n             200 COMPARE_OP               4 (>)\n             202 POP_JUMP_IF_FALSE      106 (to 212)\n             204 LOAD_FAST               15 (encoder_outputs)\n             206 LOAD_CONST               4 (2)\n             208 BINARY_SUBSCR\n             210 JUMP_FORWARD             1 (to 214)\n         >>  212 LOAD_CONST               0 (None)\n\n1236     >>  214 LOAD_CONST               5 (('last_hidden_state', 'hidden_states', 'attentions'))\n             216 CALL_FUNCTION_KW         3\n             218 STORE_FAST              15 (encoder_outputs)\n\n1243     >>  220 LOAD_FAST                1 (self)\n             222 LOAD_ATTR               11 (decoder)\n\n1244         224 LOAD_FAST                3 (decoder_input_ids)\n\n1245         226 LOAD_FAST                4 (decoder_attention_mask)\n\n1246         228 LOAD_FAST               15 (encoder_outputs)\n             230 LOAD_CONST               2 (0)\n             232 BINARY_SUBSCR\n\n1247         234 LOAD_FAST                2 (attention_mask)\n\n1248         236 LOAD_FAST                5 (decoder_head_mask)\n\n1249         238 LOAD_FAST                6 (cross_attn_head_mask)\n\n1250         240 LOAD_FAST                7 (past_key_values)\n\n1251         242 LOAD_FAST                8 (decoder_inputs_embeds)\n\n1252         244 LOAD_FAST                9 (use_cache)\n\n1253         246 LOAD_FAST               10 (output_attentions)\n\n1254         248 LOAD_FAST               11 (output_hidden_states)\n\n1255         250 LOAD_FAST               12 (return_dict)\n\n1243         252 LOAD_CONST               6 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             254 CALL_FUNCTION_KW        12\n             256 STORE_FAST              17 (decoder_outputs)\n\n1258         258 LOAD_FAST               12 (return_dict)\n             260 POP_JUMP_IF_TRUE       135 (to 270)\n\n1259         262 LOAD_FAST               17 (decoder_outputs)\n             264 LOAD_FAST               15 (encoder_outputs)\n             266 BINARY_ADD\n             268 RETURN_VALUE\n\n1261     >>  270 LOAD_GLOBAL             12 (Seq2SeqModelOutput)\n\n1262         272 LOAD_FAST               17 (decoder_outputs)\n             274 LOAD_ATTR               13 (last_hidden_state)\n\n1263         276 LOAD_FAST               17 (decoder_outputs)\n             278 LOAD_ATTR               14 (past_key_values)\n\n1264         280 LOAD_FAST               17 (decoder_outputs)\n             282 LOAD_ATTR               15 (hidden_states)\n\n1265         284 LOAD_FAST               17 (decoder_outputs)\n             286 LOAD_ATTR               16 (attentions)\n\n1266         288 LOAD_FAST               17 (decoder_outputs)\n             290 LOAD_ATTR               17 (cross_attentions)\n\n1267         292 LOAD_FAST               15 (encoder_outputs)\n             294 LOAD_ATTR               13 (last_hidden_state)\n\n1268         296 LOAD_FAST               15 (encoder_outputs)\n             298 LOAD_ATTR               15 (hidden_states)\n\n1269         300 LOAD_FAST               15 (encoder_outputs)\n             302 LOAD_ATTR               16 (attentions)\n\n1261         304 LOAD_CONST               7 (('last_hidden_state', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             306 CALL_FUNCTION_KW         8\n             308 RETURN_VALUE\n\n", "ORIGINAL BYTECODE _prepare_decoder_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 910 \n913           0 LOAD_CONST               0 (None)\n              2 STORE_FAST               5 (combined_attention_mask)\n\n914           4 LOAD_FAST                2 (input_shape)\n              6 LOAD_CONST               1 (-1)\n              8 BINARY_SUBSCR\n             10 LOAD_CONST               2 (1)\n             12 COMPARE_OP               4 (>)\n             14 POP_JUMP_IF_FALSE       18 (to 36)\n\n915          16 LOAD_GLOBAL              0 (_make_causal_mask)\n\n916          18 LOAD_FAST                2 (input_shape)\n\n917          20 LOAD_FAST                3 (inputs_embeds)\n             22 LOAD_ATTR                1 (dtype)\n\n918          24 LOAD_FAST                3 (inputs_embeds)\n             26 LOAD_ATTR                2 (device)\n\n919          28 LOAD_FAST                4 (past_key_values_length)\n\n915          30 LOAD_CONST               3 (('device', 'past_key_values_length'))\n             32 CALL_FUNCTION_KW         4\n             34 STORE_FAST               5 (combined_attention_mask)\n\n922     >>   36 LOAD_FAST                1 (attention_mask)\n             38 LOAD_CONST               0 (None)\n             40 IS_OP                    1\n             42 POP_JUMP_IF_FALSE       46 (to 92)\n\n924          44 LOAD_GLOBAL              3 (_expand_mask)\n             46 LOAD_FAST                1 (attention_mask)\n             48 LOAD_FAST                3 (inputs_embeds)\n             50 LOAD_ATTR                1 (dtype)\n             52 LOAD_FAST                2 (input_shape)\n             54 LOAD_CONST               1 (-1)\n             56 BINARY_SUBSCR\n             58 LOAD_CONST               4 (('tgt_len',))\n             60 CALL_FUNCTION_KW         3\n             62 LOAD_METHOD              4 (to)\n\n925          64 LOAD_FAST                3 (inputs_embeds)\n             66 LOAD_ATTR                2 (device)\n\n924          68 CALL_METHOD              1\n             70 STORE_FAST               6 (expanded_attn_mask)\n\n928          72 LOAD_FAST                5 (combined_attention_mask)\n             74 LOAD_CONST               0 (None)\n             76 IS_OP                    0\n             78 POP_JUMP_IF_FALSE       42 (to 84)\n             80 LOAD_FAST                6 (expanded_attn_mask)\n             82 JUMP_FORWARD             3 (to 90)\n        >>   84 LOAD_FAST                6 (expanded_attn_mask)\n             86 LOAD_FAST                5 (combined_attention_mask)\n             88 BINARY_ADD\n\n927     >>   90 STORE_FAST               5 (combined_attention_mask)\n\n931     >>   92 LOAD_FAST                5 (combined_attention_mask)\n             94 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 126 \n129           0 LOAD_FAST                1 (input_ids)\n              2 LOAD_ATTR                0 (shape)\n              4 LOAD_CONST               1 (None)\n              6 LOAD_CONST               2 (2)\n              8 BUILD_SLICE              2\n             10 BINARY_SUBSCR\n             12 UNPACK_SEQUENCE          2\n             14 STORE_FAST               3 (bsz)\n             16 STORE_FAST               4 (seq_len)\n\n130          18 LOAD_GLOBAL              1 (torch)\n             20 LOAD_ATTR                2 (arange)\n\n131          22 LOAD_FAST                2 (past_key_values_length)\n             24 LOAD_FAST                2 (past_key_values_length)\n             26 LOAD_FAST                4 (seq_len)\n             28 BINARY_ADD\n             30 LOAD_GLOBAL              1 (torch)\n             32 LOAD_ATTR                3 (long)\n             34 LOAD_FAST                0 (self)\n             36 LOAD_ATTR                4 (weight)\n             38 LOAD_ATTR                5 (device)\n\n130          40 LOAD_CONST               3 (('dtype', 'device'))\n             42 CALL_FUNCTION_KW         4\n\n132          44 LOAD_METHOD              6 (expand)\n             46 LOAD_FAST                3 (bsz)\n             48 LOAD_CONST               4 (-1)\n             50 CALL_METHOD              2\n\n130          52 STORE_FAST               5 (positions)\n\n134          54 LOAD_GLOBAL              7 (super)\n             56 CALL_FUNCTION            0\n             58 LOAD_METHOD              8 (forward)\n             60 LOAD_FAST                5 (positions)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                9 (offset)\n             66 BINARY_ADD\n             68 CALL_METHOD              1\n             70 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 387 \n417           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n418           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n422          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n424          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n425          42 LOAD_FAST                1 (hidden_states)\n\n426          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          46 LOAD_FAST                2 (attention_mask)\n\n428          48 LOAD_FAST                5 (layer_head_mask)\n\n429          50 LOAD_FAST                8 (output_attentions)\n\n424          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n431          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n432          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n435          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n436          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n437         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n438         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n439         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n442         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n444         152 LOAD_FAST                1 (hidden_states)\n\n445         154 LOAD_FAST                3 (encoder_hidden_states)\n\n446         156 LOAD_FAST                4 (encoder_attention_mask)\n\n447         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         162 LOAD_FAST                8 (output_attentions)\n\n443         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n452         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n455         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n458     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n459         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n460         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n461         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n462         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n463         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n464         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n466         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n468         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n469         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n471     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n472         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n474     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (past_key_values)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (past_key_values)\n\n  5          12 LOAD_FAST                3 (hidden_states)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (hidden_states)\n\n  6          18 LOAD_FAST                4 (attentions)\n             20 LOAD_FAST                0 (self)\n             22 STORE_ATTR               3 (attentions)\n\n  7          24 LOAD_FAST                5 (cross_attentions)\n             26 LOAD_FAST                0 (self)\n             28 STORE_ATTR               4 (cross_attentions)\n\n  8          30 LOAD_FAST                0 (self)\n             32 LOAD_METHOD              5 (__post_init__)\n             34 CALL_METHOD              0\n             36 POP_TOP\n             38 LOAD_CONST               0 (None)\n             40 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (past_key_values)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (past_key_values)\n\n  5          12 LOAD_FAST                3 (decoder_hidden_states)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (decoder_hidden_states)\n\n  6          18 LOAD_FAST                4 (decoder_attentions)\n             20 LOAD_FAST                0 (self)\n             22 STORE_ATTR               3 (decoder_attentions)\n\n  7          24 LOAD_FAST                5 (cross_attentions)\n             26 LOAD_FAST                0 (self)\n             28 STORE_ATTR               4 (cross_attentions)\n\n  8          30 LOAD_FAST                6 (encoder_last_hidden_state)\n             32 LOAD_FAST                0 (self)\n             34 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          36 LOAD_FAST                7 (encoder_hidden_states)\n             38 LOAD_FAST                0 (self)\n             40 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          42 LOAD_FAST                8 (encoder_attentions)\n             44 LOAD_FAST                0 (self)\n             46 STORE_ATTR               7 (encoder_attentions)\n\n 11          48 LOAD_FAST                0 (self)\n             50 LOAD_METHOD              8 (__post_init__)\n             52 CALL_METHOD              0\n             54 POP_TOP\n             56 LOAD_CONST               0 (None)\n             58 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 3 \n  3           0 JUMP_ABSOLUTE            4 (to 8)\n              2 LOAD_FAST                8 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n\n  4     >>    8 LOAD_FAST                1 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5          14 LOAD_FAST                2 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n\n  6          20 LOAD_FAST                3 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7          26 LOAD_FAST                4 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                5 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                6 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                7 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 4 \n  4           0 JUMP_ABSOLUTE            7 (to 14)\n              2 LOAD_FAST                7 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                8 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5     >>   14 LOAD_FAST                1 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n\n  6          20 LOAD_FAST                2 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7          26 LOAD_FAST                3 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                4 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                5 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                6 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 5 \n  5           0 JUMP_ABSOLUTE           10 (to 20)\n              2 LOAD_FAST                6 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                7 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n             14 LOAD_FAST                8 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n\n  6     >>   20 LOAD_FAST                1 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7          26 LOAD_FAST                2 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                3 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                4 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                5 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 6 \n  6           0 JUMP_ABSOLUTE           13 (to 26)\n              2 LOAD_FAST                5 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                6 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n             14 LOAD_FAST                7 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n             20 LOAD_FAST                8 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7     >>   26 LOAD_FAST                1 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                2 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                3 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                4 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 7 \n  7           0 JUMP_ABSOLUTE           16 (to 32)\n              2 LOAD_FAST                4 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                5 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n             14 LOAD_FAST                6 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n             20 LOAD_FAST                7 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n             26 LOAD_FAST                8 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8     >>   32 LOAD_FAST                1 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                2 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                3 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/mbart/modeling_mbart.py line 1357 \n1357           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           59 (to 118)\n               4 LOAD_FAST                3 (return_dict)\n               6 LOAD_CONST               1 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST                3 (return_dict)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (use_return_dict)\n         >>   22 STORE_FAST               3 (return_dict)\n              24 LOAD_FAST                2 (labels)\n              26 LOAD_CONST               1 (None)\n              28 IS_OP                    1\n              30 POP_JUMP_IF_FALSE       40 (to 80)\n              32 LOAD_FAST               15 (use_cache)\n              34 POP_JUMP_IF_FALSE       23 (to 46)\n              36 LOAD_GLOBAL              2 (logger)\n              38 LOAD_ATTR                3 (warning)\n              40 LOAD_CONST               2 ('The `use_cache` argument is changed to `False` since `labels` is provided.')\n              42 CALL_FUNCTION            1\n              44 POP_TOP\n         >>   46 LOAD_CONST               3 (False)\n              48 STORE_FAST              15 (use_cache)\n              50 LOAD_FAST                6 (decoder_input_ids)\n              52 LOAD_CONST               1 (None)\n              54 IS_OP                    0\n              56 POP_JUMP_IF_FALSE       40 (to 80)\n              58 LOAD_FAST               14 (decoder_inputs_embeds)\n              60 LOAD_CONST               1 (None)\n              62 IS_OP                    0\n              64 POP_JUMP_IF_FALSE       40 (to 80)\n              66 LOAD_GLOBAL              4 (shift_tokens_right)\n              68 LOAD_FAST                2 (labels)\n              70 LOAD_FAST                1 (self)\n              72 LOAD_ATTR                0 (config)\n              74 LOAD_ATTR                5 (pad_token_id)\n              76 CALL_FUNCTION            2\n              78 STORE_FAST               6 (decoder_input_ids)\n         >>   80 LOAD_FAST                1 (self)\n              82 LOAD_ATTR                6 (model)\n              84 LOAD_FAST                4 (input_ids)\n              86 LOAD_FAST                5 (attention_mask)\n              88 LOAD_FAST                6 (decoder_input_ids)\n              90 LOAD_FAST               11 (encoder_outputs)\n              92 LOAD_FAST                7 (decoder_attention_mask)\n              94 LOAD_FAST                8 (head_mask)\n              96 LOAD_FAST                9 (decoder_head_mask)\n              98 LOAD_FAST               10 (cross_attn_head_mask)\n             100 LOAD_FAST               12 (past_key_values)\n             102 LOAD_FAST               13 (inputs_embeds)\n             104 LOAD_FAST               14 (decoder_inputs_embeds)\n             106 LOAD_FAST               15 (use_cache)\n             108 LOAD_FAST               16 (output_attentions)\n             110 LOAD_FAST               17 (output_hidden_states)\n             112 LOAD_FAST                3 (return_dict)\n             114 LOAD_CONST               4 (('attention_mask', 'decoder_input_ids', 'encoder_outputs', 'decoder_attention_mask', 'head_mask', 'decoder_head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'decoder_inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             116 CALL_FUNCTION_KW        15\n         >>  118 STORE_FAST              18 (outputs)\n\n1374         120 LOAD_FAST                1 (self)\n             122 LOAD_ATTR                7 (lm_head)\n             124 LOAD_FAST               18 (outputs)\n             126 LOAD_CONST               5 (0)\n             128 BINARY_SUBSCR\n             130 CALL_FUNCTION            1\n             132 LOAD_FAST                1 (self)\n             134 LOAD_ATTR                8 (final_logits_bias)\n             136 BINARY_ADD\n             138 STORE_FAST              19 (lm_logits)\n\n1376         140 LOAD_CONST               1 (None)\n             142 STORE_FAST              20 (masked_lm_loss)\n\n1377         144 LOAD_FAST                2 (labels)\n             146 LOAD_CONST               1 (None)\n             148 IS_OP                    1\n             150 POP_JUMP_IF_FALSE       93 (to 186)\n\n1378         152 LOAD_GLOBAL              9 (CrossEntropyLoss)\n             154 CALL_FUNCTION            0\n             156 STORE_FAST              21 (loss_fct)\n\n1379         158 LOAD_FAST               21 (loss_fct)\n             160 LOAD_FAST               19 (lm_logits)\n             162 LOAD_ATTR               10 (view)\n             164 LOAD_CONST               6 (-1)\n             166 LOAD_FAST                1 (self)\n             168 LOAD_ATTR                0 (config)\n             170 LOAD_ATTR               11 (vocab_size)\n             172 CALL_FUNCTION            2\n             174 LOAD_FAST                2 (labels)\n             176 LOAD_ATTR               10 (view)\n             178 LOAD_CONST               6 (-1)\n             180 CALL_FUNCTION            1\n             182 CALL_FUNCTION            2\n             184 STORE_FAST              20 (masked_lm_loss)\n\n1381     >>  186 LOAD_FAST                3 (return_dict)\n             188 POP_JUMP_IF_TRUE       115 (to 230)\n\n1382         190 LOAD_FAST               19 (lm_logits)\n             192 BUILD_TUPLE              1\n             194 LOAD_FAST               18 (outputs)\n             196 LOAD_CONST               7 (1)\n             198 LOAD_CONST               1 (None)\n             200 BUILD_SLICE              2\n             202 BINARY_SUBSCR\n             204 BINARY_ADD\n             206 STORE_FAST              22 (output)\n\n1383         208 LOAD_FAST               20 (masked_lm_loss)\n             210 LOAD_CONST               1 (None)\n             212 IS_OP                    1\n             214 POP_JUMP_IF_FALSE      113 (to 226)\n             216 LOAD_FAST               20 (masked_lm_loss)\n             218 BUILD_TUPLE              1\n             220 LOAD_FAST               22 (output)\n             222 BINARY_ADD\n             224 RETURN_VALUE\n         >>  226 LOAD_FAST               22 (output)\n             228 RETURN_VALUE\n\n1385     >>  230 LOAD_GLOBAL             12 (Seq2SeqLMOutput)\n\n1386         232 LOAD_FAST               20 (masked_lm_loss)\n\n1387         234 LOAD_FAST               19 (lm_logits)\n\n1388         236 LOAD_FAST               18 (outputs)\n             238 LOAD_ATTR               13 (past_key_values)\n\n1389         240 LOAD_FAST               18 (outputs)\n             242 LOAD_ATTR               14 (decoder_hidden_states)\n\n1390         244 LOAD_FAST               18 (outputs)\n             246 LOAD_ATTR               15 (decoder_attentions)\n\n1391         248 LOAD_FAST               18 (outputs)\n             250 LOAD_ATTR               16 (cross_attentions)\n\n1392         252 LOAD_FAST               18 (outputs)\n             254 LOAD_ATTR               17 (encoder_last_hidden_state)\n\n1393         256 LOAD_FAST               18 (outputs)\n             258 LOAD_ATTR               18 (encoder_hidden_states)\n\n1394         260 LOAD_FAST               18 (outputs)\n             262 LOAD_ATTR               19 (encoder_attentions)\n\n1385         264 LOAD_CONST               8 (('loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             266 CALL_FUNCTION_KW         9\n             268 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 557 \n557           0 LOAD_FAST                0 (___stack0)\n              2 CALL_FUNCTION            0\n              4 SETUP_WITH              10 (to 26)\n              6 POP_TOP\n              8 LOAD_FAST                1 (___stack1)\n             10 JUMP_ABSOLUTE           44 (to 88)\n             12 POP_BLOCK\n             14 LOAD_CONST               0 (None)\n             16 DUP_TOP\n             18 DUP_TOP\n             20 CALL_FUNCTION            3\n             22 POP_TOP\n             24 JUMP_FORWARD             8 (to 42)\n        >>   26 WITH_EXCEPT_START\n             28 POP_JUMP_IF_TRUE        16 (to 32)\n             30 RERAISE                  0\n        >>   32 POP_TOP\n             34 POP_TOP\n             36 POP_TOP\n             38 POP_EXCEPT\n             40 POP_TOP\n        >>   42 NOP\n             44 LOAD_CONST               0 (None)\n             46 RAISE_VARARGS            1\n             48 LOAD_GLOBAL              0 (clone_inputs)\n             50 LOAD_FAST                6 (inputs)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (cloned_inputs)\n             56 LOAD_FAST                2 (self)\n             58 LOAD_ATTR                1 (optimizer_zero_grad)\n             60 LOAD_FAST                3 (mod)\n             62 CALL_FUNCTION            1\n             64 POP_TOP\n             66 LOAD_FAST                2 (self)\n             68 LOAD_ATTR                2 (autocast)\n             70 CALL_FUNCTION            0\n             72 SETUP_WITH              20 (to 114)\n             74 POP_TOP\n             76 LOAD_FAST                3 (mod)\n             78 LOAD_CONST               1 (())\n             80 BUILD_MAP                0\n             82 LOAD_FAST                5 (cloned_inputs)\n             84 DICT_MERGE               1\n             86 CALL_FUNCTION_EX         1\n        >>   88 STORE_FAST               7 (pred)\n\n558          90 LOAD_FAST                2 (self)\n             92 LOAD_ATTR                3 (compute_loss)\n             94 LOAD_FAST                7 (pred)\n             96 CALL_FUNCTION            1\n             98 STORE_FAST               8 (loss)\n            100 POP_BLOCK\n\n556         102 LOAD_CONST               0 (None)\n            104 DUP_TOP\n            106 DUP_TOP\n            108 CALL_FUNCTION            3\n            110 POP_TOP\n            112 JUMP_FORWARD             8 (to 130)\n        >>  114 WITH_EXCEPT_START\n            116 POP_JUMP_IF_TRUE        60 (to 120)\n            118 RERAISE                  1\n        >>  120 POP_TOP\n            122 POP_TOP\n            124 POP_TOP\n            126 POP_EXCEPT\n            128 POP_TOP\n\n559     >>  130 LOAD_FAST                2 (self)\n            132 LOAD_ATTR                4 (grad_scaler)\n            134 LOAD_ATTR                5 (scale)\n            136 LOAD_FAST                8 (loss)\n            138 CALL_FUNCTION            1\n            140 LOAD_ATTR                6 (backward)\n            142 CALL_FUNCTION            0\n            144 POP_TOP\n\n560         146 LOAD_FAST                2 (self)\n            148 LOAD_ATTR                7 (optimizer_step)\n            150 CALL_FUNCTION            0\n            152 POP_TOP\n\n561         154 LOAD_FAST                4 (collect_outputs)\n            156 POP_JUMP_IF_FALSE       86 (to 172)\n\n562         158 LOAD_GLOBAL              8 (collect_results)\n            160 LOAD_FAST                3 (mod)\n            162 LOAD_FAST                7 (pred)\n            164 LOAD_FAST                8 (loss)\n            166 LOAD_FAST                5 (cloned_inputs)\n            168 CALL_FUNCTION            4\n            170 RETURN_VALUE\n\n563     >>  172 LOAD_CONST               0 (None)\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py line 849 \n937           0 LOAD_FAST                8 (output_attentions)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    1\n              6 POP_JUMP_IF_FALSE        6 (to 12)\n              8 LOAD_FAST                8 (output_attentions)\n             10 JUMP_FORWARD             3 (to 18)\n        >>   12 LOAD_FAST                0 (self)\n             14 LOAD_ATTR                0 (config)\n             16 LOAD_ATTR                1 (output_attentions)\n        >>   18 STORE_FAST               8 (output_attentions)\n\n939          20 LOAD_FAST                9 (output_hidden_states)\n             22 LOAD_CONST               1 (None)\n             24 IS_OP                    1\n             26 POP_JUMP_IF_FALSE       16 (to 32)\n             28 LOAD_FAST                9 (output_hidden_states)\n             30 JUMP_FORWARD             3 (to 38)\n        >>   32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                0 (config)\n             36 LOAD_ATTR                2 (output_hidden_states)\n\n938     >>   38 STORE_FAST               9 (output_hidden_states)\n\n941          40 LOAD_FAST               10 (return_dict)\n             42 LOAD_CONST               1 (None)\n             44 IS_OP                    1\n             46 POP_JUMP_IF_FALSE       26 (to 52)\n             48 LOAD_FAST               10 (return_dict)\n             50 JUMP_FORWARD             3 (to 58)\n        >>   52 LOAD_FAST                0 (self)\n             54 LOAD_ATTR                0 (config)\n             56 LOAD_ATTR                3 (use_return_dict)\n        >>   58 STORE_FAST              10 (return_dict)\n\n944          60 LOAD_FAST                0 (self)\n             62 LOAD_ATTR                4 (model)\n             64 LOAD_ATTR                5 (decoder)\n\n945          66 LOAD_FAST                1 (input_ids)\n\n946          68 LOAD_FAST                2 (attention_mask)\n\n947          70 LOAD_FAST                3 (head_mask)\n\n948          72 LOAD_FAST                4 (past_key_values)\n\n949          74 LOAD_FAST                5 (inputs_embeds)\n\n950          76 LOAD_FAST                7 (use_cache)\n\n951          78 LOAD_FAST                8 (output_attentions)\n\n952          80 LOAD_FAST                9 (output_hidden_states)\n\n953          82 LOAD_FAST               10 (return_dict)\n\n944          84 LOAD_CONST               2 (('input_ids', 'attention_mask', 'head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             86 CALL_FUNCTION_KW         9\n             88 STORE_FAST              11 (outputs)\n\n956          90 LOAD_FAST                0 (self)\n             92 LOAD_METHOD              6 (lm_head)\n             94 LOAD_FAST               11 (outputs)\n             96 LOAD_CONST               3 (0)\n             98 BINARY_SUBSCR\n            100 CALL_METHOD              1\n            102 LOAD_METHOD              7 (contiguous)\n            104 CALL_METHOD              0\n            106 STORE_FAST              12 (logits)\n\n958         108 LOAD_CONST               1 (None)\n            110 STORE_FAST              13 (loss)\n\n959         112 LOAD_FAST                6 (labels)\n            114 LOAD_CONST               1 (None)\n            116 IS_OP                    1\n            118 POP_JUMP_IF_FALSE      106 (to 212)\n\n961         120 LOAD_FAST                6 (labels)\n            122 LOAD_METHOD              8 (to)\n            124 LOAD_FAST               12 (logits)\n            126 LOAD_ATTR                9 (device)\n            128 CALL_METHOD              1\n            130 STORE_FAST               6 (labels)\n\n963         132 LOAD_FAST               12 (logits)\n            134 LOAD_CONST               4 (Ellipsis)\n            136 LOAD_CONST               1 (None)\n            138 LOAD_CONST               5 (-1)\n            140 BUILD_SLICE              2\n            142 LOAD_CONST               1 (None)\n            144 LOAD_CONST               1 (None)\n            146 BUILD_SLICE              2\n            148 BUILD_TUPLE              3\n            150 BINARY_SUBSCR\n            152 LOAD_METHOD              7 (contiguous)\n            154 CALL_METHOD              0\n            156 STORE_FAST              14 (shift_logits)\n\n964         158 LOAD_FAST                6 (labels)\n            160 LOAD_CONST               4 (Ellipsis)\n            162 LOAD_CONST               6 (1)\n            164 LOAD_CONST               1 (None)\n            166 BUILD_SLICE              2\n            168 BUILD_TUPLE              2\n            170 BINARY_SUBSCR\n            172 LOAD_METHOD              7 (contiguous)\n            174 CALL_METHOD              0\n            176 STORE_FAST              15 (shift_labels)\n\n966         178 LOAD_GLOBAL             10 (CrossEntropyLoss)\n            180 CALL_FUNCTION            0\n            182 STORE_FAST              16 (loss_fct)\n\n967         184 LOAD_FAST               16 (loss_fct)\n            186 LOAD_FAST               14 (shift_logits)\n            188 LOAD_METHOD             11 (view)\n            190 LOAD_CONST               5 (-1)\n            192 LOAD_FAST                0 (self)\n            194 LOAD_ATTR                0 (config)\n            196 LOAD_ATTR               12 (vocab_size)\n            198 CALL_METHOD              2\n            200 LOAD_FAST               15 (shift_labels)\n            202 LOAD_METHOD             11 (view)\n            204 LOAD_CONST               5 (-1)\n            206 CALL_METHOD              1\n            208 CALL_FUNCTION            2\n            210 STORE_FAST              13 (loss)\n\n969     >>  212 LOAD_FAST               10 (return_dict)\n            214 POP_JUMP_IF_TRUE       128 (to 256)\n\n970         216 LOAD_FAST               12 (logits)\n            218 BUILD_TUPLE              1\n            220 LOAD_FAST               11 (outputs)\n            222 LOAD_CONST               6 (1)\n            224 LOAD_CONST               1 (None)\n            226 BUILD_SLICE              2\n            228 BINARY_SUBSCR\n            230 BINARY_ADD\n            232 STORE_FAST              17 (output)\n\n971         234 LOAD_FAST               13 (loss)\n            236 LOAD_CONST               1 (None)\n            238 IS_OP                    1\n            240 POP_JUMP_IF_FALSE      126 (to 252)\n            242 LOAD_FAST               13 (loss)\n            244 BUILD_TUPLE              1\n            246 LOAD_FAST               17 (output)\n            248 BINARY_ADD\n            250 RETURN_VALUE\n        >>  252 LOAD_FAST               17 (output)\n            254 RETURN_VALUE\n\n973     >>  256 LOAD_GLOBAL             13 (CausalLMOutputWithPast)\n\n974         258 LOAD_FAST               13 (loss)\n\n975         260 LOAD_FAST               12 (logits)\n\n976         262 LOAD_FAST               11 (outputs)\n            264 LOAD_ATTR               14 (past_key_values)\n\n977         266 LOAD_FAST               11 (outputs)\n            268 LOAD_ATTR               15 (hidden_states)\n\n978         270 LOAD_FAST               11 (outputs)\n            272 LOAD_ATTR               16 (attentions)\n\n973         274 LOAD_CONST               7 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions'))\n            276 CALL_FUNCTION_KW         5\n            278 RETURN_VALUE\n\n", "ORIGINAL BYTECODE _prepare_decoder_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py line 533 \n536           0 LOAD_CONST               0 (None)\n              2 STORE_FAST               5 (combined_attention_mask)\n\n537           4 LOAD_FAST                2 (input_shape)\n              6 LOAD_CONST               1 (-1)\n              8 BINARY_SUBSCR\n             10 LOAD_CONST               2 (1)\n             12 COMPARE_OP               4 (>)\n             14 POP_JUMP_IF_FALSE       18 (to 36)\n\n538          16 LOAD_GLOBAL              0 (_make_causal_mask)\n\n539          18 LOAD_FAST                2 (input_shape)\n\n540          20 LOAD_FAST                3 (inputs_embeds)\n             22 LOAD_ATTR                1 (dtype)\n\n541          24 LOAD_FAST                3 (inputs_embeds)\n             26 LOAD_ATTR                2 (device)\n\n542          28 LOAD_FAST                4 (past_key_values_length)\n\n538          30 LOAD_CONST               3 (('device', 'past_key_values_length'))\n             32 CALL_FUNCTION_KW         4\n             34 STORE_FAST               5 (combined_attention_mask)\n\n545     >>   36 LOAD_FAST                1 (attention_mask)\n             38 LOAD_CONST               0 (None)\n             40 IS_OP                    1\n             42 POP_JUMP_IF_FALSE       46 (to 92)\n\n547          44 LOAD_GLOBAL              3 (_expand_mask)\n             46 LOAD_FAST                1 (attention_mask)\n             48 LOAD_FAST                3 (inputs_embeds)\n             50 LOAD_ATTR                1 (dtype)\n             52 LOAD_FAST                2 (input_shape)\n             54 LOAD_CONST               1 (-1)\n             56 BINARY_SUBSCR\n             58 LOAD_CONST               4 (('tgt_len',))\n             60 CALL_FUNCTION_KW         3\n             62 LOAD_METHOD              4 (to)\n\n548          64 LOAD_FAST                3 (inputs_embeds)\n             66 LOAD_ATTR                2 (device)\n\n547          68 CALL_METHOD              1\n             70 STORE_FAST               6 (expanded_attn_mask)\n\n551          72 LOAD_FAST                5 (combined_attention_mask)\n             74 LOAD_CONST               0 (None)\n             76 IS_OP                    0\n             78 POP_JUMP_IF_FALSE       42 (to 84)\n             80 LOAD_FAST                6 (expanded_attn_mask)\n             82 JUMP_FORWARD             3 (to 90)\n        >>   84 LOAD_FAST                6 (expanded_attn_mask)\n             86 LOAD_FAST                5 (combined_attention_mask)\n             88 BINARY_ADD\n\n550     >>   90 STORE_FAST               5 (combined_attention_mask)\n\n554     >>   92 LOAD_FAST                5 (combined_attention_mask)\n             94 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py line 109 \n111           0 LOAD_FAST                1 (attention_mask)\n              2 LOAD_METHOD              0 (long)\n              4 CALL_METHOD              0\n              6 STORE_FAST               1 (attention_mask)\n\n114           8 LOAD_GLOBAL              1 (torch)\n             10 LOAD_ATTR                2 (cumsum)\n             12 LOAD_FAST                1 (attention_mask)\n             14 LOAD_CONST               1 (1)\n             16 LOAD_CONST               2 (('dim',))\n             18 CALL_FUNCTION_KW         2\n             20 LOAD_METHOD              3 (type_as)\n             22 LOAD_FAST                1 (attention_mask)\n             24 CALL_METHOD              1\n             26 LOAD_FAST                1 (attention_mask)\n             28 BINARY_MULTIPLY\n             30 LOAD_METHOD              0 (long)\n             32 CALL_METHOD              0\n             34 LOAD_CONST               1 (1)\n             36 BINARY_SUBTRACT\n             38 STORE_FAST               3 (positions)\n\n117          40 LOAD_FAST                3 (positions)\n             42 LOAD_CONST               3 (None)\n             44 LOAD_CONST               3 (None)\n             46 BUILD_SLICE              2\n             48 LOAD_FAST                2 (past_key_values_length)\n             50 LOAD_CONST               3 (None)\n             52 BUILD_SLICE              2\n             54 BUILD_TUPLE              2\n             56 BINARY_SUBSCR\n             58 STORE_FAST               3 (positions)\n\n119          60 LOAD_GLOBAL              4 (super)\n             62 CALL_FUNCTION            0\n             64 LOAD_METHOD              5 (forward)\n             66 LOAD_FAST                3 (positions)\n             68 LOAD_FAST                0 (self)\n             70 LOAD_ATTR                6 (offset)\n             72 BINARY_ADD\n             74 CALL_METHOD              1\n             76 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py line 298 \n323           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               7 (residual)\n\n326           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (do_layer_norm_before)\n              8 POP_JUMP_IF_FALSE       10 (to 20)\n\n327          10 LOAD_FAST                0 (self)\n             12 LOAD_METHOD              1 (self_attn_layer_norm)\n             14 LOAD_FAST                1 (hidden_states)\n             16 CALL_METHOD              1\n             18 STORE_FAST               1 (hidden_states)\n\n330     >>   20 LOAD_FAST                0 (self)\n             22 LOAD_ATTR                2 (self_attn)\n\n331          24 LOAD_FAST                1 (hidden_states)\n\n332          26 LOAD_FAST                4 (past_key_value)\n\n333          28 LOAD_FAST                2 (attention_mask)\n\n334          30 LOAD_FAST                3 (layer_head_mask)\n\n335          32 LOAD_FAST                5 (output_attentions)\n\n330          34 LOAD_CONST               1 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             36 CALL_FUNCTION_KW         5\n             38 UNPACK_SEQUENCE          3\n             40 STORE_FAST               1 (hidden_states)\n             42 STORE_FAST               8 (self_attn_weights)\n             44 STORE_FAST               9 (present_key_value)\n\n337          46 LOAD_GLOBAL              3 (nn)\n             48 LOAD_ATTR                4 (functional)\n             50 LOAD_ATTR                5 (dropout)\n             52 LOAD_FAST                1 (hidden_states)\n             54 LOAD_FAST                0 (self)\n             56 LOAD_ATTR                5 (dropout)\n             58 LOAD_FAST                0 (self)\n             60 LOAD_ATTR                6 (training)\n             62 LOAD_CONST               2 (('p', 'training'))\n             64 CALL_FUNCTION_KW         3\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                7 (residual)\n             70 LOAD_FAST                1 (hidden_states)\n             72 BINARY_ADD\n             74 STORE_FAST               1 (hidden_states)\n\n341          76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                0 (do_layer_norm_before)\n             80 POP_JUMP_IF_TRUE        46 (to 92)\n\n342          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              1 (self_attn_layer_norm)\n             86 LOAD_FAST                1 (hidden_states)\n             88 CALL_METHOD              1\n             90 STORE_FAST               1 (hidden_states)\n\n345     >>   92 LOAD_FAST                1 (hidden_states)\n             94 LOAD_ATTR                7 (shape)\n             96 STORE_FAST              10 (hidden_states_shape)\n\n346          98 LOAD_FAST                1 (hidden_states)\n            100 LOAD_METHOD              8 (reshape)\n            102 LOAD_CONST               3 (-1)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_METHOD              9 (size)\n            108 LOAD_CONST               3 (-1)\n            110 CALL_METHOD              1\n            112 CALL_METHOD              2\n            114 STORE_FAST               1 (hidden_states)\n\n347         116 LOAD_FAST                1 (hidden_states)\n            118 STORE_FAST               7 (residual)\n\n350         120 LOAD_FAST                0 (self)\n            122 LOAD_ATTR                0 (do_layer_norm_before)\n            124 POP_JUMP_IF_FALSE       68 (to 136)\n\n351         126 LOAD_FAST                0 (self)\n            128 LOAD_METHOD             10 (final_layer_norm)\n            130 LOAD_FAST                1 (hidden_states)\n            132 CALL_METHOD              1\n            134 STORE_FAST               1 (hidden_states)\n\n353     >>  136 LOAD_FAST                0 (self)\n            138 LOAD_METHOD             11 (fc1)\n            140 LOAD_FAST                1 (hidden_states)\n            142 CALL_METHOD              1\n            144 STORE_FAST               1 (hidden_states)\n\n354         146 LOAD_FAST                0 (self)\n            148 LOAD_METHOD             12 (activation_fn)\n            150 LOAD_FAST                1 (hidden_states)\n            152 CALL_METHOD              1\n            154 STORE_FAST               1 (hidden_states)\n\n356         156 LOAD_FAST                0 (self)\n            158 LOAD_METHOD             13 (fc2)\n            160 LOAD_FAST                1 (hidden_states)\n            162 CALL_METHOD              1\n            164 STORE_FAST               1 (hidden_states)\n\n357         166 LOAD_GLOBAL              3 (nn)\n            168 LOAD_ATTR                4 (functional)\n            170 LOAD_ATTR                5 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                5 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                6 (training)\n            182 LOAD_CONST               2 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n359         188 LOAD_FAST                7 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 LOAD_METHOD             14 (view)\n            196 LOAD_FAST               10 (hidden_states_shape)\n            198 CALL_METHOD              1\n            200 STORE_FAST               1 (hidden_states)\n\n362         202 LOAD_FAST                0 (self)\n            204 LOAD_ATTR                0 (do_layer_norm_before)\n            206 POP_JUMP_IF_TRUE       109 (to 218)\n\n363         208 LOAD_FAST                0 (self)\n            210 LOAD_METHOD             10 (final_layer_norm)\n            212 LOAD_FAST                1 (hidden_states)\n            214 CALL_METHOD              1\n            216 STORE_FAST               1 (hidden_states)\n\n365     >>  218 LOAD_FAST                1 (hidden_states)\n            220 BUILD_TUPLE              1\n            222 STORE_FAST              11 (outputs)\n\n367         224 LOAD_FAST                5 (output_attentions)\n            226 POP_JUMP_IF_FALSE      119 (to 238)\n\n368         228 LOAD_FAST               11 (outputs)\n            230 LOAD_FAST                8 (self_attn_weights)\n            232 BUILD_TUPLE              1\n            234 INPLACE_ADD\n            236 STORE_FAST              11 (outputs)\n\n370     >>  238 LOAD_FAST                6 (use_cache)\n            240 POP_JUMP_IF_FALSE      126 (to 252)\n\n371         242 LOAD_FAST               11 (outputs)\n            244 LOAD_FAST                9 (present_key_value)\n            246 BUILD_TUPLE              1\n            248 INPLACE_ADD\n            250 STORE_FAST              11 (outputs)\n\n373     >>  252 LOAD_FAST               11 (outputs)\n            254 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py line 298 \n323           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               7 (residual)\n\n326           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (do_layer_norm_before)\n              8 POP_JUMP_IF_FALSE       10 (to 20)\n\n327          10 LOAD_FAST                0 (self)\n             12 LOAD_METHOD              1 (self_attn_layer_norm)\n             14 LOAD_FAST                1 (hidden_states)\n             16 CALL_METHOD              1\n             18 STORE_FAST               1 (hidden_states)\n\n330     >>   20 LOAD_FAST                0 (self)\n             22 LOAD_ATTR                2 (self_attn)\n\n331          24 LOAD_FAST                1 (hidden_states)\n\n332          26 LOAD_FAST                4 (past_key_value)\n\n333          28 LOAD_FAST                2 (attention_mask)\n\n334          30 LOAD_FAST                3 (layer_head_mask)\n\n335          32 LOAD_FAST                5 (output_attentions)\n\n330          34 LOAD_CONST               1 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             36 CALL_FUNCTION_KW         5\n             38 UNPACK_SEQUENCE          3\n             40 STORE_FAST               1 (hidden_states)\n             42 STORE_FAST               8 (self_attn_weights)\n             44 STORE_FAST               9 (present_key_value)\n\n337          46 LOAD_GLOBAL              3 (nn)\n             48 LOAD_ATTR                4 (functional)\n             50 LOAD_ATTR                5 (dropout)\n             52 LOAD_FAST                1 (hidden_states)\n             54 LOAD_FAST                0 (self)\n             56 LOAD_ATTR                5 (dropout)\n             58 LOAD_FAST                0 (self)\n             60 LOAD_ATTR                6 (training)\n             62 LOAD_CONST               2 (('p', 'training'))\n             64 CALL_FUNCTION_KW         3\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                7 (residual)\n             70 LOAD_FAST                1 (hidden_states)\n             72 BINARY_ADD\n             74 STORE_FAST               1 (hidden_states)\n\n341          76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                0 (do_layer_norm_before)\n             80 POP_JUMP_IF_TRUE        46 (to 92)\n\n342          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              1 (self_attn_layer_norm)\n             86 LOAD_FAST                1 (hidden_states)\n             88 CALL_METHOD              1\n             90 STORE_FAST               1 (hidden_states)\n\n345     >>   92 LOAD_FAST                1 (hidden_states)\n             94 LOAD_ATTR                7 (shape)\n             96 STORE_FAST              10 (hidden_states_shape)\n\n346          98 LOAD_FAST                1 (hidden_states)\n            100 LOAD_METHOD              8 (reshape)\n            102 LOAD_CONST               3 (-1)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_METHOD              9 (size)\n            108 LOAD_CONST               3 (-1)\n            110 CALL_METHOD              1\n            112 CALL_METHOD              2\n            114 STORE_FAST               1 (hidden_states)\n\n347         116 LOAD_FAST                1 (hidden_states)\n            118 STORE_FAST               7 (residual)\n\n350         120 LOAD_FAST                0 (self)\n            122 LOAD_ATTR                0 (do_layer_norm_before)\n            124 POP_JUMP_IF_FALSE       68 (to 136)\n\n351         126 LOAD_FAST                0 (self)\n            128 LOAD_METHOD             10 (final_layer_norm)\n            130 LOAD_FAST                1 (hidden_states)\n            132 CALL_METHOD              1\n            134 STORE_FAST               1 (hidden_states)\n\n353     >>  136 LOAD_FAST                0 (self)\n            138 LOAD_METHOD             11 (fc1)\n            140 LOAD_FAST                1 (hidden_states)\n            142 CALL_METHOD              1\n            144 STORE_FAST               1 (hidden_states)\n\n354         146 LOAD_FAST                0 (self)\n            148 LOAD_METHOD             12 (activation_fn)\n            150 LOAD_FAST                1 (hidden_states)\n            152 CALL_METHOD              1\n            154 STORE_FAST               1 (hidden_states)\n\n356         156 LOAD_FAST                0 (self)\n            158 LOAD_METHOD             13 (fc2)\n            160 LOAD_FAST                1 (hidden_states)\n            162 CALL_METHOD              1\n            164 STORE_FAST               1 (hidden_states)\n\n357         166 LOAD_GLOBAL              3 (nn)\n            168 LOAD_ATTR                4 (functional)\n            170 LOAD_ATTR                5 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                5 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                6 (training)\n            182 LOAD_CONST               2 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n359         188 LOAD_FAST                7 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 LOAD_METHOD             14 (view)\n            196 LOAD_FAST               10 (hidden_states_shape)\n            198 CALL_METHOD              1\n            200 STORE_FAST               1 (hidden_states)\n\n362         202 LOAD_FAST                0 (self)\n            204 LOAD_ATTR                0 (do_layer_norm_before)\n            206 POP_JUMP_IF_TRUE       109 (to 218)\n\n363         208 LOAD_FAST                0 (self)\n            210 LOAD_METHOD             10 (final_layer_norm)\n            212 LOAD_FAST                1 (hidden_states)\n            214 CALL_METHOD              1\n            216 STORE_FAST               1 (hidden_states)\n\n365     >>  218 LOAD_FAST                1 (hidden_states)\n            220 BUILD_TUPLE              1\n            222 STORE_FAST              11 (outputs)\n\n367         224 LOAD_FAST                5 (output_attentions)\n            226 POP_JUMP_IF_FALSE      119 (to 238)\n\n368         228 LOAD_FAST               11 (outputs)\n            230 LOAD_FAST                8 (self_attn_weights)\n            232 BUILD_TUPLE              1\n            234 INPLACE_ADD\n            236 STORE_FAST              11 (outputs)\n\n370     >>  238 LOAD_FAST                6 (use_cache)\n            240 POP_JUMP_IF_FALSE      126 (to 252)\n\n371         242 LOAD_FAST               11 (outputs)\n            244 LOAD_FAST                9 (present_key_value)\n            246 BUILD_TUPLE              1\n            248 INPLACE_ADD\n            250 STORE_FAST              11 (outputs)\n\n373     >>  252 LOAD_FAST               11 (outputs)\n            254 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py line 298 \n323           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               7 (residual)\n\n326           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (do_layer_norm_before)\n              8 POP_JUMP_IF_FALSE       10 (to 20)\n\n327          10 LOAD_FAST                0 (self)\n             12 LOAD_METHOD              1 (self_attn_layer_norm)\n             14 LOAD_FAST                1 (hidden_states)\n             16 CALL_METHOD              1\n             18 STORE_FAST               1 (hidden_states)\n\n330     >>   20 LOAD_FAST                0 (self)\n             22 LOAD_ATTR                2 (self_attn)\n\n331          24 LOAD_FAST                1 (hidden_states)\n\n332          26 LOAD_FAST                4 (past_key_value)\n\n333          28 LOAD_FAST                2 (attention_mask)\n\n334          30 LOAD_FAST                3 (layer_head_mask)\n\n335          32 LOAD_FAST                5 (output_attentions)\n\n330          34 LOAD_CONST               1 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             36 CALL_FUNCTION_KW         5\n             38 UNPACK_SEQUENCE          3\n             40 STORE_FAST               1 (hidden_states)\n             42 STORE_FAST               8 (self_attn_weights)\n             44 STORE_FAST               9 (present_key_value)\n\n337          46 LOAD_GLOBAL              3 (nn)\n             48 LOAD_ATTR                4 (functional)\n             50 LOAD_ATTR                5 (dropout)\n             52 LOAD_FAST                1 (hidden_states)\n             54 LOAD_FAST                0 (self)\n             56 LOAD_ATTR                5 (dropout)\n             58 LOAD_FAST                0 (self)\n             60 LOAD_ATTR                6 (training)\n             62 LOAD_CONST               2 (('p', 'training'))\n             64 CALL_FUNCTION_KW         3\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                7 (residual)\n             70 LOAD_FAST                1 (hidden_states)\n             72 BINARY_ADD\n             74 STORE_FAST               1 (hidden_states)\n\n341          76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                0 (do_layer_norm_before)\n             80 POP_JUMP_IF_TRUE        46 (to 92)\n\n342          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              1 (self_attn_layer_norm)\n             86 LOAD_FAST                1 (hidden_states)\n             88 CALL_METHOD              1\n             90 STORE_FAST               1 (hidden_states)\n\n345     >>   92 LOAD_FAST                1 (hidden_states)\n             94 LOAD_ATTR                7 (shape)\n             96 STORE_FAST              10 (hidden_states_shape)\n\n346          98 LOAD_FAST                1 (hidden_states)\n            100 LOAD_METHOD              8 (reshape)\n            102 LOAD_CONST               3 (-1)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_METHOD              9 (size)\n            108 LOAD_CONST               3 (-1)\n            110 CALL_METHOD              1\n            112 CALL_METHOD              2\n            114 STORE_FAST               1 (hidden_states)\n\n347         116 LOAD_FAST                1 (hidden_states)\n            118 STORE_FAST               7 (residual)\n\n350         120 LOAD_FAST                0 (self)\n            122 LOAD_ATTR                0 (do_layer_norm_before)\n            124 POP_JUMP_IF_FALSE       68 (to 136)\n\n351         126 LOAD_FAST                0 (self)\n            128 LOAD_METHOD             10 (final_layer_norm)\n            130 LOAD_FAST                1 (hidden_states)\n            132 CALL_METHOD              1\n            134 STORE_FAST               1 (hidden_states)\n\n353     >>  136 LOAD_FAST                0 (self)\n            138 LOAD_METHOD             11 (fc1)\n            140 LOAD_FAST                1 (hidden_states)\n            142 CALL_METHOD              1\n            144 STORE_FAST               1 (hidden_states)\n\n354         146 LOAD_FAST                0 (self)\n            148 LOAD_METHOD             12 (activation_fn)\n            150 LOAD_FAST                1 (hidden_states)\n            152 CALL_METHOD              1\n            154 STORE_FAST               1 (hidden_states)\n\n356         156 LOAD_FAST                0 (self)\n            158 LOAD_METHOD             13 (fc2)\n            160 LOAD_FAST                1 (hidden_states)\n            162 CALL_METHOD              1\n            164 STORE_FAST               1 (hidden_states)\n\n357         166 LOAD_GLOBAL              3 (nn)\n            168 LOAD_ATTR                4 (functional)\n            170 LOAD_ATTR                5 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                5 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                6 (training)\n            182 LOAD_CONST               2 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n359         188 LOAD_FAST                7 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 LOAD_METHOD             14 (view)\n            196 LOAD_FAST               10 (hidden_states_shape)\n            198 CALL_METHOD              1\n            200 STORE_FAST               1 (hidden_states)\n\n362         202 LOAD_FAST                0 (self)\n            204 LOAD_ATTR                0 (do_layer_norm_before)\n            206 POP_JUMP_IF_TRUE       109 (to 218)\n\n363         208 LOAD_FAST                0 (self)\n            210 LOAD_METHOD             10 (final_layer_norm)\n            212 LOAD_FAST                1 (hidden_states)\n            214 CALL_METHOD              1\n            216 STORE_FAST               1 (hidden_states)\n\n365     >>  218 LOAD_FAST                1 (hidden_states)\n            220 BUILD_TUPLE              1\n            222 STORE_FAST              11 (outputs)\n\n367         224 LOAD_FAST                5 (output_attentions)\n            226 POP_JUMP_IF_FALSE      119 (to 238)\n\n368         228 LOAD_FAST               11 (outputs)\n            230 LOAD_FAST                8 (self_attn_weights)\n            232 BUILD_TUPLE              1\n            234 INPLACE_ADD\n            236 STORE_FAST              11 (outputs)\n\n370     >>  238 LOAD_FAST                6 (use_cache)\n            240 POP_JUMP_IF_FALSE      126 (to 252)\n\n371         242 LOAD_FAST               11 (outputs)\n            244 LOAD_FAST                9 (present_key_value)\n            246 BUILD_TUPLE              1\n            248 INPLACE_ADD\n            250 STORE_FAST              11 (outputs)\n\n373     >>  252 LOAD_FAST               11 (outputs)\n            254 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py line 298 \n323           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               7 (residual)\n\n326           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (do_layer_norm_before)\n              8 POP_JUMP_IF_FALSE       10 (to 20)\n\n327          10 LOAD_FAST                0 (self)\n             12 LOAD_METHOD              1 (self_attn_layer_norm)\n             14 LOAD_FAST                1 (hidden_states)\n             16 CALL_METHOD              1\n             18 STORE_FAST               1 (hidden_states)\n\n330     >>   20 LOAD_FAST                0 (self)\n             22 LOAD_ATTR                2 (self_attn)\n\n331          24 LOAD_FAST                1 (hidden_states)\n\n332          26 LOAD_FAST                4 (past_key_value)\n\n333          28 LOAD_FAST                2 (attention_mask)\n\n334          30 LOAD_FAST                3 (layer_head_mask)\n\n335          32 LOAD_FAST                5 (output_attentions)\n\n330          34 LOAD_CONST               1 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             36 CALL_FUNCTION_KW         5\n             38 UNPACK_SEQUENCE          3\n             40 STORE_FAST               1 (hidden_states)\n             42 STORE_FAST               8 (self_attn_weights)\n             44 STORE_FAST               9 (present_key_value)\n\n337          46 LOAD_GLOBAL              3 (nn)\n             48 LOAD_ATTR                4 (functional)\n             50 LOAD_ATTR                5 (dropout)\n             52 LOAD_FAST                1 (hidden_states)\n             54 LOAD_FAST                0 (self)\n             56 LOAD_ATTR                5 (dropout)\n             58 LOAD_FAST                0 (self)\n             60 LOAD_ATTR                6 (training)\n             62 LOAD_CONST               2 (('p', 'training'))\n             64 CALL_FUNCTION_KW         3\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                7 (residual)\n             70 LOAD_FAST                1 (hidden_states)\n             72 BINARY_ADD\n             74 STORE_FAST               1 (hidden_states)\n\n341          76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                0 (do_layer_norm_before)\n             80 POP_JUMP_IF_TRUE        46 (to 92)\n\n342          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              1 (self_attn_layer_norm)\n             86 LOAD_FAST                1 (hidden_states)\n             88 CALL_METHOD              1\n             90 STORE_FAST               1 (hidden_states)\n\n345     >>   92 LOAD_FAST                1 (hidden_states)\n             94 LOAD_ATTR                7 (shape)\n             96 STORE_FAST              10 (hidden_states_shape)\n\n346          98 LOAD_FAST                1 (hidden_states)\n            100 LOAD_METHOD              8 (reshape)\n            102 LOAD_CONST               3 (-1)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_METHOD              9 (size)\n            108 LOAD_CONST               3 (-1)\n            110 CALL_METHOD              1\n            112 CALL_METHOD              2\n            114 STORE_FAST               1 (hidden_states)\n\n347         116 LOAD_FAST                1 (hidden_states)\n            118 STORE_FAST               7 (residual)\n\n350         120 LOAD_FAST                0 (self)\n            122 LOAD_ATTR                0 (do_layer_norm_before)\n            124 POP_JUMP_IF_FALSE       68 (to 136)\n\n351         126 LOAD_FAST                0 (self)\n            128 LOAD_METHOD             10 (final_layer_norm)\n            130 LOAD_FAST                1 (hidden_states)\n            132 CALL_METHOD              1\n            134 STORE_FAST               1 (hidden_states)\n\n353     >>  136 LOAD_FAST                0 (self)\n            138 LOAD_METHOD             11 (fc1)\n            140 LOAD_FAST                1 (hidden_states)\n            142 CALL_METHOD              1\n            144 STORE_FAST               1 (hidden_states)\n\n354         146 LOAD_FAST                0 (self)\n            148 LOAD_METHOD             12 (activation_fn)\n            150 LOAD_FAST                1 (hidden_states)\n            152 CALL_METHOD              1\n            154 STORE_FAST               1 (hidden_states)\n\n356         156 LOAD_FAST                0 (self)\n            158 LOAD_METHOD             13 (fc2)\n            160 LOAD_FAST                1 (hidden_states)\n            162 CALL_METHOD              1\n            164 STORE_FAST               1 (hidden_states)\n\n357         166 LOAD_GLOBAL              3 (nn)\n            168 LOAD_ATTR                4 (functional)\n            170 LOAD_ATTR                5 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                5 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                6 (training)\n            182 LOAD_CONST               2 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n359         188 LOAD_FAST                7 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 LOAD_METHOD             14 (view)\n            196 LOAD_FAST               10 (hidden_states_shape)\n            198 CALL_METHOD              1\n            200 STORE_FAST               1 (hidden_states)\n\n362         202 LOAD_FAST                0 (self)\n            204 LOAD_ATTR                0 (do_layer_norm_before)\n            206 POP_JUMP_IF_TRUE       109 (to 218)\n\n363         208 LOAD_FAST                0 (self)\n            210 LOAD_METHOD             10 (final_layer_norm)\n            212 LOAD_FAST                1 (hidden_states)\n            214 CALL_METHOD              1\n            216 STORE_FAST               1 (hidden_states)\n\n365     >>  218 LOAD_FAST                1 (hidden_states)\n            220 BUILD_TUPLE              1\n            222 STORE_FAST              11 (outputs)\n\n367         224 LOAD_FAST                5 (output_attentions)\n            226 POP_JUMP_IF_FALSE      119 (to 238)\n\n368         228 LOAD_FAST               11 (outputs)\n            230 LOAD_FAST                8 (self_attn_weights)\n            232 BUILD_TUPLE              1\n            234 INPLACE_ADD\n            236 STORE_FAST              11 (outputs)\n\n370     >>  238 LOAD_FAST                6 (use_cache)\n            240 POP_JUMP_IF_FALSE      126 (to 252)\n\n371         242 LOAD_FAST               11 (outputs)\n            244 LOAD_FAST                9 (present_key_value)\n            246 BUILD_TUPLE              1\n            248 INPLACE_ADD\n            250 STORE_FAST              11 (outputs)\n\n373     >>  252 LOAD_FAST               11 (outputs)\n            254 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py line 298 \n323           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               7 (residual)\n\n326           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (do_layer_norm_before)\n              8 POP_JUMP_IF_FALSE       10 (to 20)\n\n327          10 LOAD_FAST                0 (self)\n             12 LOAD_METHOD              1 (self_attn_layer_norm)\n             14 LOAD_FAST                1 (hidden_states)\n             16 CALL_METHOD              1\n             18 STORE_FAST               1 (hidden_states)\n\n330     >>   20 LOAD_FAST                0 (self)\n             22 LOAD_ATTR                2 (self_attn)\n\n331          24 LOAD_FAST                1 (hidden_states)\n\n332          26 LOAD_FAST                4 (past_key_value)\n\n333          28 LOAD_FAST                2 (attention_mask)\n\n334          30 LOAD_FAST                3 (layer_head_mask)\n\n335          32 LOAD_FAST                5 (output_attentions)\n\n330          34 LOAD_CONST               1 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             36 CALL_FUNCTION_KW         5\n             38 UNPACK_SEQUENCE          3\n             40 STORE_FAST               1 (hidden_states)\n             42 STORE_FAST               8 (self_attn_weights)\n             44 STORE_FAST               9 (present_key_value)\n\n337          46 LOAD_GLOBAL              3 (nn)\n             48 LOAD_ATTR                4 (functional)\n             50 LOAD_ATTR                5 (dropout)\n             52 LOAD_FAST                1 (hidden_states)\n             54 LOAD_FAST                0 (self)\n             56 LOAD_ATTR                5 (dropout)\n             58 LOAD_FAST                0 (self)\n             60 LOAD_ATTR                6 (training)\n             62 LOAD_CONST               2 (('p', 'training'))\n             64 CALL_FUNCTION_KW         3\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                7 (residual)\n             70 LOAD_FAST                1 (hidden_states)\n             72 BINARY_ADD\n             74 STORE_FAST               1 (hidden_states)\n\n341          76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                0 (do_layer_norm_before)\n             80 POP_JUMP_IF_TRUE        46 (to 92)\n\n342          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              1 (self_attn_layer_norm)\n             86 LOAD_FAST                1 (hidden_states)\n             88 CALL_METHOD              1\n             90 STORE_FAST               1 (hidden_states)\n\n345     >>   92 LOAD_FAST                1 (hidden_states)\n             94 LOAD_ATTR                7 (shape)\n             96 STORE_FAST              10 (hidden_states_shape)\n\n346          98 LOAD_FAST                1 (hidden_states)\n            100 LOAD_METHOD              8 (reshape)\n            102 LOAD_CONST               3 (-1)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_METHOD              9 (size)\n            108 LOAD_CONST               3 (-1)\n            110 CALL_METHOD              1\n            112 CALL_METHOD              2\n            114 STORE_FAST               1 (hidden_states)\n\n347         116 LOAD_FAST                1 (hidden_states)\n            118 STORE_FAST               7 (residual)\n\n350         120 LOAD_FAST                0 (self)\n            122 LOAD_ATTR                0 (do_layer_norm_before)\n            124 POP_JUMP_IF_FALSE       68 (to 136)\n\n351         126 LOAD_FAST                0 (self)\n            128 LOAD_METHOD             10 (final_layer_norm)\n            130 LOAD_FAST                1 (hidden_states)\n            132 CALL_METHOD              1\n            134 STORE_FAST               1 (hidden_states)\n\n353     >>  136 LOAD_FAST                0 (self)\n            138 LOAD_METHOD             11 (fc1)\n            140 LOAD_FAST                1 (hidden_states)\n            142 CALL_METHOD              1\n            144 STORE_FAST               1 (hidden_states)\n\n354         146 LOAD_FAST                0 (self)\n            148 LOAD_METHOD             12 (activation_fn)\n            150 LOAD_FAST                1 (hidden_states)\n            152 CALL_METHOD              1\n            154 STORE_FAST               1 (hidden_states)\n\n356         156 LOAD_FAST                0 (self)\n            158 LOAD_METHOD             13 (fc2)\n            160 LOAD_FAST                1 (hidden_states)\n            162 CALL_METHOD              1\n            164 STORE_FAST               1 (hidden_states)\n\n357         166 LOAD_GLOBAL              3 (nn)\n            168 LOAD_ATTR                4 (functional)\n            170 LOAD_ATTR                5 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                5 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                6 (training)\n            182 LOAD_CONST               2 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n359         188 LOAD_FAST                7 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 LOAD_METHOD             14 (view)\n            196 LOAD_FAST               10 (hidden_states_shape)\n            198 CALL_METHOD              1\n            200 STORE_FAST               1 (hidden_states)\n\n362         202 LOAD_FAST                0 (self)\n            204 LOAD_ATTR                0 (do_layer_norm_before)\n            206 POP_JUMP_IF_TRUE       109 (to 218)\n\n363         208 LOAD_FAST                0 (self)\n            210 LOAD_METHOD             10 (final_layer_norm)\n            212 LOAD_FAST                1 (hidden_states)\n            214 CALL_METHOD              1\n            216 STORE_FAST               1 (hidden_states)\n\n365     >>  218 LOAD_FAST                1 (hidden_states)\n            220 BUILD_TUPLE              1\n            222 STORE_FAST              11 (outputs)\n\n367         224 LOAD_FAST                5 (output_attentions)\n            226 POP_JUMP_IF_FALSE      119 (to 238)\n\n368         228 LOAD_FAST               11 (outputs)\n            230 LOAD_FAST                8 (self_attn_weights)\n            232 BUILD_TUPLE              1\n            234 INPLACE_ADD\n            236 STORE_FAST              11 (outputs)\n\n370     >>  238 LOAD_FAST                6 (use_cache)\n            240 POP_JUMP_IF_FALSE      126 (to 252)\n\n371         242 LOAD_FAST               11 (outputs)\n            244 LOAD_FAST                9 (present_key_value)\n            246 BUILD_TUPLE              1\n            248 INPLACE_ADD\n            250 STORE_FAST              11 (outputs)\n\n373     >>  252 LOAD_FAST               11 (outputs)\n            254 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py line 298 \n323           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               7 (residual)\n\n326           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (do_layer_norm_before)\n              8 POP_JUMP_IF_FALSE       10 (to 20)\n\n327          10 LOAD_FAST                0 (self)\n             12 LOAD_METHOD              1 (self_attn_layer_norm)\n             14 LOAD_FAST                1 (hidden_states)\n             16 CALL_METHOD              1\n             18 STORE_FAST               1 (hidden_states)\n\n330     >>   20 LOAD_FAST                0 (self)\n             22 LOAD_ATTR                2 (self_attn)\n\n331          24 LOAD_FAST                1 (hidden_states)\n\n332          26 LOAD_FAST                4 (past_key_value)\n\n333          28 LOAD_FAST                2 (attention_mask)\n\n334          30 LOAD_FAST                3 (layer_head_mask)\n\n335          32 LOAD_FAST                5 (output_attentions)\n\n330          34 LOAD_CONST               1 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             36 CALL_FUNCTION_KW         5\n             38 UNPACK_SEQUENCE          3\n             40 STORE_FAST               1 (hidden_states)\n             42 STORE_FAST               8 (self_attn_weights)\n             44 STORE_FAST               9 (present_key_value)\n\n337          46 LOAD_GLOBAL              3 (nn)\n             48 LOAD_ATTR                4 (functional)\n             50 LOAD_ATTR                5 (dropout)\n             52 LOAD_FAST                1 (hidden_states)\n             54 LOAD_FAST                0 (self)\n             56 LOAD_ATTR                5 (dropout)\n             58 LOAD_FAST                0 (self)\n             60 LOAD_ATTR                6 (training)\n             62 LOAD_CONST               2 (('p', 'training'))\n             64 CALL_FUNCTION_KW         3\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                7 (residual)\n             70 LOAD_FAST                1 (hidden_states)\n             72 BINARY_ADD\n             74 STORE_FAST               1 (hidden_states)\n\n341          76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                0 (do_layer_norm_before)\n             80 POP_JUMP_IF_TRUE        46 (to 92)\n\n342          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              1 (self_attn_layer_norm)\n             86 LOAD_FAST                1 (hidden_states)\n             88 CALL_METHOD              1\n             90 STORE_FAST               1 (hidden_states)\n\n345     >>   92 LOAD_FAST                1 (hidden_states)\n             94 LOAD_ATTR                7 (shape)\n             96 STORE_FAST              10 (hidden_states_shape)\n\n346          98 LOAD_FAST                1 (hidden_states)\n            100 LOAD_METHOD              8 (reshape)\n            102 LOAD_CONST               3 (-1)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_METHOD              9 (size)\n            108 LOAD_CONST               3 (-1)\n            110 CALL_METHOD              1\n            112 CALL_METHOD              2\n            114 STORE_FAST               1 (hidden_states)\n\n347         116 LOAD_FAST                1 (hidden_states)\n            118 STORE_FAST               7 (residual)\n\n350         120 LOAD_FAST                0 (self)\n            122 LOAD_ATTR                0 (do_layer_norm_before)\n            124 POP_JUMP_IF_FALSE       68 (to 136)\n\n351         126 LOAD_FAST                0 (self)\n            128 LOAD_METHOD             10 (final_layer_norm)\n            130 LOAD_FAST                1 (hidden_states)\n            132 CALL_METHOD              1\n            134 STORE_FAST               1 (hidden_states)\n\n353     >>  136 LOAD_FAST                0 (self)\n            138 LOAD_METHOD             11 (fc1)\n            140 LOAD_FAST                1 (hidden_states)\n            142 CALL_METHOD              1\n            144 STORE_FAST               1 (hidden_states)\n\n354         146 LOAD_FAST                0 (self)\n            148 LOAD_METHOD             12 (activation_fn)\n            150 LOAD_FAST                1 (hidden_states)\n            152 CALL_METHOD              1\n            154 STORE_FAST               1 (hidden_states)\n\n356         156 LOAD_FAST                0 (self)\n            158 LOAD_METHOD             13 (fc2)\n            160 LOAD_FAST                1 (hidden_states)\n            162 CALL_METHOD              1\n            164 STORE_FAST               1 (hidden_states)\n\n357         166 LOAD_GLOBAL              3 (nn)\n            168 LOAD_ATTR                4 (functional)\n            170 LOAD_ATTR                5 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                5 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                6 (training)\n            182 LOAD_CONST               2 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n359         188 LOAD_FAST                7 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 LOAD_METHOD             14 (view)\n            196 LOAD_FAST               10 (hidden_states_shape)\n            198 CALL_METHOD              1\n            200 STORE_FAST               1 (hidden_states)\n\n362         202 LOAD_FAST                0 (self)\n            204 LOAD_ATTR                0 (do_layer_norm_before)\n            206 POP_JUMP_IF_TRUE       109 (to 218)\n\n363         208 LOAD_FAST                0 (self)\n            210 LOAD_METHOD             10 (final_layer_norm)\n            212 LOAD_FAST                1 (hidden_states)\n            214 CALL_METHOD              1\n            216 STORE_FAST               1 (hidden_states)\n\n365     >>  218 LOAD_FAST                1 (hidden_states)\n            220 BUILD_TUPLE              1\n            222 STORE_FAST              11 (outputs)\n\n367         224 LOAD_FAST                5 (output_attentions)\n            226 POP_JUMP_IF_FALSE      119 (to 238)\n\n368         228 LOAD_FAST               11 (outputs)\n            230 LOAD_FAST                8 (self_attn_weights)\n            232 BUILD_TUPLE              1\n            234 INPLACE_ADD\n            236 STORE_FAST              11 (outputs)\n\n370     >>  238 LOAD_FAST                6 (use_cache)\n            240 POP_JUMP_IF_FALSE      126 (to 252)\n\n371         242 LOAD_FAST               11 (outputs)\n            244 LOAD_FAST                9 (present_key_value)\n            246 BUILD_TUPLE              1\n            248 INPLACE_ADD\n            250 STORE_FAST              11 (outputs)\n\n373     >>  252 LOAD_FAST               11 (outputs)\n            254 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py line 298 \n323           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               7 (residual)\n\n326           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (do_layer_norm_before)\n              8 POP_JUMP_IF_FALSE       10 (to 20)\n\n327          10 LOAD_FAST                0 (self)\n             12 LOAD_METHOD              1 (self_attn_layer_norm)\n             14 LOAD_FAST                1 (hidden_states)\n             16 CALL_METHOD              1\n             18 STORE_FAST               1 (hidden_states)\n\n330     >>   20 LOAD_FAST                0 (self)\n             22 LOAD_ATTR                2 (self_attn)\n\n331          24 LOAD_FAST                1 (hidden_states)\n\n332          26 LOAD_FAST                4 (past_key_value)\n\n333          28 LOAD_FAST                2 (attention_mask)\n\n334          30 LOAD_FAST                3 (layer_head_mask)\n\n335          32 LOAD_FAST                5 (output_attentions)\n\n330          34 LOAD_CONST               1 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             36 CALL_FUNCTION_KW         5\n             38 UNPACK_SEQUENCE          3\n             40 STORE_FAST               1 (hidden_states)\n             42 STORE_FAST               8 (self_attn_weights)\n             44 STORE_FAST               9 (present_key_value)\n\n337          46 LOAD_GLOBAL              3 (nn)\n             48 LOAD_ATTR                4 (functional)\n             50 LOAD_ATTR                5 (dropout)\n             52 LOAD_FAST                1 (hidden_states)\n             54 LOAD_FAST                0 (self)\n             56 LOAD_ATTR                5 (dropout)\n             58 LOAD_FAST                0 (self)\n             60 LOAD_ATTR                6 (training)\n             62 LOAD_CONST               2 (('p', 'training'))\n             64 CALL_FUNCTION_KW         3\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                7 (residual)\n             70 LOAD_FAST                1 (hidden_states)\n             72 BINARY_ADD\n             74 STORE_FAST               1 (hidden_states)\n\n341          76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                0 (do_layer_norm_before)\n             80 POP_JUMP_IF_TRUE        46 (to 92)\n\n342          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              1 (self_attn_layer_norm)\n             86 LOAD_FAST                1 (hidden_states)\n             88 CALL_METHOD              1\n             90 STORE_FAST               1 (hidden_states)\n\n345     >>   92 LOAD_FAST                1 (hidden_states)\n             94 LOAD_ATTR                7 (shape)\n             96 STORE_FAST              10 (hidden_states_shape)\n\n346          98 LOAD_FAST                1 (hidden_states)\n            100 LOAD_METHOD              8 (reshape)\n            102 LOAD_CONST               3 (-1)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_METHOD              9 (size)\n            108 LOAD_CONST               3 (-1)\n            110 CALL_METHOD              1\n            112 CALL_METHOD              2\n            114 STORE_FAST               1 (hidden_states)\n\n347         116 LOAD_FAST                1 (hidden_states)\n            118 STORE_FAST               7 (residual)\n\n350         120 LOAD_FAST                0 (self)\n            122 LOAD_ATTR                0 (do_layer_norm_before)\n            124 POP_JUMP_IF_FALSE       68 (to 136)\n\n351         126 LOAD_FAST                0 (self)\n            128 LOAD_METHOD             10 (final_layer_norm)\n            130 LOAD_FAST                1 (hidden_states)\n            132 CALL_METHOD              1\n            134 STORE_FAST               1 (hidden_states)\n\n353     >>  136 LOAD_FAST                0 (self)\n            138 LOAD_METHOD             11 (fc1)\n            140 LOAD_FAST                1 (hidden_states)\n            142 CALL_METHOD              1\n            144 STORE_FAST               1 (hidden_states)\n\n354         146 LOAD_FAST                0 (self)\n            148 LOAD_METHOD             12 (activation_fn)\n            150 LOAD_FAST                1 (hidden_states)\n            152 CALL_METHOD              1\n            154 STORE_FAST               1 (hidden_states)\n\n356         156 LOAD_FAST                0 (self)\n            158 LOAD_METHOD             13 (fc2)\n            160 LOAD_FAST                1 (hidden_states)\n            162 CALL_METHOD              1\n            164 STORE_FAST               1 (hidden_states)\n\n357         166 LOAD_GLOBAL              3 (nn)\n            168 LOAD_ATTR                4 (functional)\n            170 LOAD_ATTR                5 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                5 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                6 (training)\n            182 LOAD_CONST               2 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n359         188 LOAD_FAST                7 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 LOAD_METHOD             14 (view)\n            196 LOAD_FAST               10 (hidden_states_shape)\n            198 CALL_METHOD              1\n            200 STORE_FAST               1 (hidden_states)\n\n362         202 LOAD_FAST                0 (self)\n            204 LOAD_ATTR                0 (do_layer_norm_before)\n            206 POP_JUMP_IF_TRUE       109 (to 218)\n\n363         208 LOAD_FAST                0 (self)\n            210 LOAD_METHOD             10 (final_layer_norm)\n            212 LOAD_FAST                1 (hidden_states)\n            214 CALL_METHOD              1\n            216 STORE_FAST               1 (hidden_states)\n\n365     >>  218 LOAD_FAST                1 (hidden_states)\n            220 BUILD_TUPLE              1\n            222 STORE_FAST              11 (outputs)\n\n367         224 LOAD_FAST                5 (output_attentions)\n            226 POP_JUMP_IF_FALSE      119 (to 238)\n\n368         228 LOAD_FAST               11 (outputs)\n            230 LOAD_FAST                8 (self_attn_weights)\n            232 BUILD_TUPLE              1\n            234 INPLACE_ADD\n            236 STORE_FAST              11 (outputs)\n\n370     >>  238 LOAD_FAST                6 (use_cache)\n            240 POP_JUMP_IF_FALSE      126 (to 252)\n\n371         242 LOAD_FAST               11 (outputs)\n            244 LOAD_FAST                9 (present_key_value)\n            246 BUILD_TUPLE              1\n            248 INPLACE_ADD\n            250 STORE_FAST              11 (outputs)\n\n373     >>  252 LOAD_FAST               11 (outputs)\n            254 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py line 298 \n323           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               7 (residual)\n\n326           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (do_layer_norm_before)\n              8 POP_JUMP_IF_FALSE       10 (to 20)\n\n327          10 LOAD_FAST                0 (self)\n             12 LOAD_METHOD              1 (self_attn_layer_norm)\n             14 LOAD_FAST                1 (hidden_states)\n             16 CALL_METHOD              1\n             18 STORE_FAST               1 (hidden_states)\n\n330     >>   20 LOAD_FAST                0 (self)\n             22 LOAD_ATTR                2 (self_attn)\n\n331          24 LOAD_FAST                1 (hidden_states)\n\n332          26 LOAD_FAST                4 (past_key_value)\n\n333          28 LOAD_FAST                2 (attention_mask)\n\n334          30 LOAD_FAST                3 (layer_head_mask)\n\n335          32 LOAD_FAST                5 (output_attentions)\n\n330          34 LOAD_CONST               1 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             36 CALL_FUNCTION_KW         5\n             38 UNPACK_SEQUENCE          3\n             40 STORE_FAST               1 (hidden_states)\n             42 STORE_FAST               8 (self_attn_weights)\n             44 STORE_FAST               9 (present_key_value)\n\n337          46 LOAD_GLOBAL              3 (nn)\n             48 LOAD_ATTR                4 (functional)\n             50 LOAD_ATTR                5 (dropout)\n             52 LOAD_FAST                1 (hidden_states)\n             54 LOAD_FAST                0 (self)\n             56 LOAD_ATTR                5 (dropout)\n             58 LOAD_FAST                0 (self)\n             60 LOAD_ATTR                6 (training)\n             62 LOAD_CONST               2 (('p', 'training'))\n             64 CALL_FUNCTION_KW         3\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                7 (residual)\n             70 LOAD_FAST                1 (hidden_states)\n             72 BINARY_ADD\n             74 STORE_FAST               1 (hidden_states)\n\n341          76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                0 (do_layer_norm_before)\n             80 POP_JUMP_IF_TRUE        46 (to 92)\n\n342          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              1 (self_attn_layer_norm)\n             86 LOAD_FAST                1 (hidden_states)\n             88 CALL_METHOD              1\n             90 STORE_FAST               1 (hidden_states)\n\n345     >>   92 LOAD_FAST                1 (hidden_states)\n             94 LOAD_ATTR                7 (shape)\n             96 STORE_FAST              10 (hidden_states_shape)\n\n346          98 LOAD_FAST                1 (hidden_states)\n            100 LOAD_METHOD              8 (reshape)\n            102 LOAD_CONST               3 (-1)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_METHOD              9 (size)\n            108 LOAD_CONST               3 (-1)\n            110 CALL_METHOD              1\n            112 CALL_METHOD              2\n            114 STORE_FAST               1 (hidden_states)\n\n347         116 LOAD_FAST                1 (hidden_states)\n            118 STORE_FAST               7 (residual)\n\n350         120 LOAD_FAST                0 (self)\n            122 LOAD_ATTR                0 (do_layer_norm_before)\n            124 POP_JUMP_IF_FALSE       68 (to 136)\n\n351         126 LOAD_FAST                0 (self)\n            128 LOAD_METHOD             10 (final_layer_norm)\n            130 LOAD_FAST                1 (hidden_states)\n            132 CALL_METHOD              1\n            134 STORE_FAST               1 (hidden_states)\n\n353     >>  136 LOAD_FAST                0 (self)\n            138 LOAD_METHOD             11 (fc1)\n            140 LOAD_FAST                1 (hidden_states)\n            142 CALL_METHOD              1\n            144 STORE_FAST               1 (hidden_states)\n\n354         146 LOAD_FAST                0 (self)\n            148 LOAD_METHOD             12 (activation_fn)\n            150 LOAD_FAST                1 (hidden_states)\n            152 CALL_METHOD              1\n            154 STORE_FAST               1 (hidden_states)\n\n356         156 LOAD_FAST                0 (self)\n            158 LOAD_METHOD             13 (fc2)\n            160 LOAD_FAST                1 (hidden_states)\n            162 CALL_METHOD              1\n            164 STORE_FAST               1 (hidden_states)\n\n357         166 LOAD_GLOBAL              3 (nn)\n            168 LOAD_ATTR                4 (functional)\n            170 LOAD_ATTR                5 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                5 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                6 (training)\n            182 LOAD_CONST               2 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n359         188 LOAD_FAST                7 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 LOAD_METHOD             14 (view)\n            196 LOAD_FAST               10 (hidden_states_shape)\n            198 CALL_METHOD              1\n            200 STORE_FAST               1 (hidden_states)\n\n362         202 LOAD_FAST                0 (self)\n            204 LOAD_ATTR                0 (do_layer_norm_before)\n            206 POP_JUMP_IF_TRUE       109 (to 218)\n\n363         208 LOAD_FAST                0 (self)\n            210 LOAD_METHOD             10 (final_layer_norm)\n            212 LOAD_FAST                1 (hidden_states)\n            214 CALL_METHOD              1\n            216 STORE_FAST               1 (hidden_states)\n\n365     >>  218 LOAD_FAST                1 (hidden_states)\n            220 BUILD_TUPLE              1\n            222 STORE_FAST              11 (outputs)\n\n367         224 LOAD_FAST                5 (output_attentions)\n            226 POP_JUMP_IF_FALSE      119 (to 238)\n\n368         228 LOAD_FAST               11 (outputs)\n            230 LOAD_FAST                8 (self_attn_weights)\n            232 BUILD_TUPLE              1\n            234 INPLACE_ADD\n            236 STORE_FAST              11 (outputs)\n\n370     >>  238 LOAD_FAST                6 (use_cache)\n            240 POP_JUMP_IF_FALSE      126 (to 252)\n\n371         242 LOAD_FAST               11 (outputs)\n            244 LOAD_FAST                9 (present_key_value)\n            246 BUILD_TUPLE              1\n            248 INPLACE_ADD\n            250 STORE_FAST              11 (outputs)\n\n373     >>  252 LOAD_FAST               11 (outputs)\n            254 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py line 298 \n323           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               7 (residual)\n\n326           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (do_layer_norm_before)\n              8 POP_JUMP_IF_FALSE       10 (to 20)\n\n327          10 LOAD_FAST                0 (self)\n             12 LOAD_METHOD              1 (self_attn_layer_norm)\n             14 LOAD_FAST                1 (hidden_states)\n             16 CALL_METHOD              1\n             18 STORE_FAST               1 (hidden_states)\n\n330     >>   20 LOAD_FAST                0 (self)\n             22 LOAD_ATTR                2 (self_attn)\n\n331          24 LOAD_FAST                1 (hidden_states)\n\n332          26 LOAD_FAST                4 (past_key_value)\n\n333          28 LOAD_FAST                2 (attention_mask)\n\n334          30 LOAD_FAST                3 (layer_head_mask)\n\n335          32 LOAD_FAST                5 (output_attentions)\n\n330          34 LOAD_CONST               1 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             36 CALL_FUNCTION_KW         5\n             38 UNPACK_SEQUENCE          3\n             40 STORE_FAST               1 (hidden_states)\n             42 STORE_FAST               8 (self_attn_weights)\n             44 STORE_FAST               9 (present_key_value)\n\n337          46 LOAD_GLOBAL              3 (nn)\n             48 LOAD_ATTR                4 (functional)\n             50 LOAD_ATTR                5 (dropout)\n             52 LOAD_FAST                1 (hidden_states)\n             54 LOAD_FAST                0 (self)\n             56 LOAD_ATTR                5 (dropout)\n             58 LOAD_FAST                0 (self)\n             60 LOAD_ATTR                6 (training)\n             62 LOAD_CONST               2 (('p', 'training'))\n             64 CALL_FUNCTION_KW         3\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                7 (residual)\n             70 LOAD_FAST                1 (hidden_states)\n             72 BINARY_ADD\n             74 STORE_FAST               1 (hidden_states)\n\n341          76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                0 (do_layer_norm_before)\n             80 POP_JUMP_IF_TRUE        46 (to 92)\n\n342          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              1 (self_attn_layer_norm)\n             86 LOAD_FAST                1 (hidden_states)\n             88 CALL_METHOD              1\n             90 STORE_FAST               1 (hidden_states)\n\n345     >>   92 LOAD_FAST                1 (hidden_states)\n             94 LOAD_ATTR                7 (shape)\n             96 STORE_FAST              10 (hidden_states_shape)\n\n346          98 LOAD_FAST                1 (hidden_states)\n            100 LOAD_METHOD              8 (reshape)\n            102 LOAD_CONST               3 (-1)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_METHOD              9 (size)\n            108 LOAD_CONST               3 (-1)\n            110 CALL_METHOD              1\n            112 CALL_METHOD              2\n            114 STORE_FAST               1 (hidden_states)\n\n347         116 LOAD_FAST                1 (hidden_states)\n            118 STORE_FAST               7 (residual)\n\n350         120 LOAD_FAST                0 (self)\n            122 LOAD_ATTR                0 (do_layer_norm_before)\n            124 POP_JUMP_IF_FALSE       68 (to 136)\n\n351         126 LOAD_FAST                0 (self)\n            128 LOAD_METHOD             10 (final_layer_norm)\n            130 LOAD_FAST                1 (hidden_states)\n            132 CALL_METHOD              1\n            134 STORE_FAST               1 (hidden_states)\n\n353     >>  136 LOAD_FAST                0 (self)\n            138 LOAD_METHOD             11 (fc1)\n            140 LOAD_FAST                1 (hidden_states)\n            142 CALL_METHOD              1\n            144 STORE_FAST               1 (hidden_states)\n\n354         146 LOAD_FAST                0 (self)\n            148 LOAD_METHOD             12 (activation_fn)\n            150 LOAD_FAST                1 (hidden_states)\n            152 CALL_METHOD              1\n            154 STORE_FAST               1 (hidden_states)\n\n356         156 LOAD_FAST                0 (self)\n            158 LOAD_METHOD             13 (fc2)\n            160 LOAD_FAST                1 (hidden_states)\n            162 CALL_METHOD              1\n            164 STORE_FAST               1 (hidden_states)\n\n357         166 LOAD_GLOBAL              3 (nn)\n            168 LOAD_ATTR                4 (functional)\n            170 LOAD_ATTR                5 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                5 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                6 (training)\n            182 LOAD_CONST               2 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n359         188 LOAD_FAST                7 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 LOAD_METHOD             14 (view)\n            196 LOAD_FAST               10 (hidden_states_shape)\n            198 CALL_METHOD              1\n            200 STORE_FAST               1 (hidden_states)\n\n362         202 LOAD_FAST                0 (self)\n            204 LOAD_ATTR                0 (do_layer_norm_before)\n            206 POP_JUMP_IF_TRUE       109 (to 218)\n\n363         208 LOAD_FAST                0 (self)\n            210 LOAD_METHOD             10 (final_layer_norm)\n            212 LOAD_FAST                1 (hidden_states)\n            214 CALL_METHOD              1\n            216 STORE_FAST               1 (hidden_states)\n\n365     >>  218 LOAD_FAST                1 (hidden_states)\n            220 BUILD_TUPLE              1\n            222 STORE_FAST              11 (outputs)\n\n367         224 LOAD_FAST                5 (output_attentions)\n            226 POP_JUMP_IF_FALSE      119 (to 238)\n\n368         228 LOAD_FAST               11 (outputs)\n            230 LOAD_FAST                8 (self_attn_weights)\n            232 BUILD_TUPLE              1\n            234 INPLACE_ADD\n            236 STORE_FAST              11 (outputs)\n\n370     >>  238 LOAD_FAST                6 (use_cache)\n            240 POP_JUMP_IF_FALSE      126 (to 252)\n\n371         242 LOAD_FAST               11 (outputs)\n            244 LOAD_FAST                9 (present_key_value)\n            246 BUILD_TUPLE              1\n            248 INPLACE_ADD\n            250 STORE_FAST              11 (outputs)\n\n373     >>  252 LOAD_FAST               11 (outputs)\n            254 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py line 298 \n323           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               7 (residual)\n\n326           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (do_layer_norm_before)\n              8 POP_JUMP_IF_FALSE       10 (to 20)\n\n327          10 LOAD_FAST                0 (self)\n             12 LOAD_METHOD              1 (self_attn_layer_norm)\n             14 LOAD_FAST                1 (hidden_states)\n             16 CALL_METHOD              1\n             18 STORE_FAST               1 (hidden_states)\n\n330     >>   20 LOAD_FAST                0 (self)\n             22 LOAD_ATTR                2 (self_attn)\n\n331          24 LOAD_FAST                1 (hidden_states)\n\n332          26 LOAD_FAST                4 (past_key_value)\n\n333          28 LOAD_FAST                2 (attention_mask)\n\n334          30 LOAD_FAST                3 (layer_head_mask)\n\n335          32 LOAD_FAST                5 (output_attentions)\n\n330          34 LOAD_CONST               1 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             36 CALL_FUNCTION_KW         5\n             38 UNPACK_SEQUENCE          3\n             40 STORE_FAST               1 (hidden_states)\n             42 STORE_FAST               8 (self_attn_weights)\n             44 STORE_FAST               9 (present_key_value)\n\n337          46 LOAD_GLOBAL              3 (nn)\n             48 LOAD_ATTR                4 (functional)\n             50 LOAD_ATTR                5 (dropout)\n             52 LOAD_FAST                1 (hidden_states)\n             54 LOAD_FAST                0 (self)\n             56 LOAD_ATTR                5 (dropout)\n             58 LOAD_FAST                0 (self)\n             60 LOAD_ATTR                6 (training)\n             62 LOAD_CONST               2 (('p', 'training'))\n             64 CALL_FUNCTION_KW         3\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                7 (residual)\n             70 LOAD_FAST                1 (hidden_states)\n             72 BINARY_ADD\n             74 STORE_FAST               1 (hidden_states)\n\n341          76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                0 (do_layer_norm_before)\n             80 POP_JUMP_IF_TRUE        46 (to 92)\n\n342          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              1 (self_attn_layer_norm)\n             86 LOAD_FAST                1 (hidden_states)\n             88 CALL_METHOD              1\n             90 STORE_FAST               1 (hidden_states)\n\n345     >>   92 LOAD_FAST                1 (hidden_states)\n             94 LOAD_ATTR                7 (shape)\n             96 STORE_FAST              10 (hidden_states_shape)\n\n346          98 LOAD_FAST                1 (hidden_states)\n            100 LOAD_METHOD              8 (reshape)\n            102 LOAD_CONST               3 (-1)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_METHOD              9 (size)\n            108 LOAD_CONST               3 (-1)\n            110 CALL_METHOD              1\n            112 CALL_METHOD              2\n            114 STORE_FAST               1 (hidden_states)\n\n347         116 LOAD_FAST                1 (hidden_states)\n            118 STORE_FAST               7 (residual)\n\n350         120 LOAD_FAST                0 (self)\n            122 LOAD_ATTR                0 (do_layer_norm_before)\n            124 POP_JUMP_IF_FALSE       68 (to 136)\n\n351         126 LOAD_FAST                0 (self)\n            128 LOAD_METHOD             10 (final_layer_norm)\n            130 LOAD_FAST                1 (hidden_states)\n            132 CALL_METHOD              1\n            134 STORE_FAST               1 (hidden_states)\n\n353     >>  136 LOAD_FAST                0 (self)\n            138 LOAD_METHOD             11 (fc1)\n            140 LOAD_FAST                1 (hidden_states)\n            142 CALL_METHOD              1\n            144 STORE_FAST               1 (hidden_states)\n\n354         146 LOAD_FAST                0 (self)\n            148 LOAD_METHOD             12 (activation_fn)\n            150 LOAD_FAST                1 (hidden_states)\n            152 CALL_METHOD              1\n            154 STORE_FAST               1 (hidden_states)\n\n356         156 LOAD_FAST                0 (self)\n            158 LOAD_METHOD             13 (fc2)\n            160 LOAD_FAST                1 (hidden_states)\n            162 CALL_METHOD              1\n            164 STORE_FAST               1 (hidden_states)\n\n357         166 LOAD_GLOBAL              3 (nn)\n            168 LOAD_ATTR                4 (functional)\n            170 LOAD_ATTR                5 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                5 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                6 (training)\n            182 LOAD_CONST               2 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n359         188 LOAD_FAST                7 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 LOAD_METHOD             14 (view)\n            196 LOAD_FAST               10 (hidden_states_shape)\n            198 CALL_METHOD              1\n            200 STORE_FAST               1 (hidden_states)\n\n362         202 LOAD_FAST                0 (self)\n            204 LOAD_ATTR                0 (do_layer_norm_before)\n            206 POP_JUMP_IF_TRUE       109 (to 218)\n\n363         208 LOAD_FAST                0 (self)\n            210 LOAD_METHOD             10 (final_layer_norm)\n            212 LOAD_FAST                1 (hidden_states)\n            214 CALL_METHOD              1\n            216 STORE_FAST               1 (hidden_states)\n\n365     >>  218 LOAD_FAST                1 (hidden_states)\n            220 BUILD_TUPLE              1\n            222 STORE_FAST              11 (outputs)\n\n367         224 LOAD_FAST                5 (output_attentions)\n            226 POP_JUMP_IF_FALSE      119 (to 238)\n\n368         228 LOAD_FAST               11 (outputs)\n            230 LOAD_FAST                8 (self_attn_weights)\n            232 BUILD_TUPLE              1\n            234 INPLACE_ADD\n            236 STORE_FAST              11 (outputs)\n\n370     >>  238 LOAD_FAST                6 (use_cache)\n            240 POP_JUMP_IF_FALSE      126 (to 252)\n\n371         242 LOAD_FAST               11 (outputs)\n            244 LOAD_FAST                9 (present_key_value)\n            246 BUILD_TUPLE              1\n            248 INPLACE_ADD\n            250 STORE_FAST              11 (outputs)\n\n373     >>  252 LOAD_FAST               11 (outputs)\n            254 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py line 298 \n323           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               7 (residual)\n\n326           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (do_layer_norm_before)\n              8 POP_JUMP_IF_FALSE       10 (to 20)\n\n327          10 LOAD_FAST                0 (self)\n             12 LOAD_METHOD              1 (self_attn_layer_norm)\n             14 LOAD_FAST                1 (hidden_states)\n             16 CALL_METHOD              1\n             18 STORE_FAST               1 (hidden_states)\n\n330     >>   20 LOAD_FAST                0 (self)\n             22 LOAD_ATTR                2 (self_attn)\n\n331          24 LOAD_FAST                1 (hidden_states)\n\n332          26 LOAD_FAST                4 (past_key_value)\n\n333          28 LOAD_FAST                2 (attention_mask)\n\n334          30 LOAD_FAST                3 (layer_head_mask)\n\n335          32 LOAD_FAST                5 (output_attentions)\n\n330          34 LOAD_CONST               1 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             36 CALL_FUNCTION_KW         5\n             38 UNPACK_SEQUENCE          3\n             40 STORE_FAST               1 (hidden_states)\n             42 STORE_FAST               8 (self_attn_weights)\n             44 STORE_FAST               9 (present_key_value)\n\n337          46 LOAD_GLOBAL              3 (nn)\n             48 LOAD_ATTR                4 (functional)\n             50 LOAD_ATTR                5 (dropout)\n             52 LOAD_FAST                1 (hidden_states)\n             54 LOAD_FAST                0 (self)\n             56 LOAD_ATTR                5 (dropout)\n             58 LOAD_FAST                0 (self)\n             60 LOAD_ATTR                6 (training)\n             62 LOAD_CONST               2 (('p', 'training'))\n             64 CALL_FUNCTION_KW         3\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                7 (residual)\n             70 LOAD_FAST                1 (hidden_states)\n             72 BINARY_ADD\n             74 STORE_FAST               1 (hidden_states)\n\n341          76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                0 (do_layer_norm_before)\n             80 POP_JUMP_IF_TRUE        46 (to 92)\n\n342          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              1 (self_attn_layer_norm)\n             86 LOAD_FAST                1 (hidden_states)\n             88 CALL_METHOD              1\n             90 STORE_FAST               1 (hidden_states)\n\n345     >>   92 LOAD_FAST                1 (hidden_states)\n             94 LOAD_ATTR                7 (shape)\n             96 STORE_FAST              10 (hidden_states_shape)\n\n346          98 LOAD_FAST                1 (hidden_states)\n            100 LOAD_METHOD              8 (reshape)\n            102 LOAD_CONST               3 (-1)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_METHOD              9 (size)\n            108 LOAD_CONST               3 (-1)\n            110 CALL_METHOD              1\n            112 CALL_METHOD              2\n            114 STORE_FAST               1 (hidden_states)\n\n347         116 LOAD_FAST                1 (hidden_states)\n            118 STORE_FAST               7 (residual)\n\n350         120 LOAD_FAST                0 (self)\n            122 LOAD_ATTR                0 (do_layer_norm_before)\n            124 POP_JUMP_IF_FALSE       68 (to 136)\n\n351         126 LOAD_FAST                0 (self)\n            128 LOAD_METHOD             10 (final_layer_norm)\n            130 LOAD_FAST                1 (hidden_states)\n            132 CALL_METHOD              1\n            134 STORE_FAST               1 (hidden_states)\n\n353     >>  136 LOAD_FAST                0 (self)\n            138 LOAD_METHOD             11 (fc1)\n            140 LOAD_FAST                1 (hidden_states)\n            142 CALL_METHOD              1\n            144 STORE_FAST               1 (hidden_states)\n\n354         146 LOAD_FAST                0 (self)\n            148 LOAD_METHOD             12 (activation_fn)\n            150 LOAD_FAST                1 (hidden_states)\n            152 CALL_METHOD              1\n            154 STORE_FAST               1 (hidden_states)\n\n356         156 LOAD_FAST                0 (self)\n            158 LOAD_METHOD             13 (fc2)\n            160 LOAD_FAST                1 (hidden_states)\n            162 CALL_METHOD              1\n            164 STORE_FAST               1 (hidden_states)\n\n357         166 LOAD_GLOBAL              3 (nn)\n            168 LOAD_ATTR                4 (functional)\n            170 LOAD_ATTR                5 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                5 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                6 (training)\n            182 LOAD_CONST               2 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n359         188 LOAD_FAST                7 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 LOAD_METHOD             14 (view)\n            196 LOAD_FAST               10 (hidden_states_shape)\n            198 CALL_METHOD              1\n            200 STORE_FAST               1 (hidden_states)\n\n362         202 LOAD_FAST                0 (self)\n            204 LOAD_ATTR                0 (do_layer_norm_before)\n            206 POP_JUMP_IF_TRUE       109 (to 218)\n\n363         208 LOAD_FAST                0 (self)\n            210 LOAD_METHOD             10 (final_layer_norm)\n            212 LOAD_FAST                1 (hidden_states)\n            214 CALL_METHOD              1\n            216 STORE_FAST               1 (hidden_states)\n\n365     >>  218 LOAD_FAST                1 (hidden_states)\n            220 BUILD_TUPLE              1\n            222 STORE_FAST              11 (outputs)\n\n367         224 LOAD_FAST                5 (output_attentions)\n            226 POP_JUMP_IF_FALSE      119 (to 238)\n\n368         228 LOAD_FAST               11 (outputs)\n            230 LOAD_FAST                8 (self_attn_weights)\n            232 BUILD_TUPLE              1\n            234 INPLACE_ADD\n            236 STORE_FAST              11 (outputs)\n\n370     >>  238 LOAD_FAST                6 (use_cache)\n            240 POP_JUMP_IF_FALSE      126 (to 252)\n\n371         242 LOAD_FAST               11 (outputs)\n            244 LOAD_FAST                9 (present_key_value)\n            246 BUILD_TUPLE              1\n            248 INPLACE_ADD\n            250 STORE_FAST              11 (outputs)\n\n373     >>  252 LOAD_FAST               11 (outputs)\n            254 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py line 298 \n323           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               7 (residual)\n\n326           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (do_layer_norm_before)\n              8 POP_JUMP_IF_FALSE       10 (to 20)\n\n327          10 LOAD_FAST                0 (self)\n             12 LOAD_METHOD              1 (self_attn_layer_norm)\n             14 LOAD_FAST                1 (hidden_states)\n             16 CALL_METHOD              1\n             18 STORE_FAST               1 (hidden_states)\n\n330     >>   20 LOAD_FAST                0 (self)\n             22 LOAD_ATTR                2 (self_attn)\n\n331          24 LOAD_FAST                1 (hidden_states)\n\n332          26 LOAD_FAST                4 (past_key_value)\n\n333          28 LOAD_FAST                2 (attention_mask)\n\n334          30 LOAD_FAST                3 (layer_head_mask)\n\n335          32 LOAD_FAST                5 (output_attentions)\n\n330          34 LOAD_CONST               1 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             36 CALL_FUNCTION_KW         5\n             38 UNPACK_SEQUENCE          3\n             40 STORE_FAST               1 (hidden_states)\n             42 STORE_FAST               8 (self_attn_weights)\n             44 STORE_FAST               9 (present_key_value)\n\n337          46 LOAD_GLOBAL              3 (nn)\n             48 LOAD_ATTR                4 (functional)\n             50 LOAD_ATTR                5 (dropout)\n             52 LOAD_FAST                1 (hidden_states)\n             54 LOAD_FAST                0 (self)\n             56 LOAD_ATTR                5 (dropout)\n             58 LOAD_FAST                0 (self)\n             60 LOAD_ATTR                6 (training)\n             62 LOAD_CONST               2 (('p', 'training'))\n             64 CALL_FUNCTION_KW         3\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                7 (residual)\n             70 LOAD_FAST                1 (hidden_states)\n             72 BINARY_ADD\n             74 STORE_FAST               1 (hidden_states)\n\n341          76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                0 (do_layer_norm_before)\n             80 POP_JUMP_IF_TRUE        46 (to 92)\n\n342          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              1 (self_attn_layer_norm)\n             86 LOAD_FAST                1 (hidden_states)\n             88 CALL_METHOD              1\n             90 STORE_FAST               1 (hidden_states)\n\n345     >>   92 LOAD_FAST                1 (hidden_states)\n             94 LOAD_ATTR                7 (shape)\n             96 STORE_FAST              10 (hidden_states_shape)\n\n346          98 LOAD_FAST                1 (hidden_states)\n            100 LOAD_METHOD              8 (reshape)\n            102 LOAD_CONST               3 (-1)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_METHOD              9 (size)\n            108 LOAD_CONST               3 (-1)\n            110 CALL_METHOD              1\n            112 CALL_METHOD              2\n            114 STORE_FAST               1 (hidden_states)\n\n347         116 LOAD_FAST                1 (hidden_states)\n            118 STORE_FAST               7 (residual)\n\n350         120 LOAD_FAST                0 (self)\n            122 LOAD_ATTR                0 (do_layer_norm_before)\n            124 POP_JUMP_IF_FALSE       68 (to 136)\n\n351         126 LOAD_FAST                0 (self)\n            128 LOAD_METHOD             10 (final_layer_norm)\n            130 LOAD_FAST                1 (hidden_states)\n            132 CALL_METHOD              1\n            134 STORE_FAST               1 (hidden_states)\n\n353     >>  136 LOAD_FAST                0 (self)\n            138 LOAD_METHOD             11 (fc1)\n            140 LOAD_FAST                1 (hidden_states)\n            142 CALL_METHOD              1\n            144 STORE_FAST               1 (hidden_states)\n\n354         146 LOAD_FAST                0 (self)\n            148 LOAD_METHOD             12 (activation_fn)\n            150 LOAD_FAST                1 (hidden_states)\n            152 CALL_METHOD              1\n            154 STORE_FAST               1 (hidden_states)\n\n356         156 LOAD_FAST                0 (self)\n            158 LOAD_METHOD             13 (fc2)\n            160 LOAD_FAST                1 (hidden_states)\n            162 CALL_METHOD              1\n            164 STORE_FAST               1 (hidden_states)\n\n357         166 LOAD_GLOBAL              3 (nn)\n            168 LOAD_ATTR                4 (functional)\n            170 LOAD_ATTR                5 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                5 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                6 (training)\n            182 LOAD_CONST               2 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n359         188 LOAD_FAST                7 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 LOAD_METHOD             14 (view)\n            196 LOAD_FAST               10 (hidden_states_shape)\n            198 CALL_METHOD              1\n            200 STORE_FAST               1 (hidden_states)\n\n362         202 LOAD_FAST                0 (self)\n            204 LOAD_ATTR                0 (do_layer_norm_before)\n            206 POP_JUMP_IF_TRUE       109 (to 218)\n\n363         208 LOAD_FAST                0 (self)\n            210 LOAD_METHOD             10 (final_layer_norm)\n            212 LOAD_FAST                1 (hidden_states)\n            214 CALL_METHOD              1\n            216 STORE_FAST               1 (hidden_states)\n\n365     >>  218 LOAD_FAST                1 (hidden_states)\n            220 BUILD_TUPLE              1\n            222 STORE_FAST              11 (outputs)\n\n367         224 LOAD_FAST                5 (output_attentions)\n            226 POP_JUMP_IF_FALSE      119 (to 238)\n\n368         228 LOAD_FAST               11 (outputs)\n            230 LOAD_FAST                8 (self_attn_weights)\n            232 BUILD_TUPLE              1\n            234 INPLACE_ADD\n            236 STORE_FAST              11 (outputs)\n\n370     >>  238 LOAD_FAST                6 (use_cache)\n            240 POP_JUMP_IF_FALSE      126 (to 252)\n\n371         242 LOAD_FAST               11 (outputs)\n            244 LOAD_FAST                9 (present_key_value)\n            246 BUILD_TUPLE              1\n            248 INPLACE_ADD\n            250 STORE_FAST              11 (outputs)\n\n373     >>  252 LOAD_FAST               11 (outputs)\n            254 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (past_key_values)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (past_key_values)\n\n  5          12 LOAD_FAST                3 (hidden_states)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (hidden_states)\n\n  6          18 LOAD_FAST                4 (attentions)\n             20 LOAD_FAST                0 (self)\n             22 STORE_ATTR               3 (attentions)\n\n  7          24 LOAD_FAST                0 (self)\n             26 LOAD_METHOD              4 (__post_init__)\n             28 CALL_METHOD              0\n             30 POP_TOP\n             32 LOAD_CONST               0 (None)\n             34 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 3 \n  3           0 JUMP_ABSOLUTE            4 (to 8)\n              2 LOAD_FAST                4 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n\n  4     >>    8 LOAD_FAST                1 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5          14 LOAD_FAST                2 (hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (hidden_states)\n\n  6          20 LOAD_FAST                3 (attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (attentions)\n\n  7          26 LOAD_FAST                0 (self)\n             28 LOAD_ATTR                4 (__post_init__)\n             30 CALL_FUNCTION            0\n             32 POP_TOP\n             34 LOAD_CONST               0 (None)\n             36 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py line 944 \n944           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           46 (to 92)\n              4 LOAD_FAST               10 (output_attentions)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE        8 (to 16)\n             12 LOAD_FAST               10 (output_attentions)\n             14 JUMP_FORWARD             3 (to 22)\n        >>   16 LOAD_FAST                1 (self)\n             18 LOAD_ATTR                0 (config)\n             20 LOAD_ATTR                1 (output_attentions)\n        >>   22 STORE_FAST              10 (output_attentions)\n             24 LOAD_FAST               11 (output_hidden_states)\n             26 LOAD_CONST               1 (None)\n             28 IS_OP                    1\n             30 POP_JUMP_IF_FALSE       18 (to 36)\n             32 LOAD_FAST               11 (output_hidden_states)\n             34 JUMP_FORWARD             3 (to 42)\n        >>   36 LOAD_FAST                1 (self)\n             38 LOAD_ATTR                0 (config)\n             40 LOAD_ATTR                2 (output_hidden_states)\n        >>   42 STORE_FAST              11 (output_hidden_states)\n             44 LOAD_FAST                3 (return_dict)\n             46 LOAD_CONST               1 (None)\n             48 IS_OP                    1\n             50 POP_JUMP_IF_FALSE       28 (to 56)\n             52 LOAD_FAST                3 (return_dict)\n             54 JUMP_FORWARD             3 (to 62)\n        >>   56 LOAD_FAST                1 (self)\n             58 LOAD_ATTR                0 (config)\n             60 LOAD_ATTR                3 (use_return_dict)\n        >>   62 STORE_FAST               3 (return_dict)\n             64 LOAD_FAST                1 (self)\n             66 LOAD_ATTR                4 (model)\n             68 LOAD_ATTR                5 (decoder)\n             70 LOAD_FAST                4 (input_ids)\n             72 LOAD_FAST                5 (attention_mask)\n             74 LOAD_FAST                6 (head_mask)\n             76 LOAD_FAST                7 (past_key_values)\n             78 LOAD_FAST                8 (inputs_embeds)\n             80 LOAD_FAST                9 (use_cache)\n             82 LOAD_FAST               10 (output_attentions)\n             84 LOAD_FAST               11 (output_hidden_states)\n             86 LOAD_FAST                3 (return_dict)\n             88 LOAD_CONST               2 (('input_ids', 'attention_mask', 'head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             90 CALL_FUNCTION_KW         9\n        >>   92 STORE_FAST              12 (outputs)\n\n956          94 LOAD_FAST                1 (self)\n             96 LOAD_ATTR                6 (lm_head)\n             98 LOAD_FAST               12 (outputs)\n            100 LOAD_CONST               3 (0)\n            102 BINARY_SUBSCR\n            104 CALL_FUNCTION            1\n            106 LOAD_ATTR                7 (contiguous)\n            108 CALL_FUNCTION            0\n            110 STORE_FAST              13 (logits)\n\n958         112 LOAD_CONST               1 (None)\n            114 STORE_FAST              14 (loss)\n\n959         116 LOAD_FAST                2 (labels)\n            118 LOAD_CONST               1 (None)\n            120 IS_OP                    1\n            122 POP_JUMP_IF_FALSE      108 (to 216)\n\n961         124 LOAD_FAST                2 (labels)\n            126 LOAD_ATTR                8 (to)\n            128 LOAD_FAST               13 (logits)\n            130 LOAD_ATTR                9 (device)\n            132 CALL_FUNCTION            1\n            134 STORE_FAST               2 (labels)\n\n963         136 LOAD_FAST               13 (logits)\n            138 LOAD_CONST               4 (Ellipsis)\n            140 LOAD_CONST               1 (None)\n            142 LOAD_CONST               5 (-1)\n            144 BUILD_SLICE              2\n            146 LOAD_CONST               1 (None)\n            148 LOAD_CONST               1 (None)\n            150 BUILD_SLICE              2\n            152 BUILD_TUPLE              3\n            154 BINARY_SUBSCR\n            156 LOAD_ATTR                7 (contiguous)\n            158 CALL_FUNCTION            0\n            160 STORE_FAST              15 (shift_logits)\n\n964         162 LOAD_FAST                2 (labels)\n            164 LOAD_CONST               4 (Ellipsis)\n            166 LOAD_CONST               6 (1)\n            168 LOAD_CONST               1 (None)\n            170 BUILD_SLICE              2\n            172 BUILD_TUPLE              2\n            174 BINARY_SUBSCR\n            176 LOAD_ATTR                7 (contiguous)\n            178 CALL_FUNCTION            0\n            180 STORE_FAST              16 (shift_labels)\n\n966         182 LOAD_GLOBAL             10 (CrossEntropyLoss)\n            184 CALL_FUNCTION            0\n            186 STORE_FAST              17 (loss_fct)\n\n967         188 LOAD_FAST               17 (loss_fct)\n            190 LOAD_FAST               15 (shift_logits)\n            192 LOAD_ATTR               11 (view)\n            194 LOAD_CONST               5 (-1)\n            196 LOAD_FAST                1 (self)\n            198 LOAD_ATTR                0 (config)\n            200 LOAD_ATTR               12 (vocab_size)\n            202 CALL_FUNCTION            2\n            204 LOAD_FAST               16 (shift_labels)\n            206 LOAD_ATTR               11 (view)\n            208 LOAD_CONST               5 (-1)\n            210 CALL_FUNCTION            1\n            212 CALL_FUNCTION            2\n            214 STORE_FAST              14 (loss)\n\n969     >>  216 LOAD_FAST                3 (return_dict)\n            218 POP_JUMP_IF_TRUE       130 (to 260)\n\n970         220 LOAD_FAST               13 (logits)\n            222 BUILD_TUPLE              1\n            224 LOAD_FAST               12 (outputs)\n            226 LOAD_CONST               6 (1)\n            228 LOAD_CONST               1 (None)\n            230 BUILD_SLICE              2\n            232 BINARY_SUBSCR\n            234 BINARY_ADD\n            236 STORE_FAST              18 (output)\n\n971         238 LOAD_FAST               14 (loss)\n            240 LOAD_CONST               1 (None)\n            242 IS_OP                    1\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n            246 LOAD_FAST               14 (loss)\n            248 BUILD_TUPLE              1\n            250 LOAD_FAST               18 (output)\n            252 BINARY_ADD\n            254 RETURN_VALUE\n        >>  256 LOAD_FAST               18 (output)\n            258 RETURN_VALUE\n\n973     >>  260 LOAD_GLOBAL             13 (CausalLMOutputWithPast)\n\n974         262 LOAD_FAST               14 (loss)\n\n975         264 LOAD_FAST               13 (logits)\n\n976         266 LOAD_FAST               12 (outputs)\n            268 LOAD_ATTR               14 (past_key_values)\n\n977         270 LOAD_FAST               12 (outputs)\n            272 LOAD_ATTR               15 (hidden_states)\n\n978         274 LOAD_FAST               12 (outputs)\n            276 LOAD_ATTR               16 (attentions)\n\n973         278 LOAD_CONST               7 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions'))\n            280 CALL_FUNCTION_KW         5\n            282 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 557 \n557           0 LOAD_FAST                0 (___stack0)\n              2 CALL_FUNCTION            0\n              4 SETUP_WITH              10 (to 26)\n              6 POP_TOP\n              8 LOAD_FAST                1 (___stack1)\n             10 JUMP_ABSOLUTE           44 (to 88)\n             12 POP_BLOCK\n             14 LOAD_CONST               0 (None)\n             16 DUP_TOP\n             18 DUP_TOP\n             20 CALL_FUNCTION            3\n             22 POP_TOP\n             24 JUMP_FORWARD             8 (to 42)\n        >>   26 WITH_EXCEPT_START\n             28 POP_JUMP_IF_TRUE        16 (to 32)\n             30 RERAISE                  0\n        >>   32 POP_TOP\n             34 POP_TOP\n             36 POP_TOP\n             38 POP_EXCEPT\n             40 POP_TOP\n        >>   42 NOP\n             44 LOAD_CONST               0 (None)\n             46 RAISE_VARARGS            1\n             48 LOAD_GLOBAL              0 (clone_inputs)\n             50 LOAD_FAST                6 (inputs)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (cloned_inputs)\n             56 LOAD_FAST                2 (self)\n             58 LOAD_ATTR                1 (optimizer_zero_grad)\n             60 LOAD_FAST                3 (mod)\n             62 CALL_FUNCTION            1\n             64 POP_TOP\n             66 LOAD_FAST                2 (self)\n             68 LOAD_ATTR                2 (autocast)\n             70 CALL_FUNCTION            0\n             72 SETUP_WITH              20 (to 114)\n             74 POP_TOP\n             76 LOAD_FAST                3 (mod)\n             78 LOAD_CONST               1 (())\n             80 BUILD_MAP                0\n             82 LOAD_FAST                5 (cloned_inputs)\n             84 DICT_MERGE               1\n             86 CALL_FUNCTION_EX         1\n        >>   88 STORE_FAST               7 (pred)\n\n558          90 LOAD_FAST                2 (self)\n             92 LOAD_ATTR                3 (compute_loss)\n             94 LOAD_FAST                7 (pred)\n             96 CALL_FUNCTION            1\n             98 STORE_FAST               8 (loss)\n            100 POP_BLOCK\n\n556         102 LOAD_CONST               0 (None)\n            104 DUP_TOP\n            106 DUP_TOP\n            108 CALL_FUNCTION            3\n            110 POP_TOP\n            112 JUMP_FORWARD             8 (to 130)\n        >>  114 WITH_EXCEPT_START\n            116 POP_JUMP_IF_TRUE        60 (to 120)\n            118 RERAISE                  1\n        >>  120 POP_TOP\n            122 POP_TOP\n            124 POP_TOP\n            126 POP_EXCEPT\n            128 POP_TOP\n\n559     >>  130 LOAD_FAST                2 (self)\n            132 LOAD_ATTR                4 (grad_scaler)\n            134 LOAD_ATTR                5 (scale)\n            136 LOAD_FAST                8 (loss)\n            138 CALL_FUNCTION            1\n            140 LOAD_ATTR                6 (backward)\n            142 CALL_FUNCTION            0\n            144 POP_TOP\n\n560         146 LOAD_FAST                2 (self)\n            148 LOAD_ATTR                7 (optimizer_step)\n            150 CALL_FUNCTION            0\n            152 POP_TOP\n\n561         154 LOAD_FAST                4 (collect_outputs)\n            156 POP_JUMP_IF_FALSE       86 (to 172)\n\n562         158 LOAD_GLOBAL              8 (collect_results)\n            160 LOAD_FAST                3 (mod)\n            162 LOAD_FAST                7 (pred)\n            164 LOAD_FAST                8 (loss)\n            166 LOAD_FAST                5 (cloned_inputs)\n            168 CALL_FUNCTION            4\n            170 RETURN_VALUE\n\n563     >>  172 LOAD_CONST               0 (None)\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 1588 \n1690           0 LOAD_FAST               11 (output_attentions)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               11 (output_attentions)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (output_attentions)\n         >>   18 STORE_FAST              11 (output_attentions)\n\n1692          20 LOAD_FAST               12 (output_hidden_states)\n              22 LOAD_CONST               1 (None)\n              24 IS_OP                    1\n              26 POP_JUMP_IF_FALSE       16 (to 32)\n              28 LOAD_FAST               12 (output_hidden_states)\n              30 JUMP_FORWARD             3 (to 38)\n         >>   32 LOAD_FAST                0 (self)\n              34 LOAD_ATTR                0 (config)\n              36 LOAD_ATTR                2 (output_hidden_states)\n\n1691     >>   38 STORE_FAST              12 (output_hidden_states)\n\n1694          40 LOAD_FAST               13 (return_dict)\n              42 LOAD_CONST               1 (None)\n              44 IS_OP                    1\n              46 POP_JUMP_IF_FALSE       26 (to 52)\n              48 LOAD_FAST               13 (return_dict)\n              50 JUMP_FORWARD             3 (to 58)\n         >>   52 LOAD_FAST                0 (self)\n              54 LOAD_ATTR                0 (config)\n              56 LOAD_ATTR                3 (use_return_dict)\n         >>   58 STORE_FAST              13 (return_dict)\n\n1697          60 LOAD_FAST                0 (self)\n              62 LOAD_ATTR                4 (model)\n              64 LOAD_ATTR                5 (decoder)\n\n1698          66 LOAD_FAST                1 (input_ids)\n\n1699          68 LOAD_FAST                2 (attention_mask)\n\n1700          70 LOAD_FAST                3 (encoder_hidden_states)\n\n1701          72 LOAD_FAST                4 (encoder_attention_mask)\n\n1702          74 LOAD_FAST                5 (head_mask)\n\n1703          76 LOAD_FAST                6 (cross_attn_head_mask)\n\n1704          78 LOAD_FAST                7 (past_key_values)\n\n1705          80 LOAD_FAST                8 (inputs_embeds)\n\n1706          82 LOAD_FAST               10 (use_cache)\n\n1707          84 LOAD_FAST               11 (output_attentions)\n\n1708          86 LOAD_FAST               12 (output_hidden_states)\n\n1709          88 LOAD_FAST               13 (return_dict)\n\n1697          90 LOAD_CONST               2 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              92 CALL_FUNCTION_KW        12\n              94 STORE_FAST              14 (outputs)\n\n1712          96 LOAD_FAST                0 (self)\n              98 LOAD_METHOD              6 (lm_head)\n             100 LOAD_FAST               14 (outputs)\n             102 LOAD_CONST               3 (0)\n             104 BINARY_SUBSCR\n             106 CALL_METHOD              1\n             108 STORE_FAST              15 (logits)\n\n1714         110 LOAD_CONST               1 (None)\n             112 STORE_FAST              16 (loss)\n\n1715         114 LOAD_FAST                9 (labels)\n             116 LOAD_CONST               1 (None)\n             118 IS_OP                    1\n             120 POP_JUMP_IF_FALSE       84 (to 168)\n\n1716         122 LOAD_FAST                9 (labels)\n             124 LOAD_METHOD              7 (to)\n             126 LOAD_FAST               15 (logits)\n             128 LOAD_ATTR                8 (device)\n             130 CALL_METHOD              1\n             132 STORE_FAST               9 (labels)\n\n1717         134 LOAD_GLOBAL              9 (CrossEntropyLoss)\n             136 CALL_FUNCTION            0\n             138 STORE_FAST              17 (loss_fct)\n\n1718         140 LOAD_FAST               17 (loss_fct)\n             142 LOAD_FAST               15 (logits)\n             144 LOAD_METHOD             10 (view)\n             146 LOAD_CONST               4 (-1)\n             148 LOAD_FAST                0 (self)\n             150 LOAD_ATTR                0 (config)\n             152 LOAD_ATTR               11 (vocab_size)\n             154 CALL_METHOD              2\n             156 LOAD_FAST                9 (labels)\n             158 LOAD_METHOD             10 (view)\n             160 LOAD_CONST               4 (-1)\n             162 CALL_METHOD              1\n             164 CALL_FUNCTION            2\n             166 STORE_FAST              16 (loss)\n\n1720     >>  168 LOAD_FAST               13 (return_dict)\n             170 POP_JUMP_IF_TRUE       106 (to 212)\n\n1721         172 LOAD_FAST               15 (logits)\n             174 BUILD_TUPLE              1\n             176 LOAD_FAST               14 (outputs)\n             178 LOAD_CONST               5 (1)\n             180 LOAD_CONST               1 (None)\n             182 BUILD_SLICE              2\n             184 BINARY_SUBSCR\n             186 BINARY_ADD\n             188 STORE_FAST              18 (output)\n\n1722         190 LOAD_FAST               16 (loss)\n             192 LOAD_CONST               1 (None)\n             194 IS_OP                    1\n             196 POP_JUMP_IF_FALSE      104 (to 208)\n             198 LOAD_FAST               16 (loss)\n             200 BUILD_TUPLE              1\n             202 LOAD_FAST               18 (output)\n             204 BINARY_ADD\n             206 RETURN_VALUE\n         >>  208 LOAD_FAST               18 (output)\n             210 RETURN_VALUE\n\n1724     >>  212 LOAD_GLOBAL             12 (CausalLMOutputWithCrossAttentions)\n\n1725         214 LOAD_FAST               16 (loss)\n\n1726         216 LOAD_FAST               15 (logits)\n\n1727         218 LOAD_FAST               14 (outputs)\n             220 LOAD_ATTR               13 (past_key_values)\n\n1728         222 LOAD_FAST               14 (outputs)\n             224 LOAD_ATTR               14 (hidden_states)\n\n1729         226 LOAD_FAST               14 (outputs)\n             228 LOAD_ATTR               15 (attentions)\n\n1730         230 LOAD_FAST               14 (outputs)\n             232 LOAD_ATTR               16 (cross_attentions)\n\n1724         234 LOAD_CONST               6 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n             236 CALL_FUNCTION_KW         6\n             238 RETURN_VALUE\n\n", "ORIGINAL BYTECODE _prepare_decoder_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 886 \n889           0 LOAD_CONST               0 (None)\n              2 STORE_FAST               5 (combined_attention_mask)\n\n890           4 LOAD_FAST                2 (input_shape)\n              6 LOAD_CONST               1 (-1)\n              8 BINARY_SUBSCR\n             10 LOAD_CONST               2 (1)\n             12 COMPARE_OP               4 (>)\n             14 POP_JUMP_IF_FALSE       18 (to 36)\n\n891          16 LOAD_GLOBAL              0 (_make_causal_mask)\n\n892          18 LOAD_FAST                2 (input_shape)\n\n893          20 LOAD_FAST                3 (inputs_embeds)\n             22 LOAD_ATTR                1 (dtype)\n\n894          24 LOAD_FAST                3 (inputs_embeds)\n             26 LOAD_ATTR                2 (device)\n\n895          28 LOAD_FAST                4 (past_key_values_length)\n\n891          30 LOAD_CONST               3 (('device', 'past_key_values_length'))\n             32 CALL_FUNCTION_KW         4\n             34 STORE_FAST               5 (combined_attention_mask)\n\n898     >>   36 LOAD_FAST                1 (attention_mask)\n             38 LOAD_CONST               0 (None)\n             40 IS_OP                    1\n             42 POP_JUMP_IF_FALSE       46 (to 92)\n\n900          44 LOAD_GLOBAL              3 (_expand_mask)\n             46 LOAD_FAST                1 (attention_mask)\n             48 LOAD_FAST                3 (inputs_embeds)\n             50 LOAD_ATTR                1 (dtype)\n             52 LOAD_FAST                2 (input_shape)\n             54 LOAD_CONST               1 (-1)\n             56 BINARY_SUBSCR\n             58 LOAD_CONST               4 (('tgt_len',))\n             60 CALL_FUNCTION_KW         3\n             62 LOAD_METHOD              4 (to)\n\n901          64 LOAD_FAST                3 (inputs_embeds)\n             66 LOAD_ATTR                2 (device)\n\n900          68 CALL_METHOD              1\n             70 STORE_FAST               6 (expanded_attn_mask)\n\n904          72 LOAD_FAST                5 (combined_attention_mask)\n             74 LOAD_CONST               0 (None)\n             76 IS_OP                    0\n             78 POP_JUMP_IF_FALSE       42 (to 84)\n             80 LOAD_FAST                6 (expanded_attn_mask)\n             82 JUMP_FORWARD             3 (to 90)\n        >>   84 LOAD_FAST                6 (expanded_attn_mask)\n             86 LOAD_FAST                5 (combined_attention_mask)\n             88 BINARY_ADD\n\n903     >>   90 STORE_FAST               5 (combined_attention_mask)\n\n907     >>   92 LOAD_FAST                5 (combined_attention_mask)\n             94 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 125 \n128           0 LOAD_FAST                1 (input_ids)\n              2 LOAD_ATTR                0 (shape)\n              4 LOAD_CONST               1 (None)\n              6 LOAD_CONST               2 (2)\n              8 BUILD_SLICE              2\n             10 BINARY_SUBSCR\n             12 UNPACK_SEQUENCE          2\n             14 STORE_FAST               3 (bsz)\n             16 STORE_FAST               4 (seq_len)\n\n129          18 LOAD_GLOBAL              1 (torch)\n             20 LOAD_ATTR                2 (arange)\n\n130          22 LOAD_FAST                2 (past_key_values_length)\n             24 LOAD_FAST                2 (past_key_values_length)\n             26 LOAD_FAST                4 (seq_len)\n             28 BINARY_ADD\n             30 LOAD_GLOBAL              1 (torch)\n             32 LOAD_ATTR                3 (long)\n             34 LOAD_FAST                0 (self)\n             36 LOAD_ATTR                4 (weight)\n             38 LOAD_ATTR                5 (device)\n\n129          40 LOAD_CONST               3 (('dtype', 'device'))\n             42 CALL_FUNCTION_KW         4\n\n131          44 LOAD_METHOD              6 (expand)\n             46 LOAD_FAST                3 (bsz)\n             48 LOAD_CONST               4 (-1)\n             50 CALL_METHOD              2\n\n129          52 STORE_FAST               5 (positions)\n\n133          54 LOAD_GLOBAL              7 (super)\n             56 CALL_FUNCTION            0\n             58 LOAD_METHOD              8 (forward)\n             60 LOAD_FAST                5 (positions)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                9 (offset)\n             66 BINARY_ADD\n             68 CALL_METHOD              1\n             70 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 388 \n418           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n422           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n424          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n425          32 LOAD_FAST                1 (hidden_states)\n\n426          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          36 LOAD_FAST                2 (attention_mask)\n\n428          38 LOAD_FAST                5 (layer_head_mask)\n\n429          40 LOAD_FAST                8 (output_attentions)\n\n424          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n431          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n432          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n433          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n436          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n437          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n438         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n439         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n442         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n444         142 LOAD_FAST                1 (hidden_states)\n\n445         144 LOAD_FAST                3 (encoder_hidden_states)\n\n446         146 LOAD_FAST                4 (encoder_attention_mask)\n\n447         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         152 LOAD_FAST                8 (output_attentions)\n\n443         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n452         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n453         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n456         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n459     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n460         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n461         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n462         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n463         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n464         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n465         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n467         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n469         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n470         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n472     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n473         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n475     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 388 \n418           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n422           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n424          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n425          32 LOAD_FAST                1 (hidden_states)\n\n426          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          36 LOAD_FAST                2 (attention_mask)\n\n428          38 LOAD_FAST                5 (layer_head_mask)\n\n429          40 LOAD_FAST                8 (output_attentions)\n\n424          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n431          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n432          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n433          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n436          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n437          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n438         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n439         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n442         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n444         142 LOAD_FAST                1 (hidden_states)\n\n445         144 LOAD_FAST                3 (encoder_hidden_states)\n\n446         146 LOAD_FAST                4 (encoder_attention_mask)\n\n447         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         152 LOAD_FAST                8 (output_attentions)\n\n443         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n452         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n453         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n456         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n459     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n460         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n461         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n462         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n463         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n464         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n465         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n467         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n469         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n470         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n472     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n473         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n475     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 388 \n418           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n422           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n424          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n425          32 LOAD_FAST                1 (hidden_states)\n\n426          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          36 LOAD_FAST                2 (attention_mask)\n\n428          38 LOAD_FAST                5 (layer_head_mask)\n\n429          40 LOAD_FAST                8 (output_attentions)\n\n424          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n431          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n432          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n433          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n436          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n437          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n438         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n439         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n442         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n444         142 LOAD_FAST                1 (hidden_states)\n\n445         144 LOAD_FAST                3 (encoder_hidden_states)\n\n446         146 LOAD_FAST                4 (encoder_attention_mask)\n\n447         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         152 LOAD_FAST                8 (output_attentions)\n\n443         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n452         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n453         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n456         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n459     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n460         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n461         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n462         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n463         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n464         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n465         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n467         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n469         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n470         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n472     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n473         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n475     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 388 \n418           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n422           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n424          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n425          32 LOAD_FAST                1 (hidden_states)\n\n426          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          36 LOAD_FAST                2 (attention_mask)\n\n428          38 LOAD_FAST                5 (layer_head_mask)\n\n429          40 LOAD_FAST                8 (output_attentions)\n\n424          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n431          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n432          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n433          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n436          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n437          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n438         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n439         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n442         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n444         142 LOAD_FAST                1 (hidden_states)\n\n445         144 LOAD_FAST                3 (encoder_hidden_states)\n\n446         146 LOAD_FAST                4 (encoder_attention_mask)\n\n447         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         152 LOAD_FAST                8 (output_attentions)\n\n443         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n452         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n453         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n456         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n459     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n460         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n461         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n462         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n463         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n464         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n465         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n467         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n469         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n470         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n472     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n473         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n475     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 388 \n418           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n422           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n424          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n425          32 LOAD_FAST                1 (hidden_states)\n\n426          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          36 LOAD_FAST                2 (attention_mask)\n\n428          38 LOAD_FAST                5 (layer_head_mask)\n\n429          40 LOAD_FAST                8 (output_attentions)\n\n424          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n431          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n432          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n433          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n436          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n437          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n438         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n439         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n442         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n444         142 LOAD_FAST                1 (hidden_states)\n\n445         144 LOAD_FAST                3 (encoder_hidden_states)\n\n446         146 LOAD_FAST                4 (encoder_attention_mask)\n\n447         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         152 LOAD_FAST                8 (output_attentions)\n\n443         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n452         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n453         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n456         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n459     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n460         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n461         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n462         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n463         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n464         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n465         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n467         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n469         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n470         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n472     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n473         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n475     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 388 \n418           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n422           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n424          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n425          32 LOAD_FAST                1 (hidden_states)\n\n426          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          36 LOAD_FAST                2 (attention_mask)\n\n428          38 LOAD_FAST                5 (layer_head_mask)\n\n429          40 LOAD_FAST                8 (output_attentions)\n\n424          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n431          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n432          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n433          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n436          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n437          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n438         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n439         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n442         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n444         142 LOAD_FAST                1 (hidden_states)\n\n445         144 LOAD_FAST                3 (encoder_hidden_states)\n\n446         146 LOAD_FAST                4 (encoder_attention_mask)\n\n447         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         152 LOAD_FAST                8 (output_attentions)\n\n443         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n452         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n453         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n456         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n459     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n460         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n461         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n462         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n463         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n464         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n465         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n467         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n469         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n470         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n472     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n473         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n475     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (past_key_values)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (past_key_values)\n\n  5          12 LOAD_FAST                3 (hidden_states)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (hidden_states)\n\n  6          18 LOAD_FAST                4 (attentions)\n             20 LOAD_FAST                0 (self)\n             22 STORE_ATTR               3 (attentions)\n\n  7          24 LOAD_FAST                5 (cross_attentions)\n             26 LOAD_FAST                0 (self)\n             28 STORE_ATTR               4 (cross_attentions)\n\n  8          30 LOAD_FAST                0 (self)\n             32 LOAD_METHOD              5 (__post_init__)\n             34 CALL_METHOD              0\n             36 POP_TOP\n             38 LOAD_CONST               0 (None)\n             40 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 3 \n  3           0 JUMP_ABSOLUTE            4 (to 8)\n              2 LOAD_FAST                5 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n\n  4     >>    8 LOAD_FAST                1 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5          14 LOAD_FAST                2 (hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (hidden_states)\n\n  6          20 LOAD_FAST                3 (attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (attentions)\n\n  7          26 LOAD_FAST                4 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                5 (__post_init__)\n             36 CALL_FUNCTION            0\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 1697 \n1697           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           49 (to 98)\n               4 LOAD_FAST               13 (output_attentions)\n               6 LOAD_CONST               1 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST               13 (output_attentions)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (output_attentions)\n         >>   22 STORE_FAST              13 (output_attentions)\n              24 LOAD_FAST               14 (output_hidden_states)\n              26 LOAD_CONST               1 (None)\n              28 IS_OP                    1\n              30 POP_JUMP_IF_FALSE       18 (to 36)\n              32 LOAD_FAST               14 (output_hidden_states)\n              34 JUMP_FORWARD             3 (to 42)\n         >>   36 LOAD_FAST                1 (self)\n              38 LOAD_ATTR                0 (config)\n              40 LOAD_ATTR                2 (output_hidden_states)\n         >>   42 STORE_FAST              14 (output_hidden_states)\n              44 LOAD_FAST                3 (return_dict)\n              46 LOAD_CONST               1 (None)\n              48 IS_OP                    1\n              50 POP_JUMP_IF_FALSE       28 (to 56)\n              52 LOAD_FAST                3 (return_dict)\n              54 JUMP_FORWARD             3 (to 62)\n         >>   56 LOAD_FAST                1 (self)\n              58 LOAD_ATTR                0 (config)\n              60 LOAD_ATTR                3 (use_return_dict)\n         >>   62 STORE_FAST               3 (return_dict)\n              64 LOAD_FAST                1 (self)\n              66 LOAD_ATTR                4 (model)\n              68 LOAD_ATTR                5 (decoder)\n              70 LOAD_FAST                4 (input_ids)\n              72 LOAD_FAST                5 (attention_mask)\n              74 LOAD_FAST                6 (encoder_hidden_states)\n              76 LOAD_FAST                7 (encoder_attention_mask)\n              78 LOAD_FAST                8 (head_mask)\n              80 LOAD_FAST                9 (cross_attn_head_mask)\n              82 LOAD_FAST               10 (past_key_values)\n              84 LOAD_FAST               11 (inputs_embeds)\n              86 LOAD_FAST               12 (use_cache)\n              88 LOAD_FAST               13 (output_attentions)\n              90 LOAD_FAST               14 (output_hidden_states)\n              92 LOAD_FAST                3 (return_dict)\n              94 LOAD_CONST               2 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              96 CALL_FUNCTION_KW        12\n         >>   98 STORE_FAST              15 (outputs)\n\n1712         100 LOAD_FAST                1 (self)\n             102 LOAD_ATTR                6 (lm_head)\n             104 LOAD_FAST               15 (outputs)\n             106 LOAD_CONST               3 (0)\n             108 BINARY_SUBSCR\n             110 CALL_FUNCTION            1\n             112 STORE_FAST              16 (logits)\n\n1714         114 LOAD_CONST               1 (None)\n             116 STORE_FAST              17 (loss)\n\n1715         118 LOAD_FAST                2 (labels)\n             120 LOAD_CONST               1 (None)\n             122 IS_OP                    1\n             124 POP_JUMP_IF_FALSE       86 (to 172)\n\n1716         126 LOAD_FAST                2 (labels)\n             128 LOAD_ATTR                7 (to)\n             130 LOAD_FAST               16 (logits)\n             132 LOAD_ATTR                8 (device)\n             134 CALL_FUNCTION            1\n             136 STORE_FAST               2 (labels)\n\n1717         138 LOAD_GLOBAL              9 (CrossEntropyLoss)\n             140 CALL_FUNCTION            0\n             142 STORE_FAST              18 (loss_fct)\n\n1718         144 LOAD_FAST               18 (loss_fct)\n             146 LOAD_FAST               16 (logits)\n             148 LOAD_ATTR               10 (view)\n             150 LOAD_CONST               4 (-1)\n             152 LOAD_FAST                1 (self)\n             154 LOAD_ATTR                0 (config)\n             156 LOAD_ATTR               11 (vocab_size)\n             158 CALL_FUNCTION            2\n             160 LOAD_FAST                2 (labels)\n             162 LOAD_ATTR               10 (view)\n             164 LOAD_CONST               4 (-1)\n             166 CALL_FUNCTION            1\n             168 CALL_FUNCTION            2\n             170 STORE_FAST              17 (loss)\n\n1720     >>  172 LOAD_FAST                3 (return_dict)\n             174 POP_JUMP_IF_TRUE       108 (to 216)\n\n1721         176 LOAD_FAST               16 (logits)\n             178 BUILD_TUPLE              1\n             180 LOAD_FAST               15 (outputs)\n             182 LOAD_CONST               5 (1)\n             184 LOAD_CONST               1 (None)\n             186 BUILD_SLICE              2\n             188 BINARY_SUBSCR\n             190 BINARY_ADD\n             192 STORE_FAST              19 (output)\n\n1722         194 LOAD_FAST               17 (loss)\n             196 LOAD_CONST               1 (None)\n             198 IS_OP                    1\n             200 POP_JUMP_IF_FALSE      106 (to 212)\n             202 LOAD_FAST               17 (loss)\n             204 BUILD_TUPLE              1\n             206 LOAD_FAST               19 (output)\n             208 BINARY_ADD\n             210 RETURN_VALUE\n         >>  212 LOAD_FAST               19 (output)\n             214 RETURN_VALUE\n\n1724     >>  216 LOAD_GLOBAL             12 (CausalLMOutputWithCrossAttentions)\n\n1725         218 LOAD_FAST               17 (loss)\n\n1726         220 LOAD_FAST               16 (logits)\n\n1727         222 LOAD_FAST               15 (outputs)\n             224 LOAD_ATTR               13 (past_key_values)\n\n1728         226 LOAD_FAST               15 (outputs)\n             228 LOAD_ATTR               14 (hidden_states)\n\n1729         230 LOAD_FAST               15 (outputs)\n             232 LOAD_ATTR               15 (attentions)\n\n1730         234 LOAD_FAST               15 (outputs)\n             236 LOAD_ATTR               16 (cross_attentions)\n\n1724         238 LOAD_CONST               6 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n             240 CALL_FUNCTION_KW         6\n             242 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 557 \n557           0 LOAD_FAST                0 (___stack0)\n              2 CALL_FUNCTION            0\n              4 SETUP_WITH              10 (to 26)\n              6 POP_TOP\n              8 LOAD_FAST                1 (___stack1)\n             10 JUMP_ABSOLUTE           44 (to 88)\n             12 POP_BLOCK\n             14 LOAD_CONST               0 (None)\n             16 DUP_TOP\n             18 DUP_TOP\n             20 CALL_FUNCTION            3\n             22 POP_TOP\n             24 JUMP_FORWARD             8 (to 42)\n        >>   26 WITH_EXCEPT_START\n             28 POP_JUMP_IF_TRUE        16 (to 32)\n             30 RERAISE                  0\n        >>   32 POP_TOP\n             34 POP_TOP\n             36 POP_TOP\n             38 POP_EXCEPT\n             40 POP_TOP\n        >>   42 NOP\n             44 LOAD_CONST               0 (None)\n             46 RAISE_VARARGS            1\n             48 LOAD_GLOBAL              0 (clone_inputs)\n             50 LOAD_FAST                6 (inputs)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (cloned_inputs)\n             56 LOAD_FAST                2 (self)\n             58 LOAD_ATTR                1 (optimizer_zero_grad)\n             60 LOAD_FAST                3 (mod)\n             62 CALL_FUNCTION            1\n             64 POP_TOP\n             66 LOAD_FAST                2 (self)\n             68 LOAD_ATTR                2 (autocast)\n             70 CALL_FUNCTION            0\n             72 SETUP_WITH              20 (to 114)\n             74 POP_TOP\n             76 LOAD_FAST                3 (mod)\n             78 LOAD_CONST               1 (())\n             80 BUILD_MAP                0\n             82 LOAD_FAST                5 (cloned_inputs)\n             84 DICT_MERGE               1\n             86 CALL_FUNCTION_EX         1\n        >>   88 STORE_FAST               7 (pred)\n\n558          90 LOAD_FAST                2 (self)\n             92 LOAD_ATTR                3 (compute_loss)\n             94 LOAD_FAST                7 (pred)\n             96 CALL_FUNCTION            1\n             98 STORE_FAST               8 (loss)\n            100 POP_BLOCK\n\n556         102 LOAD_CONST               0 (None)\n            104 DUP_TOP\n            106 DUP_TOP\n            108 CALL_FUNCTION            3\n            110 POP_TOP\n            112 JUMP_FORWARD             8 (to 130)\n        >>  114 WITH_EXCEPT_START\n            116 POP_JUMP_IF_TRUE        60 (to 120)\n            118 RERAISE                  1\n        >>  120 POP_TOP\n            122 POP_TOP\n            124 POP_TOP\n            126 POP_EXCEPT\n            128 POP_TOP\n\n559     >>  130 LOAD_FAST                2 (self)\n            132 LOAD_ATTR                4 (grad_scaler)\n            134 LOAD_ATTR                5 (scale)\n            136 LOAD_FAST                8 (loss)\n            138 CALL_FUNCTION            1\n            140 LOAD_ATTR                6 (backward)\n            142 CALL_FUNCTION            0\n            144 POP_TOP\n\n560         146 LOAD_FAST                2 (self)\n            148 LOAD_ATTR                7 (optimizer_step)\n            150 CALL_FUNCTION            0\n            152 POP_TOP\n\n561         154 LOAD_FAST                4 (collect_outputs)\n            156 POP_JUMP_IF_FALSE       86 (to 172)\n\n562         158 LOAD_GLOBAL              8 (collect_results)\n            160 LOAD_FAST                3 (mod)\n            162 LOAD_FAST                7 (pred)\n            164 LOAD_FAST                8 (loss)\n            166 LOAD_FAST                5 (cloned_inputs)\n            168 CALL_FUNCTION            4\n            170 RETURN_VALUE\n\n563     >>  172 LOAD_CONST               0 (None)\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 1290 \n1321           0 LOAD_FAST               16 (return_dict)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               16 (return_dict)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (use_return_dict)\n         >>   18 STORE_FAST              16 (return_dict)\n\n1323          20 LOAD_FAST               12 (labels)\n              22 LOAD_CONST               1 (None)\n              24 IS_OP                    1\n              26 POP_JUMP_IF_FALSE       29 (to 58)\n\n1324          28 LOAD_FAST                3 (decoder_input_ids)\n              30 LOAD_CONST               1 (None)\n              32 IS_OP                    0\n              34 POP_JUMP_IF_FALSE       29 (to 58)\n              36 LOAD_FAST               11 (decoder_inputs_embeds)\n              38 LOAD_CONST               1 (None)\n              40 IS_OP                    0\n              42 POP_JUMP_IF_FALSE       29 (to 58)\n\n1325          44 LOAD_GLOBAL              2 (shift_tokens_right)\n              46 LOAD_FAST               12 (labels)\n              48 LOAD_FAST                0 (self)\n              50 LOAD_ATTR                0 (config)\n              52 LOAD_ATTR                3 (pad_token_id)\n              54 CALL_FUNCTION            2\n              56 STORE_FAST               3 (decoder_input_ids)\n\n1327     >>   58 LOAD_FAST                0 (self)\n              60 LOAD_ATTR                4 (model)\n\n1328          62 LOAD_FAST                1 (input_ids)\n\n1329          64 LOAD_FAST                2 (attention_mask)\n\n1330          66 LOAD_FAST                3 (decoder_input_ids)\n\n1331          68 LOAD_FAST                8 (encoder_outputs)\n\n1332          70 LOAD_FAST                4 (decoder_attention_mask)\n\n1333          72 LOAD_FAST                5 (head_mask)\n\n1334          74 LOAD_FAST                6 (decoder_head_mask)\n\n1335          76 LOAD_FAST                7 (cross_attn_head_mask)\n\n1336          78 LOAD_FAST                9 (past_key_values)\n\n1337          80 LOAD_FAST               10 (inputs_embeds)\n\n1338          82 LOAD_FAST               11 (decoder_inputs_embeds)\n\n1339          84 LOAD_FAST               13 (use_cache)\n\n1340          86 LOAD_FAST               14 (output_attentions)\n\n1341          88 LOAD_FAST               15 (output_hidden_states)\n\n1342          90 LOAD_FAST               16 (return_dict)\n\n1327          92 LOAD_CONST               2 (('attention_mask', 'decoder_input_ids', 'encoder_outputs', 'decoder_attention_mask', 'head_mask', 'decoder_head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'decoder_inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              94 CALL_FUNCTION_KW        15\n              96 STORE_FAST              17 (outputs)\n\n1344          98 LOAD_FAST                0 (self)\n             100 LOAD_METHOD              5 (lm_head)\n             102 LOAD_FAST               17 (outputs)\n             104 LOAD_CONST               3 (0)\n             106 BINARY_SUBSCR\n             108 CALL_METHOD              1\n             110 STORE_FAST              18 (lm_logits)\n\n1345         112 LOAD_FAST               18 (lm_logits)\n             114 LOAD_FAST                0 (self)\n             116 LOAD_ATTR                6 (final_logits_bias)\n             118 LOAD_METHOD              7 (to)\n             120 LOAD_FAST               18 (lm_logits)\n             122 LOAD_ATTR                8 (device)\n             124 CALL_METHOD              1\n             126 BINARY_ADD\n             128 STORE_FAST              18 (lm_logits)\n\n1347         130 LOAD_CONST               1 (None)\n             132 STORE_FAST              19 (masked_lm_loss)\n\n1348         134 LOAD_FAST               12 (labels)\n             136 LOAD_CONST               1 (None)\n             138 IS_OP                    1\n             140 POP_JUMP_IF_FALSE       88 (to 176)\n\n1349         142 LOAD_GLOBAL              9 (CrossEntropyLoss)\n             144 CALL_FUNCTION            0\n             146 STORE_FAST              20 (loss_fct)\n\n1350         148 LOAD_FAST               20 (loss_fct)\n             150 LOAD_FAST               18 (lm_logits)\n             152 LOAD_METHOD             10 (view)\n             154 LOAD_CONST               4 (-1)\n             156 LOAD_FAST                0 (self)\n             158 LOAD_ATTR                0 (config)\n             160 LOAD_ATTR               11 (vocab_size)\n             162 CALL_METHOD              2\n             164 LOAD_FAST               12 (labels)\n             166 LOAD_METHOD             10 (view)\n             168 LOAD_CONST               4 (-1)\n             170 CALL_METHOD              1\n             172 CALL_FUNCTION            2\n             174 STORE_FAST              19 (masked_lm_loss)\n\n1352     >>  176 LOAD_FAST               16 (return_dict)\n             178 POP_JUMP_IF_TRUE       110 (to 220)\n\n1353         180 LOAD_FAST               18 (lm_logits)\n             182 BUILD_TUPLE              1\n             184 LOAD_FAST               17 (outputs)\n             186 LOAD_CONST               5 (1)\n             188 LOAD_CONST               1 (None)\n             190 BUILD_SLICE              2\n             192 BINARY_SUBSCR\n             194 BINARY_ADD\n             196 STORE_FAST              21 (output)\n\n1354         198 LOAD_FAST               19 (masked_lm_loss)\n             200 LOAD_CONST               1 (None)\n             202 IS_OP                    1\n             204 POP_JUMP_IF_FALSE      108 (to 216)\n             206 LOAD_FAST               19 (masked_lm_loss)\n             208 BUILD_TUPLE              1\n             210 LOAD_FAST               21 (output)\n             212 BINARY_ADD\n             214 RETURN_VALUE\n         >>  216 LOAD_FAST               21 (output)\n             218 RETURN_VALUE\n\n1356     >>  220 LOAD_GLOBAL             12 (Seq2SeqLMOutput)\n\n1357         222 LOAD_FAST               19 (masked_lm_loss)\n\n1358         224 LOAD_FAST               18 (lm_logits)\n\n1359         226 LOAD_FAST               17 (outputs)\n             228 LOAD_ATTR               13 (past_key_values)\n\n1360         230 LOAD_FAST               17 (outputs)\n             232 LOAD_ATTR               14 (decoder_hidden_states)\n\n1361         234 LOAD_FAST               17 (outputs)\n             236 LOAD_ATTR               15 (decoder_attentions)\n\n1362         238 LOAD_FAST               17 (outputs)\n             240 LOAD_ATTR               16 (cross_attentions)\n\n1363         242 LOAD_FAST               17 (outputs)\n             244 LOAD_ATTR               17 (encoder_last_hidden_state)\n\n1364         246 LOAD_FAST               17 (outputs)\n             248 LOAD_ATTR               18 (encoder_hidden_states)\n\n1365         250 LOAD_FAST               17 (outputs)\n             252 LOAD_ATTR               19 (encoder_attentions)\n\n1356         254 LOAD_CONST               6 (('loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             256 CALL_FUNCTION_KW         9\n             258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 1162 \n1186           0 LOAD_FAST               13 (output_attentions)\n               2 LOAD_CONST               0 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               13 (output_attentions)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (output_attentions)\n         >>   18 STORE_FAST              13 (output_attentions)\n\n1188          20 LOAD_FAST               14 (output_hidden_states)\n              22 LOAD_CONST               0 (None)\n              24 IS_OP                    1\n              26 POP_JUMP_IF_FALSE       16 (to 32)\n              28 LOAD_FAST               14 (output_hidden_states)\n              30 JUMP_FORWARD             3 (to 38)\n         >>   32 LOAD_FAST                0 (self)\n              34 LOAD_ATTR                0 (config)\n              36 LOAD_ATTR                2 (output_hidden_states)\n\n1187     >>   38 STORE_FAST              14 (output_hidden_states)\n\n1190          40 LOAD_FAST               12 (use_cache)\n              42 LOAD_CONST               0 (None)\n              44 IS_OP                    1\n              46 POP_JUMP_IF_FALSE       26 (to 52)\n              48 LOAD_FAST               12 (use_cache)\n              50 JUMP_FORWARD             3 (to 58)\n         >>   52 LOAD_FAST                0 (self)\n              54 LOAD_ATTR                0 (config)\n              56 LOAD_ATTR                3 (use_cache)\n         >>   58 STORE_FAST              12 (use_cache)\n\n1191          60 LOAD_FAST               15 (return_dict)\n              62 LOAD_CONST               0 (None)\n              64 IS_OP                    1\n              66 POP_JUMP_IF_FALSE       36 (to 72)\n              68 LOAD_FAST               15 (return_dict)\n              70 JUMP_FORWARD             3 (to 78)\n         >>   72 LOAD_FAST                0 (self)\n              74 LOAD_ATTR                0 (config)\n              76 LOAD_ATTR                4 (use_return_dict)\n         >>   78 STORE_FAST              15 (return_dict)\n\n1195          80 LOAD_FAST                3 (decoder_input_ids)\n              82 LOAD_CONST               0 (None)\n              84 IS_OP                    0\n              86 POP_JUMP_IF_FALSE       55 (to 110)\n              88 LOAD_FAST               11 (decoder_inputs_embeds)\n              90 LOAD_CONST               0 (None)\n              92 IS_OP                    0\n              94 POP_JUMP_IF_FALSE       55 (to 110)\n\n1196          96 LOAD_GLOBAL              5 (shift_tokens_right)\n              98 LOAD_FAST                1 (input_ids)\n             100 LOAD_FAST                0 (self)\n             102 LOAD_ATTR                0 (config)\n             104 LOAD_ATTR                6 (pad_token_id)\n             106 CALL_FUNCTION            2\n             108 STORE_FAST               3 (decoder_input_ids)\n\n1198     >>  110 LOAD_FAST                8 (encoder_outputs)\n             112 LOAD_CONST               0 (None)\n             114 IS_OP                    0\n             116 POP_JUMP_IF_FALSE       72 (to 144)\n\n1199         118 LOAD_FAST                0 (self)\n             120 LOAD_ATTR                7 (encoder)\n\n1200         122 LOAD_FAST                1 (input_ids)\n\n1201         124 LOAD_FAST                2 (attention_mask)\n\n1202         126 LOAD_FAST                5 (head_mask)\n\n1203         128 LOAD_FAST               10 (inputs_embeds)\n\n1204         130 LOAD_FAST               13 (output_attentions)\n\n1205         132 LOAD_FAST               14 (output_hidden_states)\n\n1206         134 LOAD_FAST               15 (return_dict)\n\n1199         136 LOAD_CONST               1 (('input_ids', 'attention_mask', 'head_mask', 'inputs_embeds', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             138 CALL_FUNCTION_KW         7\n             140 STORE_FAST               8 (encoder_outputs)\n             142 JUMP_FORWARD            36 (to 216)\n\n1209     >>  144 LOAD_FAST               15 (return_dict)\n             146 POP_JUMP_IF_FALSE      108 (to 216)\n             148 LOAD_GLOBAL              8 (isinstance)\n             150 LOAD_FAST                8 (encoder_outputs)\n             152 LOAD_GLOBAL              9 (BaseModelOutput)\n             154 CALL_FUNCTION            2\n             156 POP_JUMP_IF_TRUE       108 (to 216)\n\n1210         158 LOAD_GLOBAL              9 (BaseModelOutput)\n\n1211         160 LOAD_FAST                8 (encoder_outputs)\n             162 LOAD_CONST               2 (0)\n             164 BINARY_SUBSCR\n\n1212         166 LOAD_GLOBAL             10 (len)\n             168 LOAD_FAST                8 (encoder_outputs)\n             170 CALL_FUNCTION            1\n             172 LOAD_CONST               3 (1)\n             174 COMPARE_OP               4 (>)\n             176 POP_JUMP_IF_FALSE       93 (to 186)\n             178 LOAD_FAST                8 (encoder_outputs)\n             180 LOAD_CONST               3 (1)\n             182 BINARY_SUBSCR\n             184 JUMP_FORWARD             1 (to 188)\n         >>  186 LOAD_CONST               0 (None)\n\n1213     >>  188 LOAD_GLOBAL             10 (len)\n             190 LOAD_FAST                8 (encoder_outputs)\n             192 CALL_FUNCTION            1\n             194 LOAD_CONST               4 (2)\n             196 COMPARE_OP               4 (>)\n             198 POP_JUMP_IF_FALSE      104 (to 208)\n             200 LOAD_FAST                8 (encoder_outputs)\n             202 LOAD_CONST               4 (2)\n             204 BINARY_SUBSCR\n             206 JUMP_FORWARD             1 (to 210)\n         >>  208 LOAD_CONST               0 (None)\n\n1210     >>  210 LOAD_CONST               5 (('last_hidden_state', 'hidden_states', 'attentions'))\n             212 CALL_FUNCTION_KW         3\n             214 STORE_FAST               8 (encoder_outputs)\n\n1217     >>  216 LOAD_FAST                0 (self)\n             218 LOAD_ATTR               11 (decoder)\n\n1218         220 LOAD_FAST                3 (decoder_input_ids)\n\n1219         222 LOAD_FAST                4 (decoder_attention_mask)\n\n1220         224 LOAD_FAST                8 (encoder_outputs)\n             226 LOAD_CONST               2 (0)\n             228 BINARY_SUBSCR\n\n1221         230 LOAD_FAST                2 (attention_mask)\n\n1222         232 LOAD_FAST                6 (decoder_head_mask)\n\n1223         234 LOAD_FAST                7 (cross_attn_head_mask)\n\n1224         236 LOAD_FAST                9 (past_key_values)\n\n1225         238 LOAD_FAST               11 (decoder_inputs_embeds)\n\n1226         240 LOAD_FAST               12 (use_cache)\n\n1227         242 LOAD_FAST               13 (output_attentions)\n\n1228         244 LOAD_FAST               14 (output_hidden_states)\n\n1229         246 LOAD_FAST               15 (return_dict)\n\n1217         248 LOAD_CONST               6 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             250 CALL_FUNCTION_KW        12\n             252 STORE_FAST              16 (decoder_outputs)\n\n1232         254 LOAD_FAST               15 (return_dict)\n             256 POP_JUMP_IF_TRUE       133 (to 266)\n\n1233         258 LOAD_FAST               16 (decoder_outputs)\n             260 LOAD_FAST                8 (encoder_outputs)\n             262 BINARY_ADD\n             264 RETURN_VALUE\n\n1235     >>  266 LOAD_GLOBAL             12 (Seq2SeqModelOutput)\n\n1236         268 LOAD_FAST               16 (decoder_outputs)\n             270 LOAD_ATTR               13 (last_hidden_state)\n\n1237         272 LOAD_FAST               16 (decoder_outputs)\n             274 LOAD_ATTR               14 (past_key_values)\n\n1238         276 LOAD_FAST               16 (decoder_outputs)\n             278 LOAD_ATTR               15 (hidden_states)\n\n1239         280 LOAD_FAST               16 (decoder_outputs)\n             282 LOAD_ATTR               16 (attentions)\n\n1240         284 LOAD_FAST               16 (decoder_outputs)\n             286 LOAD_ATTR               17 (cross_attentions)\n\n1241         288 LOAD_FAST                8 (encoder_outputs)\n             290 LOAD_ATTR               13 (last_hidden_state)\n\n1242         292 LOAD_FAST                8 (encoder_outputs)\n             294 LOAD_ATTR               15 (hidden_states)\n\n1243         296 LOAD_FAST                8 (encoder_outputs)\n             298 LOAD_ATTR               16 (attentions)\n\n1235         300 LOAD_CONST               7 (('last_hidden_state', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             302 CALL_FUNCTION_KW         8\n             304 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 125 \n128           0 LOAD_FAST                1 (input_ids)\n              2 LOAD_ATTR                0 (shape)\n              4 LOAD_CONST               1 (None)\n              6 LOAD_CONST               2 (2)\n              8 BUILD_SLICE              2\n             10 BINARY_SUBSCR\n             12 UNPACK_SEQUENCE          2\n             14 STORE_FAST               3 (bsz)\n             16 STORE_FAST               4 (seq_len)\n\n129          18 LOAD_GLOBAL              1 (torch)\n             20 LOAD_ATTR                2 (arange)\n\n130          22 LOAD_FAST                2 (past_key_values_length)\n             24 LOAD_FAST                2 (past_key_values_length)\n             26 LOAD_FAST                4 (seq_len)\n             28 BINARY_ADD\n             30 LOAD_GLOBAL              1 (torch)\n             32 LOAD_ATTR                3 (long)\n             34 LOAD_FAST                0 (self)\n             36 LOAD_ATTR                4 (weight)\n             38 LOAD_ATTR                5 (device)\n\n129          40 LOAD_CONST               3 (('dtype', 'device'))\n             42 CALL_FUNCTION_KW         4\n\n131          44 LOAD_METHOD              6 (expand)\n             46 LOAD_FAST                3 (bsz)\n             48 LOAD_CONST               4 (-1)\n             50 CALL_METHOD              2\n\n129          52 STORE_FAST               5 (positions)\n\n133          54 LOAD_GLOBAL              7 (super)\n             56 CALL_FUNCTION            0\n             58 LOAD_METHOD              8 (forward)\n             60 LOAD_FAST                5 (positions)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                9 (offset)\n             66 BINARY_ADD\n             68 CALL_METHOD              1\n             70 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 309 \n327           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n328           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n329           8 LOAD_FAST                1 (hidden_states)\n\n330          10 LOAD_FAST                2 (attention_mask)\n\n331          12 LOAD_FAST                3 (layer_head_mask)\n\n332          14 LOAD_FAST                4 (output_attentions)\n\n328          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n334          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n335          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n336          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n339          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n340          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n341         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n342         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n343         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n344         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n346         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n347         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n346         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n347         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n346         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n349     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n350         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n352     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n354         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n355         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n357     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 309 \n327           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n328           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n329           8 LOAD_FAST                1 (hidden_states)\n\n330          10 LOAD_FAST                2 (attention_mask)\n\n331          12 LOAD_FAST                3 (layer_head_mask)\n\n332          14 LOAD_FAST                4 (output_attentions)\n\n328          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n334          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n335          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n336          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n339          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n340          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n341         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n342         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n343         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n344         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n346         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n347         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n346         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n347         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n346         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n349     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n350         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n352     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n354         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n355         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n357     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 309 \n327           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n328           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n329           8 LOAD_FAST                1 (hidden_states)\n\n330          10 LOAD_FAST                2 (attention_mask)\n\n331          12 LOAD_FAST                3 (layer_head_mask)\n\n332          14 LOAD_FAST                4 (output_attentions)\n\n328          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n334          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n335          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n336          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n339          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n340          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n341         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n342         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n343         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n344         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n346         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n347         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n346         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n347         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n346         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n349     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n350         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n352     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n354         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n355         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n357     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 309 \n327           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n328           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n329           8 LOAD_FAST                1 (hidden_states)\n\n330          10 LOAD_FAST                2 (attention_mask)\n\n331          12 LOAD_FAST                3 (layer_head_mask)\n\n332          14 LOAD_FAST                4 (output_attentions)\n\n328          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n334          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n335          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n336          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n339          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n340          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n341         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n342         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n343         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n344         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n346         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n347         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n346         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n347         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n346         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n349     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n350         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n352     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n354         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n355         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n357     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 309 \n327           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n328           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n329           8 LOAD_FAST                1 (hidden_states)\n\n330          10 LOAD_FAST                2 (attention_mask)\n\n331          12 LOAD_FAST                3 (layer_head_mask)\n\n332          14 LOAD_FAST                4 (output_attentions)\n\n328          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n334          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n335          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n336          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n339          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n340          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n341         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n342         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n343         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n344         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n346         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n347         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n346         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n347         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n346         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n349     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n350         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n352     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n354         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n355         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n357     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 309 \n327           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n328           4 LOAD_FAST                0 (self)\n              6 LOAD_ATTR                0 (self_attn)\n\n329           8 LOAD_FAST                1 (hidden_states)\n\n330          10 LOAD_FAST                2 (attention_mask)\n\n331          12 LOAD_FAST                3 (layer_head_mask)\n\n332          14 LOAD_FAST                4 (output_attentions)\n\n328          16 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             18 CALL_FUNCTION_KW         4\n             20 UNPACK_SEQUENCE          3\n             22 STORE_FAST               1 (hidden_states)\n             24 STORE_FAST               6 (attn_weights)\n             26 STORE_FAST               7 (_)\n\n334          28 LOAD_GLOBAL              1 (nn)\n             30 LOAD_ATTR                2 (functional)\n             32 LOAD_ATTR                3 (dropout)\n             34 LOAD_FAST                1 (hidden_states)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                3 (dropout)\n             40 LOAD_FAST                0 (self)\n             42 LOAD_ATTR                4 (training)\n             44 LOAD_CONST               2 (('p', 'training'))\n             46 CALL_FUNCTION_KW         3\n             48 STORE_FAST               1 (hidden_states)\n\n335          50 LOAD_FAST                5 (residual)\n             52 LOAD_FAST                1 (hidden_states)\n             54 BINARY_ADD\n             56 STORE_FAST               1 (hidden_states)\n\n336          58 LOAD_FAST                0 (self)\n             60 LOAD_METHOD              5 (self_attn_layer_norm)\n             62 LOAD_FAST                1 (hidden_states)\n             64 CALL_METHOD              1\n             66 STORE_FAST               1 (hidden_states)\n\n338          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n339          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (activation_fn)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_METHOD              7 (fc1)\n             80 LOAD_FAST                1 (hidden_states)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              1\n             86 STORE_FAST               1 (hidden_states)\n\n340          88 LOAD_GLOBAL              1 (nn)\n             90 LOAD_ATTR                2 (functional)\n             92 LOAD_ATTR                3 (dropout)\n             94 LOAD_FAST                1 (hidden_states)\n             96 LOAD_FAST                0 (self)\n             98 LOAD_ATTR                8 (activation_dropout)\n            100 LOAD_FAST                0 (self)\n            102 LOAD_ATTR                4 (training)\n            104 LOAD_CONST               2 (('p', 'training'))\n            106 CALL_FUNCTION_KW         3\n            108 STORE_FAST               1 (hidden_states)\n\n341         110 LOAD_FAST                0 (self)\n            112 LOAD_METHOD              9 (fc2)\n            114 LOAD_FAST                1 (hidden_states)\n            116 CALL_METHOD              1\n            118 STORE_FAST               1 (hidden_states)\n\n342         120 LOAD_GLOBAL              1 (nn)\n            122 LOAD_ATTR                2 (functional)\n            124 LOAD_ATTR                3 (dropout)\n            126 LOAD_FAST                1 (hidden_states)\n            128 LOAD_FAST                0 (self)\n            130 LOAD_ATTR                3 (dropout)\n            132 LOAD_FAST                0 (self)\n            134 LOAD_ATTR                4 (training)\n            136 LOAD_CONST               2 (('p', 'training'))\n            138 CALL_FUNCTION_KW         3\n            140 STORE_FAST               1 (hidden_states)\n\n343         142 LOAD_FAST                5 (residual)\n            144 LOAD_FAST                1 (hidden_states)\n            146 BINARY_ADD\n            148 STORE_FAST               1 (hidden_states)\n\n344         150 LOAD_FAST                0 (self)\n            152 LOAD_METHOD             10 (final_layer_norm)\n            154 LOAD_FAST                1 (hidden_states)\n            156 CALL_METHOD              1\n            158 STORE_FAST               1 (hidden_states)\n\n346         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n347         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n346         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n347         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n346         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n349     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n350         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n352     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n354         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n355         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n357     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (hidden_states)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (hidden_states)\n\n  5          12 LOAD_FAST                3 (attentions)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (attentions)\n\n  6          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              3 (__post_init__)\n             22 CALL_METHOD              0\n             24 POP_TOP\n             26 LOAD_CONST               0 (None)\n             28 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 1199 \n1199           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           72 (to 144)\n               4 LOAD_FAST               10 (output_attentions)\n               6 LOAD_CONST               0 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST               10 (output_attentions)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (output_attentions)\n         >>   22 STORE_FAST              10 (output_attentions)\n              24 LOAD_FAST               11 (output_hidden_states)\n              26 LOAD_CONST               0 (None)\n              28 IS_OP                    1\n              30 POP_JUMP_IF_FALSE       18 (to 36)\n              32 LOAD_FAST               11 (output_hidden_states)\n              34 JUMP_FORWARD             3 (to 42)\n         >>   36 LOAD_FAST                1 (self)\n              38 LOAD_ATTR                0 (config)\n              40 LOAD_ATTR                2 (output_hidden_states)\n         >>   42 STORE_FAST              11 (output_hidden_states)\n              44 LOAD_FAST                9 (use_cache)\n              46 LOAD_CONST               0 (None)\n              48 IS_OP                    1\n              50 POP_JUMP_IF_FALSE       28 (to 56)\n              52 LOAD_FAST                9 (use_cache)\n              54 JUMP_FORWARD             3 (to 62)\n         >>   56 LOAD_FAST                1 (self)\n              58 LOAD_ATTR                0 (config)\n              60 LOAD_ATTR                3 (use_cache)\n         >>   62 STORE_FAST               9 (use_cache)\n              64 LOAD_FAST               12 (return_dict)\n              66 LOAD_CONST               0 (None)\n              68 IS_OP                    1\n              70 POP_JUMP_IF_FALSE       38 (to 76)\n              72 LOAD_FAST               12 (return_dict)\n              74 JUMP_FORWARD             3 (to 82)\n         >>   76 LOAD_FAST                1 (self)\n              78 LOAD_ATTR                0 (config)\n              80 LOAD_ATTR                4 (use_return_dict)\n         >>   82 STORE_FAST              12 (return_dict)\n              84 LOAD_FAST                3 (decoder_input_ids)\n              86 LOAD_CONST               0 (None)\n              88 IS_OP                    0\n              90 POP_JUMP_IF_FALSE       57 (to 114)\n              92 LOAD_FAST                8 (decoder_inputs_embeds)\n              94 LOAD_CONST               0 (None)\n              96 IS_OP                    0\n              98 POP_JUMP_IF_FALSE       57 (to 114)\n             100 LOAD_GLOBAL              5 (shift_tokens_right)\n             102 LOAD_FAST               13 (input_ids)\n             104 LOAD_FAST                1 (self)\n             106 LOAD_ATTR                0 (config)\n             108 LOAD_ATTR                6 (pad_token_id)\n             110 CALL_FUNCTION            2\n             112 STORE_FAST               3 (decoder_input_ids)\n         >>  114 LOAD_FAST               15 (encoder_outputs)\n             116 LOAD_CONST               0 (None)\n             118 IS_OP                    0\n             120 POP_JUMP_IF_FALSE       74 (to 148)\n             122 LOAD_FAST                1 (self)\n             124 LOAD_ATTR                7 (encoder)\n             126 LOAD_FAST               13 (input_ids)\n             128 LOAD_FAST                2 (attention_mask)\n             130 LOAD_FAST               14 (head_mask)\n             132 LOAD_FAST               16 (inputs_embeds)\n             134 LOAD_FAST               10 (output_attentions)\n             136 LOAD_FAST               11 (output_hidden_states)\n             138 LOAD_FAST               12 (return_dict)\n             140 LOAD_CONST               1 (('input_ids', 'attention_mask', 'head_mask', 'inputs_embeds', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             142 CALL_FUNCTION_KW         7\n         >>  144 STORE_FAST              15 (encoder_outputs)\n             146 JUMP_FORWARD            36 (to 220)\n\n1209     >>  148 LOAD_FAST               12 (return_dict)\n             150 POP_JUMP_IF_FALSE      110 (to 220)\n             152 LOAD_GLOBAL              8 (isinstance)\n             154 LOAD_FAST               15 (encoder_outputs)\n             156 LOAD_GLOBAL              9 (BaseModelOutput)\n             158 CALL_FUNCTION            2\n             160 POP_JUMP_IF_TRUE       110 (to 220)\n\n1210         162 LOAD_GLOBAL              9 (BaseModelOutput)\n\n1211         164 LOAD_FAST               15 (encoder_outputs)\n             166 LOAD_CONST               2 (0)\n             168 BINARY_SUBSCR\n\n1212         170 LOAD_GLOBAL             10 (len)\n             172 LOAD_FAST               15 (encoder_outputs)\n             174 CALL_FUNCTION            1\n             176 LOAD_CONST               3 (1)\n             178 COMPARE_OP               4 (>)\n             180 POP_JUMP_IF_FALSE       95 (to 190)\n             182 LOAD_FAST               15 (encoder_outputs)\n             184 LOAD_CONST               3 (1)\n             186 BINARY_SUBSCR\n             188 JUMP_FORWARD             1 (to 192)\n         >>  190 LOAD_CONST               0 (None)\n\n1213     >>  192 LOAD_GLOBAL             10 (len)\n             194 LOAD_FAST               15 (encoder_outputs)\n             196 CALL_FUNCTION            1\n             198 LOAD_CONST               4 (2)\n             200 COMPARE_OP               4 (>)\n             202 POP_JUMP_IF_FALSE      106 (to 212)\n             204 LOAD_FAST               15 (encoder_outputs)\n             206 LOAD_CONST               4 (2)\n             208 BINARY_SUBSCR\n             210 JUMP_FORWARD             1 (to 214)\n         >>  212 LOAD_CONST               0 (None)\n\n1210     >>  214 LOAD_CONST               5 (('last_hidden_state', 'hidden_states', 'attentions'))\n             216 CALL_FUNCTION_KW         3\n             218 STORE_FAST              15 (encoder_outputs)\n\n1217     >>  220 LOAD_FAST                1 (self)\n             222 LOAD_ATTR               11 (decoder)\n\n1218         224 LOAD_FAST                3 (decoder_input_ids)\n\n1219         226 LOAD_FAST                4 (decoder_attention_mask)\n\n1220         228 LOAD_FAST               15 (encoder_outputs)\n             230 LOAD_CONST               2 (0)\n             232 BINARY_SUBSCR\n\n1221         234 LOAD_FAST                2 (attention_mask)\n\n1222         236 LOAD_FAST                5 (decoder_head_mask)\n\n1223         238 LOAD_FAST                6 (cross_attn_head_mask)\n\n1224         240 LOAD_FAST                7 (past_key_values)\n\n1225         242 LOAD_FAST                8 (decoder_inputs_embeds)\n\n1226         244 LOAD_FAST                9 (use_cache)\n\n1227         246 LOAD_FAST               10 (output_attentions)\n\n1228         248 LOAD_FAST               11 (output_hidden_states)\n\n1229         250 LOAD_FAST               12 (return_dict)\n\n1217         252 LOAD_CONST               6 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             254 CALL_FUNCTION_KW        12\n             256 STORE_FAST              17 (decoder_outputs)\n\n1232         258 LOAD_FAST               12 (return_dict)\n             260 POP_JUMP_IF_TRUE       135 (to 270)\n\n1233         262 LOAD_FAST               17 (decoder_outputs)\n             264 LOAD_FAST               15 (encoder_outputs)\n             266 BINARY_ADD\n             268 RETURN_VALUE\n\n1235     >>  270 LOAD_GLOBAL             12 (Seq2SeqModelOutput)\n\n1236         272 LOAD_FAST               17 (decoder_outputs)\n             274 LOAD_ATTR               13 (last_hidden_state)\n\n1237         276 LOAD_FAST               17 (decoder_outputs)\n             278 LOAD_ATTR               14 (past_key_values)\n\n1238         280 LOAD_FAST               17 (decoder_outputs)\n             282 LOAD_ATTR               15 (hidden_states)\n\n1239         284 LOAD_FAST               17 (decoder_outputs)\n             286 LOAD_ATTR               16 (attentions)\n\n1240         288 LOAD_FAST               17 (decoder_outputs)\n             290 LOAD_ATTR               17 (cross_attentions)\n\n1241         292 LOAD_FAST               15 (encoder_outputs)\n             294 LOAD_ATTR               13 (last_hidden_state)\n\n1242         296 LOAD_FAST               15 (encoder_outputs)\n             298 LOAD_ATTR               15 (hidden_states)\n\n1243         300 LOAD_FAST               15 (encoder_outputs)\n             302 LOAD_ATTR               16 (attentions)\n\n1235         304 LOAD_CONST               7 (('last_hidden_state', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             306 CALL_FUNCTION_KW         8\n             308 RETURN_VALUE\n\n", "ORIGINAL BYTECODE _prepare_decoder_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 886 \n889           0 LOAD_CONST               0 (None)\n              2 STORE_FAST               5 (combined_attention_mask)\n\n890           4 LOAD_FAST                2 (input_shape)\n              6 LOAD_CONST               1 (-1)\n              8 BINARY_SUBSCR\n             10 LOAD_CONST               2 (1)\n             12 COMPARE_OP               4 (>)\n             14 POP_JUMP_IF_FALSE       18 (to 36)\n\n891          16 LOAD_GLOBAL              0 (_make_causal_mask)\n\n892          18 LOAD_FAST                2 (input_shape)\n\n893          20 LOAD_FAST                3 (inputs_embeds)\n             22 LOAD_ATTR                1 (dtype)\n\n894          24 LOAD_FAST                3 (inputs_embeds)\n             26 LOAD_ATTR                2 (device)\n\n895          28 LOAD_FAST                4 (past_key_values_length)\n\n891          30 LOAD_CONST               3 (('device', 'past_key_values_length'))\n             32 CALL_FUNCTION_KW         4\n             34 STORE_FAST               5 (combined_attention_mask)\n\n898     >>   36 LOAD_FAST                1 (attention_mask)\n             38 LOAD_CONST               0 (None)\n             40 IS_OP                    1\n             42 POP_JUMP_IF_FALSE       46 (to 92)\n\n900          44 LOAD_GLOBAL              3 (_expand_mask)\n             46 LOAD_FAST                1 (attention_mask)\n             48 LOAD_FAST                3 (inputs_embeds)\n             50 LOAD_ATTR                1 (dtype)\n             52 LOAD_FAST                2 (input_shape)\n             54 LOAD_CONST               1 (-1)\n             56 BINARY_SUBSCR\n             58 LOAD_CONST               4 (('tgt_len',))\n             60 CALL_FUNCTION_KW         3\n             62 LOAD_METHOD              4 (to)\n\n901          64 LOAD_FAST                3 (inputs_embeds)\n             66 LOAD_ATTR                2 (device)\n\n900          68 CALL_METHOD              1\n             70 STORE_FAST               6 (expanded_attn_mask)\n\n904          72 LOAD_FAST                5 (combined_attention_mask)\n             74 LOAD_CONST               0 (None)\n             76 IS_OP                    0\n             78 POP_JUMP_IF_FALSE       42 (to 84)\n             80 LOAD_FAST                6 (expanded_attn_mask)\n             82 JUMP_FORWARD             3 (to 90)\n        >>   84 LOAD_FAST                6 (expanded_attn_mask)\n             86 LOAD_FAST                5 (combined_attention_mask)\n             88 BINARY_ADD\n\n903     >>   90 STORE_FAST               5 (combined_attention_mask)\n\n907     >>   92 LOAD_FAST                5 (combined_attention_mask)\n             94 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 125 \n128           0 LOAD_FAST                1 (input_ids)\n              2 LOAD_ATTR                0 (shape)\n              4 LOAD_CONST               1 (None)\n              6 LOAD_CONST               2 (2)\n              8 BUILD_SLICE              2\n             10 BINARY_SUBSCR\n             12 UNPACK_SEQUENCE          2\n             14 STORE_FAST               3 (bsz)\n             16 STORE_FAST               4 (seq_len)\n\n129          18 LOAD_GLOBAL              1 (torch)\n             20 LOAD_ATTR                2 (arange)\n\n130          22 LOAD_FAST                2 (past_key_values_length)\n             24 LOAD_FAST                2 (past_key_values_length)\n             26 LOAD_FAST                4 (seq_len)\n             28 BINARY_ADD\n             30 LOAD_GLOBAL              1 (torch)\n             32 LOAD_ATTR                3 (long)\n             34 LOAD_FAST                0 (self)\n             36 LOAD_ATTR                4 (weight)\n             38 LOAD_ATTR                5 (device)\n\n129          40 LOAD_CONST               3 (('dtype', 'device'))\n             42 CALL_FUNCTION_KW         4\n\n131          44 LOAD_METHOD              6 (expand)\n             46 LOAD_FAST                3 (bsz)\n             48 LOAD_CONST               4 (-1)\n             50 CALL_METHOD              2\n\n129          52 STORE_FAST               5 (positions)\n\n133          54 LOAD_GLOBAL              7 (super)\n             56 CALL_FUNCTION            0\n             58 LOAD_METHOD              8 (forward)\n             60 LOAD_FAST                5 (positions)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                9 (offset)\n             66 BINARY_ADD\n             68 CALL_METHOD              1\n             70 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 388 \n418           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n422           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n424          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n425          32 LOAD_FAST                1 (hidden_states)\n\n426          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          36 LOAD_FAST                2 (attention_mask)\n\n428          38 LOAD_FAST                5 (layer_head_mask)\n\n429          40 LOAD_FAST                8 (output_attentions)\n\n424          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n431          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n432          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n433          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n436          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n437          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n438         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n439         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n442         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n444         142 LOAD_FAST                1 (hidden_states)\n\n445         144 LOAD_FAST                3 (encoder_hidden_states)\n\n446         146 LOAD_FAST                4 (encoder_attention_mask)\n\n447         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         152 LOAD_FAST                8 (output_attentions)\n\n443         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n452         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n453         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n456         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n459     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n460         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n461         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n462         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n463         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n464         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n465         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n467         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n469         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n470         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n472     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n473         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n475     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 388 \n418           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n422           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n424          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n425          32 LOAD_FAST                1 (hidden_states)\n\n426          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          36 LOAD_FAST                2 (attention_mask)\n\n428          38 LOAD_FAST                5 (layer_head_mask)\n\n429          40 LOAD_FAST                8 (output_attentions)\n\n424          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n431          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n432          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n433          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n436          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n437          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n438         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n439         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n442         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n444         142 LOAD_FAST                1 (hidden_states)\n\n445         144 LOAD_FAST                3 (encoder_hidden_states)\n\n446         146 LOAD_FAST                4 (encoder_attention_mask)\n\n447         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         152 LOAD_FAST                8 (output_attentions)\n\n443         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n452         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n453         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n456         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n459     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n460         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n461         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n462         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n463         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n464         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n465         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n467         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n469         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n470         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n472     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n473         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n475     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 388 \n418           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n422           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n424          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n425          32 LOAD_FAST                1 (hidden_states)\n\n426          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          36 LOAD_FAST                2 (attention_mask)\n\n428          38 LOAD_FAST                5 (layer_head_mask)\n\n429          40 LOAD_FAST                8 (output_attentions)\n\n424          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n431          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n432          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n433          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n436          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n437          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n438         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n439         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n442         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n444         142 LOAD_FAST                1 (hidden_states)\n\n445         144 LOAD_FAST                3 (encoder_hidden_states)\n\n446         146 LOAD_FAST                4 (encoder_attention_mask)\n\n447         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         152 LOAD_FAST                8 (output_attentions)\n\n443         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n452         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n453         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n456         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n459     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n460         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n461         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n462         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n463         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n464         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n465         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n467         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n469         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n470         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n472     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n473         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n475     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 388 \n418           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n422           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n424          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n425          32 LOAD_FAST                1 (hidden_states)\n\n426          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          36 LOAD_FAST                2 (attention_mask)\n\n428          38 LOAD_FAST                5 (layer_head_mask)\n\n429          40 LOAD_FAST                8 (output_attentions)\n\n424          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n431          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n432          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n433          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n436          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n437          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n438         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n439         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n442         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n444         142 LOAD_FAST                1 (hidden_states)\n\n445         144 LOAD_FAST                3 (encoder_hidden_states)\n\n446         146 LOAD_FAST                4 (encoder_attention_mask)\n\n447         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         152 LOAD_FAST                8 (output_attentions)\n\n443         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n452         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n453         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n456         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n459     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n460         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n461         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n462         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n463         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n464         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n465         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n467         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n469         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n470         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n472     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n473         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n475     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 388 \n418           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n422           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n424          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n425          32 LOAD_FAST                1 (hidden_states)\n\n426          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          36 LOAD_FAST                2 (attention_mask)\n\n428          38 LOAD_FAST                5 (layer_head_mask)\n\n429          40 LOAD_FAST                8 (output_attentions)\n\n424          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n431          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n432          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n433          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n436          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n437          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n438         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n439         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n442         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n444         142 LOAD_FAST                1 (hidden_states)\n\n445         144 LOAD_FAST                3 (encoder_hidden_states)\n\n446         146 LOAD_FAST                4 (encoder_attention_mask)\n\n447         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         152 LOAD_FAST                8 (output_attentions)\n\n443         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n452         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n453         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n456         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n459     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n460         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n461         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n462         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n463         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n464         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n465         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n467         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n469         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n470         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n472     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n473         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n475     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 388 \n418           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n422           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n424          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n425          32 LOAD_FAST                1 (hidden_states)\n\n426          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n427          36 LOAD_FAST                2 (attention_mask)\n\n428          38 LOAD_FAST                5 (layer_head_mask)\n\n429          40 LOAD_FAST                8 (output_attentions)\n\n424          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n431          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n432          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n433          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n436          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n437          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n438         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n439         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n442         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n443         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n444         142 LOAD_FAST                1 (hidden_states)\n\n445         144 LOAD_FAST                3 (encoder_hidden_states)\n\n446         146 LOAD_FAST                4 (encoder_attention_mask)\n\n447         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n448         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n449         152 LOAD_FAST                8 (output_attentions)\n\n443         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n451         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n452         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n453         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n456         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n459     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n460         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n461         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n462         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n463         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n464         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n465         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n467         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n469         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n470         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n472     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n473         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n475     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (past_key_values)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (past_key_values)\n\n  5          12 LOAD_FAST                3 (hidden_states)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (hidden_states)\n\n  6          18 LOAD_FAST                4 (attentions)\n             20 LOAD_FAST                0 (self)\n             22 STORE_ATTR               3 (attentions)\n\n  7          24 LOAD_FAST                5 (cross_attentions)\n             26 LOAD_FAST                0 (self)\n             28 STORE_ATTR               4 (cross_attentions)\n\n  8          30 LOAD_FAST                0 (self)\n             32 LOAD_METHOD              5 (__post_init__)\n             34 CALL_METHOD              0\n             36 POP_TOP\n             38 LOAD_CONST               0 (None)\n             40 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 3 \n  3           0 JUMP_ABSOLUTE            4 (to 8)\n              2 LOAD_FAST                5 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n\n  4     >>    8 LOAD_FAST                1 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5          14 LOAD_FAST                2 (hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (hidden_states)\n\n  6          20 LOAD_FAST                3 (attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (attentions)\n\n  7          26 LOAD_FAST                4 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                5 (__post_init__)\n             36 CALL_FUNCTION            0\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (past_key_values)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (past_key_values)\n\n  5          12 LOAD_FAST                3 (decoder_hidden_states)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (decoder_hidden_states)\n\n  6          18 LOAD_FAST                4 (decoder_attentions)\n             20 LOAD_FAST                0 (self)\n             22 STORE_ATTR               3 (decoder_attentions)\n\n  7          24 LOAD_FAST                5 (cross_attentions)\n             26 LOAD_FAST                0 (self)\n             28 STORE_ATTR               4 (cross_attentions)\n\n  8          30 LOAD_FAST                6 (encoder_last_hidden_state)\n             32 LOAD_FAST                0 (self)\n             34 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          36 LOAD_FAST                7 (encoder_hidden_states)\n             38 LOAD_FAST                0 (self)\n             40 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          42 LOAD_FAST                8 (encoder_attentions)\n             44 LOAD_FAST                0 (self)\n             46 STORE_ATTR               7 (encoder_attentions)\n\n 11          48 LOAD_FAST                0 (self)\n             50 LOAD_METHOD              8 (__post_init__)\n             52 CALL_METHOD              0\n             54 POP_TOP\n             56 LOAD_CONST               0 (None)\n             58 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 3 \n  3           0 JUMP_ABSOLUTE            4 (to 8)\n              2 LOAD_FAST                8 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n\n  4     >>    8 LOAD_FAST                1 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5          14 LOAD_FAST                2 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n\n  6          20 LOAD_FAST                3 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7          26 LOAD_FAST                4 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                5 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                6 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                7 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 4 \n  4           0 JUMP_ABSOLUTE            7 (to 14)\n              2 LOAD_FAST                7 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                8 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5     >>   14 LOAD_FAST                1 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n\n  6          20 LOAD_FAST                2 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7          26 LOAD_FAST                3 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                4 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                5 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                6 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 5 \n  5           0 JUMP_ABSOLUTE           10 (to 20)\n              2 LOAD_FAST                6 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                7 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n             14 LOAD_FAST                8 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n\n  6     >>   20 LOAD_FAST                1 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7          26 LOAD_FAST                2 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                3 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                4 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                5 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 6 \n  6           0 JUMP_ABSOLUTE           13 (to 26)\n              2 LOAD_FAST                5 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                6 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n             14 LOAD_FAST                7 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n             20 LOAD_FAST                8 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7     >>   26 LOAD_FAST                1 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                2 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                3 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                4 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 7 \n  7           0 JUMP_ABSOLUTE           16 (to 32)\n              2 LOAD_FAST                4 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                5 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n             14 LOAD_FAST                6 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n             20 LOAD_FAST                7 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n             26 LOAD_FAST                8 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8     >>   32 LOAD_FAST                1 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                2 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                3 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/plbart/modeling_plbart.py line 1327 \n1327           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           50 (to 100)\n               4 LOAD_FAST                3 (return_dict)\n               6 LOAD_CONST               1 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST                3 (return_dict)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (use_return_dict)\n         >>   22 STORE_FAST               3 (return_dict)\n              24 LOAD_FAST                2 (labels)\n              26 LOAD_CONST               1 (None)\n              28 IS_OP                    1\n              30 POP_JUMP_IF_FALSE       31 (to 62)\n              32 LOAD_FAST                6 (decoder_input_ids)\n              34 LOAD_CONST               1 (None)\n              36 IS_OP                    0\n              38 POP_JUMP_IF_FALSE       31 (to 62)\n              40 LOAD_FAST               14 (decoder_inputs_embeds)\n              42 LOAD_CONST               1 (None)\n              44 IS_OP                    0\n              46 POP_JUMP_IF_FALSE       31 (to 62)\n              48 LOAD_GLOBAL              2 (shift_tokens_right)\n              50 LOAD_FAST                2 (labels)\n              52 LOAD_FAST                1 (self)\n              54 LOAD_ATTR                0 (config)\n              56 LOAD_ATTR                3 (pad_token_id)\n              58 CALL_FUNCTION            2\n              60 STORE_FAST               6 (decoder_input_ids)\n         >>   62 LOAD_FAST                1 (self)\n              64 LOAD_ATTR                4 (model)\n              66 LOAD_FAST                4 (input_ids)\n              68 LOAD_FAST                5 (attention_mask)\n              70 LOAD_FAST                6 (decoder_input_ids)\n              72 LOAD_FAST               11 (encoder_outputs)\n              74 LOAD_FAST                7 (decoder_attention_mask)\n              76 LOAD_FAST                8 (head_mask)\n              78 LOAD_FAST                9 (decoder_head_mask)\n              80 LOAD_FAST               10 (cross_attn_head_mask)\n              82 LOAD_FAST               12 (past_key_values)\n              84 LOAD_FAST               13 (inputs_embeds)\n              86 LOAD_FAST               14 (decoder_inputs_embeds)\n              88 LOAD_FAST               15 (use_cache)\n              90 LOAD_FAST               16 (output_attentions)\n              92 LOAD_FAST               17 (output_hidden_states)\n              94 LOAD_FAST                3 (return_dict)\n              96 LOAD_CONST               2 (('attention_mask', 'decoder_input_ids', 'encoder_outputs', 'decoder_attention_mask', 'head_mask', 'decoder_head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'decoder_inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              98 CALL_FUNCTION_KW        15\n         >>  100 STORE_FAST              18 (outputs)\n\n1344         102 LOAD_FAST                1 (self)\n             104 LOAD_ATTR                5 (lm_head)\n             106 LOAD_FAST               18 (outputs)\n             108 LOAD_CONST               3 (0)\n             110 BINARY_SUBSCR\n             112 CALL_FUNCTION            1\n             114 STORE_FAST              19 (lm_logits)\n\n1345         116 LOAD_FAST               19 (lm_logits)\n             118 LOAD_FAST                1 (self)\n             120 LOAD_ATTR                6 (final_logits_bias)\n             122 LOAD_ATTR                7 (to)\n             124 LOAD_FAST               19 (lm_logits)\n             126 LOAD_ATTR                8 (device)\n             128 CALL_FUNCTION            1\n             130 BINARY_ADD\n             132 STORE_FAST              19 (lm_logits)\n\n1347         134 LOAD_CONST               1 (None)\n             136 STORE_FAST              20 (masked_lm_loss)\n\n1348         138 LOAD_FAST                2 (labels)\n             140 LOAD_CONST               1 (None)\n             142 IS_OP                    1\n             144 POP_JUMP_IF_FALSE       90 (to 180)\n\n1349         146 LOAD_GLOBAL              9 (CrossEntropyLoss)\n             148 CALL_FUNCTION            0\n             150 STORE_FAST              21 (loss_fct)\n\n1350         152 LOAD_FAST               21 (loss_fct)\n             154 LOAD_FAST               19 (lm_logits)\n             156 LOAD_ATTR               10 (view)\n             158 LOAD_CONST               4 (-1)\n             160 LOAD_FAST                1 (self)\n             162 LOAD_ATTR                0 (config)\n             164 LOAD_ATTR               11 (vocab_size)\n             166 CALL_FUNCTION            2\n             168 LOAD_FAST                2 (labels)\n             170 LOAD_ATTR               10 (view)\n             172 LOAD_CONST               4 (-1)\n             174 CALL_FUNCTION            1\n             176 CALL_FUNCTION            2\n             178 STORE_FAST              20 (masked_lm_loss)\n\n1352     >>  180 LOAD_FAST                3 (return_dict)\n             182 POP_JUMP_IF_TRUE       112 (to 224)\n\n1353         184 LOAD_FAST               19 (lm_logits)\n             186 BUILD_TUPLE              1\n             188 LOAD_FAST               18 (outputs)\n             190 LOAD_CONST               5 (1)\n             192 LOAD_CONST               1 (None)\n             194 BUILD_SLICE              2\n             196 BINARY_SUBSCR\n             198 BINARY_ADD\n             200 STORE_FAST              22 (output)\n\n1354         202 LOAD_FAST               20 (masked_lm_loss)\n             204 LOAD_CONST               1 (None)\n             206 IS_OP                    1\n             208 POP_JUMP_IF_FALSE      110 (to 220)\n             210 LOAD_FAST               20 (masked_lm_loss)\n             212 BUILD_TUPLE              1\n             214 LOAD_FAST               22 (output)\n             216 BINARY_ADD\n             218 RETURN_VALUE\n         >>  220 LOAD_FAST               22 (output)\n             222 RETURN_VALUE\n\n1356     >>  224 LOAD_GLOBAL             12 (Seq2SeqLMOutput)\n\n1357         226 LOAD_FAST               20 (masked_lm_loss)\n\n1358         228 LOAD_FAST               19 (lm_logits)\n\n1359         230 LOAD_FAST               18 (outputs)\n             232 LOAD_ATTR               13 (past_key_values)\n\n1360         234 LOAD_FAST               18 (outputs)\n             236 LOAD_ATTR               14 (decoder_hidden_states)\n\n1361         238 LOAD_FAST               18 (outputs)\n             240 LOAD_ATTR               15 (decoder_attentions)\n\n1362         242 LOAD_FAST               18 (outputs)\n             244 LOAD_ATTR               16 (cross_attentions)\n\n1363         246 LOAD_FAST               18 (outputs)\n             248 LOAD_ATTR               17 (encoder_last_hidden_state)\n\n1364         250 LOAD_FAST               18 (outputs)\n             252 LOAD_ATTR               18 (encoder_hidden_states)\n\n1365         254 LOAD_FAST               18 (outputs)\n             256 LOAD_ATTR               19 (encoder_attentions)\n\n1356         258 LOAD_CONST               6 (('loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             260 CALL_FUNCTION_KW         9\n             262 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 557 \n557           0 LOAD_FAST                0 (___stack0)\n              2 CALL_FUNCTION            0\n              4 SETUP_WITH              10 (to 26)\n              6 POP_TOP\n              8 LOAD_FAST                1 (___stack1)\n             10 JUMP_ABSOLUTE           44 (to 88)\n             12 POP_BLOCK\n             14 LOAD_CONST               0 (None)\n             16 DUP_TOP\n             18 DUP_TOP\n             20 CALL_FUNCTION            3\n             22 POP_TOP\n             24 JUMP_FORWARD             8 (to 42)\n        >>   26 WITH_EXCEPT_START\n             28 POP_JUMP_IF_TRUE        16 (to 32)\n             30 RERAISE                  0\n        >>   32 POP_TOP\n             34 POP_TOP\n             36 POP_TOP\n             38 POP_EXCEPT\n             40 POP_TOP\n        >>   42 NOP\n             44 LOAD_CONST               0 (None)\n             46 RAISE_VARARGS            1\n             48 LOAD_GLOBAL              0 (clone_inputs)\n             50 LOAD_FAST                6 (inputs)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (cloned_inputs)\n             56 LOAD_FAST                2 (self)\n             58 LOAD_ATTR                1 (optimizer_zero_grad)\n             60 LOAD_FAST                3 (mod)\n             62 CALL_FUNCTION            1\n             64 POP_TOP\n             66 LOAD_FAST                2 (self)\n             68 LOAD_ATTR                2 (autocast)\n             70 CALL_FUNCTION            0\n             72 SETUP_WITH              20 (to 114)\n             74 POP_TOP\n             76 LOAD_FAST                3 (mod)\n             78 LOAD_CONST               1 (())\n             80 BUILD_MAP                0\n             82 LOAD_FAST                5 (cloned_inputs)\n             84 DICT_MERGE               1\n             86 CALL_FUNCTION_EX         1\n        >>   88 STORE_FAST               7 (pred)\n\n558          90 LOAD_FAST                2 (self)\n             92 LOAD_ATTR                3 (compute_loss)\n             94 LOAD_FAST                7 (pred)\n             96 CALL_FUNCTION            1\n             98 STORE_FAST               8 (loss)\n            100 POP_BLOCK\n\n556         102 LOAD_CONST               0 (None)\n            104 DUP_TOP\n            106 DUP_TOP\n            108 CALL_FUNCTION            3\n            110 POP_TOP\n            112 JUMP_FORWARD             8 (to 130)\n        >>  114 WITH_EXCEPT_START\n            116 POP_JUMP_IF_TRUE        60 (to 120)\n            118 RERAISE                  1\n        >>  120 POP_TOP\n            122 POP_TOP\n            124 POP_TOP\n            126 POP_EXCEPT\n            128 POP_TOP\n\n559     >>  130 LOAD_FAST                2 (self)\n            132 LOAD_ATTR                4 (grad_scaler)\n            134 LOAD_ATTR                5 (scale)\n            136 LOAD_FAST                8 (loss)\n            138 CALL_FUNCTION            1\n            140 LOAD_ATTR                6 (backward)\n            142 CALL_FUNCTION            0\n            144 POP_TOP\n\n560         146 LOAD_FAST                2 (self)\n            148 LOAD_ATTR                7 (optimizer_step)\n            150 CALL_FUNCTION            0\n            152 POP_TOP\n\n561         154 LOAD_FAST                4 (collect_outputs)\n            156 POP_JUMP_IF_FALSE       86 (to 172)\n\n562         158 LOAD_GLOBAL              8 (collect_results)\n            160 LOAD_FAST                3 (mod)\n            162 LOAD_FAST                7 (pred)\n            164 LOAD_FAST                8 (loss)\n            166 LOAD_FAST                5 (cloned_inputs)\n            168 CALL_FUNCTION            4\n            170 RETURN_VALUE\n\n563     >>  172 LOAD_CONST               0 (None)\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 1566 \n1669           0 LOAD_FAST               11 (output_attentions)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               11 (output_attentions)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (output_attentions)\n         >>   18 STORE_FAST              11 (output_attentions)\n\n1671          20 LOAD_FAST               12 (output_hidden_states)\n              22 LOAD_CONST               1 (None)\n              24 IS_OP                    1\n              26 POP_JUMP_IF_FALSE       16 (to 32)\n              28 LOAD_FAST               12 (output_hidden_states)\n              30 JUMP_FORWARD             3 (to 38)\n         >>   32 LOAD_FAST                0 (self)\n              34 LOAD_ATTR                0 (config)\n              36 LOAD_ATTR                2 (output_hidden_states)\n\n1670     >>   38 STORE_FAST              12 (output_hidden_states)\n\n1673          40 LOAD_FAST               13 (return_dict)\n              42 LOAD_CONST               1 (None)\n              44 IS_OP                    1\n              46 POP_JUMP_IF_FALSE       26 (to 52)\n              48 LOAD_FAST               13 (return_dict)\n              50 JUMP_FORWARD             3 (to 58)\n         >>   52 LOAD_FAST                0 (self)\n              54 LOAD_ATTR                0 (config)\n              56 LOAD_ATTR                3 (use_return_dict)\n         >>   58 STORE_FAST              13 (return_dict)\n\n1676          60 LOAD_FAST                0 (self)\n              62 LOAD_ATTR                4 (model)\n              64 LOAD_ATTR                5 (decoder)\n\n1677          66 LOAD_FAST                1 (input_ids)\n\n1678          68 LOAD_FAST                2 (attention_mask)\n\n1679          70 LOAD_FAST                3 (encoder_hidden_states)\n\n1680          72 LOAD_FAST                4 (encoder_attention_mask)\n\n1681          74 LOAD_FAST                5 (head_mask)\n\n1682          76 LOAD_FAST                6 (cross_attn_head_mask)\n\n1683          78 LOAD_FAST                7 (past_key_values)\n\n1684          80 LOAD_FAST                8 (inputs_embeds)\n\n1685          82 LOAD_FAST               10 (use_cache)\n\n1686          84 LOAD_FAST               11 (output_attentions)\n\n1687          86 LOAD_FAST               12 (output_hidden_states)\n\n1688          88 LOAD_FAST               13 (return_dict)\n\n1676          90 LOAD_CONST               2 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              92 CALL_FUNCTION_KW        12\n              94 STORE_FAST              14 (outputs)\n\n1691          96 LOAD_FAST                0 (self)\n              98 LOAD_METHOD              6 (lm_head)\n             100 LOAD_FAST               14 (outputs)\n             102 LOAD_CONST               3 (0)\n             104 BINARY_SUBSCR\n             106 CALL_METHOD              1\n             108 STORE_FAST              15 (logits)\n\n1693         110 LOAD_CONST               1 (None)\n             112 STORE_FAST              16 (loss)\n\n1694         114 LOAD_FAST                9 (labels)\n             116 LOAD_CONST               1 (None)\n             118 IS_OP                    1\n             120 POP_JUMP_IF_FALSE       84 (to 168)\n\n1695         122 LOAD_FAST                9 (labels)\n             124 LOAD_METHOD              7 (to)\n             126 LOAD_FAST               15 (logits)\n             128 LOAD_ATTR                8 (device)\n             130 CALL_METHOD              1\n             132 STORE_FAST               9 (labels)\n\n1696         134 LOAD_GLOBAL              9 (CrossEntropyLoss)\n             136 CALL_FUNCTION            0\n             138 STORE_FAST              17 (loss_fct)\n\n1697         140 LOAD_FAST               17 (loss_fct)\n             142 LOAD_FAST               15 (logits)\n             144 LOAD_METHOD             10 (view)\n             146 LOAD_CONST               4 (-1)\n             148 LOAD_FAST                0 (self)\n             150 LOAD_ATTR                0 (config)\n             152 LOAD_ATTR               11 (vocab_size)\n             154 CALL_METHOD              2\n             156 LOAD_FAST                9 (labels)\n             158 LOAD_METHOD             10 (view)\n             160 LOAD_CONST               4 (-1)\n             162 CALL_METHOD              1\n             164 CALL_FUNCTION            2\n             166 STORE_FAST              16 (loss)\n\n1699     >>  168 LOAD_FAST               13 (return_dict)\n             170 POP_JUMP_IF_TRUE       106 (to 212)\n\n1700         172 LOAD_FAST               15 (logits)\n             174 BUILD_TUPLE              1\n             176 LOAD_FAST               14 (outputs)\n             178 LOAD_CONST               5 (1)\n             180 LOAD_CONST               1 (None)\n             182 BUILD_SLICE              2\n             184 BINARY_SUBSCR\n             186 BINARY_ADD\n             188 STORE_FAST              18 (output)\n\n1701         190 LOAD_FAST               16 (loss)\n             192 LOAD_CONST               1 (None)\n             194 IS_OP                    1\n             196 POP_JUMP_IF_FALSE      104 (to 208)\n             198 LOAD_FAST               16 (loss)\n             200 BUILD_TUPLE              1\n             202 LOAD_FAST               18 (output)\n             204 BINARY_ADD\n             206 RETURN_VALUE\n         >>  208 LOAD_FAST               18 (output)\n             210 RETURN_VALUE\n\n1703     >>  212 LOAD_GLOBAL             12 (CausalLMOutputWithCrossAttentions)\n\n1704         214 LOAD_FAST               16 (loss)\n\n1705         216 LOAD_FAST               15 (logits)\n\n1706         218 LOAD_FAST               14 (outputs)\n             220 LOAD_ATTR               13 (past_key_values)\n\n1707         222 LOAD_FAST               14 (outputs)\n             224 LOAD_ATTR               14 (hidden_states)\n\n1708         226 LOAD_FAST               14 (outputs)\n             228 LOAD_ATTR               15 (attentions)\n\n1709         230 LOAD_FAST               14 (outputs)\n             232 LOAD_ATTR               16 (cross_attentions)\n\n1703         234 LOAD_CONST               6 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n             236 CALL_FUNCTION_KW         6\n             238 RETURN_VALUE\n\n", "ORIGINAL BYTECODE _prepare_decoder_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 884 \n887           0 LOAD_CONST               0 (None)\n              2 STORE_FAST               5 (combined_attention_mask)\n\n888           4 LOAD_FAST                2 (input_shape)\n              6 LOAD_CONST               1 (-1)\n              8 BINARY_SUBSCR\n             10 LOAD_CONST               2 (1)\n             12 COMPARE_OP               4 (>)\n             14 POP_JUMP_IF_FALSE       18 (to 36)\n\n889          16 LOAD_GLOBAL              0 (_make_causal_mask)\n\n890          18 LOAD_FAST                2 (input_shape)\n\n891          20 LOAD_FAST                3 (inputs_embeds)\n             22 LOAD_ATTR                1 (dtype)\n\n892          24 LOAD_FAST                3 (inputs_embeds)\n             26 LOAD_ATTR                2 (device)\n\n893          28 LOAD_FAST                4 (past_key_values_length)\n\n889          30 LOAD_CONST               3 (('device', 'past_key_values_length'))\n             32 CALL_FUNCTION_KW         4\n             34 STORE_FAST               5 (combined_attention_mask)\n\n896     >>   36 LOAD_FAST                1 (attention_mask)\n             38 LOAD_CONST               0 (None)\n             40 IS_OP                    1\n             42 POP_JUMP_IF_FALSE       46 (to 92)\n\n898          44 LOAD_GLOBAL              3 (_expand_mask)\n             46 LOAD_FAST                1 (attention_mask)\n             48 LOAD_FAST                3 (inputs_embeds)\n             50 LOAD_ATTR                1 (dtype)\n             52 LOAD_FAST                2 (input_shape)\n             54 LOAD_CONST               1 (-1)\n             56 BINARY_SUBSCR\n             58 LOAD_CONST               4 (('tgt_len',))\n             60 CALL_FUNCTION_KW         3\n             62 LOAD_METHOD              4 (to)\n\n899          64 LOAD_FAST                3 (inputs_embeds)\n             66 LOAD_ATTR                2 (device)\n\n898          68 CALL_METHOD              1\n             70 STORE_FAST               6 (expanded_attn_mask)\n\n902          72 LOAD_FAST                5 (combined_attention_mask)\n             74 LOAD_CONST               0 (None)\n             76 IS_OP                    0\n             78 POP_JUMP_IF_FALSE       42 (to 84)\n             80 LOAD_FAST                6 (expanded_attn_mask)\n             82 JUMP_FORWARD             3 (to 90)\n        >>   84 LOAD_FAST                6 (expanded_attn_mask)\n             86 LOAD_FAST                5 (combined_attention_mask)\n             88 BINARY_ADD\n\n901     >>   90 STORE_FAST               5 (combined_attention_mask)\n\n905     >>   92 LOAD_FAST                5 (combined_attention_mask)\n             94 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 133 \n136           0 LOAD_FAST                1 (input_ids_shape)\n              2 LOAD_CONST               1 (None)\n              4 LOAD_CONST               2 (2)\n              6 BUILD_SLICE              2\n              8 BINARY_SUBSCR\n             10 UNPACK_SEQUENCE          2\n             12 STORE_FAST               3 (bsz)\n             14 STORE_FAST               4 (seq_len)\n\n137          16 LOAD_GLOBAL              0 (torch)\n             18 LOAD_ATTR                1 (arange)\n\n138          20 LOAD_FAST                2 (past_key_values_length)\n             22 LOAD_FAST                2 (past_key_values_length)\n             24 LOAD_FAST                4 (seq_len)\n             26 BINARY_ADD\n             28 LOAD_GLOBAL              0 (torch)\n             30 LOAD_ATTR                2 (long)\n             32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                3 (weight)\n             36 LOAD_ATTR                4 (device)\n\n137          38 LOAD_CONST               3 (('dtype', 'device'))\n             40 CALL_FUNCTION_KW         4\n             42 STORE_FAST               5 (positions)\n\n140          44 LOAD_GLOBAL              5 (super)\n             46 CALL_FUNCTION            0\n             48 LOAD_METHOD              6 (forward)\n             50 LOAD_FAST                5 (positions)\n             52 CALL_METHOD              1\n             54 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (past_key_values)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (past_key_values)\n\n  5          12 LOAD_FAST                3 (hidden_states)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (hidden_states)\n\n  6          18 LOAD_FAST                4 (attentions)\n             20 LOAD_FAST                0 (self)\n             22 STORE_ATTR               3 (attentions)\n\n  7          24 LOAD_FAST                5 (cross_attentions)\n             26 LOAD_FAST                0 (self)\n             28 STORE_ATTR               4 (cross_attentions)\n\n  8          30 LOAD_FAST                0 (self)\n             32 LOAD_METHOD              5 (__post_init__)\n             34 CALL_METHOD              0\n             36 POP_TOP\n             38 LOAD_CONST               0 (None)\n             40 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 3 \n  3           0 JUMP_ABSOLUTE            4 (to 8)\n              2 LOAD_FAST                5 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n\n  4     >>    8 LOAD_FAST                1 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5          14 LOAD_FAST                2 (hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (hidden_states)\n\n  6          20 LOAD_FAST                3 (attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (attentions)\n\n  7          26 LOAD_FAST                4 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                5 (__post_init__)\n             36 CALL_FUNCTION            0\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 1676 \n1676           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           49 (to 98)\n               4 LOAD_FAST               13 (output_attentions)\n               6 LOAD_CONST               1 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST               13 (output_attentions)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (output_attentions)\n         >>   22 STORE_FAST              13 (output_attentions)\n              24 LOAD_FAST               14 (output_hidden_states)\n              26 LOAD_CONST               1 (None)\n              28 IS_OP                    1\n              30 POP_JUMP_IF_FALSE       18 (to 36)\n              32 LOAD_FAST               14 (output_hidden_states)\n              34 JUMP_FORWARD             3 (to 42)\n         >>   36 LOAD_FAST                1 (self)\n              38 LOAD_ATTR                0 (config)\n              40 LOAD_ATTR                2 (output_hidden_states)\n         >>   42 STORE_FAST              14 (output_hidden_states)\n              44 LOAD_FAST                3 (return_dict)\n              46 LOAD_CONST               1 (None)\n              48 IS_OP                    1\n              50 POP_JUMP_IF_FALSE       28 (to 56)\n              52 LOAD_FAST                3 (return_dict)\n              54 JUMP_FORWARD             3 (to 62)\n         >>   56 LOAD_FAST                1 (self)\n              58 LOAD_ATTR                0 (config)\n              60 LOAD_ATTR                3 (use_return_dict)\n         >>   62 STORE_FAST               3 (return_dict)\n              64 LOAD_FAST                1 (self)\n              66 LOAD_ATTR                4 (model)\n              68 LOAD_ATTR                5 (decoder)\n              70 LOAD_FAST                4 (input_ids)\n              72 LOAD_FAST                5 (attention_mask)\n              74 LOAD_FAST                6 (encoder_hidden_states)\n              76 LOAD_FAST                7 (encoder_attention_mask)\n              78 LOAD_FAST                8 (head_mask)\n              80 LOAD_FAST                9 (cross_attn_head_mask)\n              82 LOAD_FAST               10 (past_key_values)\n              84 LOAD_FAST               11 (inputs_embeds)\n              86 LOAD_FAST               12 (use_cache)\n              88 LOAD_FAST               13 (output_attentions)\n              90 LOAD_FAST               14 (output_hidden_states)\n              92 LOAD_FAST                3 (return_dict)\n              94 LOAD_CONST               2 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              96 CALL_FUNCTION_KW        12\n         >>   98 STORE_FAST              15 (outputs)\n\n1691         100 LOAD_FAST                1 (self)\n             102 LOAD_ATTR                6 (lm_head)\n             104 LOAD_FAST               15 (outputs)\n             106 LOAD_CONST               3 (0)\n             108 BINARY_SUBSCR\n             110 CALL_FUNCTION            1\n             112 STORE_FAST              16 (logits)\n\n1693         114 LOAD_CONST               1 (None)\n             116 STORE_FAST              17 (loss)\n\n1694         118 LOAD_FAST                2 (labels)\n             120 LOAD_CONST               1 (None)\n             122 IS_OP                    1\n             124 POP_JUMP_IF_FALSE       86 (to 172)\n\n1695         126 LOAD_FAST                2 (labels)\n             128 LOAD_ATTR                7 (to)\n             130 LOAD_FAST               16 (logits)\n             132 LOAD_ATTR                8 (device)\n             134 CALL_FUNCTION            1\n             136 STORE_FAST               2 (labels)\n\n1696         138 LOAD_GLOBAL              9 (CrossEntropyLoss)\n             140 CALL_FUNCTION            0\n             142 STORE_FAST              18 (loss_fct)\n\n1697         144 LOAD_FAST               18 (loss_fct)\n             146 LOAD_FAST               16 (logits)\n             148 LOAD_ATTR               10 (view)\n             150 LOAD_CONST               4 (-1)\n             152 LOAD_FAST                1 (self)\n             154 LOAD_ATTR                0 (config)\n             156 LOAD_ATTR               11 (vocab_size)\n             158 CALL_FUNCTION            2\n             160 LOAD_FAST                2 (labels)\n             162 LOAD_ATTR               10 (view)\n             164 LOAD_CONST               4 (-1)\n             166 CALL_FUNCTION            1\n             168 CALL_FUNCTION            2\n             170 STORE_FAST              17 (loss)\n\n1699     >>  172 LOAD_FAST                3 (return_dict)\n             174 POP_JUMP_IF_TRUE       108 (to 216)\n\n1700         176 LOAD_FAST               16 (logits)\n             178 BUILD_TUPLE              1\n             180 LOAD_FAST               15 (outputs)\n             182 LOAD_CONST               5 (1)\n             184 LOAD_CONST               1 (None)\n             186 BUILD_SLICE              2\n             188 BINARY_SUBSCR\n             190 BINARY_ADD\n             192 STORE_FAST              19 (output)\n\n1701         194 LOAD_FAST               17 (loss)\n             196 LOAD_CONST               1 (None)\n             198 IS_OP                    1\n             200 POP_JUMP_IF_FALSE      106 (to 212)\n             202 LOAD_FAST               17 (loss)\n             204 BUILD_TUPLE              1\n             206 LOAD_FAST               19 (output)\n             208 BINARY_ADD\n             210 RETURN_VALUE\n         >>  212 LOAD_FAST               19 (output)\n             214 RETURN_VALUE\n\n1703     >>  216 LOAD_GLOBAL             12 (CausalLMOutputWithCrossAttentions)\n\n1704         218 LOAD_FAST               17 (loss)\n\n1705         220 LOAD_FAST               16 (logits)\n\n1706         222 LOAD_FAST               15 (outputs)\n             224 LOAD_ATTR               13 (past_key_values)\n\n1707         226 LOAD_FAST               15 (outputs)\n             228 LOAD_ATTR               14 (hidden_states)\n\n1708         230 LOAD_FAST               15 (outputs)\n             232 LOAD_ATTR               15 (attentions)\n\n1709         234 LOAD_FAST               15 (outputs)\n             236 LOAD_ATTR               16 (cross_attentions)\n\n1703         238 LOAD_CONST               6 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n             240 CALL_FUNCTION_KW         6\n             242 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 557 \n557           0 LOAD_FAST                0 (___stack0)\n              2 CALL_FUNCTION            0\n              4 SETUP_WITH              10 (to 26)\n              6 POP_TOP\n              8 LOAD_FAST                1 (___stack1)\n             10 JUMP_ABSOLUTE           44 (to 88)\n             12 POP_BLOCK\n             14 LOAD_CONST               0 (None)\n             16 DUP_TOP\n             18 DUP_TOP\n             20 CALL_FUNCTION            3\n             22 POP_TOP\n             24 JUMP_FORWARD             8 (to 42)\n        >>   26 WITH_EXCEPT_START\n             28 POP_JUMP_IF_TRUE        16 (to 32)\n             30 RERAISE                  0\n        >>   32 POP_TOP\n             34 POP_TOP\n             36 POP_TOP\n             38 POP_EXCEPT\n             40 POP_TOP\n        >>   42 NOP\n             44 LOAD_CONST               0 (None)\n             46 RAISE_VARARGS            1\n             48 LOAD_GLOBAL              0 (clone_inputs)\n             50 LOAD_FAST                6 (inputs)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (cloned_inputs)\n             56 LOAD_FAST                2 (self)\n             58 LOAD_ATTR                1 (optimizer_zero_grad)\n             60 LOAD_FAST                3 (mod)\n             62 CALL_FUNCTION            1\n             64 POP_TOP\n             66 LOAD_FAST                2 (self)\n             68 LOAD_ATTR                2 (autocast)\n             70 CALL_FUNCTION            0\n             72 SETUP_WITH              20 (to 114)\n             74 POP_TOP\n             76 LOAD_FAST                3 (mod)\n             78 LOAD_CONST               1 (())\n             80 BUILD_MAP                0\n             82 LOAD_FAST                5 (cloned_inputs)\n             84 DICT_MERGE               1\n             86 CALL_FUNCTION_EX         1\n        >>   88 STORE_FAST               7 (pred)\n\n558          90 LOAD_FAST                2 (self)\n             92 LOAD_ATTR                3 (compute_loss)\n             94 LOAD_FAST                7 (pred)\n             96 CALL_FUNCTION            1\n             98 STORE_FAST               8 (loss)\n            100 POP_BLOCK\n\n556         102 LOAD_CONST               0 (None)\n            104 DUP_TOP\n            106 DUP_TOP\n            108 CALL_FUNCTION            3\n            110 POP_TOP\n            112 JUMP_FORWARD             8 (to 130)\n        >>  114 WITH_EXCEPT_START\n            116 POP_JUMP_IF_TRUE        60 (to 120)\n            118 RERAISE                  1\n        >>  120 POP_TOP\n            122 POP_TOP\n            124 POP_TOP\n            126 POP_EXCEPT\n            128 POP_TOP\n\n559     >>  130 LOAD_FAST                2 (self)\n            132 LOAD_ATTR                4 (grad_scaler)\n            134 LOAD_ATTR                5 (scale)\n            136 LOAD_FAST                8 (loss)\n            138 CALL_FUNCTION            1\n            140 LOAD_ATTR                6 (backward)\n            142 CALL_FUNCTION            0\n            144 POP_TOP\n\n560         146 LOAD_FAST                2 (self)\n            148 LOAD_ATTR                7 (optimizer_step)\n            150 CALL_FUNCTION            0\n            152 POP_TOP\n\n561         154 LOAD_FAST                4 (collect_outputs)\n            156 POP_JUMP_IF_FALSE       86 (to 172)\n\n562         158 LOAD_GLOBAL              8 (collect_results)\n            160 LOAD_FAST                3 (mod)\n            162 LOAD_FAST                7 (pred)\n            164 LOAD_FAST                8 (loss)\n            166 LOAD_FAST                5 (cloned_inputs)\n            168 CALL_FUNCTION            4\n            170 RETURN_VALUE\n\n563     >>  172 LOAD_CONST               0 (None)\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 1372 \n1403           0 LOAD_FAST               16 (return_dict)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               16 (return_dict)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (use_return_dict)\n         >>   18 STORE_FAST              16 (return_dict)\n\n1405          20 LOAD_FAST               12 (labels)\n              22 LOAD_CONST               1 (None)\n              24 IS_OP                    1\n              26 POP_JUMP_IF_FALSE       41 (to 82)\n\n1406          28 LOAD_FAST               13 (use_cache)\n              30 POP_JUMP_IF_FALSE       21 (to 42)\n\n1407          32 LOAD_GLOBAL              2 (logger)\n              34 LOAD_METHOD              3 (warning)\n              36 LOAD_CONST               2 ('The `use_cache` argument is changed to `False` since `labels` is provided.')\n              38 CALL_METHOD              1\n              40 POP_TOP\n\n1408     >>   42 LOAD_CONST               3 (False)\n              44 STORE_FAST              13 (use_cache)\n\n1409          46 LOAD_FAST                3 (decoder_input_ids)\n              48 LOAD_CONST               1 (None)\n              50 IS_OP                    0\n              52 POP_JUMP_IF_FALSE       41 (to 82)\n              54 LOAD_FAST               11 (decoder_inputs_embeds)\n              56 LOAD_CONST               1 (None)\n              58 IS_OP                    0\n              60 POP_JUMP_IF_FALSE       41 (to 82)\n\n1410          62 LOAD_GLOBAL              4 (shift_tokens_right)\n\n1411          64 LOAD_FAST               12 (labels)\n              66 LOAD_FAST                0 (self)\n              68 LOAD_ATTR                0 (config)\n              70 LOAD_ATTR                5 (pad_token_id)\n              72 LOAD_FAST                0 (self)\n              74 LOAD_ATTR                0 (config)\n              76 LOAD_ATTR                6 (decoder_start_token_id)\n\n1410          78 CALL_FUNCTION            3\n              80 STORE_FAST               3 (decoder_input_ids)\n\n1414     >>   82 LOAD_FAST                0 (self)\n              84 LOAD_ATTR                7 (model)\n\n1415          86 LOAD_FAST                1 (input_ids)\n\n1416          88 LOAD_FAST                2 (attention_mask)\n\n1417          90 LOAD_FAST                3 (decoder_input_ids)\n\n1418          92 LOAD_FAST                8 (encoder_outputs)\n\n1419          94 LOAD_FAST                4 (decoder_attention_mask)\n\n1420          96 LOAD_FAST                5 (head_mask)\n\n1421          98 LOAD_FAST                6 (decoder_head_mask)\n\n1422         100 LOAD_FAST                7 (cross_attn_head_mask)\n\n1423         102 LOAD_FAST                9 (past_key_values)\n\n1424         104 LOAD_FAST               10 (inputs_embeds)\n\n1425         106 LOAD_FAST               11 (decoder_inputs_embeds)\n\n1426         108 LOAD_FAST               13 (use_cache)\n\n1427         110 LOAD_FAST               14 (output_attentions)\n\n1428         112 LOAD_FAST               15 (output_hidden_states)\n\n1429         114 LOAD_FAST               16 (return_dict)\n\n1414         116 LOAD_CONST               4 (('attention_mask', 'decoder_input_ids', 'encoder_outputs', 'decoder_attention_mask', 'head_mask', 'decoder_head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'decoder_inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             118 CALL_FUNCTION_KW        15\n             120 STORE_FAST              17 (outputs)\n\n1431         122 LOAD_FAST                0 (self)\n             124 LOAD_METHOD              8 (lm_head)\n             126 LOAD_FAST               17 (outputs)\n             128 LOAD_CONST               5 (0)\n             130 BINARY_SUBSCR\n             132 CALL_METHOD              1\n             134 LOAD_FAST                0 (self)\n             136 LOAD_ATTR                9 (final_logits_bias)\n             138 BINARY_ADD\n             140 STORE_FAST              18 (lm_logits)\n\n1433         142 LOAD_CONST               1 (None)\n             144 STORE_FAST              19 (masked_lm_loss)\n\n1434         146 LOAD_FAST               12 (labels)\n             148 LOAD_CONST               1 (None)\n             150 IS_OP                    1\n             152 POP_JUMP_IF_FALSE       94 (to 188)\n\n1435         154 LOAD_GLOBAL             10 (CrossEntropyLoss)\n             156 CALL_FUNCTION            0\n             158 STORE_FAST              20 (loss_fct)\n\n1436         160 LOAD_FAST               20 (loss_fct)\n             162 LOAD_FAST               18 (lm_logits)\n             164 LOAD_METHOD             11 (view)\n             166 LOAD_CONST               6 (-1)\n             168 LOAD_FAST                0 (self)\n             170 LOAD_ATTR                0 (config)\n             172 LOAD_ATTR               12 (vocab_size)\n             174 CALL_METHOD              2\n             176 LOAD_FAST               12 (labels)\n             178 LOAD_METHOD             11 (view)\n             180 LOAD_CONST               6 (-1)\n             182 CALL_METHOD              1\n             184 CALL_FUNCTION            2\n             186 STORE_FAST              19 (masked_lm_loss)\n\n1438     >>  188 LOAD_FAST               16 (return_dict)\n             190 POP_JUMP_IF_TRUE       116 (to 232)\n\n1439         192 LOAD_FAST               18 (lm_logits)\n             194 BUILD_TUPLE              1\n             196 LOAD_FAST               17 (outputs)\n             198 LOAD_CONST               7 (1)\n             200 LOAD_CONST               1 (None)\n             202 BUILD_SLICE              2\n             204 BINARY_SUBSCR\n             206 BINARY_ADD\n             208 STORE_FAST              21 (output)\n\n1440         210 LOAD_FAST               19 (masked_lm_loss)\n             212 LOAD_CONST               1 (None)\n             214 IS_OP                    1\n             216 POP_JUMP_IF_FALSE      114 (to 228)\n             218 LOAD_FAST               19 (masked_lm_loss)\n             220 BUILD_TUPLE              1\n             222 LOAD_FAST               21 (output)\n             224 BINARY_ADD\n             226 RETURN_VALUE\n         >>  228 LOAD_FAST               21 (output)\n             230 RETURN_VALUE\n\n1442     >>  232 LOAD_GLOBAL             13 (Seq2SeqLMOutput)\n\n1443         234 LOAD_FAST               19 (masked_lm_loss)\n\n1444         236 LOAD_FAST               18 (lm_logits)\n\n1445         238 LOAD_FAST               17 (outputs)\n             240 LOAD_ATTR               14 (past_key_values)\n\n1446         242 LOAD_FAST               17 (outputs)\n             244 LOAD_ATTR               15 (decoder_hidden_states)\n\n1447         246 LOAD_FAST               17 (outputs)\n             248 LOAD_ATTR               16 (decoder_attentions)\n\n1448         250 LOAD_FAST               17 (outputs)\n             252 LOAD_ATTR               17 (cross_attentions)\n\n1449         254 LOAD_FAST               17 (outputs)\n             256 LOAD_ATTR               18 (encoder_last_hidden_state)\n\n1450         258 LOAD_FAST               17 (outputs)\n             260 LOAD_ATTR               19 (encoder_hidden_states)\n\n1451         262 LOAD_FAST               17 (outputs)\n             264 LOAD_ATTR               20 (encoder_attentions)\n\n1442         266 LOAD_CONST               8 (('loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             268 CALL_FUNCTION_KW         9\n             270 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 1210 \n1250           0 LOAD_FAST               13 (output_attentions)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               13 (output_attentions)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (output_attentions)\n         >>   18 STORE_FAST              13 (output_attentions)\n\n1252          20 LOAD_FAST               14 (output_hidden_states)\n              22 LOAD_CONST               1 (None)\n              24 IS_OP                    1\n              26 POP_JUMP_IF_FALSE       16 (to 32)\n              28 LOAD_FAST               14 (output_hidden_states)\n              30 JUMP_FORWARD             3 (to 38)\n         >>   32 LOAD_FAST                0 (self)\n              34 LOAD_ATTR                0 (config)\n              36 LOAD_ATTR                2 (output_hidden_states)\n\n1251     >>   38 STORE_FAST              14 (output_hidden_states)\n\n1254          40 LOAD_FAST               12 (use_cache)\n              42 LOAD_CONST               1 (None)\n              44 IS_OP                    1\n              46 POP_JUMP_IF_FALSE       26 (to 52)\n              48 LOAD_FAST               12 (use_cache)\n              50 JUMP_FORWARD             3 (to 58)\n         >>   52 LOAD_FAST                0 (self)\n              54 LOAD_ATTR                0 (config)\n              56 LOAD_ATTR                3 (use_cache)\n         >>   58 STORE_FAST              12 (use_cache)\n\n1255          60 LOAD_FAST               15 (return_dict)\n              62 LOAD_CONST               1 (None)\n              64 IS_OP                    1\n              66 POP_JUMP_IF_FALSE       36 (to 72)\n              68 LOAD_FAST               15 (return_dict)\n              70 JUMP_FORWARD             3 (to 78)\n         >>   72 LOAD_FAST                0 (self)\n              74 LOAD_ATTR                0 (config)\n              76 LOAD_ATTR                4 (use_return_dict)\n         >>   78 STORE_FAST              15 (return_dict)\n\n1257          80 LOAD_FAST                8 (encoder_outputs)\n              82 LOAD_CONST               1 (None)\n              84 IS_OP                    0\n              86 POP_JUMP_IF_FALSE       57 (to 114)\n\n1258          88 LOAD_FAST                0 (self)\n              90 LOAD_ATTR                5 (encoder)\n\n1259          92 LOAD_FAST                1 (input_ids)\n\n1260          94 LOAD_FAST                2 (attention_mask)\n\n1261          96 LOAD_FAST                5 (head_mask)\n\n1262          98 LOAD_FAST               10 (inputs_embeds)\n\n1263         100 LOAD_FAST               13 (output_attentions)\n\n1264         102 LOAD_FAST               14 (output_hidden_states)\n\n1265         104 LOAD_FAST               15 (return_dict)\n\n1258         106 LOAD_CONST               2 (('input_ids', 'attention_mask', 'head_mask', 'inputs_embeds', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             108 CALL_FUNCTION_KW         7\n             110 STORE_FAST               8 (encoder_outputs)\n             112 JUMP_FORWARD            36 (to 186)\n\n1268     >>  114 LOAD_FAST               15 (return_dict)\n             116 POP_JUMP_IF_FALSE       93 (to 186)\n             118 LOAD_GLOBAL              6 (isinstance)\n             120 LOAD_FAST                8 (encoder_outputs)\n             122 LOAD_GLOBAL              7 (BaseModelOutput)\n             124 CALL_FUNCTION            2\n             126 POP_JUMP_IF_TRUE        93 (to 186)\n\n1269         128 LOAD_GLOBAL              7 (BaseModelOutput)\n\n1270         130 LOAD_FAST                8 (encoder_outputs)\n             132 LOAD_CONST               3 (0)\n             134 BINARY_SUBSCR\n\n1271         136 LOAD_GLOBAL              8 (len)\n             138 LOAD_FAST                8 (encoder_outputs)\n             140 CALL_FUNCTION            1\n             142 LOAD_CONST               4 (1)\n             144 COMPARE_OP               4 (>)\n             146 POP_JUMP_IF_FALSE       78 (to 156)\n             148 LOAD_FAST                8 (encoder_outputs)\n             150 LOAD_CONST               4 (1)\n             152 BINARY_SUBSCR\n             154 JUMP_FORWARD             1 (to 158)\n         >>  156 LOAD_CONST               1 (None)\n\n1272     >>  158 LOAD_GLOBAL              8 (len)\n             160 LOAD_FAST                8 (encoder_outputs)\n             162 CALL_FUNCTION            1\n             164 LOAD_CONST               5 (2)\n             166 COMPARE_OP               4 (>)\n             168 POP_JUMP_IF_FALSE       89 (to 178)\n             170 LOAD_FAST                8 (encoder_outputs)\n             172 LOAD_CONST               5 (2)\n             174 BINARY_SUBSCR\n             176 JUMP_FORWARD             1 (to 180)\n         >>  178 LOAD_CONST               1 (None)\n\n1269     >>  180 LOAD_CONST               6 (('last_hidden_state', 'hidden_states', 'attentions'))\n             182 CALL_FUNCTION_KW         3\n             184 STORE_FAST               8 (encoder_outputs)\n\n1276     >>  186 LOAD_FAST                0 (self)\n             188 LOAD_ATTR                9 (decoder)\n\n1277         190 LOAD_FAST                3 (decoder_input_ids)\n\n1278         192 LOAD_FAST                4 (decoder_attention_mask)\n\n1279         194 LOAD_FAST                8 (encoder_outputs)\n             196 LOAD_CONST               3 (0)\n             198 BINARY_SUBSCR\n\n1280         200 LOAD_FAST                2 (attention_mask)\n\n1281         202 LOAD_FAST                6 (decoder_head_mask)\n\n1282         204 LOAD_FAST                7 (cross_attn_head_mask)\n\n1283         206 LOAD_FAST                9 (past_key_values)\n\n1284         208 LOAD_FAST               11 (decoder_inputs_embeds)\n\n1285         210 LOAD_FAST               12 (use_cache)\n\n1286         212 LOAD_FAST               13 (output_attentions)\n\n1287         214 LOAD_FAST               14 (output_hidden_states)\n\n1288         216 LOAD_FAST               15 (return_dict)\n\n1276         218 LOAD_CONST               7 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             220 CALL_FUNCTION_KW        12\n             222 STORE_FAST              16 (decoder_outputs)\n\n1291         224 LOAD_FAST               15 (return_dict)\n             226 POP_JUMP_IF_TRUE       118 (to 236)\n\n1292         228 LOAD_FAST               16 (decoder_outputs)\n             230 LOAD_FAST                8 (encoder_outputs)\n             232 BINARY_ADD\n             234 RETURN_VALUE\n\n1294     >>  236 LOAD_GLOBAL             10 (Seq2SeqModelOutput)\n\n1295         238 LOAD_FAST               16 (decoder_outputs)\n             240 LOAD_ATTR               11 (last_hidden_state)\n\n1296         242 LOAD_FAST               16 (decoder_outputs)\n             244 LOAD_ATTR               12 (past_key_values)\n\n1297         246 LOAD_FAST               16 (decoder_outputs)\n             248 LOAD_ATTR               13 (hidden_states)\n\n1298         250 LOAD_FAST               16 (decoder_outputs)\n             252 LOAD_ATTR               14 (attentions)\n\n1299         254 LOAD_FAST               16 (decoder_outputs)\n             256 LOAD_ATTR               15 (cross_attentions)\n\n1300         258 LOAD_FAST                8 (encoder_outputs)\n             260 LOAD_ATTR               11 (last_hidden_state)\n\n1301         262 LOAD_FAST                8 (encoder_outputs)\n             264 LOAD_ATTR               13 (hidden_states)\n\n1302         266 LOAD_FAST                8 (encoder_outputs)\n             268 LOAD_ATTR               14 (attentions)\n\n1294         270 LOAD_CONST               8 (('last_hidden_state', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             272 CALL_FUNCTION_KW         8\n             274 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 133 \n136           0 LOAD_FAST                1 (input_ids_shape)\n              2 LOAD_CONST               1 (None)\n              4 LOAD_CONST               2 (2)\n              6 BUILD_SLICE              2\n              8 BINARY_SUBSCR\n             10 UNPACK_SEQUENCE          2\n             12 STORE_FAST               3 (bsz)\n             14 STORE_FAST               4 (seq_len)\n\n137          16 LOAD_GLOBAL              0 (torch)\n             18 LOAD_ATTR                1 (arange)\n\n138          20 LOAD_FAST                2 (past_key_values_length)\n             22 LOAD_FAST                2 (past_key_values_length)\n             24 LOAD_FAST                4 (seq_len)\n             26 BINARY_ADD\n             28 LOAD_GLOBAL              0 (torch)\n             30 LOAD_ATTR                2 (long)\n             32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                3 (weight)\n             36 LOAD_ATTR                4 (device)\n\n137          38 LOAD_CONST               3 (('dtype', 'device'))\n             40 CALL_FUNCTION_KW         4\n             42 STORE_FAST               5 (positions)\n\n140          44 LOAD_GLOBAL              5 (super)\n             46 CALL_FUNCTION            0\n             48 LOAD_METHOD              6 (forward)\n             50 LOAD_FAST                5 (positions)\n             52 CALL_METHOD              1\n             54 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 316 \n334           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n335           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n336          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n337          18 LOAD_FAST                1 (hidden_states)\n\n338          20 LOAD_FAST                2 (attention_mask)\n\n339          22 LOAD_FAST                3 (layer_head_mask)\n\n340          24 LOAD_FAST                4 (output_attentions)\n\n336          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n342          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n343          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n345          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n346          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n347          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n348          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n349         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n350         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n351         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n353         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n354         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n353         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n354         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n353         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n356     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n357         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n359     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n361         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n362         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n364     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 316 \n334           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n335           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n336          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n337          18 LOAD_FAST                1 (hidden_states)\n\n338          20 LOAD_FAST                2 (attention_mask)\n\n339          22 LOAD_FAST                3 (layer_head_mask)\n\n340          24 LOAD_FAST                4 (output_attentions)\n\n336          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n342          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n343          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n345          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n346          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n347          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n348          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n349         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n350         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n351         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n353         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n354         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n353         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n354         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n353         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n356     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n357         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n359     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n361         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n362         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n364     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 316 \n334           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n335           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n336          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n337          18 LOAD_FAST                1 (hidden_states)\n\n338          20 LOAD_FAST                2 (attention_mask)\n\n339          22 LOAD_FAST                3 (layer_head_mask)\n\n340          24 LOAD_FAST                4 (output_attentions)\n\n336          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n342          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n343          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n345          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n346          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n347          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n348          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n349         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n350         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n351         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n353         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n354         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n353         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n354         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n353         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n356     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n357         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n359     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n361         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n362         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n364     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 316 \n334           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n335           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n336          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n337          18 LOAD_FAST                1 (hidden_states)\n\n338          20 LOAD_FAST                2 (attention_mask)\n\n339          22 LOAD_FAST                3 (layer_head_mask)\n\n340          24 LOAD_FAST                4 (output_attentions)\n\n336          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n342          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n343          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n345          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n346          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n347          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n348          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n349         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n350         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n351         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n353         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n354         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n353         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n354         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n353         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n356     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n357         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n359     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n361         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n362         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n364     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 316 \n334           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n335           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n336          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n337          18 LOAD_FAST                1 (hidden_states)\n\n338          20 LOAD_FAST                2 (attention_mask)\n\n339          22 LOAD_FAST                3 (layer_head_mask)\n\n340          24 LOAD_FAST                4 (output_attentions)\n\n336          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n342          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n343          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n345          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n346          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n347          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n348          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n349         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n350         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n351         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n353         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n354         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n353         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n354         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n353         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n356     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n357         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n359     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n361         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n362         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n364     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 316 \n334           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n335           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n336          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n337          18 LOAD_FAST                1 (hidden_states)\n\n338          20 LOAD_FAST                2 (attention_mask)\n\n339          22 LOAD_FAST                3 (layer_head_mask)\n\n340          24 LOAD_FAST                4 (output_attentions)\n\n336          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n342          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n343          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n345          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n346          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n347          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n348          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n349         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n350         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n351         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n353         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n354         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n353         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n354         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n353         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n356     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n357         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n359     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n361         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n362         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n364     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 316 \n334           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n335           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n336          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n337          18 LOAD_FAST                1 (hidden_states)\n\n338          20 LOAD_FAST                2 (attention_mask)\n\n339          22 LOAD_FAST                3 (layer_head_mask)\n\n340          24 LOAD_FAST                4 (output_attentions)\n\n336          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n342          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n343          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n345          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n346          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n347          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n348          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n349         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n350         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n351         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n353         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n354         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n353         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n354         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n353         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n356     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n357         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n359     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n361         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n362         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n364     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 316 \n334           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n335           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n336          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n337          18 LOAD_FAST                1 (hidden_states)\n\n338          20 LOAD_FAST                2 (attention_mask)\n\n339          22 LOAD_FAST                3 (layer_head_mask)\n\n340          24 LOAD_FAST                4 (output_attentions)\n\n336          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n342          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n343          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n345          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n346          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n347          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n348          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n349         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n350         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n351         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n353         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n354         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n353         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n354         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n353         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n356     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n357         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n359     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n361         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n362         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n364     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 316 \n334           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n335           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n336          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n337          18 LOAD_FAST                1 (hidden_states)\n\n338          20 LOAD_FAST                2 (attention_mask)\n\n339          22 LOAD_FAST                3 (layer_head_mask)\n\n340          24 LOAD_FAST                4 (output_attentions)\n\n336          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n342          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n343          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n345          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n346          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n347          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n348          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n349         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n350         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n351         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n353         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n354         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n353         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n354         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n353         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n356     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n357         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n359     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n361         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n362         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n364     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 316 \n334           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n335           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n336          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n337          18 LOAD_FAST                1 (hidden_states)\n\n338          20 LOAD_FAST                2 (attention_mask)\n\n339          22 LOAD_FAST                3 (layer_head_mask)\n\n340          24 LOAD_FAST                4 (output_attentions)\n\n336          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n342          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n343          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n345          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n346          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n347          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n348          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n349         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n350         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n351         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n353         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n354         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n353         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n354         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n353         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n356     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n357         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n359     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n361         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n362         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n364     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 316 \n334           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n335           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n336          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n337          18 LOAD_FAST                1 (hidden_states)\n\n338          20 LOAD_FAST                2 (attention_mask)\n\n339          22 LOAD_FAST                3 (layer_head_mask)\n\n340          24 LOAD_FAST                4 (output_attentions)\n\n336          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n342          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n343          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n345          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n346          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n347          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n348          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n349         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n350         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n351         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n353         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n354         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n353         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n354         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n353         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n356     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n357         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n359     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n361         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n362         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n364     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 316 \n334           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST               5 (residual)\n\n335           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n336          14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (self_attn)\n\n337          18 LOAD_FAST                1 (hidden_states)\n\n338          20 LOAD_FAST                2 (attention_mask)\n\n339          22 LOAD_FAST                3 (layer_head_mask)\n\n340          24 LOAD_FAST                4 (output_attentions)\n\n336          26 LOAD_CONST               1 (('hidden_states', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             28 CALL_FUNCTION_KW         4\n             30 UNPACK_SEQUENCE          3\n             32 STORE_FAST               1 (hidden_states)\n             34 STORE_FAST               6 (attn_weights)\n             36 STORE_FAST               7 (_)\n\n342          38 LOAD_GLOBAL              2 (nn)\n             40 LOAD_ATTR                3 (functional)\n             42 LOAD_ATTR                4 (dropout)\n             44 LOAD_FAST                1 (hidden_states)\n             46 LOAD_FAST                0 (self)\n             48 LOAD_ATTR                4 (dropout)\n             50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                5 (training)\n             54 LOAD_CONST               2 (('p', 'training'))\n             56 CALL_FUNCTION_KW         3\n             58 STORE_FAST               1 (hidden_states)\n\n343          60 LOAD_FAST                5 (residual)\n             62 LOAD_FAST                1 (hidden_states)\n             64 BINARY_ADD\n             66 STORE_FAST               1 (hidden_states)\n\n345          68 LOAD_FAST                1 (hidden_states)\n             70 STORE_FAST               5 (residual)\n\n346          72 LOAD_FAST                0 (self)\n             74 LOAD_METHOD              6 (final_layer_norm)\n             76 LOAD_FAST                1 (hidden_states)\n             78 CALL_METHOD              1\n             80 STORE_FAST               1 (hidden_states)\n\n347          82 LOAD_FAST                0 (self)\n             84 LOAD_METHOD              7 (activation_fn)\n             86 LOAD_FAST                0 (self)\n             88 LOAD_METHOD              8 (fc1)\n             90 LOAD_FAST                1 (hidden_states)\n             92 CALL_METHOD              1\n             94 CALL_METHOD              1\n             96 STORE_FAST               1 (hidden_states)\n\n348          98 LOAD_GLOBAL              2 (nn)\n            100 LOAD_ATTR                3 (functional)\n            102 LOAD_ATTR                4 (dropout)\n            104 LOAD_FAST                1 (hidden_states)\n            106 LOAD_FAST                0 (self)\n            108 LOAD_ATTR                9 (activation_dropout)\n            110 LOAD_FAST                0 (self)\n            112 LOAD_ATTR                5 (training)\n            114 LOAD_CONST               2 (('p', 'training'))\n            116 CALL_FUNCTION_KW         3\n            118 STORE_FAST               1 (hidden_states)\n\n349         120 LOAD_FAST                0 (self)\n            122 LOAD_METHOD             10 (fc2)\n            124 LOAD_FAST                1 (hidden_states)\n            126 CALL_METHOD              1\n            128 STORE_FAST               1 (hidden_states)\n\n350         130 LOAD_GLOBAL              2 (nn)\n            132 LOAD_ATTR                3 (functional)\n            134 LOAD_ATTR                4 (dropout)\n            136 LOAD_FAST                1 (hidden_states)\n            138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                4 (dropout)\n            142 LOAD_FAST                0 (self)\n            144 LOAD_ATTR                5 (training)\n            146 LOAD_CONST               2 (('p', 'training'))\n            148 CALL_FUNCTION_KW         3\n            150 STORE_FAST               1 (hidden_states)\n\n351         152 LOAD_FAST                5 (residual)\n            154 LOAD_FAST                1 (hidden_states)\n            156 BINARY_ADD\n            158 STORE_FAST               1 (hidden_states)\n\n353         160 LOAD_FAST                1 (hidden_states)\n            162 LOAD_ATTR               11 (dtype)\n            164 LOAD_GLOBAL             12 (torch)\n            166 LOAD_ATTR               13 (float16)\n            168 COMPARE_OP               2 (==)\n            170 POP_JUMP_IF_FALSE      118 (to 236)\n\n354         172 LOAD_GLOBAL             12 (torch)\n            174 LOAD_METHOD             14 (isinf)\n            176 LOAD_FAST                1 (hidden_states)\n            178 CALL_METHOD              1\n            180 LOAD_METHOD             15 (any)\n            182 CALL_METHOD              0\n\n353         184 POP_JUMP_IF_TRUE       100 (to 200)\n\n354         186 LOAD_GLOBAL             12 (torch)\n            188 LOAD_METHOD             16 (isnan)\n            190 LOAD_FAST                1 (hidden_states)\n            192 CALL_METHOD              1\n            194 LOAD_METHOD             15 (any)\n            196 CALL_METHOD              0\n\n353         198 POP_JUMP_IF_FALSE      118 (to 236)\n\n356     >>  200 LOAD_GLOBAL             12 (torch)\n            202 LOAD_METHOD             17 (finfo)\n            204 LOAD_FAST                1 (hidden_states)\n            206 LOAD_ATTR               11 (dtype)\n            208 CALL_METHOD              1\n            210 LOAD_ATTR               18 (max)\n            212 LOAD_CONST               3 (1000)\n            214 BINARY_SUBTRACT\n            216 STORE_FAST               8 (clamp_value)\n\n357         218 LOAD_GLOBAL             12 (torch)\n            220 LOAD_ATTR               19 (clamp)\n            222 LOAD_FAST                1 (hidden_states)\n            224 LOAD_FAST                8 (clamp_value)\n            226 UNARY_NEGATIVE\n            228 LOAD_FAST                8 (clamp_value)\n            230 LOAD_CONST               4 (('min', 'max'))\n            232 CALL_FUNCTION_KW         3\n            234 STORE_FAST               1 (hidden_states)\n\n359     >>  236 LOAD_FAST                1 (hidden_states)\n            238 BUILD_TUPLE              1\n            240 STORE_FAST               9 (outputs)\n\n361         242 LOAD_FAST                4 (output_attentions)\n            244 POP_JUMP_IF_FALSE      128 (to 256)\n\n362         246 LOAD_FAST                9 (outputs)\n            248 LOAD_FAST                6 (attn_weights)\n            250 BUILD_TUPLE              1\n            252 INPLACE_ADD\n            254 STORE_FAST               9 (outputs)\n\n364     >>  256 LOAD_FAST                9 (outputs)\n            258 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (hidden_states)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (hidden_states)\n\n  5          12 LOAD_FAST                3 (attentions)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (attentions)\n\n  6          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              3 (__post_init__)\n             22 CALL_METHOD              0\n             24 POP_TOP\n             26 LOAD_CONST               0 (None)\n             28 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 1258 \n1258           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           57 (to 114)\n               4 LOAD_FAST               10 (output_attentions)\n               6 LOAD_CONST               1 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST               10 (output_attentions)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (output_attentions)\n         >>   22 STORE_FAST              10 (output_attentions)\n              24 LOAD_FAST               11 (output_hidden_states)\n              26 LOAD_CONST               1 (None)\n              28 IS_OP                    1\n              30 POP_JUMP_IF_FALSE       18 (to 36)\n              32 LOAD_FAST               11 (output_hidden_states)\n              34 JUMP_FORWARD             3 (to 42)\n         >>   36 LOAD_FAST                1 (self)\n              38 LOAD_ATTR                0 (config)\n              40 LOAD_ATTR                2 (output_hidden_states)\n         >>   42 STORE_FAST              11 (output_hidden_states)\n              44 LOAD_FAST                9 (use_cache)\n              46 LOAD_CONST               1 (None)\n              48 IS_OP                    1\n              50 POP_JUMP_IF_FALSE       28 (to 56)\n              52 LOAD_FAST                9 (use_cache)\n              54 JUMP_FORWARD             3 (to 62)\n         >>   56 LOAD_FAST                1 (self)\n              58 LOAD_ATTR                0 (config)\n              60 LOAD_ATTR                3 (use_cache)\n         >>   62 STORE_FAST               9 (use_cache)\n              64 LOAD_FAST               12 (return_dict)\n              66 LOAD_CONST               1 (None)\n              68 IS_OP                    1\n              70 POP_JUMP_IF_FALSE       38 (to 76)\n              72 LOAD_FAST               12 (return_dict)\n              74 JUMP_FORWARD             3 (to 82)\n         >>   76 LOAD_FAST                1 (self)\n              78 LOAD_ATTR                0 (config)\n              80 LOAD_ATTR                4 (use_return_dict)\n         >>   82 STORE_FAST              12 (return_dict)\n              84 LOAD_FAST               15 (encoder_outputs)\n              86 LOAD_CONST               1 (None)\n              88 IS_OP                    0\n              90 POP_JUMP_IF_FALSE       59 (to 118)\n              92 LOAD_FAST                1 (self)\n              94 LOAD_ATTR                5 (encoder)\n              96 LOAD_FAST               13 (input_ids)\n              98 LOAD_FAST                2 (attention_mask)\n             100 LOAD_FAST               14 (head_mask)\n             102 LOAD_FAST               16 (inputs_embeds)\n             104 LOAD_FAST               10 (output_attentions)\n             106 LOAD_FAST               11 (output_hidden_states)\n             108 LOAD_FAST               12 (return_dict)\n             110 LOAD_CONST               2 (('input_ids', 'attention_mask', 'head_mask', 'inputs_embeds', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             112 CALL_FUNCTION_KW         7\n         >>  114 STORE_FAST              15 (encoder_outputs)\n             116 JUMP_FORWARD            36 (to 190)\n\n1268     >>  118 LOAD_FAST               12 (return_dict)\n             120 POP_JUMP_IF_FALSE       95 (to 190)\n             122 LOAD_GLOBAL              6 (isinstance)\n             124 LOAD_FAST               15 (encoder_outputs)\n             126 LOAD_GLOBAL              7 (BaseModelOutput)\n             128 CALL_FUNCTION            2\n             130 POP_JUMP_IF_TRUE        95 (to 190)\n\n1269         132 LOAD_GLOBAL              7 (BaseModelOutput)\n\n1270         134 LOAD_FAST               15 (encoder_outputs)\n             136 LOAD_CONST               3 (0)\n             138 BINARY_SUBSCR\n\n1271         140 LOAD_GLOBAL              8 (len)\n             142 LOAD_FAST               15 (encoder_outputs)\n             144 CALL_FUNCTION            1\n             146 LOAD_CONST               4 (1)\n             148 COMPARE_OP               4 (>)\n             150 POP_JUMP_IF_FALSE       80 (to 160)\n             152 LOAD_FAST               15 (encoder_outputs)\n             154 LOAD_CONST               4 (1)\n             156 BINARY_SUBSCR\n             158 JUMP_FORWARD             1 (to 162)\n         >>  160 LOAD_CONST               1 (None)\n\n1272     >>  162 LOAD_GLOBAL              8 (len)\n             164 LOAD_FAST               15 (encoder_outputs)\n             166 CALL_FUNCTION            1\n             168 LOAD_CONST               5 (2)\n             170 COMPARE_OP               4 (>)\n             172 POP_JUMP_IF_FALSE       91 (to 182)\n             174 LOAD_FAST               15 (encoder_outputs)\n             176 LOAD_CONST               5 (2)\n             178 BINARY_SUBSCR\n             180 JUMP_FORWARD             1 (to 184)\n         >>  182 LOAD_CONST               1 (None)\n\n1269     >>  184 LOAD_CONST               6 (('last_hidden_state', 'hidden_states', 'attentions'))\n             186 CALL_FUNCTION_KW         3\n             188 STORE_FAST              15 (encoder_outputs)\n\n1276     >>  190 LOAD_FAST                1 (self)\n             192 LOAD_ATTR                9 (decoder)\n\n1277         194 LOAD_FAST                3 (decoder_input_ids)\n\n1278         196 LOAD_FAST                4 (decoder_attention_mask)\n\n1279         198 LOAD_FAST               15 (encoder_outputs)\n             200 LOAD_CONST               3 (0)\n             202 BINARY_SUBSCR\n\n1280         204 LOAD_FAST                2 (attention_mask)\n\n1281         206 LOAD_FAST                5 (decoder_head_mask)\n\n1282         208 LOAD_FAST                6 (cross_attn_head_mask)\n\n1283         210 LOAD_FAST                7 (past_key_values)\n\n1284         212 LOAD_FAST                8 (decoder_inputs_embeds)\n\n1285         214 LOAD_FAST                9 (use_cache)\n\n1286         216 LOAD_FAST               10 (output_attentions)\n\n1287         218 LOAD_FAST               11 (output_hidden_states)\n\n1288         220 LOAD_FAST               12 (return_dict)\n\n1276         222 LOAD_CONST               7 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             224 CALL_FUNCTION_KW        12\n             226 STORE_FAST              17 (decoder_outputs)\n\n1291         228 LOAD_FAST               12 (return_dict)\n             230 POP_JUMP_IF_TRUE       120 (to 240)\n\n1292         232 LOAD_FAST               17 (decoder_outputs)\n             234 LOAD_FAST               15 (encoder_outputs)\n             236 BINARY_ADD\n             238 RETURN_VALUE\n\n1294     >>  240 LOAD_GLOBAL             10 (Seq2SeqModelOutput)\n\n1295         242 LOAD_FAST               17 (decoder_outputs)\n             244 LOAD_ATTR               11 (last_hidden_state)\n\n1296         246 LOAD_FAST               17 (decoder_outputs)\n             248 LOAD_ATTR               12 (past_key_values)\n\n1297         250 LOAD_FAST               17 (decoder_outputs)\n             252 LOAD_ATTR               13 (hidden_states)\n\n1298         254 LOAD_FAST               17 (decoder_outputs)\n             256 LOAD_ATTR               14 (attentions)\n\n1299         258 LOAD_FAST               17 (decoder_outputs)\n             260 LOAD_ATTR               15 (cross_attentions)\n\n1300         262 LOAD_FAST               15 (encoder_outputs)\n             264 LOAD_ATTR               11 (last_hidden_state)\n\n1301         266 LOAD_FAST               15 (encoder_outputs)\n             268 LOAD_ATTR               13 (hidden_states)\n\n1302         270 LOAD_FAST               15 (encoder_outputs)\n             272 LOAD_ATTR               14 (attentions)\n\n1294         274 LOAD_CONST               8 (('last_hidden_state', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             276 CALL_FUNCTION_KW         8\n             278 RETURN_VALUE\n\n", "ORIGINAL BYTECODE _prepare_decoder_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 884 \n887           0 LOAD_CONST               0 (None)\n              2 STORE_FAST               5 (combined_attention_mask)\n\n888           4 LOAD_FAST                2 (input_shape)\n              6 LOAD_CONST               1 (-1)\n              8 BINARY_SUBSCR\n             10 LOAD_CONST               2 (1)\n             12 COMPARE_OP               4 (>)\n             14 POP_JUMP_IF_FALSE       18 (to 36)\n\n889          16 LOAD_GLOBAL              0 (_make_causal_mask)\n\n890          18 LOAD_FAST                2 (input_shape)\n\n891          20 LOAD_FAST                3 (inputs_embeds)\n             22 LOAD_ATTR                1 (dtype)\n\n892          24 LOAD_FAST                3 (inputs_embeds)\n             26 LOAD_ATTR                2 (device)\n\n893          28 LOAD_FAST                4 (past_key_values_length)\n\n889          30 LOAD_CONST               3 (('device', 'past_key_values_length'))\n             32 CALL_FUNCTION_KW         4\n             34 STORE_FAST               5 (combined_attention_mask)\n\n896     >>   36 LOAD_FAST                1 (attention_mask)\n             38 LOAD_CONST               0 (None)\n             40 IS_OP                    1\n             42 POP_JUMP_IF_FALSE       46 (to 92)\n\n898          44 LOAD_GLOBAL              3 (_expand_mask)\n             46 LOAD_FAST                1 (attention_mask)\n             48 LOAD_FAST                3 (inputs_embeds)\n             50 LOAD_ATTR                1 (dtype)\n             52 LOAD_FAST                2 (input_shape)\n             54 LOAD_CONST               1 (-1)\n             56 BINARY_SUBSCR\n             58 LOAD_CONST               4 (('tgt_len',))\n             60 CALL_FUNCTION_KW         3\n             62 LOAD_METHOD              4 (to)\n\n899          64 LOAD_FAST                3 (inputs_embeds)\n             66 LOAD_ATTR                2 (device)\n\n898          68 CALL_METHOD              1\n             70 STORE_FAST               6 (expanded_attn_mask)\n\n902          72 LOAD_FAST                5 (combined_attention_mask)\n             74 LOAD_CONST               0 (None)\n             76 IS_OP                    0\n             78 POP_JUMP_IF_FALSE       42 (to 84)\n             80 LOAD_FAST                6 (expanded_attn_mask)\n             82 JUMP_FORWARD             3 (to 90)\n        >>   84 LOAD_FAST                6 (expanded_attn_mask)\n             86 LOAD_FAST                5 (combined_attention_mask)\n             88 BINARY_ADD\n\n901     >>   90 STORE_FAST               5 (combined_attention_mask)\n\n905     >>   92 LOAD_FAST                5 (combined_attention_mask)\n             94 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 133 \n136           0 LOAD_FAST                1 (input_ids_shape)\n              2 LOAD_CONST               1 (None)\n              4 LOAD_CONST               2 (2)\n              6 BUILD_SLICE              2\n              8 BINARY_SUBSCR\n             10 UNPACK_SEQUENCE          2\n             12 STORE_FAST               3 (bsz)\n             14 STORE_FAST               4 (seq_len)\n\n137          16 LOAD_GLOBAL              0 (torch)\n             18 LOAD_ATTR                1 (arange)\n\n138          20 LOAD_FAST                2 (past_key_values_length)\n             22 LOAD_FAST                2 (past_key_values_length)\n             24 LOAD_FAST                4 (seq_len)\n             26 BINARY_ADD\n             28 LOAD_GLOBAL              0 (torch)\n             30 LOAD_ATTR                2 (long)\n             32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                3 (weight)\n             36 LOAD_ATTR                4 (device)\n\n137          38 LOAD_CONST               3 (('dtype', 'device'))\n             40 CALL_FUNCTION_KW         4\n             42 STORE_FAST               5 (positions)\n\n140          44 LOAD_GLOBAL              5 (super)\n             46 CALL_FUNCTION            0\n             48 LOAD_METHOD              6 (forward)\n             50 LOAD_FAST                5 (positions)\n             52 CALL_METHOD              1\n             54 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 395 \n425           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n426           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n430          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n432          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n433          42 LOAD_FAST                1 (hidden_states)\n\n434          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n435          46 LOAD_FAST                2 (attention_mask)\n\n436          48 LOAD_FAST                5 (layer_head_mask)\n\n437          50 LOAD_FAST                8 (output_attentions)\n\n432          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n439          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n440          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n443          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n444          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n445         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n446         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n447         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n450         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n451         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n452         152 LOAD_FAST                1 (hidden_states)\n\n453         154 LOAD_FAST                3 (encoder_hidden_states)\n\n454         156 LOAD_FAST                4 (encoder_attention_mask)\n\n455         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n456         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n457         162 LOAD_FAST                8 (output_attentions)\n\n451         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n459         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n460         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n463         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n466     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n467         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n468         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n469         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n470         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n471         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n472         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n474         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n476         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n477         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n479     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n480         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n482     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (past_key_values)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (past_key_values)\n\n  5          12 LOAD_FAST                3 (hidden_states)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (hidden_states)\n\n  6          18 LOAD_FAST                4 (attentions)\n             20 LOAD_FAST                0 (self)\n             22 STORE_ATTR               3 (attentions)\n\n  7          24 LOAD_FAST                5 (cross_attentions)\n             26 LOAD_FAST                0 (self)\n             28 STORE_ATTR               4 (cross_attentions)\n\n  8          30 LOAD_FAST                0 (self)\n             32 LOAD_METHOD              5 (__post_init__)\n             34 CALL_METHOD              0\n             36 POP_TOP\n             38 LOAD_CONST               0 (None)\n             40 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (past_key_values)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (past_key_values)\n\n  5          12 LOAD_FAST                3 (decoder_hidden_states)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (decoder_hidden_states)\n\n  6          18 LOAD_FAST                4 (decoder_attentions)\n             20 LOAD_FAST                0 (self)\n             22 STORE_ATTR               3 (decoder_attentions)\n\n  7          24 LOAD_FAST                5 (cross_attentions)\n             26 LOAD_FAST                0 (self)\n             28 STORE_ATTR               4 (cross_attentions)\n\n  8          30 LOAD_FAST                6 (encoder_last_hidden_state)\n             32 LOAD_FAST                0 (self)\n             34 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          36 LOAD_FAST                7 (encoder_hidden_states)\n             38 LOAD_FAST                0 (self)\n             40 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          42 LOAD_FAST                8 (encoder_attentions)\n             44 LOAD_FAST                0 (self)\n             46 STORE_ATTR               7 (encoder_attentions)\n\n 11          48 LOAD_FAST                0 (self)\n             50 LOAD_METHOD              8 (__post_init__)\n             52 CALL_METHOD              0\n             54 POP_TOP\n             56 LOAD_CONST               0 (None)\n             58 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 3 \n  3           0 JUMP_ABSOLUTE            4 (to 8)\n              2 LOAD_FAST                8 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n\n  4     >>    8 LOAD_FAST                1 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5          14 LOAD_FAST                2 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n\n  6          20 LOAD_FAST                3 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7          26 LOAD_FAST                4 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                5 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                6 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                7 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 4 \n  4           0 JUMP_ABSOLUTE            7 (to 14)\n              2 LOAD_FAST                7 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                8 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5     >>   14 LOAD_FAST                1 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n\n  6          20 LOAD_FAST                2 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7          26 LOAD_FAST                3 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                4 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                5 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                6 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 5 \n  5           0 JUMP_ABSOLUTE           10 (to 20)\n              2 LOAD_FAST                6 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                7 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n             14 LOAD_FAST                8 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n\n  6     >>   20 LOAD_FAST                1 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7          26 LOAD_FAST                2 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                3 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                4 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                5 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 6 \n  6           0 JUMP_ABSOLUTE           13 (to 26)\n              2 LOAD_FAST                5 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                6 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n             14 LOAD_FAST                7 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n             20 LOAD_FAST                8 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n\n  7     >>   26 LOAD_FAST                1 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                2 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                3 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                4 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 7 \n  7           0 JUMP_ABSOLUTE           16 (to 32)\n              2 LOAD_FAST                4 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n              8 LOAD_FAST                5 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n             14 LOAD_FAST                6 (decoder_hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (decoder_hidden_states)\n             20 LOAD_FAST                7 (decoder_attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (decoder_attentions)\n             26 LOAD_FAST                8 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8     >>   32 LOAD_FAST                1 (encoder_last_hidden_state)\n             34 LOAD_FAST                0 (self)\n             36 STORE_ATTR               5 (encoder_last_hidden_state)\n\n  9          38 LOAD_FAST                2 (encoder_hidden_states)\n             40 LOAD_FAST                0 (self)\n             42 STORE_ATTR               6 (encoder_hidden_states)\n\n 10          44 LOAD_FAST                3 (encoder_attentions)\n             46 LOAD_FAST                0 (self)\n             48 STORE_ATTR               7 (encoder_attentions)\n\n 11          50 LOAD_FAST                0 (self)\n             52 LOAD_ATTR                8 (__post_init__)\n             54 CALL_FUNCTION            0\n             56 POP_TOP\n             58 LOAD_CONST               0 (None)\n             60 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py line 1414 \n1414           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           62 (to 124)\n               4 LOAD_FAST                3 (return_dict)\n               6 LOAD_CONST               1 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST                3 (return_dict)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (use_return_dict)\n         >>   22 STORE_FAST               3 (return_dict)\n              24 LOAD_FAST                2 (labels)\n              26 LOAD_CONST               1 (None)\n              28 IS_OP                    1\n              30 POP_JUMP_IF_FALSE       43 (to 86)\n              32 LOAD_FAST               15 (use_cache)\n              34 POP_JUMP_IF_FALSE       23 (to 46)\n              36 LOAD_GLOBAL              2 (logger)\n              38 LOAD_ATTR                3 (warning)\n              40 LOAD_CONST               2 ('The `use_cache` argument is changed to `False` since `labels` is provided.')\n              42 CALL_FUNCTION            1\n              44 POP_TOP\n         >>   46 LOAD_CONST               3 (False)\n              48 STORE_FAST              15 (use_cache)\n              50 LOAD_FAST                6 (decoder_input_ids)\n              52 LOAD_CONST               1 (None)\n              54 IS_OP                    0\n              56 POP_JUMP_IF_FALSE       43 (to 86)\n              58 LOAD_FAST               14 (decoder_inputs_embeds)\n              60 LOAD_CONST               1 (None)\n              62 IS_OP                    0\n              64 POP_JUMP_IF_FALSE       43 (to 86)\n              66 LOAD_GLOBAL              4 (shift_tokens_right)\n              68 LOAD_FAST                2 (labels)\n              70 LOAD_FAST                1 (self)\n              72 LOAD_ATTR                0 (config)\n              74 LOAD_ATTR                5 (pad_token_id)\n              76 LOAD_FAST                1 (self)\n              78 LOAD_ATTR                0 (config)\n              80 LOAD_ATTR                6 (decoder_start_token_id)\n              82 CALL_FUNCTION            3\n              84 STORE_FAST               6 (decoder_input_ids)\n         >>   86 LOAD_FAST                1 (self)\n              88 LOAD_ATTR                7 (model)\n              90 LOAD_FAST                4 (input_ids)\n              92 LOAD_FAST                5 (attention_mask)\n              94 LOAD_FAST                6 (decoder_input_ids)\n              96 LOAD_FAST               11 (encoder_outputs)\n              98 LOAD_FAST                7 (decoder_attention_mask)\n             100 LOAD_FAST                8 (head_mask)\n             102 LOAD_FAST                9 (decoder_head_mask)\n             104 LOAD_FAST               10 (cross_attn_head_mask)\n             106 LOAD_FAST               12 (past_key_values)\n             108 LOAD_FAST               13 (inputs_embeds)\n             110 LOAD_FAST               14 (decoder_inputs_embeds)\n             112 LOAD_FAST               15 (use_cache)\n             114 LOAD_FAST               16 (output_attentions)\n             116 LOAD_FAST               17 (output_hidden_states)\n             118 LOAD_FAST                3 (return_dict)\n             120 LOAD_CONST               4 (('attention_mask', 'decoder_input_ids', 'encoder_outputs', 'decoder_attention_mask', 'head_mask', 'decoder_head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'decoder_inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             122 CALL_FUNCTION_KW        15\n         >>  124 STORE_FAST              18 (outputs)\n\n1431         126 LOAD_FAST                1 (self)\n             128 LOAD_ATTR                8 (lm_head)\n             130 LOAD_FAST               18 (outputs)\n             132 LOAD_CONST               5 (0)\n             134 BINARY_SUBSCR\n             136 CALL_FUNCTION            1\n             138 LOAD_FAST                1 (self)\n             140 LOAD_ATTR                9 (final_logits_bias)\n             142 BINARY_ADD\n             144 STORE_FAST              19 (lm_logits)\n\n1433         146 LOAD_CONST               1 (None)\n             148 STORE_FAST              20 (masked_lm_loss)\n\n1434         150 LOAD_FAST                2 (labels)\n             152 LOAD_CONST               1 (None)\n             154 IS_OP                    1\n             156 POP_JUMP_IF_FALSE       96 (to 192)\n\n1435         158 LOAD_GLOBAL             10 (CrossEntropyLoss)\n             160 CALL_FUNCTION            0\n             162 STORE_FAST              21 (loss_fct)\n\n1436         164 LOAD_FAST               21 (loss_fct)\n             166 LOAD_FAST               19 (lm_logits)\n             168 LOAD_ATTR               11 (view)\n             170 LOAD_CONST               6 (-1)\n             172 LOAD_FAST                1 (self)\n             174 LOAD_ATTR                0 (config)\n             176 LOAD_ATTR               12 (vocab_size)\n             178 CALL_FUNCTION            2\n             180 LOAD_FAST                2 (labels)\n             182 LOAD_ATTR               11 (view)\n             184 LOAD_CONST               6 (-1)\n             186 CALL_FUNCTION            1\n             188 CALL_FUNCTION            2\n             190 STORE_FAST              20 (masked_lm_loss)\n\n1438     >>  192 LOAD_FAST                3 (return_dict)\n             194 POP_JUMP_IF_TRUE       118 (to 236)\n\n1439         196 LOAD_FAST               19 (lm_logits)\n             198 BUILD_TUPLE              1\n             200 LOAD_FAST               18 (outputs)\n             202 LOAD_CONST               7 (1)\n             204 LOAD_CONST               1 (None)\n             206 BUILD_SLICE              2\n             208 BINARY_SUBSCR\n             210 BINARY_ADD\n             212 STORE_FAST              22 (output)\n\n1440         214 LOAD_FAST               20 (masked_lm_loss)\n             216 LOAD_CONST               1 (None)\n             218 IS_OP                    1\n             220 POP_JUMP_IF_FALSE      116 (to 232)\n             222 LOAD_FAST               20 (masked_lm_loss)\n             224 BUILD_TUPLE              1\n             226 LOAD_FAST               22 (output)\n             228 BINARY_ADD\n             230 RETURN_VALUE\n         >>  232 LOAD_FAST               22 (output)\n             234 RETURN_VALUE\n\n1442     >>  236 LOAD_GLOBAL             13 (Seq2SeqLMOutput)\n\n1443         238 LOAD_FAST               20 (masked_lm_loss)\n\n1444         240 LOAD_FAST               19 (lm_logits)\n\n1445         242 LOAD_FAST               18 (outputs)\n             244 LOAD_ATTR               14 (past_key_values)\n\n1446         246 LOAD_FAST               18 (outputs)\n             248 LOAD_ATTR               15 (decoder_hidden_states)\n\n1447         250 LOAD_FAST               18 (outputs)\n             252 LOAD_ATTR               16 (decoder_attentions)\n\n1448         254 LOAD_FAST               18 (outputs)\n             256 LOAD_ATTR               17 (cross_attentions)\n\n1449         258 LOAD_FAST               18 (outputs)\n             260 LOAD_ATTR               18 (encoder_last_hidden_state)\n\n1450         262 LOAD_FAST               18 (outputs)\n             264 LOAD_ATTR               19 (encoder_hidden_states)\n\n1451         266 LOAD_FAST               18 (outputs)\n             268 LOAD_ATTR               20 (encoder_attentions)\n\n1442         270 LOAD_CONST               8 (('loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'))\n             272 CALL_FUNCTION_KW         9\n             274 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 557 \n557           0 LOAD_FAST                0 (___stack0)\n              2 CALL_FUNCTION            0\n              4 SETUP_WITH              10 (to 26)\n              6 POP_TOP\n              8 LOAD_FAST                1 (___stack1)\n             10 JUMP_ABSOLUTE           44 (to 88)\n             12 POP_BLOCK\n             14 LOAD_CONST               0 (None)\n             16 DUP_TOP\n             18 DUP_TOP\n             20 CALL_FUNCTION            3\n             22 POP_TOP\n             24 JUMP_FORWARD             8 (to 42)\n        >>   26 WITH_EXCEPT_START\n             28 POP_JUMP_IF_TRUE        16 (to 32)\n             30 RERAISE                  0\n        >>   32 POP_TOP\n             34 POP_TOP\n             36 POP_TOP\n             38 POP_EXCEPT\n             40 POP_TOP\n        >>   42 NOP\n             44 LOAD_CONST               0 (None)\n             46 RAISE_VARARGS            1\n             48 LOAD_GLOBAL              0 (clone_inputs)\n             50 LOAD_FAST                6 (inputs)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (cloned_inputs)\n             56 LOAD_FAST                2 (self)\n             58 LOAD_ATTR                1 (optimizer_zero_grad)\n             60 LOAD_FAST                3 (mod)\n             62 CALL_FUNCTION            1\n             64 POP_TOP\n             66 LOAD_FAST                2 (self)\n             68 LOAD_ATTR                2 (autocast)\n             70 CALL_FUNCTION            0\n             72 SETUP_WITH              20 (to 114)\n             74 POP_TOP\n             76 LOAD_FAST                3 (mod)\n             78 LOAD_CONST               1 (())\n             80 BUILD_MAP                0\n             82 LOAD_FAST                5 (cloned_inputs)\n             84 DICT_MERGE               1\n             86 CALL_FUNCTION_EX         1\n        >>   88 STORE_FAST               7 (pred)\n\n558          90 LOAD_FAST                2 (self)\n             92 LOAD_ATTR                3 (compute_loss)\n             94 LOAD_FAST                7 (pred)\n             96 CALL_FUNCTION            1\n             98 STORE_FAST               8 (loss)\n            100 POP_BLOCK\n\n556         102 LOAD_CONST               0 (None)\n            104 DUP_TOP\n            106 DUP_TOP\n            108 CALL_FUNCTION            3\n            110 POP_TOP\n            112 JUMP_FORWARD             8 (to 130)\n        >>  114 WITH_EXCEPT_START\n            116 POP_JUMP_IF_TRUE        60 (to 120)\n            118 RERAISE                  1\n        >>  120 POP_TOP\n            122 POP_TOP\n            124 POP_TOP\n            126 POP_EXCEPT\n            128 POP_TOP\n\n559     >>  130 LOAD_FAST                2 (self)\n            132 LOAD_ATTR                4 (grad_scaler)\n            134 LOAD_ATTR                5 (scale)\n            136 LOAD_FAST                8 (loss)\n            138 CALL_FUNCTION            1\n            140 LOAD_ATTR                6 (backward)\n            142 CALL_FUNCTION            0\n            144 POP_TOP\n\n560         146 LOAD_FAST                2 (self)\n            148 LOAD_ATTR                7 (optimizer_step)\n            150 CALL_FUNCTION            0\n            152 POP_TOP\n\n561         154 LOAD_FAST                4 (collect_outputs)\n            156 POP_JUMP_IF_FALSE       86 (to 172)\n\n562         158 LOAD_GLOBAL              8 (collect_results)\n            160 LOAD_FAST                3 (mod)\n            162 LOAD_FAST                7 (pred)\n            164 LOAD_FAST                8 (loss)\n            166 LOAD_FAST                5 (cloned_inputs)\n            168 CALL_FUNCTION            4\n            170 RETURN_VALUE\n\n563     >>  172 LOAD_CONST               0 (None)\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py line 896 \n 958           0 LOAD_FAST               14 (return_dict)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               14 (return_dict)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (use_return_dict)\n         >>   18 STORE_FAST              14 (return_dict)\n\n 959          20 LOAD_FAST                9 (labels)\n              22 LOAD_CONST               1 (None)\n              24 IS_OP                    1\n              26 POP_JUMP_IF_FALSE       16 (to 32)\n\n 960          28 LOAD_CONST               2 (False)\n              30 STORE_FAST              11 (use_cache)\n\n 962     >>   32 LOAD_FAST                0 (self)\n              34 LOAD_ATTR                2 (roberta)\n\n 963          36 LOAD_FAST                1 (input_ids)\n\n 964          38 LOAD_FAST                2 (attention_mask)\n\n 965          40 LOAD_FAST                3 (token_type_ids)\n\n 966          42 LOAD_FAST                4 (position_ids)\n\n 967          44 LOAD_FAST                5 (head_mask)\n\n 968          46 LOAD_FAST                6 (inputs_embeds)\n\n 969          48 LOAD_FAST                7 (encoder_hidden_states)\n\n 970          50 LOAD_FAST                8 (encoder_attention_mask)\n\n 971          52 LOAD_FAST               10 (past_key_values)\n\n 972          54 LOAD_FAST               11 (use_cache)\n\n 973          56 LOAD_FAST               12 (output_attentions)\n\n 974          58 LOAD_FAST               13 (output_hidden_states)\n\n 975          60 LOAD_FAST               14 (return_dict)\n\n 962          62 LOAD_CONST               3 (('attention_mask', 'token_type_ids', 'position_ids', 'head_mask', 'inputs_embeds', 'encoder_hidden_states', 'encoder_attention_mask', 'past_key_values', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              64 CALL_FUNCTION_KW        13\n              66 STORE_FAST              15 (outputs)\n\n 978          68 LOAD_FAST               15 (outputs)\n              70 LOAD_CONST               4 (0)\n              72 BINARY_SUBSCR\n              74 STORE_FAST              16 (sequence_output)\n\n 979          76 LOAD_FAST                0 (self)\n              78 LOAD_METHOD              3 (lm_head)\n              80 LOAD_FAST               16 (sequence_output)\n              82 CALL_METHOD              1\n              84 STORE_FAST              17 (prediction_scores)\n\n 981          86 LOAD_CONST               1 (None)\n              88 STORE_FAST              18 (lm_loss)\n\n 982          90 LOAD_FAST                9 (labels)\n              92 LOAD_CONST               1 (None)\n              94 IS_OP                    1\n              96 POP_JUMP_IF_FALSE       99 (to 198)\n\n 984          98 LOAD_FAST                9 (labels)\n             100 LOAD_METHOD              4 (to)\n             102 LOAD_FAST               17 (prediction_scores)\n             104 LOAD_ATTR                5 (device)\n             106 CALL_METHOD              1\n             108 STORE_FAST               9 (labels)\n\n 986         110 LOAD_FAST               17 (prediction_scores)\n             112 LOAD_CONST               1 (None)\n             114 LOAD_CONST               1 (None)\n             116 BUILD_SLICE              2\n             118 LOAD_CONST               1 (None)\n             120 LOAD_CONST               5 (-1)\n             122 BUILD_SLICE              2\n             124 LOAD_CONST               1 (None)\n             126 LOAD_CONST               1 (None)\n             128 BUILD_SLICE              2\n             130 BUILD_TUPLE              3\n             132 BINARY_SUBSCR\n             134 LOAD_METHOD              6 (contiguous)\n             136 CALL_METHOD              0\n             138 STORE_FAST              19 (shifted_prediction_scores)\n\n 987         140 LOAD_FAST                9 (labels)\n             142 LOAD_CONST               1 (None)\n             144 LOAD_CONST               1 (None)\n             146 BUILD_SLICE              2\n             148 LOAD_CONST               6 (1)\n             150 LOAD_CONST               1 (None)\n             152 BUILD_SLICE              2\n             154 BUILD_TUPLE              2\n             156 BINARY_SUBSCR\n             158 LOAD_METHOD              6 (contiguous)\n             160 CALL_METHOD              0\n             162 STORE_FAST               9 (labels)\n\n 988         164 LOAD_GLOBAL              7 (CrossEntropyLoss)\n             166 CALL_FUNCTION            0\n             168 STORE_FAST              20 (loss_fct)\n\n 989         170 LOAD_FAST               20 (loss_fct)\n             172 LOAD_FAST               19 (shifted_prediction_scores)\n             174 LOAD_METHOD              8 (view)\n             176 LOAD_CONST               5 (-1)\n             178 LOAD_FAST                0 (self)\n             180 LOAD_ATTR                0 (config)\n             182 LOAD_ATTR                9 (vocab_size)\n             184 CALL_METHOD              2\n             186 LOAD_FAST                9 (labels)\n             188 LOAD_METHOD              8 (view)\n             190 LOAD_CONST               5 (-1)\n             192 CALL_METHOD              1\n             194 CALL_FUNCTION            2\n             196 STORE_FAST              18 (lm_loss)\n\n 991     >>  198 LOAD_FAST               14 (return_dict)\n             200 POP_JUMP_IF_TRUE       121 (to 242)\n\n 992         202 LOAD_FAST               17 (prediction_scores)\n             204 BUILD_TUPLE              1\n             206 LOAD_FAST               15 (outputs)\n             208 LOAD_CONST               7 (2)\n             210 LOAD_CONST               1 (None)\n             212 BUILD_SLICE              2\n             214 BINARY_SUBSCR\n             216 BINARY_ADD\n             218 STORE_FAST              21 (output)\n\n 993         220 LOAD_FAST               18 (lm_loss)\n             222 LOAD_CONST               1 (None)\n             224 IS_OP                    1\n             226 POP_JUMP_IF_FALSE      119 (to 238)\n             228 LOAD_FAST               18 (lm_loss)\n             230 BUILD_TUPLE              1\n             232 LOAD_FAST               21 (output)\n             234 BINARY_ADD\n             236 RETURN_VALUE\n         >>  238 LOAD_FAST               21 (output)\n             240 RETURN_VALUE\n\n 995     >>  242 LOAD_GLOBAL             10 (CausalLMOutputWithCrossAttentions)\n\n 996         244 LOAD_FAST               18 (lm_loss)\n\n 997         246 LOAD_FAST               17 (prediction_scores)\n\n 998         248 LOAD_FAST               15 (outputs)\n             250 LOAD_ATTR               11 (past_key_values)\n\n 999         252 LOAD_FAST               15 (outputs)\n             254 LOAD_ATTR               12 (hidden_states)\n\n1000         256 LOAD_FAST               15 (outputs)\n             258 LOAD_ATTR               13 (attentions)\n\n1001         260 LOAD_FAST               15 (outputs)\n             262 LOAD_ATTR               14 (cross_attentions)\n\n 995         264 LOAD_CONST               8 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n             266 CALL_FUNCTION_KW         6\n             268 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py line 734 \n777           0 LOAD_FAST               11 (output_attentions)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    1\n              6 POP_JUMP_IF_FALSE        6 (to 12)\n              8 LOAD_FAST               11 (output_attentions)\n             10 JUMP_FORWARD             3 (to 18)\n        >>   12 LOAD_FAST                0 (self)\n             14 LOAD_ATTR                0 (config)\n             16 LOAD_ATTR                1 (output_attentions)\n        >>   18 STORE_FAST              11 (output_attentions)\n\n779          20 LOAD_FAST               12 (output_hidden_states)\n             22 LOAD_CONST               1 (None)\n             24 IS_OP                    1\n             26 POP_JUMP_IF_FALSE       16 (to 32)\n             28 LOAD_FAST               12 (output_hidden_states)\n             30 JUMP_FORWARD             3 (to 38)\n        >>   32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                0 (config)\n             36 LOAD_ATTR                2 (output_hidden_states)\n\n778     >>   38 STORE_FAST              12 (output_hidden_states)\n\n781          40 LOAD_FAST               13 (return_dict)\n             42 LOAD_CONST               1 (None)\n             44 IS_OP                    1\n             46 POP_JUMP_IF_FALSE       26 (to 52)\n             48 LOAD_FAST               13 (return_dict)\n             50 JUMP_FORWARD             3 (to 58)\n        >>   52 LOAD_FAST                0 (self)\n             54 LOAD_ATTR                0 (config)\n             56 LOAD_ATTR                3 (use_return_dict)\n        >>   58 STORE_FAST              13 (return_dict)\n\n783          60 LOAD_FAST                0 (self)\n             62 LOAD_ATTR                0 (config)\n             64 LOAD_ATTR                4 (is_decoder)\n             66 POP_JUMP_IF_FALSE       45 (to 90)\n\n784          68 LOAD_FAST               10 (use_cache)\n             70 LOAD_CONST               1 (None)\n             72 IS_OP                    1\n             74 POP_JUMP_IF_FALSE       40 (to 80)\n             76 LOAD_FAST               10 (use_cache)\n             78 JUMP_FORWARD             3 (to 86)\n        >>   80 LOAD_FAST                0 (self)\n             82 LOAD_ATTR                0 (config)\n             84 LOAD_ATTR                5 (use_cache)\n        >>   86 STORE_FAST              10 (use_cache)\n             88 JUMP_FORWARD             2 (to 94)\n\n786     >>   90 LOAD_CONST               2 (False)\n             92 STORE_FAST              10 (use_cache)\n\n788     >>   94 LOAD_FAST                1 (input_ids)\n             96 LOAD_CONST               1 (None)\n             98 IS_OP                    1\n            100 POP_JUMP_IF_FALSE       59 (to 118)\n            102 LOAD_FAST                6 (inputs_embeds)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE       59 (to 118)\n\n789         110 LOAD_GLOBAL              6 (ValueError)\n            112 LOAD_CONST               3 ('You cannot specify both input_ids and inputs_embeds at the same time')\n            114 CALL_FUNCTION            1\n            116 RAISE_VARARGS            1\n\n790     >>  118 LOAD_FAST                1 (input_ids)\n            120 LOAD_CONST               1 (None)\n            122 IS_OP                    1\n            124 POP_JUMP_IF_FALSE       74 (to 148)\n\n791         126 LOAD_FAST                1 (input_ids)\n            128 LOAD_METHOD              7 (size)\n            130 CALL_METHOD              0\n            132 STORE_FAST              14 (input_shape)\n\n792         134 LOAD_FAST                0 (self)\n            136 LOAD_METHOD              8 (warn_if_padding_and_no_attention_mask)\n            138 LOAD_FAST                1 (input_ids)\n            140 LOAD_FAST                2 (attention_mask)\n            142 CALL_METHOD              2\n            144 POP_TOP\n            146 JUMP_FORWARD            17 (to 182)\n\n793     >>  148 LOAD_FAST                6 (inputs_embeds)\n            150 LOAD_CONST               1 (None)\n            152 IS_OP                    1\n            154 POP_JUMP_IF_FALSE       87 (to 174)\n\n794         156 LOAD_FAST                6 (inputs_embeds)\n            158 LOAD_METHOD              7 (size)\n            160 CALL_METHOD              0\n            162 LOAD_CONST               1 (None)\n            164 LOAD_CONST               4 (-1)\n            166 BUILD_SLICE              2\n            168 BINARY_SUBSCR\n            170 STORE_FAST              14 (input_shape)\n            172 JUMP_FORWARD             4 (to 182)\n\n796     >>  174 LOAD_GLOBAL              6 (ValueError)\n            176 LOAD_CONST               5 ('You have to specify either input_ids or inputs_embeds')\n            178 CALL_FUNCTION            1\n            180 RAISE_VARARGS            1\n\n798     >>  182 LOAD_FAST               14 (input_shape)\n            184 UNPACK_SEQUENCE          2\n            186 STORE_FAST              15 (batch_size)\n            188 STORE_FAST              16 (seq_length)\n\n799         190 LOAD_FAST                1 (input_ids)\n            192 LOAD_CONST               1 (None)\n            194 IS_OP                    1\n            196 POP_JUMP_IF_FALSE      102 (to 204)\n            198 LOAD_FAST                1 (input_ids)\n            200 LOAD_ATTR                9 (device)\n            202 JUMP_FORWARD             2 (to 208)\n        >>  204 LOAD_FAST                6 (inputs_embeds)\n            206 LOAD_ATTR                9 (device)\n        >>  208 STORE_FAST              17 (device)\n\n802         210 LOAD_FAST                9 (past_key_values)\n            212 LOAD_CONST               1 (None)\n            214 IS_OP                    1\n            216 POP_JUMP_IF_FALSE      118 (to 236)\n            218 LOAD_FAST                9 (past_key_values)\n            220 LOAD_CONST               6 (0)\n            222 BINARY_SUBSCR\n            224 LOAD_CONST               6 (0)\n            226 BINARY_SUBSCR\n            228 LOAD_ATTR               10 (shape)\n            230 LOAD_CONST               7 (2)\n            232 BINARY_SUBSCR\n            234 JUMP_FORWARD             1 (to 238)\n        >>  236 LOAD_CONST               6 (0)\n        >>  238 STORE_FAST              18 (past_key_values_length)\n\n804         240 LOAD_FAST                2 (attention_mask)\n            242 LOAD_CONST               1 (None)\n            244 IS_OP                    0\n            246 POP_JUMP_IF_FALSE      135 (to 270)\n\n805         248 LOAD_GLOBAL             11 (torch)\n            250 LOAD_ATTR               12 (ones)\n            252 LOAD_FAST               15 (batch_size)\n            254 LOAD_FAST               16 (seq_length)\n            256 LOAD_FAST               18 (past_key_values_length)\n            258 BINARY_ADD\n            260 BUILD_TUPLE              2\n            262 LOAD_FAST               17 (device)\n            264 LOAD_CONST               8 (('device',))\n            266 CALL_FUNCTION_KW         2\n            268 STORE_FAST               2 (attention_mask)\n\n807     >>  270 LOAD_FAST                3 (token_type_ids)\n            272 LOAD_CONST               1 (None)\n            274 IS_OP                    0\n            276 POP_JUMP_IF_FALSE      175 (to 350)\n\n808         278 LOAD_GLOBAL             13 (hasattr)\n            280 LOAD_FAST                0 (self)\n            282 LOAD_ATTR               14 (embeddings)\n            284 LOAD_CONST               9 ('token_type_ids')\n            286 CALL_FUNCTION            2\n            288 POP_JUMP_IF_FALSE      166 (to 332)\n\n809         290 LOAD_FAST                0 (self)\n            292 LOAD_ATTR               14 (embeddings)\n            294 LOAD_ATTR               15 (token_type_ids)\n            296 LOAD_CONST               1 (None)\n            298 LOAD_CONST               1 (None)\n            300 BUILD_SLICE              2\n            302 LOAD_CONST               1 (None)\n            304 LOAD_FAST               16 (seq_length)\n            306 BUILD_SLICE              2\n            308 BUILD_TUPLE              2\n            310 BINARY_SUBSCR\n            312 STORE_FAST              19 (buffered_token_type_ids)\n\n810         314 LOAD_FAST               19 (buffered_token_type_ids)\n            316 LOAD_METHOD             16 (expand)\n            318 LOAD_FAST               15 (batch_size)\n            320 LOAD_FAST               16 (seq_length)\n            322 CALL_METHOD              2\n            324 STORE_FAST              20 (buffered_token_type_ids_expanded)\n\n811         326 LOAD_FAST               20 (buffered_token_type_ids_expanded)\n            328 STORE_FAST               3 (token_type_ids)\n            330 JUMP_FORWARD             9 (to 350)\n\n813     >>  332 LOAD_GLOBAL             11 (torch)\n            334 LOAD_ATTR               17 (zeros)\n            336 LOAD_FAST               14 (input_shape)\n            338 LOAD_GLOBAL             11 (torch)\n            340 LOAD_ATTR               18 (long)\n            342 LOAD_FAST               17 (device)\n            344 LOAD_CONST              10 (('dtype', 'device'))\n            346 CALL_FUNCTION_KW         3\n            348 STORE_FAST               3 (token_type_ids)\n\n817     >>  350 LOAD_FAST                0 (self)\n            352 LOAD_METHOD             19 (get_extended_attention_mask)\n            354 LOAD_FAST                2 (attention_mask)\n            356 LOAD_FAST               14 (input_shape)\n            358 CALL_METHOD              2\n            360 STORE_FAST              21 (extended_attention_mask)\n\n821         362 LOAD_FAST                0 (self)\n            364 LOAD_ATTR                0 (config)\n            366 LOAD_ATTR                4 (is_decoder)\n            368 POP_JUMP_IF_FALSE      217 (to 434)\n            370 LOAD_FAST                7 (encoder_hidden_states)\n            372 LOAD_CONST               1 (None)\n            374 IS_OP                    1\n            376 POP_JUMP_IF_FALSE      217 (to 434)\n\n822         378 LOAD_FAST                7 (encoder_hidden_states)\n            380 LOAD_METHOD              7 (size)\n            382 CALL_METHOD              0\n            384 UNPACK_SEQUENCE          3\n            386 STORE_FAST              22 (encoder_batch_size)\n            388 STORE_FAST              23 (encoder_sequence_length)\n            390 STORE_FAST              24 (_)\n\n823         392 LOAD_FAST               22 (encoder_batch_size)\n            394 LOAD_FAST               23 (encoder_sequence_length)\n            396 BUILD_TUPLE              2\n            398 STORE_FAST              25 (encoder_hidden_shape)\n\n824         400 LOAD_FAST                8 (encoder_attention_mask)\n            402 LOAD_CONST               1 (None)\n            404 IS_OP                    0\n            406 POP_JUMP_IF_FALSE      211 (to 422)\n\n825         408 LOAD_GLOBAL             11 (torch)\n            410 LOAD_ATTR               12 (ones)\n            412 LOAD_FAST               25 (encoder_hidden_shape)\n            414 LOAD_FAST               17 (device)\n            416 LOAD_CONST               8 (('device',))\n            418 CALL_FUNCTION_KW         2\n            420 STORE_FAST               8 (encoder_attention_mask)\n\n826     >>  422 LOAD_FAST                0 (self)\n            424 LOAD_METHOD             20 (invert_attention_mask)\n            426 LOAD_FAST                8 (encoder_attention_mask)\n            428 CALL_METHOD              1\n            430 STORE_FAST              26 (encoder_extended_attention_mask)\n            432 JUMP_FORWARD             2 (to 438)\n\n828     >>  434 LOAD_CONST               1 (None)\n            436 STORE_FAST              26 (encoder_extended_attention_mask)\n\n835     >>  438 LOAD_FAST                0 (self)\n            440 LOAD_METHOD             21 (get_head_mask)\n            442 LOAD_FAST                5 (head_mask)\n            444 LOAD_FAST                0 (self)\n            446 LOAD_ATTR                0 (config)\n            448 LOAD_ATTR               22 (num_hidden_layers)\n            450 CALL_METHOD              2\n            452 STORE_FAST               5 (head_mask)\n\n837         454 LOAD_FAST                0 (self)\n            456 LOAD_ATTR               14 (embeddings)\n\n838         458 LOAD_FAST                1 (input_ids)\n\n839         460 LOAD_FAST                4 (position_ids)\n\n840         462 LOAD_FAST                3 (token_type_ids)\n\n841         464 LOAD_FAST                6 (inputs_embeds)\n\n842         466 LOAD_FAST               18 (past_key_values_length)\n\n837         468 LOAD_CONST              11 (('input_ids', 'position_ids', 'token_type_ids', 'inputs_embeds', 'past_key_values_length'))\n            470 CALL_FUNCTION_KW         5\n            472 STORE_FAST              27 (embedding_output)\n\n844         474 LOAD_FAST                0 (self)\n            476 LOAD_ATTR               23 (encoder)\n\n845         478 LOAD_FAST               27 (embedding_output)\n\n846         480 LOAD_FAST               21 (extended_attention_mask)\n\n847         482 LOAD_FAST                5 (head_mask)\n\n848         484 LOAD_FAST                7 (encoder_hidden_states)\n\n849         486 LOAD_FAST               26 (encoder_extended_attention_mask)\n\n850         488 LOAD_FAST                9 (past_key_values)\n\n851         490 LOAD_FAST               10 (use_cache)\n\n852         492 LOAD_FAST               11 (output_attentions)\n\n853         494 LOAD_FAST               12 (output_hidden_states)\n\n854         496 LOAD_FAST               13 (return_dict)\n\n844         498 LOAD_CONST              12 (('attention_mask', 'head_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'past_key_values', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n            500 CALL_FUNCTION_KW        10\n            502 STORE_FAST              28 (encoder_outputs)\n\n856         504 LOAD_FAST               28 (encoder_outputs)\n            506 LOAD_CONST               6 (0)\n            508 BINARY_SUBSCR\n            510 STORE_FAST              29 (sequence_output)\n\n857         512 LOAD_FAST                0 (self)\n            514 LOAD_ATTR               24 (pooler)\n            516 LOAD_CONST               1 (None)\n            518 IS_OP                    1\n            520 EXTENDED_ARG             1\n            522 POP_JUMP_IF_FALSE      267 (to 534)\n            524 LOAD_FAST                0 (self)\n            526 LOAD_METHOD             24 (pooler)\n            528 LOAD_FAST               29 (sequence_output)\n            530 CALL_METHOD              1\n            532 JUMP_FORWARD             1 (to 536)\n        >>  534 LOAD_CONST               1 (None)\n        >>  536 STORE_FAST              30 (pooled_output)\n\n859         538 LOAD_FAST               13 (return_dict)\n            540 EXTENDED_ARG             1\n            542 POP_JUMP_IF_TRUE       282 (to 564)\n\n860         544 LOAD_FAST               29 (sequence_output)\n            546 LOAD_FAST               30 (pooled_output)\n            548 BUILD_TUPLE              2\n            550 LOAD_FAST               28 (encoder_outputs)\n            552 LOAD_CONST              13 (1)\n            554 LOAD_CONST               1 (None)\n            556 BUILD_SLICE              2\n            558 BINARY_SUBSCR\n            560 BINARY_ADD\n            562 RETURN_VALUE\n\n862     >>  564 LOAD_GLOBAL             25 (BaseModelOutputWithPoolingAndCrossAttentions)\n\n863         566 LOAD_FAST               29 (sequence_output)\n\n864         568 LOAD_FAST               30 (pooled_output)\n\n865         570 LOAD_FAST               28 (encoder_outputs)\n            572 LOAD_ATTR               26 (past_key_values)\n\n866         574 LOAD_FAST               28 (encoder_outputs)\n            576 LOAD_ATTR               27 (hidden_states)\n\n867         578 LOAD_FAST               28 (encoder_outputs)\n            580 LOAD_ATTR               28 (attentions)\n\n868         582 LOAD_FAST               28 (encoder_outputs)\n            584 LOAD_ATTR               29 (cross_attentions)\n\n862         586 LOAD_CONST              14 (('last_hidden_state', 'pooler_output', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n            588 CALL_FUNCTION_KW         6\n            590 RETURN_VALUE\n\n", "ORIGINAL BYTECODE warn_if_padding_and_no_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/modeling_utils.py line 3482 \n3486           0 LOAD_FAST                2 (attention_mask)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_TRUE        10 (to 20)\n               8 LOAD_FAST                0 (self)\n              10 LOAD_ATTR                0 (config)\n              12 LOAD_ATTR                1 (pad_token_id)\n              14 LOAD_CONST               1 (None)\n              16 IS_OP                    0\n              18 POP_JUMP_IF_FALSE       12 (to 24)\n\n3487     >>   20 LOAD_CONST               1 (None)\n              22 RETURN_VALUE\n\n3490     >>   24 LOAD_FAST                0 (self)\n              26 LOAD_ATTR                0 (config)\n              28 LOAD_ATTR                1 (pad_token_id)\n              30 LOAD_FAST                1 (input_ids)\n              32 LOAD_CONST               1 (None)\n              34 LOAD_CONST               1 (None)\n              36 BUILD_SLICE              2\n              38 LOAD_CONST               2 (-1)\n              40 LOAD_CONST               3 (0)\n              42 BUILD_LIST               2\n              44 BUILD_TUPLE              2\n              46 BINARY_SUBSCR\n              48 CONTAINS_OP              0\n              50 POP_JUMP_IF_FALSE      102 (to 204)\n\n3492          52 LOAD_CONST               4 ('We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.')\n\n3491          54 STORE_FAST               3 (warn_string)\n\n3500          56 LOAD_FAST                0 (self)\n              58 LOAD_ATTR                0 (config)\n              60 LOAD_ATTR                2 (bos_token_id)\n              62 LOAD_CONST               1 (None)\n              64 IS_OP                    1\n              66 POP_JUMP_IF_FALSE       42 (to 84)\n              68 LOAD_FAST                0 (self)\n              70 LOAD_ATTR                0 (config)\n              72 LOAD_ATTR                2 (bos_token_id)\n              74 LOAD_FAST                0 (self)\n              76 LOAD_ATTR                0 (config)\n              78 LOAD_ATTR                1 (pad_token_id)\n              80 COMPARE_OP               2 (==)\n              82 POP_JUMP_IF_TRUE        70 (to 140)\n\n3501     >>   84 LOAD_FAST                0 (self)\n              86 LOAD_ATTR                0 (config)\n              88 LOAD_ATTR                3 (eos_token_id)\n              90 LOAD_CONST               1 (None)\n              92 IS_OP                    1\n              94 POP_JUMP_IF_FALSE       56 (to 112)\n              96 LOAD_FAST                0 (self)\n              98 LOAD_ATTR                0 (config)\n             100 LOAD_ATTR                3 (eos_token_id)\n             102 LOAD_FAST                0 (self)\n             104 LOAD_ATTR                0 (config)\n             106 LOAD_ATTR                1 (pad_token_id)\n             108 COMPARE_OP               2 (==)\n             110 POP_JUMP_IF_TRUE        70 (to 140)\n\n3502     >>  112 LOAD_FAST                0 (self)\n             114 LOAD_ATTR                0 (config)\n             116 LOAD_ATTR                4 (sep_token_id)\n             118 LOAD_CONST               1 (None)\n             120 IS_OP                    1\n             122 POP_JUMP_IF_FALSE       95 (to 190)\n             124 LOAD_FAST                0 (self)\n             126 LOAD_ATTR                0 (config)\n             128 LOAD_ATTR                4 (sep_token_id)\n             130 LOAD_FAST                0 (self)\n             132 LOAD_ATTR                0 (config)\n             134 LOAD_ATTR                1 (pad_token_id)\n             136 COMPARE_OP               2 (==)\n             138 POP_JUMP_IF_FALSE       95 (to 190)\n\n3504     >>  140 LOAD_FAST                3 (warn_string)\n\n3505         142 LOAD_CONST               5 ('\\nYou may ignore this warning if your `pad_token_id` (')\n             144 LOAD_FAST                0 (self)\n             146 LOAD_ATTR                0 (config)\n             148 LOAD_ATTR                1 (pad_token_id)\n             150 FORMAT_VALUE             0\n             152 LOAD_CONST               6 (') is identical to the `bos_token_id` (')\n\n3506         154 LOAD_FAST                0 (self)\n             156 LOAD_ATTR                0 (config)\n             158 LOAD_ATTR                2 (bos_token_id)\n\n3505         160 FORMAT_VALUE             0\n             162 LOAD_CONST               7 ('), `eos_token_id` (')\n\n3506         164 LOAD_FAST                0 (self)\n             166 LOAD_ATTR                0 (config)\n             168 LOAD_ATTR                3 (eos_token_id)\n\n3505         170 FORMAT_VALUE             0\n             172 LOAD_CONST               8 ('), or the `sep_token_id` (')\n\n3507         174 LOAD_FAST                0 (self)\n             176 LOAD_ATTR                0 (config)\n             178 LOAD_ATTR                4 (sep_token_id)\n\n3505         180 FORMAT_VALUE             0\n             182 LOAD_CONST               9 ('), and your input is not padded.')\n             184 BUILD_STRING             9\n\n3504         186 INPLACE_ADD\n             188 STORE_FAST               3 (warn_string)\n\n3510     >>  190 LOAD_GLOBAL              5 (logger)\n             192 LOAD_METHOD              6 (warning_once)\n             194 LOAD_FAST                3 (warn_string)\n             196 CALL_METHOD              1\n             198 POP_TOP\n             200 LOAD_CONST               1 (None)\n             202 RETURN_VALUE\n\n3490     >>  204 LOAD_CONST               1 (None)\n             206 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py line 792 \n792           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           74 (to 148)\n              4 LOAD_FAST               12 (output_attentions)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE        8 (to 16)\n             12 LOAD_FAST               12 (output_attentions)\n             14 JUMP_FORWARD             3 (to 22)\n        >>   16 LOAD_FAST                1 (self)\n             18 LOAD_ATTR                0 (config)\n             20 LOAD_ATTR                1 (output_attentions)\n        >>   22 STORE_FAST              12 (output_attentions)\n             24 LOAD_FAST               13 (output_hidden_states)\n             26 LOAD_CONST               1 (None)\n             28 IS_OP                    1\n             30 POP_JUMP_IF_FALSE       18 (to 36)\n             32 LOAD_FAST               13 (output_hidden_states)\n             34 JUMP_FORWARD             3 (to 42)\n        >>   36 LOAD_FAST                1 (self)\n             38 LOAD_ATTR                0 (config)\n             40 LOAD_ATTR                2 (output_hidden_states)\n        >>   42 STORE_FAST              13 (output_hidden_states)\n             44 LOAD_FAST               14 (return_dict)\n             46 LOAD_CONST               1 (None)\n             48 IS_OP                    1\n             50 POP_JUMP_IF_FALSE       28 (to 56)\n             52 LOAD_FAST               14 (return_dict)\n             54 JUMP_FORWARD             3 (to 62)\n        >>   56 LOAD_FAST                1 (self)\n             58 LOAD_ATTR                0 (config)\n             60 LOAD_ATTR                3 (use_return_dict)\n        >>   62 STORE_FAST              14 (return_dict)\n             64 LOAD_FAST                1 (self)\n             66 LOAD_ATTR                0 (config)\n             68 LOAD_ATTR                4 (is_decoder)\n             70 POP_JUMP_IF_FALSE       47 (to 94)\n             72 LOAD_FAST               11 (use_cache)\n             74 LOAD_CONST               1 (None)\n             76 IS_OP                    1\n             78 POP_JUMP_IF_FALSE       42 (to 84)\n             80 LOAD_FAST               11 (use_cache)\n             82 JUMP_FORWARD             3 (to 90)\n        >>   84 LOAD_FAST                1 (self)\n             86 LOAD_ATTR                0 (config)\n             88 LOAD_ATTR                5 (use_cache)\n        >>   90 STORE_FAST              11 (use_cache)\n             92 JUMP_FORWARD             2 (to 98)\n        >>   94 LOAD_CONST               2 (False)\n             96 STORE_FAST              11 (use_cache)\n        >>   98 LOAD_FAST                2 (input_ids)\n            100 LOAD_CONST               1 (None)\n            102 IS_OP                    1\n            104 POP_JUMP_IF_FALSE       61 (to 122)\n            106 LOAD_FAST                7 (inputs_embeds)\n            108 LOAD_CONST               1 (None)\n            110 IS_OP                    1\n            112 POP_JUMP_IF_FALSE       61 (to 122)\n            114 LOAD_GLOBAL              6 (ValueError)\n            116 LOAD_CONST               3 ('You cannot specify both input_ids and inputs_embeds at the same time')\n            118 CALL_FUNCTION            1\n            120 RAISE_VARARGS            1\n        >>  122 LOAD_FAST                2 (input_ids)\n            124 LOAD_CONST               1 (None)\n            126 IS_OP                    1\n            128 POP_JUMP_IF_FALSE       76 (to 152)\n            130 LOAD_FAST                2 (input_ids)\n            132 LOAD_ATTR                7 (size)\n            134 CALL_FUNCTION            0\n            136 STORE_FAST              15 (input_shape)\n            138 LOAD_FAST                1 (self)\n            140 LOAD_ATTR                8 (warn_if_padding_and_no_attention_mask)\n            142 LOAD_FAST                2 (input_ids)\n            144 LOAD_FAST                3 (attention_mask)\n            146 CALL_FUNCTION            2\n        >>  148 POP_TOP\n            150 JUMP_FORWARD            17 (to 186)\n\n793     >>  152 LOAD_FAST                7 (inputs_embeds)\n            154 LOAD_CONST               1 (None)\n            156 IS_OP                    1\n            158 POP_JUMP_IF_FALSE       89 (to 178)\n\n794         160 LOAD_FAST                7 (inputs_embeds)\n            162 LOAD_ATTR                7 (size)\n            164 CALL_FUNCTION            0\n            166 LOAD_CONST               1 (None)\n            168 LOAD_CONST               4 (-1)\n            170 BUILD_SLICE              2\n            172 BINARY_SUBSCR\n            174 STORE_FAST              15 (input_shape)\n            176 JUMP_FORWARD             4 (to 186)\n\n796     >>  178 LOAD_GLOBAL              6 (ValueError)\n            180 LOAD_CONST               5 ('You have to specify either input_ids or inputs_embeds')\n            182 CALL_FUNCTION            1\n            184 RAISE_VARARGS            1\n\n798     >>  186 LOAD_FAST               15 (input_shape)\n            188 UNPACK_SEQUENCE          2\n            190 STORE_FAST              16 (batch_size)\n            192 STORE_FAST              17 (seq_length)\n\n799         194 LOAD_FAST                2 (input_ids)\n            196 LOAD_CONST               1 (None)\n            198 IS_OP                    1\n            200 POP_JUMP_IF_FALSE      104 (to 208)\n            202 LOAD_FAST                2 (input_ids)\n            204 LOAD_ATTR                9 (device)\n            206 JUMP_FORWARD             2 (to 212)\n        >>  208 LOAD_FAST                7 (inputs_embeds)\n            210 LOAD_ATTR                9 (device)\n        >>  212 STORE_FAST              18 (device)\n\n802         214 LOAD_FAST               10 (past_key_values)\n            216 LOAD_CONST               1 (None)\n            218 IS_OP                    1\n            220 POP_JUMP_IF_FALSE      120 (to 240)\n            222 LOAD_FAST               10 (past_key_values)\n            224 LOAD_CONST               6 (0)\n            226 BINARY_SUBSCR\n            228 LOAD_CONST               6 (0)\n            230 BINARY_SUBSCR\n            232 LOAD_ATTR               10 (shape)\n            234 LOAD_CONST               7 (2)\n            236 BINARY_SUBSCR\n            238 JUMP_FORWARD             1 (to 242)\n        >>  240 LOAD_CONST               6 (0)\n        >>  242 STORE_FAST              19 (past_key_values_length)\n\n804         244 LOAD_FAST                3 (attention_mask)\n            246 LOAD_CONST               1 (None)\n            248 IS_OP                    0\n            250 POP_JUMP_IF_FALSE      137 (to 274)\n\n805         252 LOAD_GLOBAL             11 (torch)\n            254 LOAD_ATTR               12 (ones)\n            256 LOAD_FAST               16 (batch_size)\n            258 LOAD_FAST               17 (seq_length)\n            260 LOAD_FAST               19 (past_key_values_length)\n            262 BINARY_ADD\n            264 BUILD_TUPLE              2\n            266 LOAD_FAST               18 (device)\n            268 LOAD_CONST               8 (('device',))\n            270 CALL_FUNCTION_KW         2\n            272 STORE_FAST               3 (attention_mask)\n\n807     >>  274 LOAD_FAST                4 (token_type_ids)\n            276 LOAD_CONST               1 (None)\n            278 IS_OP                    0\n            280 POP_JUMP_IF_FALSE      177 (to 354)\n\n808         282 LOAD_GLOBAL             13 (hasattr)\n            284 LOAD_FAST                1 (self)\n            286 LOAD_ATTR               14 (embeddings)\n            288 LOAD_CONST               9 ('token_type_ids')\n            290 CALL_FUNCTION            2\n            292 POP_JUMP_IF_FALSE      168 (to 336)\n\n809         294 LOAD_FAST                1 (self)\n            296 LOAD_ATTR               14 (embeddings)\n            298 LOAD_ATTR               15 (token_type_ids)\n            300 LOAD_CONST               1 (None)\n            302 LOAD_CONST               1 (None)\n            304 BUILD_SLICE              2\n            306 LOAD_CONST               1 (None)\n            308 LOAD_FAST               17 (seq_length)\n            310 BUILD_SLICE              2\n            312 BUILD_TUPLE              2\n            314 BINARY_SUBSCR\n            316 STORE_FAST              20 (buffered_token_type_ids)\n\n810         318 LOAD_FAST               20 (buffered_token_type_ids)\n            320 LOAD_ATTR               16 (expand)\n            322 LOAD_FAST               16 (batch_size)\n            324 LOAD_FAST               17 (seq_length)\n            326 CALL_FUNCTION            2\n            328 STORE_FAST              21 (buffered_token_type_ids_expanded)\n\n811         330 LOAD_FAST               21 (buffered_token_type_ids_expanded)\n            332 STORE_FAST               4 (token_type_ids)\n            334 JUMP_FORWARD             9 (to 354)\n\n813     >>  336 LOAD_GLOBAL             11 (torch)\n            338 LOAD_ATTR               17 (zeros)\n            340 LOAD_FAST               15 (input_shape)\n            342 LOAD_GLOBAL             11 (torch)\n            344 LOAD_ATTR               18 (long)\n            346 LOAD_FAST               18 (device)\n            348 LOAD_CONST              10 (('dtype', 'device'))\n            350 CALL_FUNCTION_KW         3\n            352 STORE_FAST               4 (token_type_ids)\n\n817     >>  354 LOAD_FAST                1 (self)\n            356 LOAD_ATTR               19 (get_extended_attention_mask)\n            358 LOAD_FAST                3 (attention_mask)\n            360 LOAD_FAST               15 (input_shape)\n            362 CALL_FUNCTION            2\n            364 STORE_FAST              22 (extended_attention_mask)\n\n821         366 LOAD_FAST                1 (self)\n            368 LOAD_ATTR                0 (config)\n            370 LOAD_ATTR                4 (is_decoder)\n            372 POP_JUMP_IF_FALSE      219 (to 438)\n            374 LOAD_FAST                8 (encoder_hidden_states)\n            376 LOAD_CONST               1 (None)\n            378 IS_OP                    1\n            380 POP_JUMP_IF_FALSE      219 (to 438)\n\n822         382 LOAD_FAST                8 (encoder_hidden_states)\n            384 LOAD_ATTR                7 (size)\n            386 CALL_FUNCTION            0\n            388 UNPACK_SEQUENCE          3\n            390 STORE_FAST              23 (encoder_batch_size)\n            392 STORE_FAST              24 (encoder_sequence_length)\n            394 STORE_FAST              25 (_)\n\n823         396 LOAD_FAST               23 (encoder_batch_size)\n            398 LOAD_FAST               24 (encoder_sequence_length)\n            400 BUILD_TUPLE              2\n            402 STORE_FAST              26 (encoder_hidden_shape)\n\n824         404 LOAD_FAST                9 (encoder_attention_mask)\n            406 LOAD_CONST               1 (None)\n            408 IS_OP                    0\n            410 POP_JUMP_IF_FALSE      213 (to 426)\n\n825         412 LOAD_GLOBAL             11 (torch)\n            414 LOAD_ATTR               12 (ones)\n            416 LOAD_FAST               26 (encoder_hidden_shape)\n            418 LOAD_FAST               18 (device)\n            420 LOAD_CONST               8 (('device',))\n            422 CALL_FUNCTION_KW         2\n            424 STORE_FAST               9 (encoder_attention_mask)\n\n826     >>  426 LOAD_FAST                1 (self)\n            428 LOAD_ATTR               20 (invert_attention_mask)\n            430 LOAD_FAST                9 (encoder_attention_mask)\n            432 CALL_FUNCTION            1\n            434 STORE_FAST              27 (encoder_extended_attention_mask)\n            436 JUMP_FORWARD             2 (to 442)\n\n828     >>  438 LOAD_CONST               1 (None)\n            440 STORE_FAST              27 (encoder_extended_attention_mask)\n\n835     >>  442 LOAD_FAST                1 (self)\n            444 LOAD_ATTR               21 (get_head_mask)\n            446 LOAD_FAST                6 (head_mask)\n            448 LOAD_FAST                1 (self)\n            450 LOAD_ATTR                0 (config)\n            452 LOAD_ATTR               22 (num_hidden_layers)\n            454 CALL_FUNCTION            2\n            456 STORE_FAST               6 (head_mask)\n\n837         458 LOAD_FAST                1 (self)\n            460 LOAD_ATTR               14 (embeddings)\n\n838         462 LOAD_FAST                2 (input_ids)\n\n839         464 LOAD_FAST                5 (position_ids)\n\n840         466 LOAD_FAST                4 (token_type_ids)\n\n841         468 LOAD_FAST                7 (inputs_embeds)\n\n842         470 LOAD_FAST               19 (past_key_values_length)\n\n837         472 LOAD_CONST              11 (('input_ids', 'position_ids', 'token_type_ids', 'inputs_embeds', 'past_key_values_length'))\n            474 CALL_FUNCTION_KW         5\n            476 STORE_FAST              28 (embedding_output)\n\n844         478 LOAD_FAST                1 (self)\n            480 LOAD_ATTR               23 (encoder)\n\n845         482 LOAD_FAST               28 (embedding_output)\n\n846         484 LOAD_FAST               22 (extended_attention_mask)\n\n847         486 LOAD_FAST                6 (head_mask)\n\n848         488 LOAD_FAST                8 (encoder_hidden_states)\n\n849         490 LOAD_FAST               27 (encoder_extended_attention_mask)\n\n850         492 LOAD_FAST               10 (past_key_values)\n\n851         494 LOAD_FAST               11 (use_cache)\n\n852         496 LOAD_FAST               12 (output_attentions)\n\n853         498 LOAD_FAST               13 (output_hidden_states)\n\n854         500 LOAD_FAST               14 (return_dict)\n\n844         502 LOAD_CONST              12 (('attention_mask', 'head_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'past_key_values', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n            504 CALL_FUNCTION_KW        10\n            506 STORE_FAST              29 (encoder_outputs)\n\n856         508 LOAD_FAST               29 (encoder_outputs)\n            510 LOAD_CONST               6 (0)\n            512 BINARY_SUBSCR\n            514 STORE_FAST              30 (sequence_output)\n\n857         516 LOAD_FAST                1 (self)\n            518 LOAD_ATTR               24 (pooler)\n            520 LOAD_CONST               1 (None)\n            522 IS_OP                    1\n            524 EXTENDED_ARG             1\n            526 POP_JUMP_IF_FALSE      269 (to 538)\n            528 LOAD_FAST                1 (self)\n            530 LOAD_ATTR               24 (pooler)\n            532 LOAD_FAST               30 (sequence_output)\n            534 CALL_FUNCTION            1\n            536 JUMP_FORWARD             1 (to 540)\n        >>  538 LOAD_CONST               1 (None)\n        >>  540 STORE_FAST              31 (pooled_output)\n\n859         542 LOAD_FAST               14 (return_dict)\n            544 EXTENDED_ARG             1\n            546 POP_JUMP_IF_TRUE       284 (to 568)\n\n860         548 LOAD_FAST               30 (sequence_output)\n            550 LOAD_FAST               31 (pooled_output)\n            552 BUILD_TUPLE              2\n            554 LOAD_FAST               29 (encoder_outputs)\n            556 LOAD_CONST              13 (1)\n            558 LOAD_CONST               1 (None)\n            560 BUILD_SLICE              2\n            562 BINARY_SUBSCR\n            564 BINARY_ADD\n            566 RETURN_VALUE\n\n862     >>  568 LOAD_GLOBAL             25 (BaseModelOutputWithPoolingAndCrossAttentions)\n\n863         570 LOAD_FAST               30 (sequence_output)\n\n864         572 LOAD_FAST               31 (pooled_output)\n\n865         574 LOAD_FAST               29 (encoder_outputs)\n            576 LOAD_ATTR               26 (past_key_values)\n\n866         578 LOAD_FAST               29 (encoder_outputs)\n            580 LOAD_ATTR               27 (hidden_states)\n\n867         582 LOAD_FAST               29 (encoder_outputs)\n            584 LOAD_ATTR               28 (attentions)\n\n868         586 LOAD_FAST               29 (encoder_outputs)\n            588 LOAD_ATTR               29 (cross_attentions)\n\n862         590 LOAD_CONST              14 (('last_hidden_state', 'pooler_output', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n            592 CALL_FUNCTION_KW         6\n            594 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py line 962 \n 962           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           35 (to 70)\n               4 LOAD_FAST                3 (return_dict)\n               6 LOAD_CONST               1 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST                3 (return_dict)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (use_return_dict)\n         >>   22 STORE_FAST               3 (return_dict)\n              24 LOAD_FAST                2 (labels)\n              26 LOAD_CONST               1 (None)\n              28 IS_OP                    1\n              30 POP_JUMP_IF_FALSE       18 (to 36)\n              32 LOAD_CONST               2 (False)\n              34 STORE_FAST              13 (use_cache)\n         >>   36 LOAD_FAST                1 (self)\n              38 LOAD_ATTR                2 (roberta)\n              40 LOAD_FAST                4 (input_ids)\n              42 LOAD_FAST                5 (attention_mask)\n              44 LOAD_FAST                6 (token_type_ids)\n              46 LOAD_FAST                7 (position_ids)\n              48 LOAD_FAST                8 (head_mask)\n              50 LOAD_FAST                9 (inputs_embeds)\n              52 LOAD_FAST               10 (encoder_hidden_states)\n              54 LOAD_FAST               11 (encoder_attention_mask)\n              56 LOAD_FAST               12 (past_key_values)\n              58 LOAD_FAST               13 (use_cache)\n              60 LOAD_FAST               14 (output_attentions)\n              62 LOAD_FAST               15 (output_hidden_states)\n              64 LOAD_FAST                3 (return_dict)\n              66 LOAD_CONST               3 (('attention_mask', 'token_type_ids', 'position_ids', 'head_mask', 'inputs_embeds', 'encoder_hidden_states', 'encoder_attention_mask', 'past_key_values', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              68 CALL_FUNCTION_KW        13\n         >>   70 STORE_FAST              16 (outputs)\n\n 978          72 LOAD_FAST               16 (outputs)\n              74 LOAD_CONST               4 (0)\n              76 BINARY_SUBSCR\n              78 STORE_FAST              17 (sequence_output)\n\n 979          80 LOAD_FAST                1 (self)\n              82 LOAD_ATTR                3 (lm_head)\n              84 LOAD_FAST               17 (sequence_output)\n              86 CALL_FUNCTION            1\n              88 STORE_FAST              18 (prediction_scores)\n\n 981          90 LOAD_CONST               1 (None)\n              92 STORE_FAST              19 (lm_loss)\n\n 982          94 LOAD_FAST                2 (labels)\n              96 LOAD_CONST               1 (None)\n              98 IS_OP                    1\n             100 POP_JUMP_IF_FALSE      101 (to 202)\n\n 984         102 LOAD_FAST                2 (labels)\n             104 LOAD_ATTR                4 (to)\n             106 LOAD_FAST               18 (prediction_scores)\n             108 LOAD_ATTR                5 (device)\n             110 CALL_FUNCTION            1\n             112 STORE_FAST               2 (labels)\n\n 986         114 LOAD_FAST               18 (prediction_scores)\n             116 LOAD_CONST               1 (None)\n             118 LOAD_CONST               1 (None)\n             120 BUILD_SLICE              2\n             122 LOAD_CONST               1 (None)\n             124 LOAD_CONST               5 (-1)\n             126 BUILD_SLICE              2\n             128 LOAD_CONST               1 (None)\n             130 LOAD_CONST               1 (None)\n             132 BUILD_SLICE              2\n             134 BUILD_TUPLE              3\n             136 BINARY_SUBSCR\n             138 LOAD_ATTR                6 (contiguous)\n             140 CALL_FUNCTION            0\n             142 STORE_FAST              20 (shifted_prediction_scores)\n\n 987         144 LOAD_FAST                2 (labels)\n             146 LOAD_CONST               1 (None)\n             148 LOAD_CONST               1 (None)\n             150 BUILD_SLICE              2\n             152 LOAD_CONST               6 (1)\n             154 LOAD_CONST               1 (None)\n             156 BUILD_SLICE              2\n             158 BUILD_TUPLE              2\n             160 BINARY_SUBSCR\n             162 LOAD_ATTR                6 (contiguous)\n             164 CALL_FUNCTION            0\n             166 STORE_FAST               2 (labels)\n\n 988         168 LOAD_GLOBAL              7 (CrossEntropyLoss)\n             170 CALL_FUNCTION            0\n             172 STORE_FAST              21 (loss_fct)\n\n 989         174 LOAD_FAST               21 (loss_fct)\n             176 LOAD_FAST               20 (shifted_prediction_scores)\n             178 LOAD_ATTR                8 (view)\n             180 LOAD_CONST               5 (-1)\n             182 LOAD_FAST                1 (self)\n             184 LOAD_ATTR                0 (config)\n             186 LOAD_ATTR                9 (vocab_size)\n             188 CALL_FUNCTION            2\n             190 LOAD_FAST                2 (labels)\n             192 LOAD_ATTR                8 (view)\n             194 LOAD_CONST               5 (-1)\n             196 CALL_FUNCTION            1\n             198 CALL_FUNCTION            2\n             200 STORE_FAST              19 (lm_loss)\n\n 991     >>  202 LOAD_FAST                3 (return_dict)\n             204 POP_JUMP_IF_TRUE       123 (to 246)\n\n 992         206 LOAD_FAST               18 (prediction_scores)\n             208 BUILD_TUPLE              1\n             210 LOAD_FAST               16 (outputs)\n             212 LOAD_CONST               7 (2)\n             214 LOAD_CONST               1 (None)\n             216 BUILD_SLICE              2\n             218 BINARY_SUBSCR\n             220 BINARY_ADD\n             222 STORE_FAST              22 (output)\n\n 993         224 LOAD_FAST               19 (lm_loss)\n             226 LOAD_CONST               1 (None)\n             228 IS_OP                    1\n             230 POP_JUMP_IF_FALSE      121 (to 242)\n             232 LOAD_FAST               19 (lm_loss)\n             234 BUILD_TUPLE              1\n             236 LOAD_FAST               22 (output)\n             238 BINARY_ADD\n             240 RETURN_VALUE\n         >>  242 LOAD_FAST               22 (output)\n             244 RETURN_VALUE\n\n 995     >>  246 LOAD_GLOBAL             10 (CausalLMOutputWithCrossAttentions)\n\n 996         248 LOAD_FAST               19 (lm_loss)\n\n 997         250 LOAD_FAST               18 (prediction_scores)\n\n 998         252 LOAD_FAST               16 (outputs)\n             254 LOAD_ATTR               11 (past_key_values)\n\n 999         256 LOAD_FAST               16 (outputs)\n             258 LOAD_ATTR               12 (hidden_states)\n\n1000         260 LOAD_FAST               16 (outputs)\n             262 LOAD_ATTR               13 (attentions)\n\n1001         264 LOAD_FAST               16 (outputs)\n             266 LOAD_ATTR               14 (cross_attentions)\n\n 995         268 LOAD_CONST               8 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n             270 CALL_FUNCTION_KW         6\n             272 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 557 \n557           0 LOAD_FAST                0 (___stack0)\n              2 CALL_FUNCTION            0\n              4 SETUP_WITH              10 (to 26)\n              6 POP_TOP\n              8 LOAD_FAST                1 (___stack1)\n             10 JUMP_ABSOLUTE           44 (to 88)\n             12 POP_BLOCK\n             14 LOAD_CONST               0 (None)\n             16 DUP_TOP\n             18 DUP_TOP\n             20 CALL_FUNCTION            3\n             22 POP_TOP\n             24 JUMP_FORWARD             8 (to 42)\n        >>   26 WITH_EXCEPT_START\n             28 POP_JUMP_IF_TRUE        16 (to 32)\n             30 RERAISE                  0\n        >>   32 POP_TOP\n             34 POP_TOP\n             36 POP_TOP\n             38 POP_EXCEPT\n             40 POP_TOP\n        >>   42 NOP\n             44 LOAD_CONST               0 (None)\n             46 RAISE_VARARGS            1\n             48 LOAD_GLOBAL              0 (clone_inputs)\n             50 LOAD_FAST                6 (inputs)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (cloned_inputs)\n             56 LOAD_FAST                2 (self)\n             58 LOAD_ATTR                1 (optimizer_zero_grad)\n             60 LOAD_FAST                3 (mod)\n             62 CALL_FUNCTION            1\n             64 POP_TOP\n             66 LOAD_FAST                2 (self)\n             68 LOAD_ATTR                2 (autocast)\n             70 CALL_FUNCTION            0\n             72 SETUP_WITH              20 (to 114)\n             74 POP_TOP\n             76 LOAD_FAST                3 (mod)\n             78 LOAD_CONST               1 (())\n             80 BUILD_MAP                0\n             82 LOAD_FAST                5 (cloned_inputs)\n             84 DICT_MERGE               1\n             86 CALL_FUNCTION_EX         1\n        >>   88 STORE_FAST               7 (pred)\n\n558          90 LOAD_FAST                2 (self)\n             92 LOAD_ATTR                3 (compute_loss)\n             94 LOAD_FAST                7 (pred)\n             96 CALL_FUNCTION            1\n             98 STORE_FAST               8 (loss)\n            100 POP_BLOCK\n\n556         102 LOAD_CONST               0 (None)\n            104 DUP_TOP\n            106 DUP_TOP\n            108 CALL_FUNCTION            3\n            110 POP_TOP\n            112 JUMP_FORWARD             8 (to 130)\n        >>  114 WITH_EXCEPT_START\n            116 POP_JUMP_IF_TRUE        60 (to 120)\n            118 RERAISE                  1\n        >>  120 POP_TOP\n            122 POP_TOP\n            124 POP_TOP\n            126 POP_EXCEPT\n            128 POP_TOP\n\n559     >>  130 LOAD_FAST                2 (self)\n            132 LOAD_ATTR                4 (grad_scaler)\n            134 LOAD_ATTR                5 (scale)\n            136 LOAD_FAST                8 (loss)\n            138 CALL_FUNCTION            1\n            140 LOAD_ATTR                6 (backward)\n            142 CALL_FUNCTION            0\n            144 POP_TOP\n\n560         146 LOAD_FAST                2 (self)\n            148 LOAD_ATTR                7 (optimizer_step)\n            150 CALL_FUNCTION            0\n            152 POP_TOP\n\n561         154 LOAD_FAST                4 (collect_outputs)\n            156 POP_JUMP_IF_FALSE       86 (to 172)\n\n562         158 LOAD_GLOBAL              8 (collect_results)\n            160 LOAD_FAST                3 (mod)\n            162 LOAD_FAST                7 (pred)\n            164 LOAD_FAST                8 (loss)\n            166 LOAD_FAST                5 (cloned_inputs)\n            168 CALL_FUNCTION            4\n            170 RETURN_VALUE\n\n563     >>  172 LOAD_CONST               0 (None)\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py line 1464 \n1496           0 LOAD_FAST               11 (return_dict)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_FALSE        6 (to 12)\n               8 LOAD_FAST               11 (return_dict)\n              10 JUMP_FORWARD             3 (to 18)\n         >>   12 LOAD_FAST                0 (self)\n              14 LOAD_ATTR                0 (config)\n              16 LOAD_ATTR                1 (use_return_dict)\n         >>   18 STORE_FAST              11 (return_dict)\n\n1498          20 LOAD_FAST                0 (self)\n              22 LOAD_ATTR                2 (roberta)\n\n1499          24 LOAD_FAST                1 (input_ids)\n\n1500          26 LOAD_FAST                2 (attention_mask)\n\n1501          28 LOAD_FAST                3 (token_type_ids)\n\n1502          30 LOAD_FAST                4 (position_ids)\n\n1503          32 LOAD_FAST                5 (head_mask)\n\n1504          34 LOAD_FAST                6 (inputs_embeds)\n\n1505          36 LOAD_FAST                9 (output_attentions)\n\n1506          38 LOAD_FAST               10 (output_hidden_states)\n\n1507          40 LOAD_FAST               11 (return_dict)\n\n1498          42 LOAD_CONST               2 (('attention_mask', 'token_type_ids', 'position_ids', 'head_mask', 'inputs_embeds', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              44 CALL_FUNCTION_KW         9\n              46 STORE_FAST              12 (outputs)\n\n1510          48 LOAD_FAST               12 (outputs)\n              50 LOAD_CONST               3 (0)\n              52 BINARY_SUBSCR\n              54 STORE_FAST              13 (sequence_output)\n\n1512          56 LOAD_FAST                0 (self)\n              58 LOAD_METHOD              3 (qa_outputs)\n              60 LOAD_FAST               13 (sequence_output)\n              62 CALL_METHOD              1\n              64 STORE_FAST              14 (logits)\n\n1513          66 LOAD_FAST               14 (logits)\n              68 LOAD_ATTR                4 (split)\n              70 LOAD_CONST               4 (1)\n              72 LOAD_CONST               5 (-1)\n              74 LOAD_CONST               6 (('dim',))\n              76 CALL_FUNCTION_KW         2\n              78 UNPACK_SEQUENCE          2\n              80 STORE_FAST              15 (start_logits)\n              82 STORE_FAST              16 (end_logits)\n\n1514          84 LOAD_FAST               15 (start_logits)\n              86 LOAD_METHOD              5 (squeeze)\n              88 LOAD_CONST               5 (-1)\n              90 CALL_METHOD              1\n              92 LOAD_METHOD              6 (contiguous)\n              94 CALL_METHOD              0\n              96 STORE_FAST              15 (start_logits)\n\n1515          98 LOAD_FAST               16 (end_logits)\n             100 LOAD_METHOD              5 (squeeze)\n             102 LOAD_CONST               5 (-1)\n             104 CALL_METHOD              1\n             106 LOAD_METHOD              6 (contiguous)\n             108 CALL_METHOD              0\n             110 STORE_FAST              16 (end_logits)\n\n1517         112 LOAD_CONST               1 (None)\n             114 STORE_FAST              17 (total_loss)\n\n1518         116 LOAD_FAST                7 (start_positions)\n             118 LOAD_CONST               1 (None)\n             120 IS_OP                    1\n             122 POP_JUMP_IF_FALSE      130 (to 260)\n             124 LOAD_FAST                8 (end_positions)\n             126 LOAD_CONST               1 (None)\n             128 IS_OP                    1\n             130 POP_JUMP_IF_FALSE      130 (to 260)\n\n1520         132 LOAD_GLOBAL              7 (len)\n             134 LOAD_FAST                7 (start_positions)\n             136 LOAD_METHOD              8 (size)\n             138 CALL_METHOD              0\n             140 CALL_FUNCTION            1\n             142 LOAD_CONST               4 (1)\n             144 COMPARE_OP               4 (>)\n             146 POP_JUMP_IF_FALSE       79 (to 158)\n\n1521         148 LOAD_FAST                7 (start_positions)\n             150 LOAD_METHOD              5 (squeeze)\n             152 LOAD_CONST               5 (-1)\n             154 CALL_METHOD              1\n             156 STORE_FAST               7 (start_positions)\n\n1522     >>  158 LOAD_GLOBAL              7 (len)\n             160 LOAD_FAST                8 (end_positions)\n             162 LOAD_METHOD              8 (size)\n             164 CALL_METHOD              0\n             166 CALL_FUNCTION            1\n             168 LOAD_CONST               4 (1)\n             170 COMPARE_OP               4 (>)\n             172 POP_JUMP_IF_FALSE       92 (to 184)\n\n1523         174 LOAD_FAST                8 (end_positions)\n             176 LOAD_METHOD              5 (squeeze)\n             178 LOAD_CONST               5 (-1)\n             180 CALL_METHOD              1\n             182 STORE_FAST               8 (end_positions)\n\n1525     >>  184 LOAD_FAST               15 (start_logits)\n             186 LOAD_METHOD              8 (size)\n             188 LOAD_CONST               4 (1)\n             190 CALL_METHOD              1\n             192 STORE_FAST              18 (ignored_index)\n\n1526         194 LOAD_FAST                7 (start_positions)\n             196 LOAD_METHOD              9 (clamp)\n             198 LOAD_CONST               3 (0)\n             200 LOAD_FAST               18 (ignored_index)\n             202 CALL_METHOD              2\n             204 STORE_FAST               7 (start_positions)\n\n1527         206 LOAD_FAST                8 (end_positions)\n             208 LOAD_METHOD              9 (clamp)\n             210 LOAD_CONST               3 (0)\n             212 LOAD_FAST               18 (ignored_index)\n             214 CALL_METHOD              2\n             216 STORE_FAST               8 (end_positions)\n\n1529         218 LOAD_GLOBAL             10 (CrossEntropyLoss)\n             220 LOAD_FAST               18 (ignored_index)\n             222 LOAD_CONST               7 (('ignore_index',))\n             224 CALL_FUNCTION_KW         1\n             226 STORE_FAST              19 (loss_fct)\n\n1530         228 LOAD_FAST               19 (loss_fct)\n             230 LOAD_FAST               15 (start_logits)\n             232 LOAD_FAST                7 (start_positions)\n             234 CALL_FUNCTION            2\n             236 STORE_FAST              20 (start_loss)\n\n1531         238 LOAD_FAST               19 (loss_fct)\n             240 LOAD_FAST               16 (end_logits)\n             242 LOAD_FAST                8 (end_positions)\n             244 CALL_FUNCTION            2\n             246 STORE_FAST              21 (end_loss)\n\n1532         248 LOAD_FAST               20 (start_loss)\n             250 LOAD_FAST               21 (end_loss)\n             252 BINARY_ADD\n             254 LOAD_CONST               8 (2)\n             256 BINARY_TRUE_DIVIDE\n             258 STORE_FAST              17 (total_loss)\n\n1534     >>  260 LOAD_FAST               11 (return_dict)\n             262 POP_JUMP_IF_TRUE       153 (to 306)\n\n1535         264 LOAD_FAST               15 (start_logits)\n             266 LOAD_FAST               16 (end_logits)\n             268 BUILD_TUPLE              2\n             270 LOAD_FAST               12 (outputs)\n             272 LOAD_CONST               8 (2)\n             274 LOAD_CONST               1 (None)\n             276 BUILD_SLICE              2\n             278 BINARY_SUBSCR\n             280 BINARY_ADD\n             282 STORE_FAST              22 (output)\n\n1536         284 LOAD_FAST               17 (total_loss)\n             286 LOAD_CONST               1 (None)\n             288 IS_OP                    1\n             290 POP_JUMP_IF_FALSE      151 (to 302)\n             292 LOAD_FAST               17 (total_loss)\n             294 BUILD_TUPLE              1\n             296 LOAD_FAST               22 (output)\n             298 BINARY_ADD\n             300 RETURN_VALUE\n         >>  302 LOAD_FAST               22 (output)\n             304 RETURN_VALUE\n\n1538     >>  306 LOAD_GLOBAL             11 (QuestionAnsweringModelOutput)\n\n1539         308 LOAD_FAST               17 (total_loss)\n\n1540         310 LOAD_FAST               15 (start_logits)\n\n1541         312 LOAD_FAST               16 (end_logits)\n\n1542         314 LOAD_FAST               12 (outputs)\n             316 LOAD_ATTR               12 (hidden_states)\n\n1543         318 LOAD_FAST               12 (outputs)\n             320 LOAD_ATTR               13 (attentions)\n\n1538         322 LOAD_CONST               9 (('loss', 'start_logits', 'end_logits', 'hidden_states', 'attentions'))\n             324 CALL_FUNCTION_KW         5\n             326 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py line 734 \n777           0 LOAD_FAST               11 (output_attentions)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    1\n              6 POP_JUMP_IF_FALSE        6 (to 12)\n              8 LOAD_FAST               11 (output_attentions)\n             10 JUMP_FORWARD             3 (to 18)\n        >>   12 LOAD_FAST                0 (self)\n             14 LOAD_ATTR                0 (config)\n             16 LOAD_ATTR                1 (output_attentions)\n        >>   18 STORE_FAST              11 (output_attentions)\n\n779          20 LOAD_FAST               12 (output_hidden_states)\n             22 LOAD_CONST               1 (None)\n             24 IS_OP                    1\n             26 POP_JUMP_IF_FALSE       16 (to 32)\n             28 LOAD_FAST               12 (output_hidden_states)\n             30 JUMP_FORWARD             3 (to 38)\n        >>   32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                0 (config)\n             36 LOAD_ATTR                2 (output_hidden_states)\n\n778     >>   38 STORE_FAST              12 (output_hidden_states)\n\n781          40 LOAD_FAST               13 (return_dict)\n             42 LOAD_CONST               1 (None)\n             44 IS_OP                    1\n             46 POP_JUMP_IF_FALSE       26 (to 52)\n             48 LOAD_FAST               13 (return_dict)\n             50 JUMP_FORWARD             3 (to 58)\n        >>   52 LOAD_FAST                0 (self)\n             54 LOAD_ATTR                0 (config)\n             56 LOAD_ATTR                3 (use_return_dict)\n        >>   58 STORE_FAST              13 (return_dict)\n\n783          60 LOAD_FAST                0 (self)\n             62 LOAD_ATTR                0 (config)\n             64 LOAD_ATTR                4 (is_decoder)\n             66 POP_JUMP_IF_FALSE       45 (to 90)\n\n784          68 LOAD_FAST               10 (use_cache)\n             70 LOAD_CONST               1 (None)\n             72 IS_OP                    1\n             74 POP_JUMP_IF_FALSE       40 (to 80)\n             76 LOAD_FAST               10 (use_cache)\n             78 JUMP_FORWARD             3 (to 86)\n        >>   80 LOAD_FAST                0 (self)\n             82 LOAD_ATTR                0 (config)\n             84 LOAD_ATTR                5 (use_cache)\n        >>   86 STORE_FAST              10 (use_cache)\n             88 JUMP_FORWARD             2 (to 94)\n\n786     >>   90 LOAD_CONST               2 (False)\n             92 STORE_FAST              10 (use_cache)\n\n788     >>   94 LOAD_FAST                1 (input_ids)\n             96 LOAD_CONST               1 (None)\n             98 IS_OP                    1\n            100 POP_JUMP_IF_FALSE       59 (to 118)\n            102 LOAD_FAST                6 (inputs_embeds)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE       59 (to 118)\n\n789         110 LOAD_GLOBAL              6 (ValueError)\n            112 LOAD_CONST               3 ('You cannot specify both input_ids and inputs_embeds at the same time')\n            114 CALL_FUNCTION            1\n            116 RAISE_VARARGS            1\n\n790     >>  118 LOAD_FAST                1 (input_ids)\n            120 LOAD_CONST               1 (None)\n            122 IS_OP                    1\n            124 POP_JUMP_IF_FALSE       74 (to 148)\n\n791         126 LOAD_FAST                1 (input_ids)\n            128 LOAD_METHOD              7 (size)\n            130 CALL_METHOD              0\n            132 STORE_FAST              14 (input_shape)\n\n792         134 LOAD_FAST                0 (self)\n            136 LOAD_METHOD              8 (warn_if_padding_and_no_attention_mask)\n            138 LOAD_FAST                1 (input_ids)\n            140 LOAD_FAST                2 (attention_mask)\n            142 CALL_METHOD              2\n            144 POP_TOP\n            146 JUMP_FORWARD            17 (to 182)\n\n793     >>  148 LOAD_FAST                6 (inputs_embeds)\n            150 LOAD_CONST               1 (None)\n            152 IS_OP                    1\n            154 POP_JUMP_IF_FALSE       87 (to 174)\n\n794         156 LOAD_FAST                6 (inputs_embeds)\n            158 LOAD_METHOD              7 (size)\n            160 CALL_METHOD              0\n            162 LOAD_CONST               1 (None)\n            164 LOAD_CONST               4 (-1)\n            166 BUILD_SLICE              2\n            168 BINARY_SUBSCR\n            170 STORE_FAST              14 (input_shape)\n            172 JUMP_FORWARD             4 (to 182)\n\n796     >>  174 LOAD_GLOBAL              6 (ValueError)\n            176 LOAD_CONST               5 ('You have to specify either input_ids or inputs_embeds')\n            178 CALL_FUNCTION            1\n            180 RAISE_VARARGS            1\n\n798     >>  182 LOAD_FAST               14 (input_shape)\n            184 UNPACK_SEQUENCE          2\n            186 STORE_FAST              15 (batch_size)\n            188 STORE_FAST              16 (seq_length)\n\n799         190 LOAD_FAST                1 (input_ids)\n            192 LOAD_CONST               1 (None)\n            194 IS_OP                    1\n            196 POP_JUMP_IF_FALSE      102 (to 204)\n            198 LOAD_FAST                1 (input_ids)\n            200 LOAD_ATTR                9 (device)\n            202 JUMP_FORWARD             2 (to 208)\n        >>  204 LOAD_FAST                6 (inputs_embeds)\n            206 LOAD_ATTR                9 (device)\n        >>  208 STORE_FAST              17 (device)\n\n802         210 LOAD_FAST                9 (past_key_values)\n            212 LOAD_CONST               1 (None)\n            214 IS_OP                    1\n            216 POP_JUMP_IF_FALSE      118 (to 236)\n            218 LOAD_FAST                9 (past_key_values)\n            220 LOAD_CONST               6 (0)\n            222 BINARY_SUBSCR\n            224 LOAD_CONST               6 (0)\n            226 BINARY_SUBSCR\n            228 LOAD_ATTR               10 (shape)\n            230 LOAD_CONST               7 (2)\n            232 BINARY_SUBSCR\n            234 JUMP_FORWARD             1 (to 238)\n        >>  236 LOAD_CONST               6 (0)\n        >>  238 STORE_FAST              18 (past_key_values_length)\n\n804         240 LOAD_FAST                2 (attention_mask)\n            242 LOAD_CONST               1 (None)\n            244 IS_OP                    0\n            246 POP_JUMP_IF_FALSE      135 (to 270)\n\n805         248 LOAD_GLOBAL             11 (torch)\n            250 LOAD_ATTR               12 (ones)\n            252 LOAD_FAST               15 (batch_size)\n            254 LOAD_FAST               16 (seq_length)\n            256 LOAD_FAST               18 (past_key_values_length)\n            258 BINARY_ADD\n            260 BUILD_TUPLE              2\n            262 LOAD_FAST               17 (device)\n            264 LOAD_CONST               8 (('device',))\n            266 CALL_FUNCTION_KW         2\n            268 STORE_FAST               2 (attention_mask)\n\n807     >>  270 LOAD_FAST                3 (token_type_ids)\n            272 LOAD_CONST               1 (None)\n            274 IS_OP                    0\n            276 POP_JUMP_IF_FALSE      175 (to 350)\n\n808         278 LOAD_GLOBAL             13 (hasattr)\n            280 LOAD_FAST                0 (self)\n            282 LOAD_ATTR               14 (embeddings)\n            284 LOAD_CONST               9 ('token_type_ids')\n            286 CALL_FUNCTION            2\n            288 POP_JUMP_IF_FALSE      166 (to 332)\n\n809         290 LOAD_FAST                0 (self)\n            292 LOAD_ATTR               14 (embeddings)\n            294 LOAD_ATTR               15 (token_type_ids)\n            296 LOAD_CONST               1 (None)\n            298 LOAD_CONST               1 (None)\n            300 BUILD_SLICE              2\n            302 LOAD_CONST               1 (None)\n            304 LOAD_FAST               16 (seq_length)\n            306 BUILD_SLICE              2\n            308 BUILD_TUPLE              2\n            310 BINARY_SUBSCR\n            312 STORE_FAST              19 (buffered_token_type_ids)\n\n810         314 LOAD_FAST               19 (buffered_token_type_ids)\n            316 LOAD_METHOD             16 (expand)\n            318 LOAD_FAST               15 (batch_size)\n            320 LOAD_FAST               16 (seq_length)\n            322 CALL_METHOD              2\n            324 STORE_FAST              20 (buffered_token_type_ids_expanded)\n\n811         326 LOAD_FAST               20 (buffered_token_type_ids_expanded)\n            328 STORE_FAST               3 (token_type_ids)\n            330 JUMP_FORWARD             9 (to 350)\n\n813     >>  332 LOAD_GLOBAL             11 (torch)\n            334 LOAD_ATTR               17 (zeros)\n            336 LOAD_FAST               14 (input_shape)\n            338 LOAD_GLOBAL             11 (torch)\n            340 LOAD_ATTR               18 (long)\n            342 LOAD_FAST               17 (device)\n            344 LOAD_CONST              10 (('dtype', 'device'))\n            346 CALL_FUNCTION_KW         3\n            348 STORE_FAST               3 (token_type_ids)\n\n817     >>  350 LOAD_FAST                0 (self)\n            352 LOAD_METHOD             19 (get_extended_attention_mask)\n            354 LOAD_FAST                2 (attention_mask)\n            356 LOAD_FAST               14 (input_shape)\n            358 CALL_METHOD              2\n            360 STORE_FAST              21 (extended_attention_mask)\n\n821         362 LOAD_FAST                0 (self)\n            364 LOAD_ATTR                0 (config)\n            366 LOAD_ATTR                4 (is_decoder)\n            368 POP_JUMP_IF_FALSE      217 (to 434)\n            370 LOAD_FAST                7 (encoder_hidden_states)\n            372 LOAD_CONST               1 (None)\n            374 IS_OP                    1\n            376 POP_JUMP_IF_FALSE      217 (to 434)\n\n822         378 LOAD_FAST                7 (encoder_hidden_states)\n            380 LOAD_METHOD              7 (size)\n            382 CALL_METHOD              0\n            384 UNPACK_SEQUENCE          3\n            386 STORE_FAST              22 (encoder_batch_size)\n            388 STORE_FAST              23 (encoder_sequence_length)\n            390 STORE_FAST              24 (_)\n\n823         392 LOAD_FAST               22 (encoder_batch_size)\n            394 LOAD_FAST               23 (encoder_sequence_length)\n            396 BUILD_TUPLE              2\n            398 STORE_FAST              25 (encoder_hidden_shape)\n\n824         400 LOAD_FAST                8 (encoder_attention_mask)\n            402 LOAD_CONST               1 (None)\n            404 IS_OP                    0\n            406 POP_JUMP_IF_FALSE      211 (to 422)\n\n825         408 LOAD_GLOBAL             11 (torch)\n            410 LOAD_ATTR               12 (ones)\n            412 LOAD_FAST               25 (encoder_hidden_shape)\n            414 LOAD_FAST               17 (device)\n            416 LOAD_CONST               8 (('device',))\n            418 CALL_FUNCTION_KW         2\n            420 STORE_FAST               8 (encoder_attention_mask)\n\n826     >>  422 LOAD_FAST                0 (self)\n            424 LOAD_METHOD             20 (invert_attention_mask)\n            426 LOAD_FAST                8 (encoder_attention_mask)\n            428 CALL_METHOD              1\n            430 STORE_FAST              26 (encoder_extended_attention_mask)\n            432 JUMP_FORWARD             2 (to 438)\n\n828     >>  434 LOAD_CONST               1 (None)\n            436 STORE_FAST              26 (encoder_extended_attention_mask)\n\n835     >>  438 LOAD_FAST                0 (self)\n            440 LOAD_METHOD             21 (get_head_mask)\n            442 LOAD_FAST                5 (head_mask)\n            444 LOAD_FAST                0 (self)\n            446 LOAD_ATTR                0 (config)\n            448 LOAD_ATTR               22 (num_hidden_layers)\n            450 CALL_METHOD              2\n            452 STORE_FAST               5 (head_mask)\n\n837         454 LOAD_FAST                0 (self)\n            456 LOAD_ATTR               14 (embeddings)\n\n838         458 LOAD_FAST                1 (input_ids)\n\n839         460 LOAD_FAST                4 (position_ids)\n\n840         462 LOAD_FAST                3 (token_type_ids)\n\n841         464 LOAD_FAST                6 (inputs_embeds)\n\n842         466 LOAD_FAST               18 (past_key_values_length)\n\n837         468 LOAD_CONST              11 (('input_ids', 'position_ids', 'token_type_ids', 'inputs_embeds', 'past_key_values_length'))\n            470 CALL_FUNCTION_KW         5\n            472 STORE_FAST              27 (embedding_output)\n\n844         474 LOAD_FAST                0 (self)\n            476 LOAD_ATTR               23 (encoder)\n\n845         478 LOAD_FAST               27 (embedding_output)\n\n846         480 LOAD_FAST               21 (extended_attention_mask)\n\n847         482 LOAD_FAST                5 (head_mask)\n\n848         484 LOAD_FAST                7 (encoder_hidden_states)\n\n849         486 LOAD_FAST               26 (encoder_extended_attention_mask)\n\n850         488 LOAD_FAST                9 (past_key_values)\n\n851         490 LOAD_FAST               10 (use_cache)\n\n852         492 LOAD_FAST               11 (output_attentions)\n\n853         494 LOAD_FAST               12 (output_hidden_states)\n\n854         496 LOAD_FAST               13 (return_dict)\n\n844         498 LOAD_CONST              12 (('attention_mask', 'head_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'past_key_values', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n            500 CALL_FUNCTION_KW        10\n            502 STORE_FAST              28 (encoder_outputs)\n\n856         504 LOAD_FAST               28 (encoder_outputs)\n            506 LOAD_CONST               6 (0)\n            508 BINARY_SUBSCR\n            510 STORE_FAST              29 (sequence_output)\n\n857         512 LOAD_FAST                0 (self)\n            514 LOAD_ATTR               24 (pooler)\n            516 LOAD_CONST               1 (None)\n            518 IS_OP                    1\n            520 EXTENDED_ARG             1\n            522 POP_JUMP_IF_FALSE      267 (to 534)\n            524 LOAD_FAST                0 (self)\n            526 LOAD_METHOD             24 (pooler)\n            528 LOAD_FAST               29 (sequence_output)\n            530 CALL_METHOD              1\n            532 JUMP_FORWARD             1 (to 536)\n        >>  534 LOAD_CONST               1 (None)\n        >>  536 STORE_FAST              30 (pooled_output)\n\n859         538 LOAD_FAST               13 (return_dict)\n            540 EXTENDED_ARG             1\n            542 POP_JUMP_IF_TRUE       282 (to 564)\n\n860         544 LOAD_FAST               29 (sequence_output)\n            546 LOAD_FAST               30 (pooled_output)\n            548 BUILD_TUPLE              2\n            550 LOAD_FAST               28 (encoder_outputs)\n            552 LOAD_CONST              13 (1)\n            554 LOAD_CONST               1 (None)\n            556 BUILD_SLICE              2\n            558 BINARY_SUBSCR\n            560 BINARY_ADD\n            562 RETURN_VALUE\n\n862     >>  564 LOAD_GLOBAL             25 (BaseModelOutputWithPoolingAndCrossAttentions)\n\n863         566 LOAD_FAST               29 (sequence_output)\n\n864         568 LOAD_FAST               30 (pooled_output)\n\n865         570 LOAD_FAST               28 (encoder_outputs)\n            572 LOAD_ATTR               26 (past_key_values)\n\n866         574 LOAD_FAST               28 (encoder_outputs)\n            576 LOAD_ATTR               27 (hidden_states)\n\n867         578 LOAD_FAST               28 (encoder_outputs)\n            580 LOAD_ATTR               28 (attentions)\n\n868         582 LOAD_FAST               28 (encoder_outputs)\n            584 LOAD_ATTR               29 (cross_attentions)\n\n862         586 LOAD_CONST              14 (('last_hidden_state', 'pooler_output', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n            588 CALL_FUNCTION_KW         6\n            590 RETURN_VALUE\n\n", "ORIGINAL BYTECODE warn_if_padding_and_no_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/modeling_utils.py line 3482 \n3486           0 LOAD_FAST                2 (attention_mask)\n               2 LOAD_CONST               1 (None)\n               4 IS_OP                    1\n               6 POP_JUMP_IF_TRUE        10 (to 20)\n               8 LOAD_FAST                0 (self)\n              10 LOAD_ATTR                0 (config)\n              12 LOAD_ATTR                1 (pad_token_id)\n              14 LOAD_CONST               1 (None)\n              16 IS_OP                    0\n              18 POP_JUMP_IF_FALSE       12 (to 24)\n\n3487     >>   20 LOAD_CONST               1 (None)\n              22 RETURN_VALUE\n\n3490     >>   24 LOAD_FAST                0 (self)\n              26 LOAD_ATTR                0 (config)\n              28 LOAD_ATTR                1 (pad_token_id)\n              30 LOAD_FAST                1 (input_ids)\n              32 LOAD_CONST               1 (None)\n              34 LOAD_CONST               1 (None)\n              36 BUILD_SLICE              2\n              38 LOAD_CONST               2 (-1)\n              40 LOAD_CONST               3 (0)\n              42 BUILD_LIST               2\n              44 BUILD_TUPLE              2\n              46 BINARY_SUBSCR\n              48 CONTAINS_OP              0\n              50 POP_JUMP_IF_FALSE      102 (to 204)\n\n3492          52 LOAD_CONST               4 ('We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.')\n\n3491          54 STORE_FAST               3 (warn_string)\n\n3500          56 LOAD_FAST                0 (self)\n              58 LOAD_ATTR                0 (config)\n              60 LOAD_ATTR                2 (bos_token_id)\n              62 LOAD_CONST               1 (None)\n              64 IS_OP                    1\n              66 POP_JUMP_IF_FALSE       42 (to 84)\n              68 LOAD_FAST                0 (self)\n              70 LOAD_ATTR                0 (config)\n              72 LOAD_ATTR                2 (bos_token_id)\n              74 LOAD_FAST                0 (self)\n              76 LOAD_ATTR                0 (config)\n              78 LOAD_ATTR                1 (pad_token_id)\n              80 COMPARE_OP               2 (==)\n              82 POP_JUMP_IF_TRUE        70 (to 140)\n\n3501     >>   84 LOAD_FAST                0 (self)\n              86 LOAD_ATTR                0 (config)\n              88 LOAD_ATTR                3 (eos_token_id)\n              90 LOAD_CONST               1 (None)\n              92 IS_OP                    1\n              94 POP_JUMP_IF_FALSE       56 (to 112)\n              96 LOAD_FAST                0 (self)\n              98 LOAD_ATTR                0 (config)\n             100 LOAD_ATTR                3 (eos_token_id)\n             102 LOAD_FAST                0 (self)\n             104 LOAD_ATTR                0 (config)\n             106 LOAD_ATTR                1 (pad_token_id)\n             108 COMPARE_OP               2 (==)\n             110 POP_JUMP_IF_TRUE        70 (to 140)\n\n3502     >>  112 LOAD_FAST                0 (self)\n             114 LOAD_ATTR                0 (config)\n             116 LOAD_ATTR                4 (sep_token_id)\n             118 LOAD_CONST               1 (None)\n             120 IS_OP                    1\n             122 POP_JUMP_IF_FALSE       95 (to 190)\n             124 LOAD_FAST                0 (self)\n             126 LOAD_ATTR                0 (config)\n             128 LOAD_ATTR                4 (sep_token_id)\n             130 LOAD_FAST                0 (self)\n             132 LOAD_ATTR                0 (config)\n             134 LOAD_ATTR                1 (pad_token_id)\n             136 COMPARE_OP               2 (==)\n             138 POP_JUMP_IF_FALSE       95 (to 190)\n\n3504     >>  140 LOAD_FAST                3 (warn_string)\n\n3505         142 LOAD_CONST               5 ('\\nYou may ignore this warning if your `pad_token_id` (')\n             144 LOAD_FAST                0 (self)\n             146 LOAD_ATTR                0 (config)\n             148 LOAD_ATTR                1 (pad_token_id)\n             150 FORMAT_VALUE             0\n             152 LOAD_CONST               6 (') is identical to the `bos_token_id` (')\n\n3506         154 LOAD_FAST                0 (self)\n             156 LOAD_ATTR                0 (config)\n             158 LOAD_ATTR                2 (bos_token_id)\n\n3505         160 FORMAT_VALUE             0\n             162 LOAD_CONST               7 ('), `eos_token_id` (')\n\n3506         164 LOAD_FAST                0 (self)\n             166 LOAD_ATTR                0 (config)\n             168 LOAD_ATTR                3 (eos_token_id)\n\n3505         170 FORMAT_VALUE             0\n             172 LOAD_CONST               8 ('), or the `sep_token_id` (')\n\n3507         174 LOAD_FAST                0 (self)\n             176 LOAD_ATTR                0 (config)\n             178 LOAD_ATTR                4 (sep_token_id)\n\n3505         180 FORMAT_VALUE             0\n             182 LOAD_CONST               9 ('), and your input is not padded.')\n             184 BUILD_STRING             9\n\n3504         186 INPLACE_ADD\n             188 STORE_FAST               3 (warn_string)\n\n3510     >>  190 LOAD_GLOBAL              5 (logger)\n             192 LOAD_METHOD              6 (warning_once)\n             194 LOAD_FAST                3 (warn_string)\n             196 CALL_METHOD              1\n             198 POP_TOP\n             200 LOAD_CONST               1 (None)\n             202 RETURN_VALUE\n\n3490     >>  204 LOAD_CONST               1 (None)\n             206 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py line 792 \n792           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           74 (to 148)\n              4 LOAD_FAST               12 (output_attentions)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE        8 (to 16)\n             12 LOAD_FAST               12 (output_attentions)\n             14 JUMP_FORWARD             3 (to 22)\n        >>   16 LOAD_FAST                1 (self)\n             18 LOAD_ATTR                0 (config)\n             20 LOAD_ATTR                1 (output_attentions)\n        >>   22 STORE_FAST              12 (output_attentions)\n             24 LOAD_FAST               13 (output_hidden_states)\n             26 LOAD_CONST               1 (None)\n             28 IS_OP                    1\n             30 POP_JUMP_IF_FALSE       18 (to 36)\n             32 LOAD_FAST               13 (output_hidden_states)\n             34 JUMP_FORWARD             3 (to 42)\n        >>   36 LOAD_FAST                1 (self)\n             38 LOAD_ATTR                0 (config)\n             40 LOAD_ATTR                2 (output_hidden_states)\n        >>   42 STORE_FAST              13 (output_hidden_states)\n             44 LOAD_FAST               14 (return_dict)\n             46 LOAD_CONST               1 (None)\n             48 IS_OP                    1\n             50 POP_JUMP_IF_FALSE       28 (to 56)\n             52 LOAD_FAST               14 (return_dict)\n             54 JUMP_FORWARD             3 (to 62)\n        >>   56 LOAD_FAST                1 (self)\n             58 LOAD_ATTR                0 (config)\n             60 LOAD_ATTR                3 (use_return_dict)\n        >>   62 STORE_FAST              14 (return_dict)\n             64 LOAD_FAST                1 (self)\n             66 LOAD_ATTR                0 (config)\n             68 LOAD_ATTR                4 (is_decoder)\n             70 POP_JUMP_IF_FALSE       47 (to 94)\n             72 LOAD_FAST               11 (use_cache)\n             74 LOAD_CONST               1 (None)\n             76 IS_OP                    1\n             78 POP_JUMP_IF_FALSE       42 (to 84)\n             80 LOAD_FAST               11 (use_cache)\n             82 JUMP_FORWARD             3 (to 90)\n        >>   84 LOAD_FAST                1 (self)\n             86 LOAD_ATTR                0 (config)\n             88 LOAD_ATTR                5 (use_cache)\n        >>   90 STORE_FAST              11 (use_cache)\n             92 JUMP_FORWARD             2 (to 98)\n        >>   94 LOAD_CONST               2 (False)\n             96 STORE_FAST              11 (use_cache)\n        >>   98 LOAD_FAST                2 (input_ids)\n            100 LOAD_CONST               1 (None)\n            102 IS_OP                    1\n            104 POP_JUMP_IF_FALSE       61 (to 122)\n            106 LOAD_FAST                7 (inputs_embeds)\n            108 LOAD_CONST               1 (None)\n            110 IS_OP                    1\n            112 POP_JUMP_IF_FALSE       61 (to 122)\n            114 LOAD_GLOBAL              6 (ValueError)\n            116 LOAD_CONST               3 ('You cannot specify both input_ids and inputs_embeds at the same time')\n            118 CALL_FUNCTION            1\n            120 RAISE_VARARGS            1\n        >>  122 LOAD_FAST                2 (input_ids)\n            124 LOAD_CONST               1 (None)\n            126 IS_OP                    1\n            128 POP_JUMP_IF_FALSE       76 (to 152)\n            130 LOAD_FAST                2 (input_ids)\n            132 LOAD_ATTR                7 (size)\n            134 CALL_FUNCTION            0\n            136 STORE_FAST              15 (input_shape)\n            138 LOAD_FAST                1 (self)\n            140 LOAD_ATTR                8 (warn_if_padding_and_no_attention_mask)\n            142 LOAD_FAST                2 (input_ids)\n            144 LOAD_FAST                3 (attention_mask)\n            146 CALL_FUNCTION            2\n        >>  148 POP_TOP\n            150 JUMP_FORWARD            17 (to 186)\n\n793     >>  152 LOAD_FAST                7 (inputs_embeds)\n            154 LOAD_CONST               1 (None)\n            156 IS_OP                    1\n            158 POP_JUMP_IF_FALSE       89 (to 178)\n\n794         160 LOAD_FAST                7 (inputs_embeds)\n            162 LOAD_ATTR                7 (size)\n            164 CALL_FUNCTION            0\n            166 LOAD_CONST               1 (None)\n            168 LOAD_CONST               4 (-1)\n            170 BUILD_SLICE              2\n            172 BINARY_SUBSCR\n            174 STORE_FAST              15 (input_shape)\n            176 JUMP_FORWARD             4 (to 186)\n\n796     >>  178 LOAD_GLOBAL              6 (ValueError)\n            180 LOAD_CONST               5 ('You have to specify either input_ids or inputs_embeds')\n            182 CALL_FUNCTION            1\n            184 RAISE_VARARGS            1\n\n798     >>  186 LOAD_FAST               15 (input_shape)\n            188 UNPACK_SEQUENCE          2\n            190 STORE_FAST              16 (batch_size)\n            192 STORE_FAST              17 (seq_length)\n\n799         194 LOAD_FAST                2 (input_ids)\n            196 LOAD_CONST               1 (None)\n            198 IS_OP                    1\n            200 POP_JUMP_IF_FALSE      104 (to 208)\n            202 LOAD_FAST                2 (input_ids)\n            204 LOAD_ATTR                9 (device)\n            206 JUMP_FORWARD             2 (to 212)\n        >>  208 LOAD_FAST                7 (inputs_embeds)\n            210 LOAD_ATTR                9 (device)\n        >>  212 STORE_FAST              18 (device)\n\n802         214 LOAD_FAST               10 (past_key_values)\n            216 LOAD_CONST               1 (None)\n            218 IS_OP                    1\n            220 POP_JUMP_IF_FALSE      120 (to 240)\n            222 LOAD_FAST               10 (past_key_values)\n            224 LOAD_CONST               6 (0)\n            226 BINARY_SUBSCR\n            228 LOAD_CONST               6 (0)\n            230 BINARY_SUBSCR\n            232 LOAD_ATTR               10 (shape)\n            234 LOAD_CONST               7 (2)\n            236 BINARY_SUBSCR\n            238 JUMP_FORWARD             1 (to 242)\n        >>  240 LOAD_CONST               6 (0)\n        >>  242 STORE_FAST              19 (past_key_values_length)\n\n804         244 LOAD_FAST                3 (attention_mask)\n            246 LOAD_CONST               1 (None)\n            248 IS_OP                    0\n            250 POP_JUMP_IF_FALSE      137 (to 274)\n\n805         252 LOAD_GLOBAL             11 (torch)\n            254 LOAD_ATTR               12 (ones)\n            256 LOAD_FAST               16 (batch_size)\n            258 LOAD_FAST               17 (seq_length)\n            260 LOAD_FAST               19 (past_key_values_length)\n            262 BINARY_ADD\n            264 BUILD_TUPLE              2\n            266 LOAD_FAST               18 (device)\n            268 LOAD_CONST               8 (('device',))\n            270 CALL_FUNCTION_KW         2\n            272 STORE_FAST               3 (attention_mask)\n\n807     >>  274 LOAD_FAST                4 (token_type_ids)\n            276 LOAD_CONST               1 (None)\n            278 IS_OP                    0\n            280 POP_JUMP_IF_FALSE      177 (to 354)\n\n808         282 LOAD_GLOBAL             13 (hasattr)\n            284 LOAD_FAST                1 (self)\n            286 LOAD_ATTR               14 (embeddings)\n            288 LOAD_CONST               9 ('token_type_ids')\n            290 CALL_FUNCTION            2\n            292 POP_JUMP_IF_FALSE      168 (to 336)\n\n809         294 LOAD_FAST                1 (self)\n            296 LOAD_ATTR               14 (embeddings)\n            298 LOAD_ATTR               15 (token_type_ids)\n            300 LOAD_CONST               1 (None)\n            302 LOAD_CONST               1 (None)\n            304 BUILD_SLICE              2\n            306 LOAD_CONST               1 (None)\n            308 LOAD_FAST               17 (seq_length)\n            310 BUILD_SLICE              2\n            312 BUILD_TUPLE              2\n            314 BINARY_SUBSCR\n            316 STORE_FAST              20 (buffered_token_type_ids)\n\n810         318 LOAD_FAST               20 (buffered_token_type_ids)\n            320 LOAD_ATTR               16 (expand)\n            322 LOAD_FAST               16 (batch_size)\n            324 LOAD_FAST               17 (seq_length)\n            326 CALL_FUNCTION            2\n            328 STORE_FAST              21 (buffered_token_type_ids_expanded)\n\n811         330 LOAD_FAST               21 (buffered_token_type_ids_expanded)\n            332 STORE_FAST               4 (token_type_ids)\n            334 JUMP_FORWARD             9 (to 354)\n\n813     >>  336 LOAD_GLOBAL             11 (torch)\n            338 LOAD_ATTR               17 (zeros)\n            340 LOAD_FAST               15 (input_shape)\n            342 LOAD_GLOBAL             11 (torch)\n            344 LOAD_ATTR               18 (long)\n            346 LOAD_FAST               18 (device)\n            348 LOAD_CONST              10 (('dtype', 'device'))\n            350 CALL_FUNCTION_KW         3\n            352 STORE_FAST               4 (token_type_ids)\n\n817     >>  354 LOAD_FAST                1 (self)\n            356 LOAD_ATTR               19 (get_extended_attention_mask)\n            358 LOAD_FAST                3 (attention_mask)\n            360 LOAD_FAST               15 (input_shape)\n            362 CALL_FUNCTION            2\n            364 STORE_FAST              22 (extended_attention_mask)\n\n821         366 LOAD_FAST                1 (self)\n            368 LOAD_ATTR                0 (config)\n            370 LOAD_ATTR                4 (is_decoder)\n            372 POP_JUMP_IF_FALSE      219 (to 438)\n            374 LOAD_FAST                8 (encoder_hidden_states)\n            376 LOAD_CONST               1 (None)\n            378 IS_OP                    1\n            380 POP_JUMP_IF_FALSE      219 (to 438)\n\n822         382 LOAD_FAST                8 (encoder_hidden_states)\n            384 LOAD_ATTR                7 (size)\n            386 CALL_FUNCTION            0\n            388 UNPACK_SEQUENCE          3\n            390 STORE_FAST              23 (encoder_batch_size)\n            392 STORE_FAST              24 (encoder_sequence_length)\n            394 STORE_FAST              25 (_)\n\n823         396 LOAD_FAST               23 (encoder_batch_size)\n            398 LOAD_FAST               24 (encoder_sequence_length)\n            400 BUILD_TUPLE              2\n            402 STORE_FAST              26 (encoder_hidden_shape)\n\n824         404 LOAD_FAST                9 (encoder_attention_mask)\n            406 LOAD_CONST               1 (None)\n            408 IS_OP                    0\n            410 POP_JUMP_IF_FALSE      213 (to 426)\n\n825         412 LOAD_GLOBAL             11 (torch)\n            414 LOAD_ATTR               12 (ones)\n            416 LOAD_FAST               26 (encoder_hidden_shape)\n            418 LOAD_FAST               18 (device)\n            420 LOAD_CONST               8 (('device',))\n            422 CALL_FUNCTION_KW         2\n            424 STORE_FAST               9 (encoder_attention_mask)\n\n826     >>  426 LOAD_FAST                1 (self)\n            428 LOAD_ATTR               20 (invert_attention_mask)\n            430 LOAD_FAST                9 (encoder_attention_mask)\n            432 CALL_FUNCTION            1\n            434 STORE_FAST              27 (encoder_extended_attention_mask)\n            436 JUMP_FORWARD             2 (to 442)\n\n828     >>  438 LOAD_CONST               1 (None)\n            440 STORE_FAST              27 (encoder_extended_attention_mask)\n\n835     >>  442 LOAD_FAST                1 (self)\n            444 LOAD_ATTR               21 (get_head_mask)\n            446 LOAD_FAST                6 (head_mask)\n            448 LOAD_FAST                1 (self)\n            450 LOAD_ATTR                0 (config)\n            452 LOAD_ATTR               22 (num_hidden_layers)\n            454 CALL_FUNCTION            2\n            456 STORE_FAST               6 (head_mask)\n\n837         458 LOAD_FAST                1 (self)\n            460 LOAD_ATTR               14 (embeddings)\n\n838         462 LOAD_FAST                2 (input_ids)\n\n839         464 LOAD_FAST                5 (position_ids)\n\n840         466 LOAD_FAST                4 (token_type_ids)\n\n841         468 LOAD_FAST                7 (inputs_embeds)\n\n842         470 LOAD_FAST               19 (past_key_values_length)\n\n837         472 LOAD_CONST              11 (('input_ids', 'position_ids', 'token_type_ids', 'inputs_embeds', 'past_key_values_length'))\n            474 CALL_FUNCTION_KW         5\n            476 STORE_FAST              28 (embedding_output)\n\n844         478 LOAD_FAST                1 (self)\n            480 LOAD_ATTR               23 (encoder)\n\n845         482 LOAD_FAST               28 (embedding_output)\n\n846         484 LOAD_FAST               22 (extended_attention_mask)\n\n847         486 LOAD_FAST                6 (head_mask)\n\n848         488 LOAD_FAST                8 (encoder_hidden_states)\n\n849         490 LOAD_FAST               27 (encoder_extended_attention_mask)\n\n850         492 LOAD_FAST               10 (past_key_values)\n\n851         494 LOAD_FAST               11 (use_cache)\n\n852         496 LOAD_FAST               12 (output_attentions)\n\n853         498 LOAD_FAST               13 (output_hidden_states)\n\n854         500 LOAD_FAST               14 (return_dict)\n\n844         502 LOAD_CONST              12 (('attention_mask', 'head_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'past_key_values', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n            504 CALL_FUNCTION_KW        10\n            506 STORE_FAST              29 (encoder_outputs)\n\n856         508 LOAD_FAST               29 (encoder_outputs)\n            510 LOAD_CONST               6 (0)\n            512 BINARY_SUBSCR\n            514 STORE_FAST              30 (sequence_output)\n\n857         516 LOAD_FAST                1 (self)\n            518 LOAD_ATTR               24 (pooler)\n            520 LOAD_CONST               1 (None)\n            522 IS_OP                    1\n            524 EXTENDED_ARG             1\n            526 POP_JUMP_IF_FALSE      269 (to 538)\n            528 LOAD_FAST                1 (self)\n            530 LOAD_ATTR               24 (pooler)\n            532 LOAD_FAST               30 (sequence_output)\n            534 CALL_FUNCTION            1\n            536 JUMP_FORWARD             1 (to 540)\n        >>  538 LOAD_CONST               1 (None)\n        >>  540 STORE_FAST              31 (pooled_output)\n\n859         542 LOAD_FAST               14 (return_dict)\n            544 EXTENDED_ARG             1\n            546 POP_JUMP_IF_TRUE       284 (to 568)\n\n860         548 LOAD_FAST               30 (sequence_output)\n            550 LOAD_FAST               31 (pooled_output)\n            552 BUILD_TUPLE              2\n            554 LOAD_FAST               29 (encoder_outputs)\n            556 LOAD_CONST              13 (1)\n            558 LOAD_CONST               1 (None)\n            560 BUILD_SLICE              2\n            562 BINARY_SUBSCR\n            564 BINARY_ADD\n            566 RETURN_VALUE\n\n862     >>  568 LOAD_GLOBAL             25 (BaseModelOutputWithPoolingAndCrossAttentions)\n\n863         570 LOAD_FAST               30 (sequence_output)\n\n864         572 LOAD_FAST               31 (pooled_output)\n\n865         574 LOAD_FAST               29 (encoder_outputs)\n            576 LOAD_ATTR               26 (past_key_values)\n\n866         578 LOAD_FAST               29 (encoder_outputs)\n            580 LOAD_ATTR               27 (hidden_states)\n\n867         582 LOAD_FAST               29 (encoder_outputs)\n            584 LOAD_ATTR               28 (attentions)\n\n868         586 LOAD_FAST               29 (encoder_outputs)\n            588 LOAD_ATTR               29 (cross_attentions)\n\n862         590 LOAD_CONST              14 (('last_hidden_state', 'pooler_output', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n            592 CALL_FUNCTION_KW         6\n            594 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py line 1498 \n1498           0 LOAD_FAST                0 (___stack0)\n               2 JUMP_ABSOLUTE           25 (to 50)\n               4 LOAD_FAST                4 (return_dict)\n               6 LOAD_CONST               1 (None)\n               8 IS_OP                    1\n              10 POP_JUMP_IF_FALSE        8 (to 16)\n              12 LOAD_FAST                4 (return_dict)\n              14 JUMP_FORWARD             3 (to 22)\n         >>   16 LOAD_FAST                1 (self)\n              18 LOAD_ATTR                0 (config)\n              20 LOAD_ATTR                1 (use_return_dict)\n         >>   22 STORE_FAST               4 (return_dict)\n              24 LOAD_FAST                1 (self)\n              26 LOAD_ATTR                2 (roberta)\n              28 LOAD_FAST                5 (input_ids)\n              30 LOAD_FAST                6 (attention_mask)\n              32 LOAD_FAST                7 (token_type_ids)\n              34 LOAD_FAST                8 (position_ids)\n              36 LOAD_FAST                9 (head_mask)\n              38 LOAD_FAST               10 (inputs_embeds)\n              40 LOAD_FAST               11 (output_attentions)\n              42 LOAD_FAST               12 (output_hidden_states)\n              44 LOAD_FAST                4 (return_dict)\n              46 LOAD_CONST               2 (('attention_mask', 'token_type_ids', 'position_ids', 'head_mask', 'inputs_embeds', 'output_attentions', 'output_hidden_states', 'return_dict'))\n              48 CALL_FUNCTION_KW         9\n         >>   50 STORE_FAST              13 (outputs)\n\n1510          52 LOAD_FAST               13 (outputs)\n              54 LOAD_CONST               3 (0)\n              56 BINARY_SUBSCR\n              58 STORE_FAST              14 (sequence_output)\n\n1512          60 LOAD_FAST                1 (self)\n              62 LOAD_ATTR                3 (qa_outputs)\n              64 LOAD_FAST               14 (sequence_output)\n              66 CALL_FUNCTION            1\n              68 STORE_FAST              15 (logits)\n\n1513          70 LOAD_FAST               15 (logits)\n              72 LOAD_ATTR                4 (split)\n              74 LOAD_CONST               4 (1)\n              76 LOAD_CONST               5 (-1)\n              78 LOAD_CONST               6 (('dim',))\n              80 CALL_FUNCTION_KW         2\n              82 UNPACK_SEQUENCE          2\n              84 STORE_FAST              16 (start_logits)\n              86 STORE_FAST              17 (end_logits)\n\n1514          88 LOAD_FAST               16 (start_logits)\n              90 LOAD_ATTR                5 (squeeze)\n              92 LOAD_CONST               5 (-1)\n              94 CALL_FUNCTION            1\n              96 LOAD_ATTR                6 (contiguous)\n              98 CALL_FUNCTION            0\n             100 STORE_FAST              16 (start_logits)\n\n1515         102 LOAD_FAST               17 (end_logits)\n             104 LOAD_ATTR                5 (squeeze)\n             106 LOAD_CONST               5 (-1)\n             108 CALL_FUNCTION            1\n             110 LOAD_ATTR                6 (contiguous)\n             112 CALL_FUNCTION            0\n             114 STORE_FAST              17 (end_logits)\n\n1517         116 LOAD_CONST               1 (None)\n             118 STORE_FAST              18 (total_loss)\n\n1518         120 LOAD_FAST                2 (start_positions)\n             122 LOAD_CONST               1 (None)\n             124 IS_OP                    1\n             126 POP_JUMP_IF_FALSE      132 (to 264)\n             128 LOAD_FAST                3 (end_positions)\n             130 LOAD_CONST               1 (None)\n             132 IS_OP                    1\n             134 POP_JUMP_IF_FALSE      132 (to 264)\n\n1520         136 LOAD_GLOBAL              7 (len)\n             138 LOAD_FAST                2 (start_positions)\n             140 LOAD_ATTR                8 (size)\n             142 CALL_FUNCTION            0\n             144 CALL_FUNCTION            1\n             146 LOAD_CONST               4 (1)\n             148 COMPARE_OP               4 (>)\n             150 POP_JUMP_IF_FALSE       81 (to 162)\n\n1521         152 LOAD_FAST                2 (start_positions)\n             154 LOAD_ATTR                5 (squeeze)\n             156 LOAD_CONST               5 (-1)\n             158 CALL_FUNCTION            1\n             160 STORE_FAST               2 (start_positions)\n\n1522     >>  162 LOAD_GLOBAL              7 (len)\n             164 LOAD_FAST                3 (end_positions)\n             166 LOAD_ATTR                8 (size)\n             168 CALL_FUNCTION            0\n             170 CALL_FUNCTION            1\n             172 LOAD_CONST               4 (1)\n             174 COMPARE_OP               4 (>)\n             176 POP_JUMP_IF_FALSE       94 (to 188)\n\n1523         178 LOAD_FAST                3 (end_positions)\n             180 LOAD_ATTR                5 (squeeze)\n             182 LOAD_CONST               5 (-1)\n             184 CALL_FUNCTION            1\n             186 STORE_FAST               3 (end_positions)\n\n1525     >>  188 LOAD_FAST               16 (start_logits)\n             190 LOAD_ATTR                8 (size)\n             192 LOAD_CONST               4 (1)\n             194 CALL_FUNCTION            1\n             196 STORE_FAST              19 (ignored_index)\n\n1526         198 LOAD_FAST                2 (start_positions)\n             200 LOAD_ATTR                9 (clamp)\n             202 LOAD_CONST               3 (0)\n             204 LOAD_FAST               19 (ignored_index)\n             206 CALL_FUNCTION            2\n             208 STORE_FAST               2 (start_positions)\n\n1527         210 LOAD_FAST                3 (end_positions)\n             212 LOAD_ATTR                9 (clamp)\n             214 LOAD_CONST               3 (0)\n             216 LOAD_FAST               19 (ignored_index)\n             218 CALL_FUNCTION            2\n             220 STORE_FAST               3 (end_positions)\n\n1529         222 LOAD_GLOBAL             10 (CrossEntropyLoss)\n             224 LOAD_FAST               19 (ignored_index)\n             226 LOAD_CONST               7 (('ignore_index',))\n             228 CALL_FUNCTION_KW         1\n             230 STORE_FAST              20 (loss_fct)\n\n1530         232 LOAD_FAST               20 (loss_fct)\n             234 LOAD_FAST               16 (start_logits)\n             236 LOAD_FAST                2 (start_positions)\n             238 CALL_FUNCTION            2\n             240 STORE_FAST              21 (start_loss)\n\n1531         242 LOAD_FAST               20 (loss_fct)\n             244 LOAD_FAST               17 (end_logits)\n             246 LOAD_FAST                3 (end_positions)\n             248 CALL_FUNCTION            2\n             250 STORE_FAST              22 (end_loss)\n\n1532         252 LOAD_FAST               21 (start_loss)\n             254 LOAD_FAST               22 (end_loss)\n             256 BINARY_ADD\n             258 LOAD_CONST               8 (2)\n             260 BINARY_TRUE_DIVIDE\n             262 STORE_FAST              18 (total_loss)\n\n1534     >>  264 LOAD_FAST                4 (return_dict)\n             266 POP_JUMP_IF_TRUE       155 (to 310)\n\n1535         268 LOAD_FAST               16 (start_logits)\n             270 LOAD_FAST               17 (end_logits)\n             272 BUILD_TUPLE              2\n             274 LOAD_FAST               13 (outputs)\n             276 LOAD_CONST               8 (2)\n             278 LOAD_CONST               1 (None)\n             280 BUILD_SLICE              2\n             282 BINARY_SUBSCR\n             284 BINARY_ADD\n             286 STORE_FAST              23 (output)\n\n1536         288 LOAD_FAST               18 (total_loss)\n             290 LOAD_CONST               1 (None)\n             292 IS_OP                    1\n             294 POP_JUMP_IF_FALSE      153 (to 306)\n             296 LOAD_FAST               18 (total_loss)\n             298 BUILD_TUPLE              1\n             300 LOAD_FAST               23 (output)\n             302 BINARY_ADD\n             304 RETURN_VALUE\n         >>  306 LOAD_FAST               23 (output)\n             308 RETURN_VALUE\n\n1538     >>  310 LOAD_GLOBAL             11 (QuestionAnsweringModelOutput)\n\n1539         312 LOAD_FAST               18 (total_loss)\n\n1540         314 LOAD_FAST               16 (start_logits)\n\n1541         316 LOAD_FAST               17 (end_logits)\n\n1542         318 LOAD_FAST               13 (outputs)\n             320 LOAD_ATTR               12 (hidden_states)\n\n1543         322 LOAD_FAST               13 (outputs)\n             324 LOAD_ATTR               13 (attentions)\n\n1538         326 LOAD_CONST               9 (('loss', 'start_logits', 'end_logits', 'hidden_states', 'attentions'))\n             328 CALL_FUNCTION_KW         5\n             330 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 557 \n557           0 LOAD_FAST                0 (___stack0)\n              2 CALL_FUNCTION            0\n              4 SETUP_WITH              10 (to 26)\n              6 POP_TOP\n              8 LOAD_FAST                1 (___stack1)\n             10 JUMP_ABSOLUTE           44 (to 88)\n             12 POP_BLOCK\n             14 LOAD_CONST               0 (None)\n             16 DUP_TOP\n             18 DUP_TOP\n             20 CALL_FUNCTION            3\n             22 POP_TOP\n             24 JUMP_FORWARD             8 (to 42)\n        >>   26 WITH_EXCEPT_START\n             28 POP_JUMP_IF_TRUE        16 (to 32)\n             30 RERAISE                  0\n        >>   32 POP_TOP\n             34 POP_TOP\n             36 POP_TOP\n             38 POP_EXCEPT\n             40 POP_TOP\n        >>   42 NOP\n             44 LOAD_CONST               0 (None)\n             46 RAISE_VARARGS            1\n             48 LOAD_GLOBAL              0 (clone_inputs)\n             50 LOAD_FAST                6 (inputs)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (cloned_inputs)\n             56 LOAD_FAST                2 (self)\n             58 LOAD_ATTR                1 (optimizer_zero_grad)\n             60 LOAD_FAST                3 (mod)\n             62 CALL_FUNCTION            1\n             64 POP_TOP\n             66 LOAD_FAST                2 (self)\n             68 LOAD_ATTR                2 (autocast)\n             70 CALL_FUNCTION            0\n             72 SETUP_WITH              20 (to 114)\n             74 POP_TOP\n             76 LOAD_FAST                3 (mod)\n             78 LOAD_CONST               1 (())\n             80 BUILD_MAP                0\n             82 LOAD_FAST                5 (cloned_inputs)\n             84 DICT_MERGE               1\n             86 CALL_FUNCTION_EX         1\n        >>   88 STORE_FAST               7 (pred)\n\n558          90 LOAD_FAST                2 (self)\n             92 LOAD_ATTR                3 (compute_loss)\n             94 LOAD_FAST                7 (pred)\n             96 CALL_FUNCTION            1\n             98 STORE_FAST               8 (loss)\n            100 POP_BLOCK\n\n556         102 LOAD_CONST               0 (None)\n            104 DUP_TOP\n            106 DUP_TOP\n            108 CALL_FUNCTION            3\n            110 POP_TOP\n            112 JUMP_FORWARD             8 (to 130)\n        >>  114 WITH_EXCEPT_START\n            116 POP_JUMP_IF_TRUE        60 (to 120)\n            118 RERAISE                  1\n        >>  120 POP_TOP\n            122 POP_TOP\n            124 POP_TOP\n            126 POP_EXCEPT\n            128 POP_TOP\n\n559     >>  130 LOAD_FAST                2 (self)\n            132 LOAD_ATTR                4 (grad_scaler)\n            134 LOAD_ATTR                5 (scale)\n            136 LOAD_FAST                8 (loss)\n            138 CALL_FUNCTION            1\n            140 LOAD_ATTR                6 (backward)\n            142 CALL_FUNCTION            0\n            144 POP_TOP\n\n560         146 LOAD_FAST                2 (self)\n            148 LOAD_ATTR                7 (optimizer_step)\n            150 CALL_FUNCTION            0\n            152 POP_TOP\n\n561         154 LOAD_FAST                4 (collect_outputs)\n            156 POP_JUMP_IF_FALSE       86 (to 172)\n\n562         158 LOAD_GLOBAL              8 (collect_results)\n            160 LOAD_FAST                3 (mod)\n            162 LOAD_FAST                7 (pred)\n            164 LOAD_FAST                8 (loss)\n            166 LOAD_FAST                5 (cloned_inputs)\n            168 CALL_FUNCTION            4\n            170 RETURN_VALUE\n\n563     >>  172 LOAD_CONST               0 (None)\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/speech_to_text_2/modeling_speech_to_text_2.py line 791 \n916           0 LOAD_FAST               11 (output_attentions)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    1\n              6 POP_JUMP_IF_FALSE        6 (to 12)\n              8 LOAD_FAST               11 (output_attentions)\n             10 JUMP_FORWARD             3 (to 18)\n        >>   12 LOAD_FAST                0 (self)\n             14 LOAD_ATTR                0 (config)\n             16 LOAD_ATTR                1 (output_attentions)\n        >>   18 STORE_FAST              11 (output_attentions)\n\n918          20 LOAD_FAST               12 (output_hidden_states)\n             22 LOAD_CONST               1 (None)\n             24 IS_OP                    1\n             26 POP_JUMP_IF_FALSE       16 (to 32)\n             28 LOAD_FAST               12 (output_hidden_states)\n             30 JUMP_FORWARD             3 (to 38)\n        >>   32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                0 (config)\n             36 LOAD_ATTR                2 (output_hidden_states)\n\n917     >>   38 STORE_FAST              12 (output_hidden_states)\n\n920          40 LOAD_FAST               13 (return_dict)\n             42 LOAD_CONST               1 (None)\n             44 IS_OP                    1\n             46 POP_JUMP_IF_FALSE       26 (to 52)\n             48 LOAD_FAST               13 (return_dict)\n             50 JUMP_FORWARD             3 (to 58)\n        >>   52 LOAD_FAST                0 (self)\n             54 LOAD_ATTR                0 (config)\n             56 LOAD_ATTR                3 (use_return_dict)\n        >>   58 STORE_FAST              13 (return_dict)\n\n923          60 LOAD_FAST                0 (self)\n             62 LOAD_ATTR                4 (model)\n             64 LOAD_ATTR                5 (decoder)\n\n924          66 LOAD_FAST                1 (input_ids)\n\n925          68 LOAD_FAST                2 (attention_mask)\n\n926          70 LOAD_FAST                3 (encoder_hidden_states)\n\n927          72 LOAD_FAST                4 (encoder_attention_mask)\n\n928          74 LOAD_FAST                5 (head_mask)\n\n929          76 LOAD_FAST                6 (cross_attn_head_mask)\n\n930          78 LOAD_FAST                7 (past_key_values)\n\n931          80 LOAD_FAST                8 (inputs_embeds)\n\n932          82 LOAD_FAST               10 (use_cache)\n\n933          84 LOAD_FAST               11 (output_attentions)\n\n934          86 LOAD_FAST               12 (output_hidden_states)\n\n935          88 LOAD_FAST               13 (return_dict)\n\n923          90 LOAD_CONST               2 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             92 CALL_FUNCTION_KW        12\n             94 STORE_FAST              14 (outputs)\n\n938          96 LOAD_FAST                0 (self)\n             98 LOAD_METHOD              6 (lm_head)\n            100 LOAD_FAST               14 (outputs)\n            102 LOAD_CONST               3 (0)\n            104 BINARY_SUBSCR\n            106 CALL_METHOD              1\n            108 STORE_FAST              15 (logits)\n\n940         110 LOAD_CONST               1 (None)\n            112 STORE_FAST              16 (loss)\n\n941         114 LOAD_FAST                9 (labels)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       78 (to 156)\n\n942         122 LOAD_GLOBAL              7 (CrossEntropyLoss)\n            124 CALL_FUNCTION            0\n            126 STORE_FAST              17 (loss_fct)\n\n943         128 LOAD_FAST               17 (loss_fct)\n            130 LOAD_FAST               15 (logits)\n            132 LOAD_METHOD              8 (view)\n            134 LOAD_CONST               4 (-1)\n            136 LOAD_FAST                0 (self)\n            138 LOAD_ATTR                0 (config)\n            140 LOAD_ATTR                9 (vocab_size)\n            142 CALL_METHOD              2\n            144 LOAD_FAST                9 (labels)\n            146 LOAD_METHOD              8 (view)\n            148 LOAD_CONST               4 (-1)\n            150 CALL_METHOD              1\n            152 CALL_FUNCTION            2\n            154 STORE_FAST              16 (loss)\n\n945     >>  156 LOAD_FAST               13 (return_dict)\n            158 POP_JUMP_IF_TRUE       100 (to 200)\n\n946         160 LOAD_FAST               15 (logits)\n            162 BUILD_TUPLE              1\n            164 LOAD_FAST               14 (outputs)\n            166 LOAD_CONST               5 (1)\n            168 LOAD_CONST               1 (None)\n            170 BUILD_SLICE              2\n            172 BINARY_SUBSCR\n            174 BINARY_ADD\n            176 STORE_FAST              18 (output)\n\n947         178 LOAD_FAST               16 (loss)\n            180 LOAD_CONST               1 (None)\n            182 IS_OP                    1\n            184 POP_JUMP_IF_FALSE       98 (to 196)\n            186 LOAD_FAST               16 (loss)\n            188 BUILD_TUPLE              1\n            190 LOAD_FAST               18 (output)\n            192 BINARY_ADD\n            194 RETURN_VALUE\n        >>  196 LOAD_FAST               18 (output)\n            198 RETURN_VALUE\n\n949     >>  200 LOAD_GLOBAL             10 (CausalLMOutputWithCrossAttentions)\n\n950         202 LOAD_FAST               16 (loss)\n\n951         204 LOAD_FAST               15 (logits)\n\n952         206 LOAD_FAST               14 (outputs)\n            208 LOAD_ATTR               11 (past_key_values)\n\n953         210 LOAD_FAST               14 (outputs)\n            212 LOAD_ATTR               12 (hidden_states)\n\n954         214 LOAD_FAST               14 (outputs)\n            216 LOAD_ATTR               13 (attentions)\n\n955         218 LOAD_FAST               14 (outputs)\n            220 LOAD_ATTR               14 (cross_attentions)\n\n949         222 LOAD_CONST               6 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n            224 CALL_FUNCTION_KW         6\n            226 RETURN_VALUE\n\n", "ORIGINAL BYTECODE _prepare_decoder_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/speech_to_text_2/modeling_speech_to_text_2.py line 499 \n502           0 LOAD_CONST               0 (None)\n              2 STORE_FAST               5 (combined_attention_mask)\n\n503           4 LOAD_FAST                2 (input_shape)\n              6 LOAD_CONST               1 (-1)\n              8 BINARY_SUBSCR\n             10 LOAD_CONST               2 (1)\n             12 COMPARE_OP               4 (>)\n             14 POP_JUMP_IF_FALSE       18 (to 36)\n\n504          16 LOAD_GLOBAL              0 (_make_causal_mask)\n\n505          18 LOAD_FAST                2 (input_shape)\n\n506          20 LOAD_FAST                3 (inputs_embeds)\n             22 LOAD_ATTR                1 (dtype)\n\n507          24 LOAD_FAST                3 (inputs_embeds)\n             26 LOAD_ATTR                2 (device)\n\n508          28 LOAD_FAST                4 (past_key_values_length)\n\n504          30 LOAD_CONST               3 (('device', 'past_key_values_length'))\n             32 CALL_FUNCTION_KW         4\n             34 STORE_FAST               5 (combined_attention_mask)\n\n511     >>   36 LOAD_FAST                1 (attention_mask)\n             38 LOAD_CONST               0 (None)\n             40 IS_OP                    1\n             42 POP_JUMP_IF_FALSE       42 (to 84)\n\n513          44 LOAD_GLOBAL              3 (_expand_mask)\n             46 LOAD_FAST                1 (attention_mask)\n             48 LOAD_FAST                3 (inputs_embeds)\n             50 LOAD_ATTR                1 (dtype)\n             52 LOAD_FAST                2 (input_shape)\n             54 LOAD_CONST               1 (-1)\n             56 BINARY_SUBSCR\n             58 LOAD_CONST               4 (('tgt_len',))\n             60 CALL_FUNCTION_KW         3\n             62 STORE_FAST               6 (expanded_attn_mask)\n\n515          64 LOAD_FAST                5 (combined_attention_mask)\n             66 LOAD_CONST               0 (None)\n             68 IS_OP                    0\n             70 POP_JUMP_IF_FALSE       38 (to 76)\n             72 LOAD_FAST                6 (expanded_attn_mask)\n             74 JUMP_FORWARD             3 (to 82)\n        >>   76 LOAD_FAST                6 (expanded_attn_mask)\n             78 LOAD_FAST                5 (combined_attention_mask)\n             80 BINARY_ADD\n\n514     >>   82 STORE_FAST               5 (combined_attention_mask)\n\n518     >>   84 LOAD_FAST                5 (combined_attention_mask)\n             86 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/speech_to_text_2/modeling_speech_to_text_2.py line 117 \n119           0 LOAD_FAST                1 (input_ids)\n              2 LOAD_METHOD              0 (size)\n              4 CALL_METHOD              0\n              6 UNPACK_SEQUENCE          2\n              8 STORE_FAST               3 (bsz)\n             10 STORE_FAST               4 (seq_len)\n\n121          12 LOAD_FAST                0 (self)\n             14 LOAD_METHOD              1 (create_position_ids_from_input_ids)\n             16 LOAD_FAST                1 (input_ids)\n             18 LOAD_FAST                0 (self)\n             20 LOAD_ATTR                2 (padding_idx)\n             22 LOAD_FAST                2 (past_key_values_length)\n             24 CALL_METHOD              3\n             26 LOAD_METHOD              3 (to)\n\n122          28 LOAD_FAST                1 (input_ids)\n             30 LOAD_ATTR                4 (device)\n\n121          32 CALL_METHOD              1\n             34 STORE_FAST               5 (position_ids)\n\n126          36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                2 (padding_idx)\n             40 LOAD_CONST               1 (1)\n             42 BINARY_ADD\n             44 LOAD_FAST                4 (seq_len)\n             46 BINARY_ADD\n             48 STORE_FAST               6 (max_pos)\n\n127          50 LOAD_FAST                6 (max_pos)\n             52 LOAD_FAST                0 (self)\n             54 LOAD_ATTR                5 (weights)\n             56 LOAD_METHOD              0 (size)\n             58 LOAD_CONST               2 (0)\n             60 CALL_METHOD              1\n             62 COMPARE_OP               4 (>)\n             64 POP_JUMP_IF_FALSE       45 (to 90)\n\n128          66 LOAD_FAST                0 (self)\n             68 LOAD_METHOD              6 (make_weights)\n             70 LOAD_FAST                6 (max_pos)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                7 (offset)\n             76 BINARY_ADD\n             78 LOAD_FAST                0 (self)\n             80 LOAD_ATTR                8 (embedding_dim)\n             82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                2 (padding_idx)\n             86 CALL_METHOD              3\n             88 POP_TOP\n\n130     >>   90 LOAD_FAST                0 (self)\n             92 LOAD_ATTR                5 (weights)\n             94 LOAD_METHOD              9 (index_select)\n             96 LOAD_CONST               2 (0)\n             98 LOAD_FAST                5 (position_ids)\n            100 LOAD_METHOD             10 (view)\n            102 LOAD_CONST               3 (-1)\n            104 CALL_METHOD              1\n            106 CALL_METHOD              2\n            108 LOAD_METHOD             10 (view)\n            110 LOAD_FAST                3 (bsz)\n            112 LOAD_FAST                4 (seq_len)\n            114 LOAD_CONST               3 (-1)\n            116 CALL_METHOD              3\n            118 LOAD_METHOD             11 (detach)\n            120 CALL_METHOD              0\n            122 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/speech_to_text_2/modeling_speech_to_text_2.py line 334 \n364           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n368           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n370          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n371          32 LOAD_FAST                1 (hidden_states)\n\n372          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n373          36 LOAD_FAST                2 (attention_mask)\n\n374          38 LOAD_FAST                5 (layer_head_mask)\n\n375          40 LOAD_FAST                8 (output_attentions)\n\n370          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n377          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n378          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n379          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n382          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n383          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n384         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n385         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n388         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n389         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n390         142 LOAD_FAST                1 (hidden_states)\n\n391         144 LOAD_FAST                3 (encoder_hidden_states)\n\n392         146 LOAD_FAST                4 (encoder_attention_mask)\n\n393         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n394         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n395         152 LOAD_FAST                8 (output_attentions)\n\n389         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n397         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n398         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n399         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n402         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n405     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n406         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n407         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n408         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n409         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n410         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n411         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n413         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n415         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n416         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n418     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n419         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n421     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/speech_to_text_2/modeling_speech_to_text_2.py line 334 \n364           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n368           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n370          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n371          32 LOAD_FAST                1 (hidden_states)\n\n372          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n373          36 LOAD_FAST                2 (attention_mask)\n\n374          38 LOAD_FAST                5 (layer_head_mask)\n\n375          40 LOAD_FAST                8 (output_attentions)\n\n370          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n377          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n378          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n379          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n382          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n383          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n384         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n385         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n388         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n389         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n390         142 LOAD_FAST                1 (hidden_states)\n\n391         144 LOAD_FAST                3 (encoder_hidden_states)\n\n392         146 LOAD_FAST                4 (encoder_attention_mask)\n\n393         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n394         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n395         152 LOAD_FAST                8 (output_attentions)\n\n389         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n397         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n398         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n399         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n402         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n405     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n406         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n407         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n408         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n409         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n410         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n411         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n413         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n415         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n416         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n418     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n419         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n421     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/speech_to_text_2/modeling_speech_to_text_2.py line 334 \n364           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n368           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n370          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n371          32 LOAD_FAST                1 (hidden_states)\n\n372          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n373          36 LOAD_FAST                2 (attention_mask)\n\n374          38 LOAD_FAST                5 (layer_head_mask)\n\n375          40 LOAD_FAST                8 (output_attentions)\n\n370          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n377          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n378          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n379          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n382          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n383          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n384         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n385         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n388         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n389         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n390         142 LOAD_FAST                1 (hidden_states)\n\n391         144 LOAD_FAST                3 (encoder_hidden_states)\n\n392         146 LOAD_FAST                4 (encoder_attention_mask)\n\n393         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n394         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n395         152 LOAD_FAST                8 (output_attentions)\n\n389         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n397         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n398         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n399         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n402         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n405     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n406         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n407         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n408         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n409         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n410         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n411         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n413         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n415         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n416         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n418     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n419         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n421     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/speech_to_text_2/modeling_speech_to_text_2.py line 334 \n364           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n368           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n370          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n371          32 LOAD_FAST                1 (hidden_states)\n\n372          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n373          36 LOAD_FAST                2 (attention_mask)\n\n374          38 LOAD_FAST                5 (layer_head_mask)\n\n375          40 LOAD_FAST                8 (output_attentions)\n\n370          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n377          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n378          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n379          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n382          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n383          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n384         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n385         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n388         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n389         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n390         142 LOAD_FAST                1 (hidden_states)\n\n391         144 LOAD_FAST                3 (encoder_hidden_states)\n\n392         146 LOAD_FAST                4 (encoder_attention_mask)\n\n393         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n394         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n395         152 LOAD_FAST                8 (output_attentions)\n\n389         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n397         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n398         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n399         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n402         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n405     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n406         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n407         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n408         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n409         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n410         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n411         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n413         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n415         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n416         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n418     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n419         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n421     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/speech_to_text_2/modeling_speech_to_text_2.py line 334 \n364           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n368           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n370          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n371          32 LOAD_FAST                1 (hidden_states)\n\n372          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n373          36 LOAD_FAST                2 (attention_mask)\n\n374          38 LOAD_FAST                5 (layer_head_mask)\n\n375          40 LOAD_FAST                8 (output_attentions)\n\n370          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n377          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n378          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n379          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n382          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n383          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n384         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n385         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n388         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n389         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n390         142 LOAD_FAST                1 (hidden_states)\n\n391         144 LOAD_FAST                3 (encoder_hidden_states)\n\n392         146 LOAD_FAST                4 (encoder_attention_mask)\n\n393         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n394         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n395         152 LOAD_FAST                8 (output_attentions)\n\n389         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n397         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n398         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n399         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n402         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n405     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n406         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n407         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n408         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n409         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n410         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n411         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n413         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n415         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n416         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n418     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n419         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n421     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/speech_to_text_2/modeling_speech_to_text_2.py line 334 \n364           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n368           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n370          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n371          32 LOAD_FAST                1 (hidden_states)\n\n372          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n373          36 LOAD_FAST                2 (attention_mask)\n\n374          38 LOAD_FAST                5 (layer_head_mask)\n\n375          40 LOAD_FAST                8 (output_attentions)\n\n370          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n377          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n378          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n379          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n382          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n383          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n384         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n385         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n388         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n389         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n390         142 LOAD_FAST                1 (hidden_states)\n\n391         144 LOAD_FAST                3 (encoder_hidden_states)\n\n392         146 LOAD_FAST                4 (encoder_attention_mask)\n\n393         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n394         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n395         152 LOAD_FAST                8 (output_attentions)\n\n389         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n397         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n398         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n399         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n402         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n405     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n406         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n407         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n408         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n409         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n410         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n411         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n413         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n415         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n416         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n418     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n419         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n421     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (past_key_values)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (past_key_values)\n\n  5          12 LOAD_FAST                3 (hidden_states)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (hidden_states)\n\n  6          18 LOAD_FAST                4 (attentions)\n             20 LOAD_FAST                0 (self)\n             22 STORE_ATTR               3 (attentions)\n\n  7          24 LOAD_FAST                5 (cross_attentions)\n             26 LOAD_FAST                0 (self)\n             28 STORE_ATTR               4 (cross_attentions)\n\n  8          30 LOAD_FAST                0 (self)\n             32 LOAD_METHOD              5 (__post_init__)\n             34 CALL_METHOD              0\n             36 POP_TOP\n             38 LOAD_CONST               0 (None)\n             40 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 3 \n  3           0 JUMP_ABSOLUTE            4 (to 8)\n              2 LOAD_FAST                5 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n\n  4     >>    8 LOAD_FAST                1 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5          14 LOAD_FAST                2 (hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (hidden_states)\n\n  6          20 LOAD_FAST                3 (attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (attentions)\n\n  7          26 LOAD_FAST                4 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                5 (__post_init__)\n             36 CALL_FUNCTION            0\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/speech_to_text_2/modeling_speech_to_text_2.py line 923 \n923           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           49 (to 98)\n              4 LOAD_FAST               13 (output_attentions)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE        8 (to 16)\n             12 LOAD_FAST               13 (output_attentions)\n             14 JUMP_FORWARD             3 (to 22)\n        >>   16 LOAD_FAST                1 (self)\n             18 LOAD_ATTR                0 (config)\n             20 LOAD_ATTR                1 (output_attentions)\n        >>   22 STORE_FAST              13 (output_attentions)\n             24 LOAD_FAST               14 (output_hidden_states)\n             26 LOAD_CONST               1 (None)\n             28 IS_OP                    1\n             30 POP_JUMP_IF_FALSE       18 (to 36)\n             32 LOAD_FAST               14 (output_hidden_states)\n             34 JUMP_FORWARD             3 (to 42)\n        >>   36 LOAD_FAST                1 (self)\n             38 LOAD_ATTR                0 (config)\n             40 LOAD_ATTR                2 (output_hidden_states)\n        >>   42 STORE_FAST              14 (output_hidden_states)\n             44 LOAD_FAST                3 (return_dict)\n             46 LOAD_CONST               1 (None)\n             48 IS_OP                    1\n             50 POP_JUMP_IF_FALSE       28 (to 56)\n             52 LOAD_FAST                3 (return_dict)\n             54 JUMP_FORWARD             3 (to 62)\n        >>   56 LOAD_FAST                1 (self)\n             58 LOAD_ATTR                0 (config)\n             60 LOAD_ATTR                3 (use_return_dict)\n        >>   62 STORE_FAST               3 (return_dict)\n             64 LOAD_FAST                1 (self)\n             66 LOAD_ATTR                4 (model)\n             68 LOAD_ATTR                5 (decoder)\n             70 LOAD_FAST                4 (input_ids)\n             72 LOAD_FAST                5 (attention_mask)\n             74 LOAD_FAST                6 (encoder_hidden_states)\n             76 LOAD_FAST                7 (encoder_attention_mask)\n             78 LOAD_FAST                8 (head_mask)\n             80 LOAD_FAST                9 (cross_attn_head_mask)\n             82 LOAD_FAST               10 (past_key_values)\n             84 LOAD_FAST               11 (inputs_embeds)\n             86 LOAD_FAST               12 (use_cache)\n             88 LOAD_FAST               13 (output_attentions)\n             90 LOAD_FAST               14 (output_hidden_states)\n             92 LOAD_FAST                3 (return_dict)\n             94 LOAD_CONST               2 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             96 CALL_FUNCTION_KW        12\n        >>   98 STORE_FAST              15 (outputs)\n\n938         100 LOAD_FAST                1 (self)\n            102 LOAD_ATTR                6 (lm_head)\n            104 LOAD_FAST               15 (outputs)\n            106 LOAD_CONST               3 (0)\n            108 BINARY_SUBSCR\n            110 CALL_FUNCTION            1\n            112 STORE_FAST              16 (logits)\n\n940         114 LOAD_CONST               1 (None)\n            116 STORE_FAST              17 (loss)\n\n941         118 LOAD_FAST                2 (labels)\n            120 LOAD_CONST               1 (None)\n            122 IS_OP                    1\n            124 POP_JUMP_IF_FALSE       80 (to 160)\n\n942         126 LOAD_GLOBAL              7 (CrossEntropyLoss)\n            128 CALL_FUNCTION            0\n            130 STORE_FAST              18 (loss_fct)\n\n943         132 LOAD_FAST               18 (loss_fct)\n            134 LOAD_FAST               16 (logits)\n            136 LOAD_ATTR                8 (view)\n            138 LOAD_CONST               4 (-1)\n            140 LOAD_FAST                1 (self)\n            142 LOAD_ATTR                0 (config)\n            144 LOAD_ATTR                9 (vocab_size)\n            146 CALL_FUNCTION            2\n            148 LOAD_FAST                2 (labels)\n            150 LOAD_ATTR                8 (view)\n            152 LOAD_CONST               4 (-1)\n            154 CALL_FUNCTION            1\n            156 CALL_FUNCTION            2\n            158 STORE_FAST              17 (loss)\n\n945     >>  160 LOAD_FAST                3 (return_dict)\n            162 POP_JUMP_IF_TRUE       102 (to 204)\n\n946         164 LOAD_FAST               16 (logits)\n            166 BUILD_TUPLE              1\n            168 LOAD_FAST               15 (outputs)\n            170 LOAD_CONST               5 (1)\n            172 LOAD_CONST               1 (None)\n            174 BUILD_SLICE              2\n            176 BINARY_SUBSCR\n            178 BINARY_ADD\n            180 STORE_FAST              19 (output)\n\n947         182 LOAD_FAST               17 (loss)\n            184 LOAD_CONST               1 (None)\n            186 IS_OP                    1\n            188 POP_JUMP_IF_FALSE      100 (to 200)\n            190 LOAD_FAST               17 (loss)\n            192 BUILD_TUPLE              1\n            194 LOAD_FAST               19 (output)\n            196 BINARY_ADD\n            198 RETURN_VALUE\n        >>  200 LOAD_FAST               19 (output)\n            202 RETURN_VALUE\n\n949     >>  204 LOAD_GLOBAL             10 (CausalLMOutputWithCrossAttentions)\n\n950         206 LOAD_FAST               17 (loss)\n\n951         208 LOAD_FAST               16 (logits)\n\n952         210 LOAD_FAST               15 (outputs)\n            212 LOAD_ATTR               11 (past_key_values)\n\n953         214 LOAD_FAST               15 (outputs)\n            216 LOAD_ATTR               12 (hidden_states)\n\n954         218 LOAD_FAST               15 (outputs)\n            220 LOAD_ATTR               13 (attentions)\n\n955         222 LOAD_FAST               15 (outputs)\n            224 LOAD_ATTR               14 (cross_attentions)\n\n949         226 LOAD_CONST               6 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n            228 CALL_FUNCTION_KW         6\n            230 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 557 \n557           0 LOAD_FAST                0 (___stack0)\n              2 CALL_FUNCTION            0\n              4 SETUP_WITH              10 (to 26)\n              6 POP_TOP\n              8 LOAD_FAST                1 (___stack1)\n             10 JUMP_ABSOLUTE           44 (to 88)\n             12 POP_BLOCK\n             14 LOAD_CONST               0 (None)\n             16 DUP_TOP\n             18 DUP_TOP\n             20 CALL_FUNCTION            3\n             22 POP_TOP\n             24 JUMP_FORWARD             8 (to 42)\n        >>   26 WITH_EXCEPT_START\n             28 POP_JUMP_IF_TRUE        16 (to 32)\n             30 RERAISE                  0\n        >>   32 POP_TOP\n             34 POP_TOP\n             36 POP_TOP\n             38 POP_EXCEPT\n             40 POP_TOP\n        >>   42 NOP\n             44 LOAD_CONST               0 (None)\n             46 RAISE_VARARGS            1\n             48 LOAD_GLOBAL              0 (clone_inputs)\n             50 LOAD_FAST                6 (inputs)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (cloned_inputs)\n             56 LOAD_FAST                2 (self)\n             58 LOAD_ATTR                1 (optimizer_zero_grad)\n             60 LOAD_FAST                3 (mod)\n             62 CALL_FUNCTION            1\n             64 POP_TOP\n             66 LOAD_FAST                2 (self)\n             68 LOAD_ATTR                2 (autocast)\n             70 CALL_FUNCTION            0\n             72 SETUP_WITH              20 (to 114)\n             74 POP_TOP\n             76 LOAD_FAST                3 (mod)\n             78 LOAD_CONST               1 (())\n             80 BUILD_MAP                0\n             82 LOAD_FAST                5 (cloned_inputs)\n             84 DICT_MERGE               1\n             86 CALL_FUNCTION_EX         1\n        >>   88 STORE_FAST               7 (pred)\n\n558          90 LOAD_FAST                2 (self)\n             92 LOAD_ATTR                3 (compute_loss)\n             94 LOAD_FAST                7 (pred)\n             96 CALL_FUNCTION            1\n             98 STORE_FAST               8 (loss)\n            100 POP_BLOCK\n\n556         102 LOAD_CONST               0 (None)\n            104 DUP_TOP\n            106 DUP_TOP\n            108 CALL_FUNCTION            3\n            110 POP_TOP\n            112 JUMP_FORWARD             8 (to 130)\n        >>  114 WITH_EXCEPT_START\n            116 POP_JUMP_IF_TRUE        60 (to 120)\n            118 RERAISE                  1\n        >>  120 POP_TOP\n            122 POP_TOP\n            124 POP_TOP\n            126 POP_EXCEPT\n            128 POP_TOP\n\n559     >>  130 LOAD_FAST                2 (self)\n            132 LOAD_ATTR                4 (grad_scaler)\n            134 LOAD_ATTR                5 (scale)\n            136 LOAD_FAST                8 (loss)\n            138 CALL_FUNCTION            1\n            140 LOAD_ATTR                6 (backward)\n            142 CALL_FUNCTION            0\n            144 POP_TOP\n\n560         146 LOAD_FAST                2 (self)\n            148 LOAD_ATTR                7 (optimizer_step)\n            150 CALL_FUNCTION            0\n            152 POP_TOP\n\n561         154 LOAD_FAST                4 (collect_outputs)\n            156 POP_JUMP_IF_FALSE       86 (to 172)\n\n562         158 LOAD_GLOBAL              8 (collect_results)\n            160 LOAD_FAST                3 (mod)\n            162 LOAD_FAST                7 (pred)\n            164 LOAD_FAST                8 (loss)\n            166 LOAD_FAST                5 (cloned_inputs)\n            168 CALL_FUNCTION            4\n            170 RETURN_VALUE\n\n563     >>  172 LOAD_CONST               0 (None)\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/trocr/modeling_trocr.py line 823 \n956           0 LOAD_FAST               11 (output_attentions)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    1\n              6 POP_JUMP_IF_FALSE        6 (to 12)\n              8 LOAD_FAST               11 (output_attentions)\n             10 JUMP_FORWARD             3 (to 18)\n        >>   12 LOAD_FAST                0 (self)\n             14 LOAD_ATTR                0 (config)\n             16 LOAD_ATTR                1 (output_attentions)\n        >>   18 STORE_FAST              11 (output_attentions)\n\n958          20 LOAD_FAST               12 (output_hidden_states)\n             22 LOAD_CONST               1 (None)\n             24 IS_OP                    1\n             26 POP_JUMP_IF_FALSE       16 (to 32)\n             28 LOAD_FAST               12 (output_hidden_states)\n             30 JUMP_FORWARD             3 (to 38)\n        >>   32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                0 (config)\n             36 LOAD_ATTR                2 (output_hidden_states)\n\n957     >>   38 STORE_FAST              12 (output_hidden_states)\n\n960          40 LOAD_FAST               13 (return_dict)\n             42 LOAD_CONST               1 (None)\n             44 IS_OP                    1\n             46 POP_JUMP_IF_FALSE       26 (to 52)\n             48 LOAD_FAST               13 (return_dict)\n             50 JUMP_FORWARD             3 (to 58)\n        >>   52 LOAD_FAST                0 (self)\n             54 LOAD_ATTR                0 (config)\n             56 LOAD_ATTR                3 (use_return_dict)\n        >>   58 STORE_FAST              13 (return_dict)\n\n963          60 LOAD_FAST                0 (self)\n             62 LOAD_ATTR                4 (model)\n             64 LOAD_ATTR                5 (decoder)\n\n964          66 LOAD_FAST                1 (input_ids)\n\n965          68 LOAD_FAST                2 (attention_mask)\n\n966          70 LOAD_FAST                3 (encoder_hidden_states)\n\n967          72 LOAD_FAST                4 (encoder_attention_mask)\n\n968          74 LOAD_FAST                5 (head_mask)\n\n969          76 LOAD_FAST                6 (cross_attn_head_mask)\n\n970          78 LOAD_FAST                7 (past_key_values)\n\n971          80 LOAD_FAST                8 (inputs_embeds)\n\n972          82 LOAD_FAST               10 (use_cache)\n\n973          84 LOAD_FAST               11 (output_attentions)\n\n974          86 LOAD_FAST               12 (output_hidden_states)\n\n975          88 LOAD_FAST               13 (return_dict)\n\n963          90 LOAD_CONST               2 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             92 CALL_FUNCTION_KW        12\n             94 STORE_FAST              14 (outputs)\n\n978          96 LOAD_FAST                0 (self)\n             98 LOAD_METHOD              6 (output_projection)\n            100 LOAD_FAST               14 (outputs)\n            102 LOAD_CONST               3 (0)\n            104 BINARY_SUBSCR\n            106 CALL_METHOD              1\n            108 STORE_FAST              15 (logits)\n\n980         110 LOAD_CONST               1 (None)\n            112 STORE_FAST              16 (loss)\n\n981         114 LOAD_FAST                9 (labels)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       78 (to 156)\n\n982         122 LOAD_GLOBAL              7 (CrossEntropyLoss)\n            124 CALL_FUNCTION            0\n            126 STORE_FAST              17 (loss_fct)\n\n983         128 LOAD_FAST               17 (loss_fct)\n            130 LOAD_FAST               15 (logits)\n            132 LOAD_METHOD              8 (view)\n            134 LOAD_CONST               4 (-1)\n            136 LOAD_FAST                0 (self)\n            138 LOAD_ATTR                0 (config)\n            140 LOAD_ATTR                9 (vocab_size)\n            142 CALL_METHOD              2\n            144 LOAD_FAST                9 (labels)\n            146 LOAD_METHOD              8 (view)\n            148 LOAD_CONST               4 (-1)\n            150 CALL_METHOD              1\n            152 CALL_FUNCTION            2\n            154 STORE_FAST              16 (loss)\n\n985     >>  156 LOAD_FAST               13 (return_dict)\n            158 POP_JUMP_IF_TRUE       100 (to 200)\n\n986         160 LOAD_FAST               15 (logits)\n            162 BUILD_TUPLE              1\n            164 LOAD_FAST               14 (outputs)\n            166 LOAD_CONST               5 (1)\n            168 LOAD_CONST               1 (None)\n            170 BUILD_SLICE              2\n            172 BINARY_SUBSCR\n            174 BINARY_ADD\n            176 STORE_FAST              18 (output)\n\n987         178 LOAD_FAST               16 (loss)\n            180 LOAD_CONST               1 (None)\n            182 IS_OP                    1\n            184 POP_JUMP_IF_FALSE       98 (to 196)\n            186 LOAD_FAST               16 (loss)\n            188 BUILD_TUPLE              1\n            190 LOAD_FAST               18 (output)\n            192 BINARY_ADD\n            194 RETURN_VALUE\n        >>  196 LOAD_FAST               18 (output)\n            198 RETURN_VALUE\n\n989     >>  200 LOAD_GLOBAL             10 (CausalLMOutputWithCrossAttentions)\n\n990         202 LOAD_FAST               16 (loss)\n\n991         204 LOAD_FAST               15 (logits)\n\n992         206 LOAD_FAST               14 (outputs)\n            208 LOAD_ATTR               11 (past_key_values)\n\n993         210 LOAD_FAST               14 (outputs)\n            212 LOAD_ATTR               12 (hidden_states)\n\n994         214 LOAD_FAST               14 (outputs)\n            216 LOAD_ATTR               13 (attentions)\n\n995         218 LOAD_FAST               14 (outputs)\n            220 LOAD_ATTR               14 (cross_attentions)\n\n989         222 LOAD_CONST               6 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n            224 CALL_FUNCTION_KW         6\n            226 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/trocr/modeling_trocr.py line 90 \n 93           0 LOAD_FAST                1 (input_ids)\n              2 LOAD_ATTR                0 (shape)\n              4 LOAD_CONST               1 (None)\n              6 LOAD_CONST               2 (2)\n              8 BUILD_SLICE              2\n             10 BINARY_SUBSCR\n             12 UNPACK_SEQUENCE          2\n             14 STORE_FAST               3 (bsz)\n             16 STORE_FAST               4 (seq_len)\n\n 94          18 LOAD_GLOBAL              1 (torch)\n             20 LOAD_ATTR                2 (arange)\n\n 95          22 LOAD_FAST                2 (past_key_values_length)\n             24 LOAD_FAST                2 (past_key_values_length)\n             26 LOAD_FAST                4 (seq_len)\n             28 BINARY_ADD\n             30 LOAD_GLOBAL              1 (torch)\n             32 LOAD_ATTR                3 (long)\n             34 LOAD_FAST                0 (self)\n             36 LOAD_ATTR                4 (weight)\n             38 LOAD_ATTR                5 (device)\n\n 94          40 LOAD_CONST               3 (('dtype', 'device'))\n             42 CALL_FUNCTION_KW         4\n\n 96          44 LOAD_METHOD              6 (expand)\n             46 LOAD_FAST                3 (bsz)\n             48 LOAD_CONST               4 (-1)\n             50 CALL_METHOD              2\n\n 94          52 STORE_FAST               5 (positions)\n\n 98          54 LOAD_GLOBAL              7 (super)\n             56 CALL_FUNCTION            0\n             58 LOAD_METHOD              8 (forward)\n             60 LOAD_FAST                5 (positions)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                9 (offset)\n             66 BINARY_ADD\n             68 CALL_METHOD              1\n             70 RETURN_VALUE\n\n", "ORIGINAL BYTECODE _prepare_decoder_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/trocr/modeling_trocr.py line 522 \n525           0 LOAD_CONST               0 (None)\n              2 STORE_FAST               5 (combined_attention_mask)\n\n526           4 LOAD_FAST                2 (input_shape)\n              6 LOAD_CONST               1 (-1)\n              8 BINARY_SUBSCR\n             10 LOAD_CONST               2 (1)\n             12 COMPARE_OP               4 (>)\n             14 POP_JUMP_IF_FALSE       18 (to 36)\n\n527          16 LOAD_GLOBAL              0 (_make_causal_mask)\n\n528          18 LOAD_FAST                2 (input_shape)\n\n529          20 LOAD_FAST                3 (inputs_embeds)\n             22 LOAD_ATTR                1 (dtype)\n\n530          24 LOAD_FAST                3 (inputs_embeds)\n             26 LOAD_ATTR                2 (device)\n\n531          28 LOAD_FAST                4 (past_key_values_length)\n\n527          30 LOAD_CONST               3 (('device', 'past_key_values_length'))\n             32 CALL_FUNCTION_KW         4\n             34 STORE_FAST               5 (combined_attention_mask)\n\n534     >>   36 LOAD_FAST                1 (attention_mask)\n             38 LOAD_CONST               0 (None)\n             40 IS_OP                    1\n             42 POP_JUMP_IF_FALSE       42 (to 84)\n\n536          44 LOAD_GLOBAL              3 (_expand_mask)\n             46 LOAD_FAST                1 (attention_mask)\n             48 LOAD_FAST                3 (inputs_embeds)\n             50 LOAD_ATTR                1 (dtype)\n             52 LOAD_FAST                2 (input_shape)\n             54 LOAD_CONST               1 (-1)\n             56 BINARY_SUBSCR\n             58 LOAD_CONST               4 (('tgt_len',))\n             60 CALL_FUNCTION_KW         3\n             62 STORE_FAST               6 (expanded_attn_mask)\n\n538          64 LOAD_FAST                5 (combined_attention_mask)\n             66 LOAD_CONST               0 (None)\n             68 IS_OP                    0\n             70 POP_JUMP_IF_FALSE       38 (to 76)\n             72 LOAD_FAST                6 (expanded_attn_mask)\n             74 JUMP_FORWARD             3 (to 82)\n        >>   76 LOAD_FAST                6 (expanded_attn_mask)\n             78 LOAD_FAST                5 (combined_attention_mask)\n             80 BINARY_ADD\n\n537     >>   82 STORE_FAST               5 (combined_attention_mask)\n\n541     >>   84 LOAD_FAST                5 (combined_attention_mask)\n             86 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/trocr/modeling_trocr.py line 347 \n377           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n381           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n383          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n384          32 LOAD_FAST                1 (hidden_states)\n\n385          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n386          36 LOAD_FAST                2 (attention_mask)\n\n387          38 LOAD_FAST                5 (layer_head_mask)\n\n388          40 LOAD_FAST                8 (output_attentions)\n\n383          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n391          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n392          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n393          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n396          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n397          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n399         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n400         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n403         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n404         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n405         142 LOAD_FAST                1 (hidden_states)\n\n406         144 LOAD_FAST                3 (encoder_hidden_states)\n\n407         146 LOAD_FAST                4 (encoder_attention_mask)\n\n408         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n409         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n410         152 LOAD_FAST                8 (output_attentions)\n\n404         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n413         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n414         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n415         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n418         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n421     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n422         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n423         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n424         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n426         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n427         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n428         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n430         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n432         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n433         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n435     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n436         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n438     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/trocr/modeling_trocr.py line 347 \n377           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n381           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n383          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n384          32 LOAD_FAST                1 (hidden_states)\n\n385          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n386          36 LOAD_FAST                2 (attention_mask)\n\n387          38 LOAD_FAST                5 (layer_head_mask)\n\n388          40 LOAD_FAST                8 (output_attentions)\n\n383          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n391          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n392          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n393          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n396          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n397          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n399         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n400         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n403         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n404         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n405         142 LOAD_FAST                1 (hidden_states)\n\n406         144 LOAD_FAST                3 (encoder_hidden_states)\n\n407         146 LOAD_FAST                4 (encoder_attention_mask)\n\n408         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n409         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n410         152 LOAD_FAST                8 (output_attentions)\n\n404         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n413         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n414         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n415         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n418         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n421     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n422         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n423         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n424         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n426         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n427         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n428         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n430         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n432         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n433         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n435     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n436         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n438     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/trocr/modeling_trocr.py line 347 \n377           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n381           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n383          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n384          32 LOAD_FAST                1 (hidden_states)\n\n385          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n386          36 LOAD_FAST                2 (attention_mask)\n\n387          38 LOAD_FAST                5 (layer_head_mask)\n\n388          40 LOAD_FAST                8 (output_attentions)\n\n383          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n391          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n392          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n393          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n396          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n397          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n399         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n400         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n403         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n404         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n405         142 LOAD_FAST                1 (hidden_states)\n\n406         144 LOAD_FAST                3 (encoder_hidden_states)\n\n407         146 LOAD_FAST                4 (encoder_attention_mask)\n\n408         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n409         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n410         152 LOAD_FAST                8 (output_attentions)\n\n404         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n413         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n414         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n415         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n418         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n421     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n422         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n423         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n424         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n426         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n427         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n428         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n430         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n432         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n433         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n435     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n436         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n438     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/trocr/modeling_trocr.py line 347 \n377           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n381           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n383          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n384          32 LOAD_FAST                1 (hidden_states)\n\n385          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n386          36 LOAD_FAST                2 (attention_mask)\n\n387          38 LOAD_FAST                5 (layer_head_mask)\n\n388          40 LOAD_FAST                8 (output_attentions)\n\n383          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n391          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n392          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n393          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n396          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n397          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n399         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n400         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n403         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n404         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n405         142 LOAD_FAST                1 (hidden_states)\n\n406         144 LOAD_FAST                3 (encoder_hidden_states)\n\n407         146 LOAD_FAST                4 (encoder_attention_mask)\n\n408         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n409         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n410         152 LOAD_FAST                8 (output_attentions)\n\n404         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n413         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n414         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n415         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n418         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n421     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n422         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n423         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n424         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n426         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n427         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n428         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n430         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n432         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n433         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n435     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n436         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n438     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/trocr/modeling_trocr.py line 347 \n377           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n381           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n383          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n384          32 LOAD_FAST                1 (hidden_states)\n\n385          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n386          36 LOAD_FAST                2 (attention_mask)\n\n387          38 LOAD_FAST                5 (layer_head_mask)\n\n388          40 LOAD_FAST                8 (output_attentions)\n\n383          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n391          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n392          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n393          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n396          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n397          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n399         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n400         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n403         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n404         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n405         142 LOAD_FAST                1 (hidden_states)\n\n406         144 LOAD_FAST                3 (encoder_hidden_states)\n\n407         146 LOAD_FAST                4 (encoder_attention_mask)\n\n408         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n409         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n410         152 LOAD_FAST                8 (output_attentions)\n\n404         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n413         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n414         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n415         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n418         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n421     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n422         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n423         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n424         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n426         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n427         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n428         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n430         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n432         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n433         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n435     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n436         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n438     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/trocr/modeling_trocr.py line 347 \n377           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n381           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n383          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n384          32 LOAD_FAST                1 (hidden_states)\n\n385          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n386          36 LOAD_FAST                2 (attention_mask)\n\n387          38 LOAD_FAST                5 (layer_head_mask)\n\n388          40 LOAD_FAST                8 (output_attentions)\n\n383          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n391          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n392          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n393          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n396          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n397          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n399         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n400         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n403         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n404         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n405         142 LOAD_FAST                1 (hidden_states)\n\n406         144 LOAD_FAST                3 (encoder_hidden_states)\n\n407         146 LOAD_FAST                4 (encoder_attention_mask)\n\n408         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n409         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n410         152 LOAD_FAST                8 (output_attentions)\n\n404         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n413         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n414         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n415         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n418         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n421     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n422         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n423         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n424         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n426         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n427         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n428         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n430         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n432         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n433         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n435     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n436         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n438     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/trocr/modeling_trocr.py line 347 \n377           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n381           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n383          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n384          32 LOAD_FAST                1 (hidden_states)\n\n385          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n386          36 LOAD_FAST                2 (attention_mask)\n\n387          38 LOAD_FAST                5 (layer_head_mask)\n\n388          40 LOAD_FAST                8 (output_attentions)\n\n383          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n391          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n392          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n393          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n396          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n397          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n399         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n400         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n403         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n404         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n405         142 LOAD_FAST                1 (hidden_states)\n\n406         144 LOAD_FAST                3 (encoder_hidden_states)\n\n407         146 LOAD_FAST                4 (encoder_attention_mask)\n\n408         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n409         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n410         152 LOAD_FAST                8 (output_attentions)\n\n404         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n413         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n414         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n415         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n418         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n421     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n422         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n423         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n424         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n426         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n427         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n428         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n430         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n432         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n433         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n435     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n436         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n438     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/trocr/modeling_trocr.py line 347 \n377           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n381           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n383          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n384          32 LOAD_FAST                1 (hidden_states)\n\n385          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n386          36 LOAD_FAST                2 (attention_mask)\n\n387          38 LOAD_FAST                5 (layer_head_mask)\n\n388          40 LOAD_FAST                8 (output_attentions)\n\n383          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n391          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n392          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n393          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n396          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n397          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n399         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n400         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n403         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n404         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n405         142 LOAD_FAST                1 (hidden_states)\n\n406         144 LOAD_FAST                3 (encoder_hidden_states)\n\n407         146 LOAD_FAST                4 (encoder_attention_mask)\n\n408         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n409         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n410         152 LOAD_FAST                8 (output_attentions)\n\n404         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n413         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n414         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n415         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n418         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n421     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n422         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n423         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n424         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n426         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n427         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n428         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n430         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n432         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n433         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n435     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n436         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n438     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/trocr/modeling_trocr.py line 347 \n377           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n381           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n383          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n384          32 LOAD_FAST                1 (hidden_states)\n\n385          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n386          36 LOAD_FAST                2 (attention_mask)\n\n387          38 LOAD_FAST                5 (layer_head_mask)\n\n388          40 LOAD_FAST                8 (output_attentions)\n\n383          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n391          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n392          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n393          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n396          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n397          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n399         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n400         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n403         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n404         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n405         142 LOAD_FAST                1 (hidden_states)\n\n406         144 LOAD_FAST                3 (encoder_hidden_states)\n\n407         146 LOAD_FAST                4 (encoder_attention_mask)\n\n408         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n409         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n410         152 LOAD_FAST                8 (output_attentions)\n\n404         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n413         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n414         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n415         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n418         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n421     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n422         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n423         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n424         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n426         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n427         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n428         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n430         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n432         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n433         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n435     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n436         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n438     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/trocr/modeling_trocr.py line 347 \n377           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n381           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n383          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n384          32 LOAD_FAST                1 (hidden_states)\n\n385          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n386          36 LOAD_FAST                2 (attention_mask)\n\n387          38 LOAD_FAST                5 (layer_head_mask)\n\n388          40 LOAD_FAST                8 (output_attentions)\n\n383          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n391          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n392          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n393          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n396          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n397          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n399         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n400         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n403         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n404         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n405         142 LOAD_FAST                1 (hidden_states)\n\n406         144 LOAD_FAST                3 (encoder_hidden_states)\n\n407         146 LOAD_FAST                4 (encoder_attention_mask)\n\n408         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n409         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n410         152 LOAD_FAST                8 (output_attentions)\n\n404         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n413         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n414         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n415         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n418         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n421     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n422         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n423         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n424         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n426         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n427         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n428         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n430         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n432         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n433         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n435     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n436         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n438     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/trocr/modeling_trocr.py line 347 \n377           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n381           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n383          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n384          32 LOAD_FAST                1 (hidden_states)\n\n385          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n386          36 LOAD_FAST                2 (attention_mask)\n\n387          38 LOAD_FAST                5 (layer_head_mask)\n\n388          40 LOAD_FAST                8 (output_attentions)\n\n383          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n391          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n392          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n393          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n396          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n397          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n399         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n400         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n403         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n404         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n405         142 LOAD_FAST                1 (hidden_states)\n\n406         144 LOAD_FAST                3 (encoder_hidden_states)\n\n407         146 LOAD_FAST                4 (encoder_attention_mask)\n\n408         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n409         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n410         152 LOAD_FAST                8 (output_attentions)\n\n404         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n413         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n414         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n415         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n418         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n421     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n422         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n423         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n424         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n426         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n427         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n428         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n430         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n432         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n433         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n435     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n436         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n438     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/trocr/modeling_trocr.py line 347 \n377           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n381           4 LOAD_FAST                7 (past_key_value)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE       12 (to 24)\n             12 LOAD_FAST                7 (past_key_value)\n             14 LOAD_CONST               1 (None)\n             16 LOAD_CONST               2 (2)\n             18 BUILD_SLICE              2\n             20 BINARY_SUBSCR\n             22 JUMP_FORWARD             1 (to 26)\n        >>   24 LOAD_CONST               1 (None)\n        >>   26 STORE_FAST              11 (self_attn_past_key_value)\n\n383          28 LOAD_FAST                0 (self)\n             30 LOAD_ATTR                0 (self_attn)\n\n384          32 LOAD_FAST                1 (hidden_states)\n\n385          34 LOAD_FAST               11 (self_attn_past_key_value)\n\n386          36 LOAD_FAST                2 (attention_mask)\n\n387          38 LOAD_FAST                5 (layer_head_mask)\n\n388          40 LOAD_FAST                8 (output_attentions)\n\n383          42 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             44 CALL_FUNCTION_KW         5\n             46 UNPACK_SEQUENCE          3\n             48 STORE_FAST               1 (hidden_states)\n             50 STORE_FAST              12 (self_attn_weights)\n             52 STORE_FAST              13 (present_key_value)\n\n391          54 LOAD_GLOBAL              1 (nn)\n             56 LOAD_ATTR                2 (functional)\n             58 LOAD_ATTR                3 (dropout)\n             60 LOAD_FAST                1 (hidden_states)\n             62 LOAD_FAST                0 (self)\n             64 LOAD_ATTR                3 (dropout)\n             66 LOAD_FAST                0 (self)\n             68 LOAD_ATTR                4 (training)\n             70 LOAD_CONST               4 (('p', 'training'))\n             72 CALL_FUNCTION_KW         3\n             74 STORE_FAST               1 (hidden_states)\n\n392          76 LOAD_FAST               10 (residual)\n             78 LOAD_FAST                1 (hidden_states)\n             80 BINARY_ADD\n             82 STORE_FAST               1 (hidden_states)\n\n393          84 LOAD_FAST                0 (self)\n             86 LOAD_METHOD              5 (self_attn_layer_norm)\n             88 LOAD_FAST                1 (hidden_states)\n             90 CALL_METHOD              1\n             92 STORE_FAST               1 (hidden_states)\n\n396          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n397          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n399         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n400         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n403         114 LOAD_FAST                7 (past_key_value)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE       67 (to 134)\n            122 LOAD_FAST                7 (past_key_value)\n            124 LOAD_CONST               5 (-2)\n            126 LOAD_CONST               1 (None)\n            128 BUILD_SLICE              2\n            130 BINARY_SUBSCR\n            132 JUMP_FORWARD             1 (to 136)\n        >>  134 LOAD_CONST               1 (None)\n        >>  136 STORE_FAST              16 (cross_attn_past_key_value)\n\n404         138 LOAD_FAST                0 (self)\n            140 LOAD_ATTR                6 (encoder_attn)\n\n405         142 LOAD_FAST                1 (hidden_states)\n\n406         144 LOAD_FAST                3 (encoder_hidden_states)\n\n407         146 LOAD_FAST                4 (encoder_attention_mask)\n\n408         148 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n409         150 LOAD_FAST               16 (cross_attn_past_key_value)\n\n410         152 LOAD_FAST                8 (output_attentions)\n\n404         154 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            156 CALL_FUNCTION_KW         6\n            158 UNPACK_SEQUENCE          3\n            160 STORE_FAST               1 (hidden_states)\n            162 STORE_FAST              15 (cross_attn_weights)\n            164 STORE_FAST              14 (cross_attn_present_key_value)\n\n413         166 LOAD_GLOBAL              1 (nn)\n            168 LOAD_ATTR                2 (functional)\n            170 LOAD_ATTR                3 (dropout)\n            172 LOAD_FAST                1 (hidden_states)\n            174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                3 (dropout)\n            178 LOAD_FAST                0 (self)\n            180 LOAD_ATTR                4 (training)\n            182 LOAD_CONST               4 (('p', 'training'))\n            184 CALL_FUNCTION_KW         3\n            186 STORE_FAST               1 (hidden_states)\n\n414         188 LOAD_FAST               10 (residual)\n            190 LOAD_FAST                1 (hidden_states)\n            192 BINARY_ADD\n            194 STORE_FAST               1 (hidden_states)\n\n415         196 LOAD_FAST                0 (self)\n            198 LOAD_METHOD              7 (encoder_attn_layer_norm)\n            200 LOAD_FAST                1 (hidden_states)\n            202 CALL_METHOD              1\n            204 STORE_FAST               1 (hidden_states)\n\n418         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n421     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n422         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (activation_fn)\n            222 LOAD_FAST                0 (self)\n            224 LOAD_METHOD              9 (fc1)\n            226 LOAD_FAST                1 (hidden_states)\n            228 CALL_METHOD              1\n            230 CALL_METHOD              1\n            232 STORE_FAST               1 (hidden_states)\n\n423         234 LOAD_GLOBAL              1 (nn)\n            236 LOAD_ATTR                2 (functional)\n            238 LOAD_ATTR                3 (dropout)\n            240 LOAD_FAST                1 (hidden_states)\n            242 LOAD_FAST                0 (self)\n            244 LOAD_ATTR               10 (activation_dropout)\n            246 LOAD_FAST                0 (self)\n            248 LOAD_ATTR                4 (training)\n            250 LOAD_CONST               4 (('p', 'training'))\n            252 CALL_FUNCTION_KW         3\n            254 STORE_FAST               1 (hidden_states)\n\n424         256 LOAD_FAST                0 (self)\n            258 LOAD_METHOD             11 (fc2)\n            260 LOAD_FAST                1 (hidden_states)\n            262 CALL_METHOD              1\n            264 STORE_FAST               1 (hidden_states)\n\n426         266 LOAD_GLOBAL              1 (nn)\n            268 LOAD_ATTR                2 (functional)\n            270 LOAD_ATTR                3 (dropout)\n            272 LOAD_FAST                1 (hidden_states)\n            274 LOAD_FAST                0 (self)\n            276 LOAD_ATTR                3 (dropout)\n            278 LOAD_FAST                0 (self)\n            280 LOAD_ATTR                4 (training)\n            282 LOAD_CONST               4 (('p', 'training'))\n            284 CALL_FUNCTION_KW         3\n            286 STORE_FAST               1 (hidden_states)\n\n427         288 LOAD_FAST               10 (residual)\n            290 LOAD_FAST                1 (hidden_states)\n            292 BINARY_ADD\n            294 STORE_FAST               1 (hidden_states)\n\n428         296 LOAD_FAST                0 (self)\n            298 LOAD_METHOD             12 (final_layer_norm)\n            300 LOAD_FAST                1 (hidden_states)\n            302 CALL_METHOD              1\n            304 STORE_FAST               1 (hidden_states)\n\n430         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n432         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n433         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n435     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n436         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n438     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (past_key_values)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (past_key_values)\n\n  5          12 LOAD_FAST                3 (hidden_states)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (hidden_states)\n\n  6          18 LOAD_FAST                4 (attentions)\n             20 LOAD_FAST                0 (self)\n             22 STORE_ATTR               3 (attentions)\n\n  7          24 LOAD_FAST                5 (cross_attentions)\n             26 LOAD_FAST                0 (self)\n             28 STORE_ATTR               4 (cross_attentions)\n\n  8          30 LOAD_FAST                0 (self)\n             32 LOAD_METHOD              5 (__post_init__)\n             34 CALL_METHOD              0\n             36 POP_TOP\n             38 LOAD_CONST               0 (None)\n             40 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 3 \n  3           0 JUMP_ABSOLUTE            4 (to 8)\n              2 LOAD_FAST                5 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n\n  4     >>    8 LOAD_FAST                1 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5          14 LOAD_FAST                2 (hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (hidden_states)\n\n  6          20 LOAD_FAST                3 (attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (attentions)\n\n  7          26 LOAD_FAST                4 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                5 (__post_init__)\n             36 CALL_FUNCTION            0\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/trocr/modeling_trocr.py line 963 \n963           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           49 (to 98)\n              4 LOAD_FAST               13 (output_attentions)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE        8 (to 16)\n             12 LOAD_FAST               13 (output_attentions)\n             14 JUMP_FORWARD             3 (to 22)\n        >>   16 LOAD_FAST                1 (self)\n             18 LOAD_ATTR                0 (config)\n             20 LOAD_ATTR                1 (output_attentions)\n        >>   22 STORE_FAST              13 (output_attentions)\n             24 LOAD_FAST               14 (output_hidden_states)\n             26 LOAD_CONST               1 (None)\n             28 IS_OP                    1\n             30 POP_JUMP_IF_FALSE       18 (to 36)\n             32 LOAD_FAST               14 (output_hidden_states)\n             34 JUMP_FORWARD             3 (to 42)\n        >>   36 LOAD_FAST                1 (self)\n             38 LOAD_ATTR                0 (config)\n             40 LOAD_ATTR                2 (output_hidden_states)\n        >>   42 STORE_FAST              14 (output_hidden_states)\n             44 LOAD_FAST                3 (return_dict)\n             46 LOAD_CONST               1 (None)\n             48 IS_OP                    1\n             50 POP_JUMP_IF_FALSE       28 (to 56)\n             52 LOAD_FAST                3 (return_dict)\n             54 JUMP_FORWARD             3 (to 62)\n        >>   56 LOAD_FAST                1 (self)\n             58 LOAD_ATTR                0 (config)\n             60 LOAD_ATTR                3 (use_return_dict)\n        >>   62 STORE_FAST               3 (return_dict)\n             64 LOAD_FAST                1 (self)\n             66 LOAD_ATTR                4 (model)\n             68 LOAD_ATTR                5 (decoder)\n             70 LOAD_FAST                4 (input_ids)\n             72 LOAD_FAST                5 (attention_mask)\n             74 LOAD_FAST                6 (encoder_hidden_states)\n             76 LOAD_FAST                7 (encoder_attention_mask)\n             78 LOAD_FAST                8 (head_mask)\n             80 LOAD_FAST                9 (cross_attn_head_mask)\n             82 LOAD_FAST               10 (past_key_values)\n             84 LOAD_FAST               11 (inputs_embeds)\n             86 LOAD_FAST               12 (use_cache)\n             88 LOAD_FAST               13 (output_attentions)\n             90 LOAD_FAST               14 (output_hidden_states)\n             92 LOAD_FAST                3 (return_dict)\n             94 LOAD_CONST               2 (('input_ids', 'attention_mask', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             96 CALL_FUNCTION_KW        12\n        >>   98 STORE_FAST              15 (outputs)\n\n978         100 LOAD_FAST                1 (self)\n            102 LOAD_ATTR                6 (output_projection)\n            104 LOAD_FAST               15 (outputs)\n            106 LOAD_CONST               3 (0)\n            108 BINARY_SUBSCR\n            110 CALL_FUNCTION            1\n            112 STORE_FAST              16 (logits)\n\n980         114 LOAD_CONST               1 (None)\n            116 STORE_FAST              17 (loss)\n\n981         118 LOAD_FAST                2 (labels)\n            120 LOAD_CONST               1 (None)\n            122 IS_OP                    1\n            124 POP_JUMP_IF_FALSE       80 (to 160)\n\n982         126 LOAD_GLOBAL              7 (CrossEntropyLoss)\n            128 CALL_FUNCTION            0\n            130 STORE_FAST              18 (loss_fct)\n\n983         132 LOAD_FAST               18 (loss_fct)\n            134 LOAD_FAST               16 (logits)\n            136 LOAD_ATTR                8 (view)\n            138 LOAD_CONST               4 (-1)\n            140 LOAD_FAST                1 (self)\n            142 LOAD_ATTR                0 (config)\n            144 LOAD_ATTR                9 (vocab_size)\n            146 CALL_FUNCTION            2\n            148 LOAD_FAST                2 (labels)\n            150 LOAD_ATTR                8 (view)\n            152 LOAD_CONST               4 (-1)\n            154 CALL_FUNCTION            1\n            156 CALL_FUNCTION            2\n            158 STORE_FAST              17 (loss)\n\n985     >>  160 LOAD_FAST                3 (return_dict)\n            162 POP_JUMP_IF_TRUE       102 (to 204)\n\n986         164 LOAD_FAST               16 (logits)\n            166 BUILD_TUPLE              1\n            168 LOAD_FAST               15 (outputs)\n            170 LOAD_CONST               5 (1)\n            172 LOAD_CONST               1 (None)\n            174 BUILD_SLICE              2\n            176 BINARY_SUBSCR\n            178 BINARY_ADD\n            180 STORE_FAST              19 (output)\n\n987         182 LOAD_FAST               17 (loss)\n            184 LOAD_CONST               1 (None)\n            186 IS_OP                    1\n            188 POP_JUMP_IF_FALSE      100 (to 200)\n            190 LOAD_FAST               17 (loss)\n            192 BUILD_TUPLE              1\n            194 LOAD_FAST               19 (output)\n            196 BINARY_ADD\n            198 RETURN_VALUE\n        >>  200 LOAD_FAST               19 (output)\n            202 RETURN_VALUE\n\n989     >>  204 LOAD_GLOBAL             10 (CausalLMOutputWithCrossAttentions)\n\n990         206 LOAD_FAST               17 (loss)\n\n991         208 LOAD_FAST               16 (logits)\n\n992         210 LOAD_FAST               15 (outputs)\n            212 LOAD_ATTR               11 (past_key_values)\n\n993         214 LOAD_FAST               15 (outputs)\n            216 LOAD_ATTR               12 (hidden_states)\n\n994         218 LOAD_FAST               15 (outputs)\n            220 LOAD_ATTR               13 (attentions)\n\n995         222 LOAD_FAST               15 (outputs)\n            224 LOAD_ATTR               14 (cross_attentions)\n\n989         226 LOAD_CONST               6 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n            228 CALL_FUNCTION_KW         6\n            230 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 557 \n557           0 LOAD_FAST                0 (___stack0)\n              2 CALL_FUNCTION            0\n              4 SETUP_WITH              10 (to 26)\n              6 POP_TOP\n              8 LOAD_FAST                1 (___stack1)\n             10 JUMP_ABSOLUTE           44 (to 88)\n             12 POP_BLOCK\n             14 LOAD_CONST               0 (None)\n             16 DUP_TOP\n             18 DUP_TOP\n             20 CALL_FUNCTION            3\n             22 POP_TOP\n             24 JUMP_FORWARD             8 (to 42)\n        >>   26 WITH_EXCEPT_START\n             28 POP_JUMP_IF_TRUE        16 (to 32)\n             30 RERAISE                  0\n        >>   32 POP_TOP\n             34 POP_TOP\n             36 POP_TOP\n             38 POP_EXCEPT\n             40 POP_TOP\n        >>   42 NOP\n             44 LOAD_CONST               0 (None)\n             46 RAISE_VARARGS            1\n             48 LOAD_GLOBAL              0 (clone_inputs)\n             50 LOAD_FAST                6 (inputs)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (cloned_inputs)\n             56 LOAD_FAST                2 (self)\n             58 LOAD_ATTR                1 (optimizer_zero_grad)\n             60 LOAD_FAST                3 (mod)\n             62 CALL_FUNCTION            1\n             64 POP_TOP\n             66 LOAD_FAST                2 (self)\n             68 LOAD_ATTR                2 (autocast)\n             70 CALL_FUNCTION            0\n             72 SETUP_WITH              20 (to 114)\n             74 POP_TOP\n             76 LOAD_FAST                3 (mod)\n             78 LOAD_CONST               1 (())\n             80 BUILD_MAP                0\n             82 LOAD_FAST                5 (cloned_inputs)\n             84 DICT_MERGE               1\n             86 CALL_FUNCTION_EX         1\n        >>   88 STORE_FAST               7 (pred)\n\n558          90 LOAD_FAST                2 (self)\n             92 LOAD_ATTR                3 (compute_loss)\n             94 LOAD_FAST                7 (pred)\n             96 CALL_FUNCTION            1\n             98 STORE_FAST               8 (loss)\n            100 POP_BLOCK\n\n556         102 LOAD_CONST               0 (None)\n            104 DUP_TOP\n            106 DUP_TOP\n            108 CALL_FUNCTION            3\n            110 POP_TOP\n            112 JUMP_FORWARD             8 (to 130)\n        >>  114 WITH_EXCEPT_START\n            116 POP_JUMP_IF_TRUE        60 (to 120)\n            118 RERAISE                  1\n        >>  120 POP_TOP\n            122 POP_TOP\n            124 POP_TOP\n            126 POP_EXCEPT\n            128 POP_TOP\n\n559     >>  130 LOAD_FAST                2 (self)\n            132 LOAD_ATTR                4 (grad_scaler)\n            134 LOAD_ATTR                5 (scale)\n            136 LOAD_FAST                8 (loss)\n            138 CALL_FUNCTION            1\n            140 LOAD_ATTR                6 (backward)\n            142 CALL_FUNCTION            0\n            144 POP_TOP\n\n560         146 LOAD_FAST                2 (self)\n            148 LOAD_ATTR                7 (optimizer_step)\n            150 CALL_FUNCTION            0\n            152 POP_TOP\n\n561         154 LOAD_FAST                4 (collect_outputs)\n            156 POP_JUMP_IF_FALSE       86 (to 172)\n\n562         158 LOAD_GLOBAL              8 (collect_results)\n            160 LOAD_FAST                3 (mod)\n            162 LOAD_FAST                7 (pred)\n            164 LOAD_FAST                8 (loss)\n            166 LOAD_FAST                5 (cloned_inputs)\n            168 CALL_FUNCTION            4\n            170 RETURN_VALUE\n\n563     >>  172 LOAD_CONST               0 (None)\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 774 \n804           0 LOAD_FAST               12 (output_attentions)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    1\n              6 POP_JUMP_IF_FALSE        6 (to 12)\n              8 LOAD_FAST               12 (output_attentions)\n             10 JUMP_FORWARD             3 (to 18)\n        >>   12 LOAD_FAST                0 (self)\n             14 LOAD_ATTR                0 (config)\n             16 LOAD_ATTR                1 (output_attentions)\n        >>   18 STORE_FAST              12 (output_attentions)\n\n806          20 LOAD_FAST               13 (output_hidden_states)\n             22 LOAD_CONST               1 (None)\n             24 IS_OP                    1\n             26 POP_JUMP_IF_FALSE       16 (to 32)\n             28 LOAD_FAST               13 (output_hidden_states)\n             30 JUMP_FORWARD             3 (to 38)\n        >>   32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                0 (config)\n             36 LOAD_ATTR                2 (output_hidden_states)\n\n805     >>   38 STORE_FAST              13 (output_hidden_states)\n\n808          40 LOAD_FAST               14 (return_dict)\n             42 LOAD_CONST               1 (None)\n             44 IS_OP                    1\n             46 POP_JUMP_IF_FALSE       26 (to 52)\n             48 LOAD_FAST               14 (return_dict)\n             50 JUMP_FORWARD             3 (to 58)\n        >>   52 LOAD_FAST                0 (self)\n             54 LOAD_ATTR                0 (config)\n             56 LOAD_ATTR                3 (use_return_dict)\n        >>   58 STORE_FAST              14 (return_dict)\n\n811          60 LOAD_FAST                0 (self)\n             62 LOAD_ATTR                4 (model)\n\n812          64 LOAD_FAST                1 (input_ids)\n\n813          66 LOAD_FAST                2 (attention_mask)\n\n814          68 LOAD_FAST                3 (position_ids)\n\n815          70 LOAD_FAST                4 (encoder_hidden_states)\n\n816          72 LOAD_FAST                5 (encoder_attention_mask)\n\n817          74 LOAD_FAST                6 (head_mask)\n\n818          76 LOAD_FAST                7 (cross_attn_head_mask)\n\n819          78 LOAD_FAST                8 (past_key_values)\n\n820          80 LOAD_FAST                9 (inputs_embeds)\n\n821          82 LOAD_FAST               11 (use_cache)\n\n822          84 LOAD_FAST               12 (output_attentions)\n\n823          86 LOAD_FAST               13 (output_hidden_states)\n\n824          88 LOAD_FAST               14 (return_dict)\n\n811          90 LOAD_CONST               2 (('input_ids', 'attention_mask', 'position_ids', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             92 CALL_FUNCTION_KW        13\n             94 STORE_FAST              15 (outputs)\n\n827          96 LOAD_FAST                0 (self)\n             98 LOAD_METHOD              5 (lm_head)\n            100 LOAD_FAST               15 (outputs)\n            102 LOAD_CONST               3 (0)\n            104 BINARY_SUBSCR\n            106 CALL_METHOD              1\n            108 STORE_FAST              16 (logits)\n\n829         110 LOAD_CONST               1 (None)\n            112 STORE_FAST              17 (loss)\n\n830         114 LOAD_FAST               10 (labels)\n            116 LOAD_CONST               1 (None)\n            118 IS_OP                    1\n            120 POP_JUMP_IF_FALSE      114 (to 228)\n\n832         122 LOAD_FAST               10 (labels)\n            124 LOAD_METHOD              6 (new_zeros)\n            126 LOAD_FAST               10 (labels)\n            128 LOAD_ATTR                7 (shape)\n            130 CALL_METHOD              1\n            132 STORE_FAST              18 (shift_labels)\n\n833         134 LOAD_FAST               10 (labels)\n            136 LOAD_CONST               1 (None)\n            138 LOAD_CONST               1 (None)\n            140 BUILD_SLICE              2\n            142 LOAD_CONST               4 (1)\n            144 LOAD_CONST               1 (None)\n            146 BUILD_SLICE              2\n            148 BUILD_TUPLE              2\n            150 BINARY_SUBSCR\n            152 LOAD_METHOD              8 (clone)\n            154 CALL_METHOD              0\n            156 LOAD_FAST               18 (shift_labels)\n            158 LOAD_CONST               1 (None)\n            160 LOAD_CONST               1 (None)\n            162 BUILD_SLICE              2\n            164 LOAD_CONST               1 (None)\n            166 LOAD_CONST               5 (-1)\n            168 BUILD_SLICE              2\n            170 BUILD_TUPLE              2\n            172 STORE_SUBSCR\n\n834         174 LOAD_FAST                0 (self)\n            176 LOAD_ATTR                0 (config)\n            178 LOAD_ATTR                9 (pad_token_id)\n            180 LOAD_FAST               18 (shift_labels)\n            182 LOAD_CONST               1 (None)\n            184 LOAD_CONST               1 (None)\n            186 BUILD_SLICE              2\n            188 LOAD_CONST               5 (-1)\n            190 BUILD_TUPLE              2\n            192 STORE_SUBSCR\n\n836         194 LOAD_GLOBAL             10 (CrossEntropyLoss)\n            196 CALL_FUNCTION            0\n            198 STORE_FAST              19 (loss_fct)\n\n837         200 LOAD_FAST               19 (loss_fct)\n            202 LOAD_FAST               16 (logits)\n            204 LOAD_METHOD             11 (view)\n            206 LOAD_CONST               5 (-1)\n            208 LOAD_FAST                0 (self)\n            210 LOAD_ATTR                0 (config)\n            212 LOAD_ATTR               12 (vocab_size)\n            214 CALL_METHOD              2\n            216 LOAD_FAST               18 (shift_labels)\n            218 LOAD_METHOD             11 (view)\n            220 LOAD_CONST               5 (-1)\n            222 CALL_METHOD              1\n            224 CALL_FUNCTION            2\n            226 STORE_FAST              17 (loss)\n\n839     >>  228 LOAD_FAST               14 (return_dict)\n            230 POP_JUMP_IF_TRUE       136 (to 272)\n\n840         232 LOAD_FAST               16 (logits)\n            234 BUILD_TUPLE              1\n            236 LOAD_FAST               15 (outputs)\n            238 LOAD_CONST               4 (1)\n            240 LOAD_CONST               1 (None)\n            242 BUILD_SLICE              2\n            244 BINARY_SUBSCR\n            246 BINARY_ADD\n            248 STORE_FAST              20 (output)\n\n841         250 LOAD_FAST               17 (loss)\n            252 LOAD_CONST               1 (None)\n            254 IS_OP                    1\n            256 POP_JUMP_IF_FALSE      134 (to 268)\n            258 LOAD_FAST               17 (loss)\n            260 BUILD_TUPLE              1\n            262 LOAD_FAST               20 (output)\n            264 BINARY_ADD\n            266 RETURN_VALUE\n        >>  268 LOAD_FAST               20 (output)\n            270 RETURN_VALUE\n\n843     >>  272 LOAD_GLOBAL             13 (CausalLMOutputWithCrossAttentions)\n\n844         274 LOAD_FAST               17 (loss)\n\n845         276 LOAD_FAST               16 (logits)\n\n846         278 LOAD_FAST               15 (outputs)\n            280 LOAD_ATTR               14 (past_key_values)\n\n847         282 LOAD_FAST               15 (outputs)\n            284 LOAD_ATTR               15 (hidden_states)\n\n848         286 LOAD_FAST               15 (outputs)\n            288 LOAD_ATTR               16 (attentions)\n\n849         290 LOAD_FAST               15 (outputs)\n            292 LOAD_ATTR               17 (cross_attentions)\n\n843         294 LOAD_CONST               6 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n            296 CALL_FUNCTION_KW         6\n            298 RETURN_VALUE\n\n", "ORIGINAL BYTECODE _prepare_decoder_attention_mask /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 555 \n558           0 LOAD_CONST               0 (None)\n              2 STORE_FAST               5 (combined_attention_mask)\n\n559           4 LOAD_FAST                2 (input_shape)\n              6 LOAD_CONST               1 (-1)\n              8 BINARY_SUBSCR\n             10 LOAD_CONST               2 (1)\n             12 COMPARE_OP               4 (>)\n             14 POP_JUMP_IF_FALSE       18 (to 36)\n\n560          16 LOAD_GLOBAL              0 (_make_causal_mask)\n\n561          18 LOAD_FAST                2 (input_shape)\n\n562          20 LOAD_FAST                3 (inputs_embeds)\n             22 LOAD_ATTR                1 (dtype)\n\n563          24 LOAD_FAST                3 (inputs_embeds)\n             26 LOAD_ATTR                2 (device)\n\n564          28 LOAD_FAST                4 (past_key_values_length)\n\n560          30 LOAD_CONST               3 (('device', 'past_key_values_length'))\n             32 CALL_FUNCTION_KW         4\n             34 STORE_FAST               5 (combined_attention_mask)\n\n567     >>   36 LOAD_FAST                1 (attention_mask)\n             38 LOAD_CONST               0 (None)\n             40 IS_OP                    1\n             42 POP_JUMP_IF_FALSE       42 (to 84)\n\n569          44 LOAD_GLOBAL              3 (_expand_mask)\n             46 LOAD_FAST                1 (attention_mask)\n             48 LOAD_FAST                3 (inputs_embeds)\n             50 LOAD_ATTR                1 (dtype)\n             52 LOAD_FAST                2 (input_shape)\n             54 LOAD_CONST               1 (-1)\n             56 BINARY_SUBSCR\n             58 LOAD_CONST               4 (('tgt_len',))\n             60 CALL_FUNCTION_KW         3\n             62 STORE_FAST               6 (expanded_attn_mask)\n\n571          64 LOAD_FAST                5 (combined_attention_mask)\n             66 LOAD_CONST               0 (None)\n             68 IS_OP                    0\n             70 POP_JUMP_IF_FALSE       38 (to 76)\n             72 LOAD_FAST                6 (expanded_attn_mask)\n             74 JUMP_FORWARD             3 (to 82)\n        >>   76 LOAD_FAST                6 (expanded_attn_mask)\n             78 LOAD_FAST                5 (combined_attention_mask)\n             80 BINARY_ADD\n\n570     >>   82 STORE_FAST               5 (combined_attention_mask)\n\n574     >>   84 LOAD_FAST                5 (combined_attention_mask)\n             86 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 202 \n204           0 LOAD_FAST                1 (position_ids)\n              2 LOAD_METHOD              0 (size)\n              4 CALL_METHOD              0\n              6 UNPACK_SEQUENCE          2\n              8 STORE_FAST               3 (bsz)\n             10 STORE_FAST               4 (seq_len)\n\n205          12 LOAD_FAST                1 (position_ids)\n             14 LOAD_FAST                0 (self)\n             16 LOAD_ATTR                1 (offset)\n             18 INPLACE_ADD\n             20 STORE_FAST               1 (position_ids)\n\n208          22 LOAD_CONST               1 (2)\n             24 LOAD_FAST                4 (seq_len)\n             26 BINARY_ADD\n             28 LOAD_FAST                2 (past_key_values_length)\n             30 BINARY_ADD\n             32 STORE_FAST               5 (max_pos)\n\n209          34 LOAD_FAST                5 (max_pos)\n             36 LOAD_FAST                0 (self)\n             38 LOAD_ATTR                2 (weights)\n             40 LOAD_METHOD              0 (size)\n             42 LOAD_CONST               2 (0)\n             44 CALL_METHOD              1\n             46 COMPARE_OP               4 (>)\n             48 POP_JUMP_IF_FALSE       34 (to 68)\n\n210          50 LOAD_FAST                0 (self)\n             52 LOAD_METHOD              3 (make_weights)\n             54 LOAD_FAST                5 (max_pos)\n             56 LOAD_FAST                0 (self)\n             58 LOAD_ATTR                4 (embedding_dim)\n             60 LOAD_FAST                0 (self)\n             62 LOAD_ATTR                5 (padding_idx)\n             64 CALL_METHOD              3\n             66 POP_TOP\n\n212     >>   68 LOAD_FAST                0 (self)\n             70 LOAD_ATTR                2 (weights)\n             72 LOAD_METHOD              6 (index_select)\n             74 LOAD_CONST               2 (0)\n             76 LOAD_FAST                1 (position_ids)\n             78 LOAD_METHOD              7 (view)\n             80 LOAD_CONST               3 (-1)\n             82 CALL_METHOD              1\n             84 CALL_METHOD              2\n             86 LOAD_METHOD              7 (view)\n             88 LOAD_FAST                3 (bsz)\n             90 LOAD_FAST                4 (seq_len)\n             92 LOAD_FAST                0 (self)\n             94 LOAD_ATTR                2 (weights)\n             96 LOAD_ATTR                8 (shape)\n             98 LOAD_CONST               3 (-1)\n            100 BINARY_SUBSCR\n            102 CALL_METHOD              3\n            104 LOAD_METHOD              9 (detach)\n            106 CALL_METHOD              0\n            108 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 399 \n429           0 LOAD_FAST                1 (hidden_states)\n              2 STORE_FAST              10 (residual)\n\n430           4 LOAD_FAST                0 (self)\n              6 LOAD_METHOD              0 (self_attn_layer_norm)\n              8 LOAD_FAST                1 (hidden_states)\n             10 CALL_METHOD              1\n             12 STORE_FAST               1 (hidden_states)\n\n434          14 LOAD_FAST                7 (past_key_value)\n             16 LOAD_CONST               1 (None)\n             18 IS_OP                    1\n             20 POP_JUMP_IF_FALSE       17 (to 34)\n             22 LOAD_FAST                7 (past_key_value)\n             24 LOAD_CONST               1 (None)\n             26 LOAD_CONST               2 (2)\n             28 BUILD_SLICE              2\n             30 BINARY_SUBSCR\n             32 JUMP_FORWARD             1 (to 36)\n        >>   34 LOAD_CONST               1 (None)\n        >>   36 STORE_FAST              11 (self_attn_past_key_value)\n\n436          38 LOAD_FAST                0 (self)\n             40 LOAD_ATTR                1 (self_attn)\n\n437          42 LOAD_FAST                1 (hidden_states)\n\n438          44 LOAD_FAST               11 (self_attn_past_key_value)\n\n439          46 LOAD_FAST                2 (attention_mask)\n\n440          48 LOAD_FAST                5 (layer_head_mask)\n\n441          50 LOAD_FAST                8 (output_attentions)\n\n436          52 LOAD_CONST               3 (('hidden_states', 'past_key_value', 'attention_mask', 'layer_head_mask', 'output_attentions'))\n             54 CALL_FUNCTION_KW         5\n             56 UNPACK_SEQUENCE          3\n             58 STORE_FAST               1 (hidden_states)\n             60 STORE_FAST              12 (self_attn_weights)\n             62 STORE_FAST              13 (present_key_value)\n\n443          64 LOAD_GLOBAL              2 (nn)\n             66 LOAD_ATTR                3 (functional)\n             68 LOAD_ATTR                4 (dropout)\n             70 LOAD_FAST                1 (hidden_states)\n             72 LOAD_FAST                0 (self)\n             74 LOAD_ATTR                4 (dropout)\n             76 LOAD_FAST                0 (self)\n             78 LOAD_ATTR                5 (training)\n             80 LOAD_CONST               4 (('p', 'training'))\n             82 CALL_FUNCTION_KW         3\n             84 STORE_FAST               1 (hidden_states)\n\n444          86 LOAD_FAST               10 (residual)\n             88 LOAD_FAST                1 (hidden_states)\n             90 BINARY_ADD\n             92 STORE_FAST               1 (hidden_states)\n\n447          94 LOAD_CONST               1 (None)\n             96 STORE_FAST              14 (cross_attn_present_key_value)\n\n448          98 LOAD_CONST               1 (None)\n            100 STORE_FAST              15 (cross_attn_weights)\n\n449         102 LOAD_FAST                3 (encoder_hidden_states)\n            104 LOAD_CONST               1 (None)\n            106 IS_OP                    1\n            108 POP_JUMP_IF_FALSE      107 (to 214)\n\n450         110 LOAD_FAST                1 (hidden_states)\n            112 STORE_FAST              10 (residual)\n\n451         114 LOAD_FAST                0 (self)\n            116 LOAD_METHOD              6 (encoder_attn_layer_norm)\n            118 LOAD_FAST                1 (hidden_states)\n            120 CALL_METHOD              1\n            122 STORE_FAST               1 (hidden_states)\n\n454         124 LOAD_FAST                7 (past_key_value)\n            126 LOAD_CONST               1 (None)\n            128 IS_OP                    1\n            130 POP_JUMP_IF_FALSE       72 (to 144)\n            132 LOAD_FAST                7 (past_key_value)\n            134 LOAD_CONST               5 (-2)\n            136 LOAD_CONST               1 (None)\n            138 BUILD_SLICE              2\n            140 BINARY_SUBSCR\n            142 JUMP_FORWARD             1 (to 146)\n        >>  144 LOAD_CONST               1 (None)\n        >>  146 STORE_FAST              16 (cross_attn_past_key_value)\n\n455         148 LOAD_FAST                0 (self)\n            150 LOAD_ATTR                7 (encoder_attn)\n\n456         152 LOAD_FAST                1 (hidden_states)\n\n457         154 LOAD_FAST                3 (encoder_hidden_states)\n\n458         156 LOAD_FAST                4 (encoder_attention_mask)\n\n459         158 LOAD_FAST                6 (cross_attn_layer_head_mask)\n\n460         160 LOAD_FAST               16 (cross_attn_past_key_value)\n\n461         162 LOAD_FAST                8 (output_attentions)\n\n455         164 LOAD_CONST               6 (('hidden_states', 'key_value_states', 'attention_mask', 'layer_head_mask', 'past_key_value', 'output_attentions'))\n            166 CALL_FUNCTION_KW         6\n            168 UNPACK_SEQUENCE          3\n            170 STORE_FAST               1 (hidden_states)\n            172 STORE_FAST              15 (cross_attn_weights)\n            174 STORE_FAST              14 (cross_attn_present_key_value)\n\n463         176 LOAD_GLOBAL              2 (nn)\n            178 LOAD_ATTR                3 (functional)\n            180 LOAD_ATTR                4 (dropout)\n            182 LOAD_FAST                1 (hidden_states)\n            184 LOAD_FAST                0 (self)\n            186 LOAD_ATTR                4 (dropout)\n            188 LOAD_FAST                0 (self)\n            190 LOAD_ATTR                5 (training)\n            192 LOAD_CONST               4 (('p', 'training'))\n            194 CALL_FUNCTION_KW         3\n            196 STORE_FAST               1 (hidden_states)\n\n464         198 LOAD_FAST               10 (residual)\n            200 LOAD_FAST                1 (hidden_states)\n            202 BINARY_ADD\n            204 STORE_FAST               1 (hidden_states)\n\n467         206 LOAD_FAST               13 (present_key_value)\n            208 LOAD_FAST               14 (cross_attn_present_key_value)\n            210 BINARY_ADD\n            212 STORE_FAST              13 (present_key_value)\n\n470     >>  214 LOAD_FAST                1 (hidden_states)\n            216 STORE_FAST              10 (residual)\n\n471         218 LOAD_FAST                0 (self)\n            220 LOAD_METHOD              8 (final_layer_norm)\n            222 LOAD_FAST                1 (hidden_states)\n            224 CALL_METHOD              1\n            226 STORE_FAST               1 (hidden_states)\n\n472         228 LOAD_FAST                0 (self)\n            230 LOAD_METHOD              9 (activation_fn)\n            232 LOAD_FAST                0 (self)\n            234 LOAD_METHOD             10 (fc1)\n            236 LOAD_FAST                1 (hidden_states)\n            238 CALL_METHOD              1\n            240 CALL_METHOD              1\n            242 STORE_FAST               1 (hidden_states)\n\n473         244 LOAD_GLOBAL              2 (nn)\n            246 LOAD_ATTR                3 (functional)\n            248 LOAD_ATTR                4 (dropout)\n            250 LOAD_FAST                1 (hidden_states)\n            252 LOAD_FAST                0 (self)\n            254 LOAD_ATTR               11 (activation_dropout)\n            256 LOAD_FAST                0 (self)\n            258 LOAD_ATTR                5 (training)\n            260 LOAD_CONST               4 (('p', 'training'))\n            262 CALL_FUNCTION_KW         3\n            264 STORE_FAST               1 (hidden_states)\n\n474         266 LOAD_FAST                0 (self)\n            268 LOAD_METHOD             12 (fc2)\n            270 LOAD_FAST                1 (hidden_states)\n            272 CALL_METHOD              1\n            274 STORE_FAST               1 (hidden_states)\n\n475         276 LOAD_GLOBAL              2 (nn)\n            278 LOAD_ATTR                3 (functional)\n            280 LOAD_ATTR                4 (dropout)\n            282 LOAD_FAST                1 (hidden_states)\n            284 LOAD_FAST                0 (self)\n            286 LOAD_ATTR                4 (dropout)\n            288 LOAD_FAST                0 (self)\n            290 LOAD_ATTR                5 (training)\n            292 LOAD_CONST               4 (('p', 'training'))\n            294 CALL_FUNCTION_KW         3\n            296 STORE_FAST               1 (hidden_states)\n\n476         298 LOAD_FAST               10 (residual)\n            300 LOAD_FAST                1 (hidden_states)\n            302 BINARY_ADD\n            304 STORE_FAST               1 (hidden_states)\n\n478         306 LOAD_FAST                1 (hidden_states)\n            308 BUILD_TUPLE              1\n            310 STORE_FAST              17 (outputs)\n\n480         312 LOAD_FAST                8 (output_attentions)\n            314 POP_JUMP_IF_FALSE      164 (to 328)\n\n481         316 LOAD_FAST               17 (outputs)\n            318 LOAD_FAST               12 (self_attn_weights)\n            320 LOAD_FAST               15 (cross_attn_weights)\n            322 BUILD_TUPLE              2\n            324 INPLACE_ADD\n            326 STORE_FAST              17 (outputs)\n\n483     >>  328 LOAD_FAST                9 (use_cache)\n            330 POP_JUMP_IF_FALSE      171 (to 342)\n\n484         332 LOAD_FAST               17 (outputs)\n            334 LOAD_FAST               13 (present_key_value)\n            336 BUILD_TUPLE              1\n            338 INPLACE_ADD\n            340 STORE_FAST              17 (outputs)\n\n486     >>  342 LOAD_FAST               17 (outputs)\n            344 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __init__ <string> line 2 \n  3           0 LOAD_FAST                1 (last_hidden_state)\n              2 LOAD_FAST                0 (self)\n              4 STORE_ATTR               0 (last_hidden_state)\n\n  4           6 LOAD_FAST                2 (past_key_values)\n              8 LOAD_FAST                0 (self)\n             10 STORE_ATTR               1 (past_key_values)\n\n  5          12 LOAD_FAST                3 (hidden_states)\n             14 LOAD_FAST                0 (self)\n             16 STORE_ATTR               2 (hidden_states)\n\n  6          18 LOAD_FAST                4 (attentions)\n             20 LOAD_FAST                0 (self)\n             22 STORE_ATTR               3 (attentions)\n\n  7          24 LOAD_FAST                5 (cross_attentions)\n             26 LOAD_FAST                0 (self)\n             28 STORE_ATTR               4 (cross_attentions)\n\n  8          30 LOAD_FAST                0 (self)\n             32 LOAD_METHOD              5 (__post_init__)\n             34 CALL_METHOD              0\n             36 POP_TOP\n             38 LOAD_CONST               0 (None)\n             40 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __init__> <string> line 3 \n  3           0 JUMP_ABSOLUTE            4 (to 8)\n              2 LOAD_FAST                5 (last_hidden_state)\n              4 LOAD_FAST                0 (self)\n              6 STORE_ATTR               0 (last_hidden_state)\n\n  4     >>    8 LOAD_FAST                1 (past_key_values)\n             10 LOAD_FAST                0 (self)\n             12 STORE_ATTR               1 (past_key_values)\n\n  5          14 LOAD_FAST                2 (hidden_states)\n             16 LOAD_FAST                0 (self)\n             18 STORE_ATTR               2 (hidden_states)\n\n  6          20 LOAD_FAST                3 (attentions)\n             22 LOAD_FAST                0 (self)\n             24 STORE_ATTR               3 (attentions)\n\n  7          26 LOAD_FAST                4 (cross_attentions)\n             28 LOAD_FAST                0 (self)\n             30 STORE_ATTR               4 (cross_attentions)\n\n  8          32 LOAD_FAST                0 (self)\n             34 LOAD_ATTR                5 (__post_init__)\n             36 CALL_FUNCTION            0\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE __setitem__ /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 328 \n330           0 LOAD_GLOBAL              0 (super)\n              2 CALL_FUNCTION            0\n              4 LOAD_METHOD              1 (__setitem__)\n              6 LOAD_FAST                1 (key)\n              8 LOAD_FAST                2 (value)\n             10 CALL_METHOD              2\n             12 POP_TOP\n\n332          14 LOAD_GLOBAL              0 (super)\n             16 CALL_FUNCTION            0\n             18 LOAD_METHOD              2 (__setattr__)\n             20 LOAD_FAST                1 (key)\n             22 LOAD_FAST                2 (value)\n             24 CALL_METHOD              2\n             26 POP_TOP\n             28 LOAD_CONST               0 (None)\n             30 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in __setitem__> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/utils/generic.py line 330 \n330           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (super)\n              6 LOAD_DEREF               0 (__class__)\n              8 LOAD_FAST                1 (self)\n             10 CALL_FUNCTION            2\n             12 LOAD_ATTR                1 (__setitem__)\n             14 LOAD_FAST                2 (key)\n             16 LOAD_FAST                3 (value)\n             18 CALL_FUNCTION            2\n        >>   20 POP_TOP\n\n332          22 LOAD_GLOBAL              0 (super)\n             24 LOAD_DEREF               0 (__class__)\n             26 LOAD_FAST                1 (self)\n             28 CALL_FUNCTION            2\n             30 LOAD_ATTR                2 (__setattr__)\n             32 LOAD_FAST                2 (key)\n             34 LOAD_FAST                3 (value)\n             36 CALL_FUNCTION            2\n             38 POP_TOP\n             40 LOAD_CONST               0 (None)\n             42 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward> /workspace/youkaichao/miniconda3/envs/build_torch/lib/python3.10/site-packages/transformers/models/xglm/modeling_xglm.py line 811 \n811           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           49 (to 98)\n              4 LOAD_FAST               14 (output_attentions)\n              6 LOAD_CONST               1 (None)\n              8 IS_OP                    1\n             10 POP_JUMP_IF_FALSE        8 (to 16)\n             12 LOAD_FAST               14 (output_attentions)\n             14 JUMP_FORWARD             3 (to 22)\n        >>   16 LOAD_FAST                1 (self)\n             18 LOAD_ATTR                0 (config)\n             20 LOAD_ATTR                1 (output_attentions)\n        >>   22 STORE_FAST              14 (output_attentions)\n             24 LOAD_FAST               15 (output_hidden_states)\n             26 LOAD_CONST               1 (None)\n             28 IS_OP                    1\n             30 POP_JUMP_IF_FALSE       18 (to 36)\n             32 LOAD_FAST               15 (output_hidden_states)\n             34 JUMP_FORWARD             3 (to 42)\n        >>   36 LOAD_FAST                1 (self)\n             38 LOAD_ATTR                0 (config)\n             40 LOAD_ATTR                2 (output_hidden_states)\n        >>   42 STORE_FAST              15 (output_hidden_states)\n             44 LOAD_FAST                3 (return_dict)\n             46 LOAD_CONST               1 (None)\n             48 IS_OP                    1\n             50 POP_JUMP_IF_FALSE       28 (to 56)\n             52 LOAD_FAST                3 (return_dict)\n             54 JUMP_FORWARD             3 (to 62)\n        >>   56 LOAD_FAST                1 (self)\n             58 LOAD_ATTR                0 (config)\n             60 LOAD_ATTR                3 (use_return_dict)\n        >>   62 STORE_FAST               3 (return_dict)\n             64 LOAD_FAST                1 (self)\n             66 LOAD_ATTR                4 (model)\n             68 LOAD_FAST                4 (input_ids)\n             70 LOAD_FAST                5 (attention_mask)\n             72 LOAD_FAST                6 (position_ids)\n             74 LOAD_FAST                7 (encoder_hidden_states)\n             76 LOAD_FAST                8 (encoder_attention_mask)\n             78 LOAD_FAST                9 (head_mask)\n             80 LOAD_FAST               10 (cross_attn_head_mask)\n             82 LOAD_FAST               11 (past_key_values)\n             84 LOAD_FAST               12 (inputs_embeds)\n             86 LOAD_FAST               13 (use_cache)\n             88 LOAD_FAST               14 (output_attentions)\n             90 LOAD_FAST               15 (output_hidden_states)\n             92 LOAD_FAST                3 (return_dict)\n             94 LOAD_CONST               2 (('input_ids', 'attention_mask', 'position_ids', 'encoder_hidden_states', 'encoder_attention_mask', 'head_mask', 'cross_attn_head_mask', 'past_key_values', 'inputs_embeds', 'use_cache', 'output_attentions', 'output_hidden_states', 'return_dict'))\n             96 CALL_FUNCTION_KW        13\n        >>   98 STORE_FAST              16 (outputs)\n\n827         100 LOAD_FAST                1 (self)\n            102 LOAD_ATTR                5 (lm_head)\n            104 LOAD_FAST               16 (outputs)\n            106 LOAD_CONST               3 (0)\n            108 BINARY_SUBSCR\n            110 CALL_FUNCTION            1\n            112 STORE_FAST              17 (logits)\n\n829         114 LOAD_CONST               1 (None)\n            116 STORE_FAST              18 (loss)\n\n830         118 LOAD_FAST                2 (labels)\n            120 LOAD_CONST               1 (None)\n            122 IS_OP                    1\n            124 POP_JUMP_IF_FALSE      116 (to 232)\n\n832         126 LOAD_FAST                2 (labels)\n            128 LOAD_ATTR                6 (new_zeros)\n            130 LOAD_FAST                2 (labels)\n            132 LOAD_ATTR                7 (shape)\n            134 CALL_FUNCTION            1\n            136 STORE_FAST              19 (shift_labels)\n\n833         138 LOAD_FAST                2 (labels)\n            140 LOAD_CONST               1 (None)\n            142 LOAD_CONST               1 (None)\n            144 BUILD_SLICE              2\n            146 LOAD_CONST               4 (1)\n            148 LOAD_CONST               1 (None)\n            150 BUILD_SLICE              2\n            152 BUILD_TUPLE              2\n            154 BINARY_SUBSCR\n            156 LOAD_ATTR                8 (clone)\n            158 CALL_FUNCTION            0\n            160 LOAD_FAST               19 (shift_labels)\n            162 LOAD_CONST               1 (None)\n            164 LOAD_CONST               1 (None)\n            166 BUILD_SLICE              2\n            168 LOAD_CONST               1 (None)\n            170 LOAD_CONST               5 (-1)\n            172 BUILD_SLICE              2\n            174 BUILD_TUPLE              2\n            176 STORE_SUBSCR\n\n834         178 LOAD_FAST                1 (self)\n            180 LOAD_ATTR                0 (config)\n            182 LOAD_ATTR                9 (pad_token_id)\n            184 LOAD_FAST               19 (shift_labels)\n            186 LOAD_CONST               1 (None)\n            188 LOAD_CONST               1 (None)\n            190 BUILD_SLICE              2\n            192 LOAD_CONST               5 (-1)\n            194 BUILD_TUPLE              2\n            196 STORE_SUBSCR\n\n836         198 LOAD_GLOBAL             10 (CrossEntropyLoss)\n            200 CALL_FUNCTION            0\n            202 STORE_FAST              20 (loss_fct)\n\n837         204 LOAD_FAST               20 (loss_fct)\n            206 LOAD_FAST               17 (logits)\n            208 LOAD_ATTR               11 (view)\n            210 LOAD_CONST               5 (-1)\n            212 LOAD_FAST                1 (self)\n            214 LOAD_ATTR                0 (config)\n            216 LOAD_ATTR               12 (vocab_size)\n            218 CALL_FUNCTION            2\n            220 LOAD_FAST               19 (shift_labels)\n            222 LOAD_ATTR               11 (view)\n            224 LOAD_CONST               5 (-1)\n            226 CALL_FUNCTION            1\n            228 CALL_FUNCTION            2\n            230 STORE_FAST              18 (loss)\n\n839     >>  232 LOAD_FAST                3 (return_dict)\n            234 POP_JUMP_IF_TRUE       138 (to 276)\n\n840         236 LOAD_FAST               17 (logits)\n            238 BUILD_TUPLE              1\n            240 LOAD_FAST               16 (outputs)\n            242 LOAD_CONST               4 (1)\n            244 LOAD_CONST               1 (None)\n            246 BUILD_SLICE              2\n            248 BINARY_SUBSCR\n            250 BINARY_ADD\n            252 STORE_FAST              21 (output)\n\n841         254 LOAD_FAST               18 (loss)\n            256 LOAD_CONST               1 (None)\n            258 IS_OP                    1\n            260 POP_JUMP_IF_FALSE      136 (to 272)\n            262 LOAD_FAST               18 (loss)\n            264 BUILD_TUPLE              1\n            266 LOAD_FAST               21 (output)\n            268 BINARY_ADD\n            270 RETURN_VALUE\n        >>  272 LOAD_FAST               21 (output)\n            274 RETURN_VALUE\n\n843     >>  276 LOAD_GLOBAL             13 (CausalLMOutputWithCrossAttentions)\n\n844         278 LOAD_FAST               18 (loss)\n\n845         280 LOAD_FAST               17 (logits)\n\n846         282 LOAD_FAST               16 (outputs)\n            284 LOAD_ATTR               14 (past_key_values)\n\n847         286 LOAD_FAST               16 (outputs)\n            288 LOAD_ATTR               15 (hidden_states)\n\n848         290 LOAD_FAST               16 (outputs)\n            292 LOAD_ATTR               16 (attentions)\n\n849         294 LOAD_FAST               16 (outputs)\n            296 LOAD_ATTR               17 (cross_attentions)\n\n843         298 LOAD_CONST               6 (('loss', 'logits', 'past_key_values', 'hidden_states', 'attentions', 'cross_attentions'))\n            300 CALL_FUNCTION_KW         6\n            302 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 557 \n557           0 LOAD_FAST                0 (___stack0)\n              2 CALL_FUNCTION            0\n              4 SETUP_WITH              10 (to 26)\n              6 POP_TOP\n              8 LOAD_FAST                1 (___stack1)\n             10 JUMP_ABSOLUTE           44 (to 88)\n             12 POP_BLOCK\n             14 LOAD_CONST               0 (None)\n             16 DUP_TOP\n             18 DUP_TOP\n             20 CALL_FUNCTION            3\n             22 POP_TOP\n             24 JUMP_FORWARD             8 (to 42)\n        >>   26 WITH_EXCEPT_START\n             28 POP_JUMP_IF_TRUE        16 (to 32)\n             30 RERAISE                  0\n        >>   32 POP_TOP\n             34 POP_TOP\n             36 POP_TOP\n             38 POP_EXCEPT\n             40 POP_TOP\n        >>   42 NOP\n             44 LOAD_CONST               0 (None)\n             46 RAISE_VARARGS            1\n             48 LOAD_GLOBAL              0 (clone_inputs)\n             50 LOAD_FAST                6 (inputs)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (cloned_inputs)\n             56 LOAD_FAST                2 (self)\n             58 LOAD_ATTR                1 (optimizer_zero_grad)\n             60 LOAD_FAST                3 (mod)\n             62 CALL_FUNCTION            1\n             64 POP_TOP\n             66 LOAD_FAST                2 (self)\n             68 LOAD_ATTR                2 (autocast)\n             70 CALL_FUNCTION            0\n             72 SETUP_WITH              20 (to 114)\n             74 POP_TOP\n             76 LOAD_FAST                3 (mod)\n             78 LOAD_CONST               1 (())\n             80 BUILD_MAP                0\n             82 LOAD_FAST                5 (cloned_inputs)\n             84 DICT_MERGE               1\n             86 CALL_FUNCTION_EX         1\n        >>   88 STORE_FAST               7 (pred)\n\n558          90 LOAD_FAST                2 (self)\n             92 LOAD_ATTR                3 (compute_loss)\n             94 LOAD_FAST                7 (pred)\n             96 CALL_FUNCTION            1\n             98 STORE_FAST               8 (loss)\n            100 POP_BLOCK\n\n556         102 LOAD_CONST               0 (None)\n            104 DUP_TOP\n            106 DUP_TOP\n            108 CALL_FUNCTION            3\n            110 POP_TOP\n            112 JUMP_FORWARD             8 (to 130)\n        >>  114 WITH_EXCEPT_START\n            116 POP_JUMP_IF_TRUE        60 (to 120)\n            118 RERAISE                  1\n        >>  120 POP_TOP\n            122 POP_TOP\n            124 POP_TOP\n            126 POP_EXCEPT\n            128 POP_TOP\n\n559     >>  130 LOAD_FAST                2 (self)\n            132 LOAD_ATTR                4 (grad_scaler)\n            134 LOAD_ATTR                5 (scale)\n            136 LOAD_FAST                8 (loss)\n            138 CALL_FUNCTION            1\n            140 LOAD_ATTR                6 (backward)\n            142 CALL_FUNCTION            0\n            144 POP_TOP\n\n560         146 LOAD_FAST                2 (self)\n            148 LOAD_ATTR                7 (optimizer_step)\n            150 CALL_FUNCTION            0\n            152 POP_TOP\n\n561         154 LOAD_FAST                4 (collect_outputs)\n            156 POP_JUMP_IF_FALSE       86 (to 172)\n\n562         158 LOAD_GLOBAL              8 (collect_results)\n            160 LOAD_FAST                3 (mod)\n            162 LOAD_FAST                7 (pred)\n            164 LOAD_FAST                8 (loss)\n            166 LOAD_FAST                5 (cloned_inputs)\n            168 CALL_FUNCTION            4\n            170 RETURN_VALUE\n\n563     >>  172 LOAD_CONST               0 (None)\n            174 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE forward_and_backward_pass /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 553 \n554           0 LOAD_GLOBAL              0 (clone_inputs)\n              2 LOAD_FAST                2 (inputs)\n              4 CALL_FUNCTION            1\n              6 STORE_FAST               4 (cloned_inputs)\n\n555           8 LOAD_FAST                0 (self)\n             10 LOAD_METHOD              1 (optimizer_zero_grad)\n             12 LOAD_FAST                1 (mod)\n             14 CALL_METHOD              1\n             16 POP_TOP\n\n556          18 LOAD_FAST                0 (self)\n             20 LOAD_METHOD              2 (autocast)\n             22 CALL_METHOD              0\n             24 SETUP_WITH              20 (to 66)\n             26 POP_TOP\n\n557          28 LOAD_FAST                1 (mod)\n             30 LOAD_CONST               1 (())\n             32 BUILD_MAP                0\n             34 LOAD_FAST                4 (cloned_inputs)\n             36 DICT_MERGE               1\n             38 CALL_FUNCTION_EX         1\n             40 STORE_FAST               5 (pred)\n\n558          42 LOAD_FAST                0 (self)\n             44 LOAD_METHOD              3 (compute_loss)\n             46 LOAD_FAST                5 (pred)\n             48 CALL_METHOD              1\n             50 STORE_FAST               6 (loss)\n             52 POP_BLOCK\n\n556          54 LOAD_CONST               0 (None)\n             56 DUP_TOP\n             58 DUP_TOP\n             60 CALL_FUNCTION            3\n             62 POP_TOP\n             64 JUMP_FORWARD             8 (to 82)\n        >>   66 WITH_EXCEPT_START\n             68 POP_JUMP_IF_TRUE        36 (to 72)\n             70 RERAISE                  1\n        >>   72 POP_TOP\n             74 POP_TOP\n             76 POP_TOP\n             78 POP_EXCEPT\n             80 POP_TOP\n\n559     >>   82 LOAD_FAST                0 (self)\n             84 LOAD_ATTR                4 (grad_scaler)\n             86 LOAD_METHOD              5 (scale)\n             88 LOAD_FAST                6 (loss)\n             90 CALL_METHOD              1\n             92 LOAD_METHOD              6 (backward)\n             94 CALL_METHOD              0\n             96 POP_TOP\n\n560          98 LOAD_FAST                0 (self)\n            100 LOAD_METHOD              7 (optimizer_step)\n            102 CALL_METHOD              0\n            104 POP_TOP\n\n561         106 LOAD_FAST                3 (collect_outputs)\n            108 POP_JUMP_IF_FALSE       62 (to 124)\n\n562         110 LOAD_GLOBAL              8 (collect_results)\n            112 LOAD_FAST                1 (mod)\n            114 LOAD_FAST                5 (pred)\n            116 LOAD_FAST                6 (loss)\n            118 LOAD_FAST                4 (cloned_inputs)\n            120 CALL_FUNCTION            4\n            122 RETURN_VALUE\n\n563     >>  124 LOAD_CONST               0 (None)\n            126 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 554 \n554           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE            5 (to 10)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                4 (inputs)\n              8 CALL_FUNCTION            1\n        >>   10 STORE_FAST               5 (cloned_inputs)\n\n555          12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                5 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                5 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE optimizer_zero_grad /workspace/youkaichao/code/pytorch/benchmarks/dynamo/common.py line 1875 \n1876           0 LOAD_FAST                0 (self)\n               2 LOAD_ATTR                0 (optimizer)\n               4 LOAD_CONST               0 (None)\n               6 IS_OP                    1\n               8 POP_JUMP_IF_FALSE       13 (to 26)\n\n1877          10 LOAD_FAST                0 (self)\n              12 LOAD_ATTR                0 (optimizer)\n              14 LOAD_METHOD              1 (zero_grad)\n              16 LOAD_CONST               1 (True)\n              18 CALL_METHOD              1\n              20 POP_TOP\n              22 LOAD_CONST               0 (None)\n              24 RETURN_VALUE\n\n1879     >>   26 LOAD_FAST                1 (mod)\n              28 LOAD_METHOD              1 (zero_grad)\n              30 LOAD_CONST               1 (True)\n              32 CALL_METHOD              1\n              34 POP_TOP\n              36 LOAD_CONST               0 (None)\n              38 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 555 \n555           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           10 (to 20)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                5 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n        >>   20 POP_TOP\n\n556          22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n\n557          32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               6 (pred)\n\n558          46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                6 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               7 (loss)\n             56 POP_BLOCK\n\n556          58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n\n559     >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                7 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                6 (pred)\n            120 LOAD_FAST                7 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 559 \n559           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           50 (to 100)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               4 (cloned_inputs)\n             12 LOAD_FAST                1 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                2 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                1 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                2 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                4 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               5 (pred)\n             46 LOAD_FAST                1 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                5 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               6 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                1 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                6 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n        >>  100 POP_TOP\n\n560         102 LOAD_FAST                1 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n            108 POP_TOP\n\n561         110 LOAD_FAST                3 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                2 (mod)\n            118 LOAD_FAST                5 (pred)\n            120 LOAD_FAST                6 (loss)\n            122 LOAD_FAST                4 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n", "ORIGINAL BYTECODE sgd /workspace/youkaichao/code/pytorch/torch/optim/sgd.py line 185 \n204           0 LOAD_FAST                4 (foreach)\n              2 LOAD_CONST               1 (None)\n              4 IS_OP                    0\n              6 POP_JUMP_IF_FALSE       21 (to 42)\n\n207           8 LOAD_GLOBAL              0 (torch)\n             10 LOAD_ATTR                1 (jit)\n             12 LOAD_METHOD              2 (is_scripting)\n             14 CALL_METHOD              0\n             16 POP_JUMP_IF_TRUE        19 (to 38)\n\n208          18 LOAD_GLOBAL              3 (_default_to_fused_or_foreach)\n             20 LOAD_FAST                0 (params)\n             22 LOAD_CONST               2 (False)\n             24 LOAD_CONST               2 (False)\n             26 LOAD_CONST               3 (('differentiable', 'use_fused'))\n             28 CALL_FUNCTION_KW         3\n             30 UNPACK_SEQUENCE          2\n             32 STORE_FAST              11 (_)\n             34 STORE_FAST               4 (foreach)\n             36 JUMP_FORWARD             2 (to 42)\n\n210     >>   38 LOAD_CONST               2 (False)\n             40 STORE_FAST               4 (foreach)\n\n212     >>   42 LOAD_FAST                4 (foreach)\n             44 POP_JUMP_IF_FALSE       32 (to 64)\n             46 LOAD_GLOBAL              0 (torch)\n             48 LOAD_ATTR                1 (jit)\n             50 LOAD_METHOD              2 (is_scripting)\n             52 CALL_METHOD              0\n             54 POP_JUMP_IF_FALSE       32 (to 64)\n\n213          56 LOAD_GLOBAL              4 (RuntimeError)\n             58 LOAD_CONST               4 ('torch.jit.script not supported with foreach optimizers')\n             60 CALL_FUNCTION            1\n             62 RAISE_VARARGS            1\n\n215     >>   64 LOAD_FAST                4 (foreach)\n             66 POP_JUMP_IF_FALSE       42 (to 84)\n             68 LOAD_GLOBAL              0 (torch)\n             70 LOAD_ATTR                1 (jit)\n             72 LOAD_METHOD              2 (is_scripting)\n             74 CALL_METHOD              0\n             76 POP_JUMP_IF_TRUE        42 (to 84)\n\n216          78 LOAD_GLOBAL              5 (_multi_tensor_sgd)\n             80 STORE_FAST              12 (func)\n             82 JUMP_FORWARD             2 (to 88)\n\n218     >>   84 LOAD_GLOBAL              6 (_single_tensor_sgd)\n             86 STORE_FAST              12 (func)\n\n220     >>   88 LOAD_FAST               12 (func)\n             90 LOAD_FAST                0 (params)\n\n221          92 LOAD_FAST                1 (d_p_list)\n\n222          94 LOAD_FAST                2 (momentum_buffer_list)\n\n223          96 LOAD_FAST                5 (weight_decay)\n\n224          98 LOAD_FAST                6 (momentum)\n\n225         100 LOAD_FAST                7 (lr)\n\n226         102 LOAD_FAST                8 (dampening)\n\n227         104 LOAD_FAST                9 (nesterov)\n\n228         106 LOAD_FAST                3 (has_sparse_grad)\n\n229         108 LOAD_FAST               10 (maximize)\n\n220         110 LOAD_CONST               5 (('weight_decay', 'momentum', 'lr', 'dampening', 'nesterov', 'has_sparse_grad', 'maximize'))\n            112 CALL_FUNCTION_KW        10\n            114 POP_TOP\n            116 LOAD_CONST               1 (None)\n            118 RETURN_VALUE\n\n", "ORIGINAL BYTECODE <resume in forward_and_backward_pass> /workspace/youkaichao/code/pytorch/./benchmarks/dynamo/huggingface.py line 560 \n560           0 LOAD_FAST                0 (___stack0)\n              2 JUMP_ABSOLUTE           54 (to 108)\n              4 LOAD_GLOBAL              0 (clone_inputs)\n              6 LOAD_FAST                7 (inputs)\n              8 CALL_FUNCTION            1\n             10 STORE_FAST               3 (cloned_inputs)\n             12 LOAD_FAST                6 (self)\n             14 LOAD_ATTR                1 (optimizer_zero_grad)\n             16 LOAD_FAST                1 (mod)\n             18 CALL_FUNCTION            1\n             20 POP_TOP\n             22 LOAD_FAST                6 (self)\n             24 LOAD_ATTR                2 (autocast)\n             26 CALL_FUNCTION            0\n             28 SETUP_WITH              20 (to 70)\n             30 POP_TOP\n             32 LOAD_FAST                1 (mod)\n             34 LOAD_CONST               1 (())\n             36 BUILD_MAP                0\n             38 LOAD_FAST                3 (cloned_inputs)\n             40 DICT_MERGE               1\n             42 CALL_FUNCTION_EX         1\n             44 STORE_FAST               4 (pred)\n             46 LOAD_FAST                6 (self)\n             48 LOAD_ATTR                3 (compute_loss)\n             50 LOAD_FAST                4 (pred)\n             52 CALL_FUNCTION            1\n             54 STORE_FAST               5 (loss)\n             56 POP_BLOCK\n             58 LOAD_CONST               0 (None)\n             60 DUP_TOP\n             62 DUP_TOP\n             64 CALL_FUNCTION            3\n             66 POP_TOP\n             68 JUMP_FORWARD             8 (to 86)\n        >>   70 WITH_EXCEPT_START\n             72 POP_JUMP_IF_TRUE        38 (to 76)\n             74 RERAISE                  1\n        >>   76 POP_TOP\n             78 POP_TOP\n             80 POP_TOP\n             82 POP_EXCEPT\n             84 POP_TOP\n        >>   86 LOAD_FAST                6 (self)\n             88 LOAD_ATTR                4 (grad_scaler)\n             90 LOAD_ATTR                5 (scale)\n             92 LOAD_FAST                5 (loss)\n             94 CALL_FUNCTION            1\n             96 LOAD_ATTR                6 (backward)\n             98 CALL_FUNCTION            0\n            100 POP_TOP\n            102 LOAD_FAST                6 (self)\n            104 LOAD_ATTR                7 (optimizer_step)\n            106 CALL_FUNCTION            0\n        >>  108 POP_TOP\n\n561         110 LOAD_FAST                2 (collect_outputs)\n            112 POP_JUMP_IF_FALSE       64 (to 128)\n\n562         114 LOAD_GLOBAL              8 (collect_results)\n            116 LOAD_FAST                1 (mod)\n            118 LOAD_FAST                4 (pred)\n            120 LOAD_FAST                5 (loss)\n            122 LOAD_FAST                3 (cloned_inputs)\n            124 CALL_FUNCTION            4\n            126 RETURN_VALUE\n\n563     >>  128 LOAD_CONST               0 (None)\n            130 RETURN_VALUE\n\n"]