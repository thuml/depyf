# :snake: depyf: decompile python functions, from bytecode to source code!

This is used primarily to understand the bytecode produced by PyTorch 2.0 Dynamo (PT 2.0 compiler stack).

# Installation

`pip install git+https://github.com/youkaichao/depyf.git`

# Usage

## Simple Usage:

```python
# obtain a callable object or codeobject
def func():
    print("hello, world!")
# import the `decompile` function
from depyf import decompile
# and decompile it into source code!
print(decompile(func))
```

Example output:

```text
def func():
    __temp_1 = print('hello, world!')
    return None
```

The output source code is semantically equivalent to the function, but not syntactically the same. It verbosely adds many details that are hidden in the python code. For example, the above output code explicitly stores the return value of `print`, which is typically ignored.

## Used to understand PyTorch generated bytecode

First, run a pytorch program with `torch.compile`:

```python
from typing import List
import torch
from torch import _dynamo as torchdynamo
def my_compiler(gm: torch.fx.GraphModule, example_inputs: List[torch.Tensor]):
    print("my_compiler() called with FX graph:")
    gm.graph.print_tabular()
    return gm.forward  # return a python callable

@torchdynamo.optimize(my_compiler)
def toy_example(a, b):
    x = a / (torch.abs(a) + 1)
    if b.sum() < 0:
        b = b * -1
    return x * b
for _ in range(100):
    toy_example(torch.randn(10), torch.randn(10))
```

Second, get compiled code and guard code from pytorch:

```python
from torch._dynamo.eval_frame import _debug_get_cache_entry_list
cache_entries = _debug_get_cache_entry_list(toy_example._torchdynamo_orig_callable.__code__)
guard, code = cache_entries[0]
```

Third, decompile the code to see how the code works:

```python
from depyf import decompile

print("guard code:")
print(decompile(guard))

print("compiled code:")
print(decompile(code))
```

Output on my computer:

```text
guard code:
def guard(L):
    if not getattr(___guarded_code, 'valid'):
        return False
    else:
        _var0 = L['a']
        __temp_1 = hasattr(_var0, '_dynamo_dynamic_indices')
        if not (__temp_1 == False):
            return False
        else:
            _var1 = L['b']
            __temp_2 = hasattr(_var1, '_dynamo_dynamic_indices')
            if not (__temp_2 == False):
                return False
            else:
                __temp_3 = ___is_grad_enabled()
                if not __temp_3:
                    return False
                else:
                    __temp_4 = ___are_deterministic_algorithms_enabled()
                    if __temp_4:
                        return False
                    else:
                        __temp_5 = ___is_torch_function_enabled()
                        if not __temp_5:
                            return False
                        else:
                            if not (getattr(utils_device, 'CURRENT_DEVICE') == None):
                                return False
                            else:
                                __temp_6 = ___check_tensors(_var0, _var1, tensor_check_names=tensor_check_names)
                                if not __temp_6:
                                    return False
                                else:
                                    return True

compiled code:
def toy_example(a, b):
    __temp_1 = __compiled_fn_0(a, b)
    x = __temp_1[0]
    if __temp_1[1]:
        __temp_2 = __resume_at_30_1(b, x)
        return __temp_2
    else:
        __temp_3 = __resume_at_38_2(b, x)
        return __temp_3
```

Hopefully, by using this package, you can understand python bytecode now!

:warning: The above example should be run using pytorch nightly. Some debug functions like `_debug_get_cache_entry_list` might not exist in stable releases yet.

# Python Version Coverage

The following python major versions are tested:

- Python 3.10

You can see the coverage report by simply running `python python_coverage.py`.

# Full Python Syntax Is Not Supported

This package is intended to understand the generated pytorch bytecode, and does not aim to fully cover all the syntax of python. For example, async operations like `async/await` is not supported.

Support for very complicated control flow (while-loop/for-loop) is limited.

# Contributions are welcome!

If you find any error in the decompilation, feel free to open issues or pull requests to fix it!

# How it works

The code first analyzes the bytecode to discover basic code blocks (blocks that do not have control flow). Then it builds a control flow graph, and decompile bytecode into source code by traversing the graph.
