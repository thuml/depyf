{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c033961d-e588-4913-930c-a467f746985b",
   "metadata": {},
   "source": [
    "# Explain what does PyTorch 2.0 do to your code\n",
    "\n",
    "PyTorch 2.0 looks like magic to many researchers, as they dynamically translate the bytecode for you. Many people don't know Python bytecode, so they don't know how do the translated code look like. Fortunately, with `depyf`, we can clearly illustrate it for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66dc808-699f-4db6-be39-103a504103b4",
   "metadata": {},
   "source": [
    "# Run some code with `torch.compile`, and use `eager` backend\n",
    "\n",
    "Note that we use `eager` backend so that the compiled subgraph runs in eager mode, and then we can easily get its code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60a95337-ef1a-40be-9d8b-2ba1a5e7cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "@torch.compile(backend=\"eager\")\n",
    "def toy_example(a, b):\n",
    "    x = a / (torch.abs(a) + 1)\n",
    "    if b.sum() < 0:\n",
    "        b = b * -1\n",
    "    return x * b\n",
    "\n",
    "for _ in range(100):\n",
    "    toy_example(torch.randn(10), torch.randn(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aedd01-78ba-4393-8b26-79a9ba210796",
   "metadata": {},
   "source": [
    "# Interactively explore everything you are curious about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd1080f-6852-43d4-972a-0aa26fb0e1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# transformed source code:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "compiled_code_entries": [
        {
         "compiled_code": "compiled_code_0",
         "compiled_subgraph": "__compiled_fn_0",
         "guard": [
          "___guarded_code.valid",
          "___check_global_state()",
          "hasattr(L['a'], '_dynamo_dynamic_indices') == False",
          "hasattr(L['b'], '_dynamo_dynamic_indices') == False",
          "utils_device.CURRENT_DEVICE == None",
          "___skip_backend_check() or ___current_backend() == ___lookup_backend(4845050256)",
          "___check_tensors(L['a'], L['b'], tensor_check_names=tensor_check_names)"
         ],
         "referenced_global_functions": {
          "__resume_at_30_1": {
           "compiled_code_entries": [
            {
             "compiled_code": "compiled_code_1",
             "compiled_subgraph": "__compiled_fn_3",
             "guard": [
              "___guarded_code.valid",
              "___check_global_state()",
              "hasattr(L['b'], '_dynamo_dynamic_indices') == False",
              "hasattr(L['x'], '_dynamo_dynamic_indices') == False",
              "utils_device.CURRENT_DEVICE == None",
              "___skip_backend_check() or ___current_backend() == ___lookup_backend(4845050256)",
              "___check_tensors(L['b'], L['x'], tensor_check_names=tensor_check_names)"
             ],
             "referenced_global_functions": {}
            }
           ],
           "name": "__resume_at_30_1",
           "source_code": "__resume_at_30_1"
          },
          "__resume_at_38_2": {
           "compiled_code_entries": [
            {
             "compiled_code": "compiled_code_2",
             "compiled_subgraph": "__compiled_fn_4",
             "guard": [
              "___guarded_code.valid",
              "___check_global_state()",
              "hasattr(L['b'], '_dynamo_dynamic_indices') == False",
              "hasattr(L['x'], '_dynamo_dynamic_indices') == False",
              "utils_device.CURRENT_DEVICE == None",
              "___skip_backend_check() or ___current_backend() == ___lookup_backend(4845050256)",
              "___check_tensors(L['b'], L['x'], tensor_check_names=tensor_check_names)"
             ],
             "referenced_global_functions": {}
            }
           ],
           "name": "__resume_at_38_2",
           "source_code": "__resume_at_38_2"
          }
         }
        }
       ],
       "name": "toy_example",
       "source_code": "toy_example"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# source code of referenced function:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<details>\n",
       "  <summary>toy_example</summary>\n",
       "\n",
       "  ```python\n",
       "  def toy_example(a, b):\n",
       "      x = a / (torch.abs(a) + 1)\n",
       "      if b.sum() < 0:\n",
       "          b = b * -1\n",
       "      return x * b\n",
       "\n",
       "  ```\n",
       "</details>\n",
       "<details>\n",
       "  <summary>__compiled_fn_0</summary>\n",
       "\n",
       "  ```python\n",
       "  def forward(self, L_a_ : torch.Tensor, L_b_ : torch.Tensor):\n",
       "      l_a_ = L_a_\n",
       "      l_b_ = L_b_\n",
       "      abs_1 = torch.abs(l_a_)\n",
       "      add = abs_1 + 1;  abs_1 = None\n",
       "      x = l_a_ / add;  l_a_ = add = None\n",
       "      sum_1 = l_b_.sum();  l_b_ = None\n",
       "      lt = sum_1 < 0;  sum_1 = None\n",
       "      return (x, lt)\n",
       "\n",
       "  ```\n",
       "</details>\n",
       "<details>\n",
       "  <summary>__resume_at_30_1</summary>\n",
       "\n",
       "  ```python\n",
       "  def __resume_at_30_1(b, x):\n",
       "      b = b * -1\n",
       "      return x * b\n",
       "\n",
       "  ```\n",
       "</details>\n",
       "<details>\n",
       "  <summary>__compiled_fn_4</summary>\n",
       "\n",
       "  ```python\n",
       "  def forward(self, L_b_ : torch.Tensor, L_x_ : torch.Tensor):\n",
       "      l_b_ = L_b_\n",
       "      l_x_ = L_x_\n",
       "      mul = l_x_ * l_b_;  l_x_ = l_b_ = None\n",
       "      return (mul,)\n",
       "\n",
       "  ```\n",
       "</details>\n",
       "<details>\n",
       "  <summary>__compiled_fn_3</summary>\n",
       "\n",
       "  ```python\n",
       "  def forward(self, L_b_ : torch.Tensor, L_x_ : torch.Tensor):\n",
       "      l_b_ = L_b_\n",
       "      l_x_ = L_x_\n",
       "      b = l_b_ * -1;  l_b_ = None\n",
       "      mul_1 = l_x_ * b;  l_x_ = b = None\n",
       "      return (mul_1,)\n",
       "\n",
       "  ```\n",
       "</details>\n",
       "<details>\n",
       "  <summary>__resume_at_38_2</summary>\n",
       "\n",
       "  ```python\n",
       "  def __resume_at_38_2(b, x):\n",
       "      return x * b\n",
       "\n",
       "  ```\n",
       "</details>\n",
       "<details>\n",
       "  <summary>compiled_code_0</summary>\n",
       "\n",
       "  ```python\n",
       "  def toy_example(a, b):\n",
       "      __temp_1 = __compiled_fn_0(a, b)\n",
       "      x = __temp_1[0]\n",
       "      if __temp_1[1]:\n",
       "          return __resume_at_30_1(b, x)\n",
       "      return __resume_at_38_2(b, x)\n",
       "\n",
       "  ```\n",
       "</details>\n",
       "<details>\n",
       "  <summary>compiled_code_2</summary>\n",
       "\n",
       "  ```python\n",
       "  def <resume in toy_example>(b, x):\n",
       "      return __compiled_fn_4(b, x)[0]\n",
       "\n",
       "  ```\n",
       "</details>\n",
       "<details>\n",
       "  <summary>compiled_code_1</summary>\n",
       "\n",
       "  ```python\n",
       "  def <resume in toy_example>(b, x):\n",
       "      return __compiled_fn_3(b, x)[0]\n",
       "\n",
       "  ```\n",
       "</details>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from depyf.explain import interactive_explain\n",
    "interactive_explain(toy_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e38342e-b772-4675-84cd-0846fe1dd948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
